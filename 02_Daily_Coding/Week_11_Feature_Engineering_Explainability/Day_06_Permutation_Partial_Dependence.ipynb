{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a03b2e57",
   "metadata": {},
   "source": [
    "# Day 6: Permutation Importance & Partial Dependence\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand permutation importance vs built-in importance\n",
    "- Create Partial Dependence Plots (PDPs)\n",
    "- Individual Conditional Expectation (ICE) plots\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance, partial_dependence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Libraries loaded!\")\n",
    "print(\"ğŸ“š Day 6: Permutation Importance & Partial Dependence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARE DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"PREPARING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_days = 1500\n",
    "\n",
    "returns = np.random.normal(0.0002, 0.015, n_days)\n",
    "for i in range(1, len(returns)):\n",
    "    returns[i] += 0.05 * returns[i-1]\n",
    "\n",
    "prices = 100 * np.cumprod(1 + returns)\n",
    "df = pd.DataFrame({'price': prices, 'returns': returns})\n",
    "\n",
    "# Features\n",
    "df['ret_5d'] = df['price'].pct_change(5)\n",
    "df['ret_20d'] = df['price'].pct_change(20)\n",
    "df['vol_5d'] = df['returns'].rolling(5).std()\n",
    "df['vol_20d'] = df['returns'].rolling(20).std()\n",
    "df['mom_5d'] = df['returns'].rolling(5).sum()\n",
    "df['mom_20d'] = df['returns'].rolling(20).sum()\n",
    "\n",
    "gains = df['returns'].where(df['returns'] > 0, 0).rolling(14).mean()\n",
    "losses = (-df['returns'].where(df['returns'] < 0, 0)).rolling(14).mean()\n",
    "df['rsi'] = 100 - (100 / (1 + gains / (losses + 1e-10)))\n",
    "\n",
    "df['vol_ratio'] = df['vol_5d'] / df['vol_20d']\n",
    "\n",
    "df['target'] = (df['returns'].shift(-1) > 0).astype(int)\n",
    "df = df.dropna()\n",
    "\n",
    "feature_cols = ['ret_5d', 'ret_20d', 'vol_5d', 'vol_20d', 'mom_5d', 'mom_20d', 'rsi', 'vol_ratio']\n",
    "X = df[feature_cols].values\n",
    "y = df['target'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "split = int(len(X) * 0.7)\n",
    "X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6235d3",
   "metadata": {},
   "source": [
    "## Part 1: Permutation Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN MODEL & PERMUTATION IMPORTANCE\n",
    "# ============================================================\n",
    "\n",
    "print(\"PERMUTATION IMPORTANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Test accuracy: {model.score(X_test, y_test):.3f}\")\n",
    "\n",
    "# Built-in importance\n",
    "builtin_imp = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Permutation importance (on test set)\n",
    "perm_imp = permutation_importance(model, X_test, y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': perm_imp.importances_mean,\n",
    "    'std': perm_imp.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nBuilt-in Importance:\")\n",
    "print(builtin_imp.head(5).to_string(index=False))\n",
    "\n",
    "print(\"\\nPermutation Importance (test set):\")\n",
    "print(perm_df.head(5).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466c951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPARE IMPORTANCE METHODS\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "builtin_imp.plot(x='feature', y='importance', kind='barh', ax=axes[0],\n",
    "                 color='steelblue', alpha=0.7, legend=False)\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Built-in (Gini) Importance', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "perm_df.plot(x='feature', y='importance', kind='barh', ax=axes[1],\n",
    "             xerr=perm_df['std'], color='coral', alpha=0.7, legend=False)\n",
    "axes[1].set_xlabel('Mean Accuracy Decrease')\n",
    "axes[1].set_title('Permutation Importance (with std)', fontweight='bold')\n",
    "axes[1].axvline(0, color='gray', linestyle='--')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ KEY INSIGHT: Permutation importance is more reliable because:\")\n",
    "print(\"   - It measures actual model performance drop\")\n",
    "print(\"   - It's computed on test data (no training bias)\")\n",
    "print(\"   - Built-in importance can be biased toward high-cardinality features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d2ad84",
   "metadata": {},
   "source": [
    "## Part 2: Partial Dependence Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba19fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PARTIAL DEPENDENCE PLOTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"PARTIAL DEPENDENCE PLOTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def plot_partial_dependence(model, X, feature_idx, feature_name, ax, n_points=50):\n",
    "    \"\"\"\n",
    "    Create a partial dependence plot.\n",
    "    \n",
    "    PDP shows the marginal effect of a feature on the prediction:\n",
    "    Average prediction as we vary one feature, keeping others at their actual values.\n",
    "    \"\"\"\n",
    "    # Get range for feature\n",
    "    feat_vals = np.linspace(X[:, feature_idx].min(), X[:, feature_idx].max(), n_points)\n",
    "    \n",
    "    # Calculate PD\n",
    "    pdp_values = []\n",
    "    for val in feat_vals:\n",
    "        X_temp = X.copy()\n",
    "        X_temp[:, feature_idx] = val\n",
    "        avg_pred = model.predict_proba(X_temp)[:, 1].mean()\n",
    "        pdp_values.append(avg_pred)\n",
    "    \n",
    "    ax.plot(feat_vals, pdp_values, color='steelblue', linewidth=2)\n",
    "    ax.set_xlabel(feature_name)\n",
    "    ax.set_ylabel('Partial Dependence')\n",
    "    ax.set_title(f'PDP: {feature_name}', fontweight='bold')\n",
    "    ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add feature histogram\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.hist(X[:, feature_idx], bins=30, alpha=0.2, color='gray')\n",
    "    ax2.set_ylabel('Frequency', color='gray')\n",
    "    ax2.tick_params(axis='y', labelcolor='gray')\n",
    "\n",
    "# Plot PDPs for top features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "top_features = perm_df.head(4)['feature'].tolist()\n",
    "for ax, feat in zip(axes.flat, top_features):\n",
    "    feat_idx = feature_cols.index(feat)\n",
    "    plot_partial_dependence(model, X_test, feat_idx, feat, ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c928ae8",
   "metadata": {},
   "source": [
    "## Part 3: ICE Plots (Individual Conditional Expectation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00445389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ICE PLOTS\n",
    "# ============================================================\n",
    "\n",
    "print(\"ICE PLOTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def plot_ice(model, X, feature_idx, feature_name, ax, n_samples=50, n_points=50):\n",
    "    \"\"\"\n",
    "    Create an ICE plot with centered lines.\n",
    "    \n",
    "    ICE shows individual prediction trajectories as we vary a feature.\n",
    "    It reveals heterogeneous effects that PDP averages over.\n",
    "    \"\"\"\n",
    "    feat_vals = np.linspace(X[:, feature_idx].min(), X[:, feature_idx].max(), n_points)\n",
    "    \n",
    "    # Random subset of samples\n",
    "    sample_idx = np.random.choice(len(X), min(n_samples, len(X)), replace=False)\n",
    "    \n",
    "    ice_curves = []\n",
    "    for i in sample_idx:\n",
    "        curve = []\n",
    "        for val in feat_vals:\n",
    "            X_temp = X[i:i+1].copy()\n",
    "            X_temp[0, feature_idx] = val\n",
    "            pred = model.predict_proba(X_temp)[0, 1]\n",
    "            curve.append(pred)\n",
    "        ice_curves.append(curve)\n",
    "    \n",
    "    ice_curves = np.array(ice_curves)\n",
    "    \n",
    "    # Plot individual curves\n",
    "    for curve in ice_curves:\n",
    "        ax.plot(feat_vals, curve, color='steelblue', alpha=0.1, linewidth=0.5)\n",
    "    \n",
    "    # Plot mean (PDP)\n",
    "    ax.plot(feat_vals, ice_curves.mean(axis=0), color='red', linewidth=2, label='Mean (PDP)')\n",
    "    \n",
    "    ax.set_xlabel(feature_name)\n",
    "    ax.set_ylabel('Prediction Probability')\n",
    "    ax.set_title(f'ICE Plot: {feature_name}', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot ICE for top features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for ax, feat in zip(axes.flat, top_features):\n",
    "    feat_idx = feature_cols.index(feat)\n",
    "    plot_ice(model, X_test, feat_idx, feat, ax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ICE reveals heterogeneous effects:\")\n",
    "print(\"   - If lines are parallel: homogeneous effect (PDP is representative)\")\n",
    "print(\"   - If lines cross: interaction effects exist (PDP may be misleading)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77797ba",
   "metadata": {},
   "source": [
    "## Part 4: 2D Partial Dependence (Interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63943fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2D PARTIAL DEPENDENCE\n",
    "# ============================================================\n",
    "\n",
    "print(\"2D PARTIAL DEPENDENCE (INTERACTIONS)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def plot_2d_pdp(model, X, feat_idx1, feat_idx2, feat_name1, feat_name2, ax, n_points=20):\n",
    "    \"\"\"Create 2D PDP to show feature interactions.\"\"\"\n",
    "    \n",
    "    vals1 = np.linspace(X[:, feat_idx1].min(), X[:, feat_idx1].max(), n_points)\n",
    "    vals2 = np.linspace(X[:, feat_idx2].min(), X[:, feat_idx2].max(), n_points)\n",
    "    \n",
    "    pdp_2d = np.zeros((n_points, n_points))\n",
    "    \n",
    "    for i, v1 in enumerate(vals1):\n",
    "        for j, v2 in enumerate(vals2):\n",
    "            X_temp = X.copy()\n",
    "            X_temp[:, feat_idx1] = v1\n",
    "            X_temp[:, feat_idx2] = v2\n",
    "            pdp_2d[i, j] = model.predict_proba(X_temp)[:, 1].mean()\n",
    "    \n",
    "    im = ax.contourf(vals2, vals1, pdp_2d, levels=20, cmap='RdYlBu_r')\n",
    "    ax.set_xlabel(feat_name2)\n",
    "    ax.set_ylabel(feat_name1)\n",
    "    ax.set_title(f'2D PDP: {feat_name1} vs {feat_name2}', fontweight='bold')\n",
    "    plt.colorbar(im, ax=ax)\n",
    "\n",
    "# Plot 2D PDP for feature pairs\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# vol_5d vs mom_5d\n",
    "idx1 = feature_cols.index('vol_5d')\n",
    "idx2 = feature_cols.index('mom_5d')\n",
    "plot_2d_pdp(model, X_test, idx1, idx2, 'vol_5d', 'mom_5d', axes[0])\n",
    "\n",
    "# rsi vs ret_5d\n",
    "idx1 = feature_cols.index('rsi')\n",
    "idx2 = feature_cols.index('ret_5d')\n",
    "plot_2d_pdp(model, X_test, idx1, idx2, 'rsi', 'ret_5d', axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘      DAY 6 COMPLETE: PERMUTATION & PARTIAL DEPENDENCE            â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  âœ“ Permutation importance (model-agnostic)                      â•‘\n",
    "â•‘  âœ“ Comparison with built-in importance                          â•‘\n",
    "â•‘  âœ“ Partial Dependence Plots (PDPs)                              â•‘\n",
    "â•‘  âœ“ ICE plots for heterogeneous effects                          â•‘\n",
    "â•‘  âœ“ 2D PDPs for feature interactions                             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Tomorrow: Day 7 - Complete Interpretable Pipeline\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
