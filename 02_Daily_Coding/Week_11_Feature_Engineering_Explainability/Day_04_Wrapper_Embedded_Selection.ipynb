{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7547dbbc",
   "metadata": {},
   "source": [
    "# Day 4: Wrapper & Embedded Selection\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement Recursive Feature Elimination (RFE)\n",
    "- Use tree-based feature importance\n",
    "- L1 regularization for feature selection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "450be143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded!\n",
      "ğŸ“š Day 4: Wrapper & Embedded Selection\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Libraries loaded!\")\n",
    "print(\"ğŸ“š Day 4: Wrapper & Embedded Selection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa01968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING FEATURE SET\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 18)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 41\u001b[39m\n\u001b[32m     38\u001b[39m y = df[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m     40\u001b[39m scaler = StandardScaler()\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m X_scaled = \u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m split = \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X) * \u001b[32m0.7\u001b[39m)\n\u001b[32m     44\u001b[39m X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/sklearn/utils/_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/sklearn/base.py:907\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    892\u001b[39m         warnings.warn(\n\u001b[32m    893\u001b[39m             (\n\u001b[32m    894\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    902\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    903\u001b[39m         )\n\u001b[32m    905\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    906\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m907\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    908\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    909\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/sklearn/preprocessing/_data.py:924\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    922\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    923\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/sklearn/base.py:1336\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1329\u001b[39m     estimator._validate_params()\n\u001b[32m   1331\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1332\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1333\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1334\u001b[39m     )\n\u001b[32m   1335\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1336\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/sklearn/preprocessing/_data.py:961\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    959\u001b[39m xp, _, X_device = get_namespace_and_device(X)\n\u001b[32m    960\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43msupported_float_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    969\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/sklearn/utils/validation.py:2902\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2900\u001b[39m         out = X, y\n\u001b[32m   2901\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2902\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2903\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2904\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/sklearn/utils/validation.py:1097\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1095\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1096\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1097\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1098\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1099\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1100\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1101\u001b[39m         )\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1104\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 18)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# BUILD FEATURE SET\n",
    "# ============================================================\n",
    "\n",
    "print(\"BUILDING FEATURE SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_days = 1500\n",
    "\n",
    "returns = np.random.normal(0.0002, 0.015, n_days)\n",
    "for i in range(1, len(returns)):\n",
    "    returns[i] += 0.05 * returns[i-1]\n",
    "\n",
    "prices = 100 * np.cumprod(1 + returns)\n",
    "df = pd.DataFrame({'price': prices, 'returns': returns})\n",
    "\n",
    "# Create features\n",
    "for h in [1, 5, 10, 20, 60]:\n",
    "    df[f'ret_{h}d'] = df['price'].pct_change(h)\n",
    "    df[f'vol_{h}d'] = df['returns'].rolling(h).std()\n",
    "    df[f'mom_{h}d'] = df['returns'].rolling(h).sum()\n",
    "\n",
    "# Technical\n",
    "gains = df['returns'].where(df['returns'] > 0, 0).rolling(14).mean()\n",
    "losses = (-df['returns'].where(df['returns'] < 0, 0)).rolling(14).mean()\n",
    "df['rsi'] = 100 - (100 / (1 + gains / (losses + 1e-10)))\n",
    "\n",
    "df['ma_ratio'] = df['price'].rolling(5).mean() / df['price'].rolling(20).mean()\n",
    "df['vol_ratio'] = df['vol_5d'] / df['vol_20d']\n",
    "\n",
    "# Target\n",
    "df['target'] = (df['returns'].shift(-1) > 0).astype(int)\n",
    "df = df.dropna()\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in ['price', 'returns', 'target']]\n",
    "X = df[feature_cols].values\n",
    "y = df['target'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "split = int(len(X) * 0.7)\n",
    "X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f02ec64",
   "metadata": {},
   "source": [
    "## Part 1: Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdac23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RECURSIVE FEATURE ELIMINATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"RECURSIVE FEATURE ELIMINATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# RFE with Random Forest\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rfe = RFE(rf, n_features_to_select=8, step=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "rfe_ranking = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'rank': rfe.ranking_,\n",
    "    'selected': rfe.support_\n",
    "}).sort_values('rank')\n",
    "\n",
    "print(\"\\nRFE Ranking:\")\n",
    "print(rfe_ranking.to_string(index=False))\n",
    "\n",
    "# Selected features\n",
    "rfe_features = [f for f, s in zip(feature_cols, rfe.support_) if s]\n",
    "print(f\"\\nSelected: {rfe_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f98017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RFE WITH CROSS-VALIDATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nRFECV: FINDING OPTIMAL NUMBER OF FEATURES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "rfecv = RFECV(rf, step=1, cv=5, scoring='accuracy', min_features_to_select=3)\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimal number of features: {rfecv.n_features_}\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(range(1, len(rfecv.cv_results_['mean_test_score']) + 1), \n",
    "        rfecv.cv_results_['mean_test_score'], marker='o')\n",
    "ax.axvline(rfecv.n_features_, color='red', linestyle='--', label=f'Optimal: {rfecv.n_features_}')\n",
    "ax.set_xlabel('Number of Features')\n",
    "ax.set_ylabel('CV Accuracy')\n",
    "ax.set_title('RFECV: Feature Selection Performance', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2880cfe7",
   "metadata": {},
   "source": [
    "## Part 2: Tree-Based Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RANDOM FOREST IMPORTANCE\n",
    "# ============================================================\n",
    "\n",
    "print(\"TREE-BASED IMPORTANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train full RF\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Gini importance\n",
    "gini_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nGini Importance:\")\n",
    "print(gini_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Permutation importance (more reliable)\n",
    "perm_imp = permutation_importance(rf, X_test, y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "perm_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': perm_imp.importances_mean,\n",
    "    'std': perm_imp.importances_std\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nPermutation Importance:\")\n",
    "print(perm_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5dba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPARE IMPORTANCE METHODS\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "gini_importance.head(12).plot(x='feature', y='importance', kind='barh', ax=axes[0],\n",
    "                               color='steelblue', alpha=0.7, legend=False)\n",
    "axes[0].set_xlabel('Gini Importance')\n",
    "axes[0].set_title('Random Forest: Gini Importance', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "perm_importance.head(12).plot(x='feature', y='importance', kind='barh', ax=axes[1],\n",
    "                               color='coral', alpha=0.7, legend=False)\n",
    "axes[1].set_xlabel('Permutation Importance')\n",
    "axes[1].set_title('Permutation Importance (on test set)', fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9da8b",
   "metadata": {},
   "source": [
    "## Part 3: L1 Regularization (Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b43036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# L1 REGULARIZATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"L1 REGULARIZATION (LASSO)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Logistic Regression with L1\n",
    "lr_l1 = LogisticRegression(penalty='l1', solver='saga', C=0.5, max_iter=1000, random_state=42)\n",
    "lr_l1.fit(X_train, y_train)\n",
    "\n",
    "l1_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'coefficient': np.abs(lr_l1.coef_[0]),\n",
    "    'sign': np.sign(lr_l1.coef_[0])\n",
    "}).sort_values('coefficient', ascending=False)\n",
    "\n",
    "print(\"\\nL1 Coefficients:\")\n",
    "print(l1_importance.head(10).to_string(index=False))\n",
    "\n",
    "# Non-zero features\n",
    "l1_selected = l1_importance[l1_importance['coefficient'] > 0.001]['feature'].tolist()\n",
    "print(f\"\\nNon-zero features ({len(l1_selected)}): {l1_selected}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c4b4d",
   "metadata": {},
   "source": [
    "## Part 4: Consensus Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0141089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONSENSUS RANKING\n",
    "# ============================================================\n",
    "\n",
    "print(\"CONSENSUS RANKING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Combine rankings\n",
    "consensus = pd.DataFrame({'feature': feature_cols})\n",
    "\n",
    "# Add ranks\n",
    "consensus['rfe_rank'] = consensus['feature'].map(\n",
    "    dict(zip(rfe_ranking['feature'], rfe_ranking['rank'])))\n",
    "consensus['gini_rank'] = consensus['feature'].map(\n",
    "    dict(zip(gini_importance['feature'], range(1, len(gini_importance)+1))))\n",
    "consensus['perm_rank'] = consensus['feature'].map(\n",
    "    dict(zip(perm_importance['feature'], range(1, len(perm_importance)+1))))\n",
    "consensus['l1_rank'] = consensus['feature'].map(\n",
    "    dict(zip(l1_importance['feature'], range(1, len(l1_importance)+1))))\n",
    "\n",
    "consensus['avg_rank'] = consensus[['rfe_rank', 'gini_rank', 'perm_rank', 'l1_rank']].mean(axis=1)\n",
    "consensus = consensus.sort_values('avg_rank')\n",
    "\n",
    "print(\"\\nConsensus Ranking:\")\n",
    "print(consensus.head(10).to_string(index=False))\n",
    "\n",
    "final_features = consensus.head(8)['feature'].tolist()\n",
    "print(f\"\\nâœ… Final selected features: {final_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cc7299",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘        DAY 4 COMPLETE: WRAPPER & EMBEDDED SELECTION              â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  âœ“ RFE and RFECV for optimal feature count                      â•‘\n",
    "â•‘  âœ“ Random Forest Gini importance                                â•‘\n",
    "â•‘  âœ“ Permutation importance (more reliable)                       â•‘\n",
    "â•‘  âœ“ L1 regularization (Lasso) for sparse selection               â•‘\n",
    "â•‘  âœ“ Consensus ranking across methods                             â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Tomorrow: Day 5 - SHAP Analysis\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
