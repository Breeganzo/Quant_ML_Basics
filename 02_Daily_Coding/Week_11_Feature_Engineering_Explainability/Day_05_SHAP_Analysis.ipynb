{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9fdc5bf",
   "metadata": {},
   "source": [
    "# Day 5: SHAP Analysis\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand SHAP (SHapley Additive exPlanations)\n",
    "- Implement SHAP-like analysis from scratch\n",
    "- Interpret global and local explanations\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31e1bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded!\n",
      "ğŸ“š Day 5: SHAP Analysis\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"âœ… Libraries loaded!\")\n",
    "print(\"ğŸ“š Day 5: SHAP Analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f2be0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PREPARE DATA\n",
    "# ============================================================\n",
    "\n",
    "print(\"PREPARING DATA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_days = 1500\n",
    "\n",
    "returns = np.random.normal(0.0002, 0.015, n_days)\n",
    "for i in range(1, len(returns)):\n",
    "    returns[i] += 0.05 * returns[i-1]\n",
    "\n",
    "prices = 100 * np.cumprod(1 + returns)\n",
    "df = pd.DataFrame({'price': prices, 'returns': returns})\n",
    "\n",
    "# Create features\n",
    "df['ret_1d'] = df['price'].pct_change(1)\n",
    "df['ret_5d'] = df['price'].pct_change(5)\n",
    "df['vol_5d'] = df['returns'].rolling(5).std()\n",
    "df['vol_20d'] = df['returns'].rolling(20).std()\n",
    "df['mom_5d'] = df['returns'].rolling(5).sum()\n",
    "df['mom_20d'] = df['returns'].rolling(20).sum()\n",
    "\n",
    "gains = df['returns'].where(df['returns'] > 0, 0).rolling(14).mean()\n",
    "losses = (-df['returns'].where(df['returns'] < 0, 0)).rolling(14).mean()\n",
    "df['rsi'] = 100 - (100 / (1 + gains / (losses + 1e-10)))\n",
    "\n",
    "df['target'] = (df['returns'].shift(-1) > 0).astype(int)\n",
    "df = df.dropna()\n",
    "\n",
    "feature_cols = ['ret_1d', 'ret_5d', 'vol_5d', 'vol_20d', 'mom_5d', 'mom_20d', 'rsi']\n",
    "X = df[feature_cols].values\n",
    "y = df['target'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "split = int(len(X) * 0.7)\n",
    "X_train, X_test = X_scaled[:split], X_scaled[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45db878b",
   "metadata": {},
   "source": [
    "## Part 1: SHAP Concept\n",
    "\n",
    "**SHAP values** use game theory to allocate prediction \"credit\" to features:\n",
    "\n",
    "$$\\phi_i = \\sum_{S \\subseteq N \\setminus \\{i\\}} \\frac{|S|!(n-|S|-1)!}{n!} [f(S \\cup \\{i\\}) - f(S)]$$\n",
    "\n",
    "Key properties:\n",
    "- **Local accuracy**: Sum of SHAP values = prediction - expected value\n",
    "- **Missingness**: Features not in model get SHAP = 0\n",
    "- **Consistency**: If a model relies more on feature, its SHAP increases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2c98b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"TRAINING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=100, max_depth=4, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "train_acc = model.score(X_train, y_train)\n",
    "test_acc = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train accuracy: {train_acc:.3f}\")\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f64a9a",
   "metadata": {},
   "source": [
    "## Part 2: SHAP-Like Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a03502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SIMPLIFIED SHAP CALCULATION\n",
    "# ============================================================\n",
    "\n",
    "print(\"CALCULATING SHAP-LIKE VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def calculate_shap_values(model, X_background, X_explain, n_samples=100):\n",
    "    \"\"\"\n",
    "    Calculate SHAP-like values using baseline comparison.\n",
    "    \n",
    "    For each feature, we measure how much the prediction changes\n",
    "    when we replace that feature with background values.\n",
    "    \"\"\"\n",
    "    n_explain = min(n_samples, len(X_explain))\n",
    "    n_features = X_explain.shape[1]\n",
    "    \n",
    "    shap_values = np.zeros((n_explain, n_features))\n",
    "    expected_value = model.predict_proba(X_background)[:, 1].mean()\n",
    "    \n",
    "    for i in range(n_explain):\n",
    "        x = X_explain[i:i+1]\n",
    "        original_pred = model.predict_proba(x)[0, 1]\n",
    "        \n",
    "        for j in range(n_features):\n",
    "            # Replace feature j with background mean\n",
    "            x_modified = x.copy()\n",
    "            x_modified[0, j] = X_background[:, j].mean()\n",
    "            \n",
    "            modified_pred = model.predict_proba(x_modified)[0, 1]\n",
    "            \n",
    "            # SHAP value = contribution of this feature\n",
    "            shap_values[i, j] = original_pred - modified_pred\n",
    "    \n",
    "    return shap_values, expected_value\n",
    "\n",
    "# Calculate\n",
    "shap_values, expected = calculate_shap_values(model, X_train, X_test, n_samples=200)\n",
    "\n",
    "print(f\"Expected value (base prediction): {expected:.3f}\")\n",
    "print(f\"SHAP values shape: {shap_values.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3abbec",
   "metadata": {},
   "source": [
    "## Part 3: Global Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1927af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GLOBAL FEATURE IMPORTANCE\n",
    "# ============================================================\n",
    "\n",
    "print(\"GLOBAL FEATURE IMPORTANCE (SHAP)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Mean absolute SHAP\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'mean_shap': mean_abs_shap\n",
    "}).sort_values('mean_shap', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (Mean |SHAP|):\")\n",
    "for _, row in importance_df.iterrows():\n",
    "    print(f\"  {row['feature']:<12} {row['mean_shap']:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "importance_df.plot(x='feature', y='mean_shap', kind='barh', ax=axes[0],\n",
    "                   color='steelblue', alpha=0.7, legend=False)\n",
    "axes[0].set_xlabel('Mean |SHAP Value|')\n",
    "axes[0].set_title('Global Feature Importance', fontweight='bold')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# Summary plot (beeswarm)\n",
    "for i, feat in enumerate(importance_df['feature'].values):\n",
    "    feat_idx = feature_cols.index(feat)\n",
    "    shap_vals = shap_values[:, feat_idx]\n",
    "    feat_vals = X_test[:len(shap_vals), feat_idx]\n",
    "    \n",
    "    # Normalize for color\n",
    "    norm_feat = (feat_vals - feat_vals.min()) / (feat_vals.max() - feat_vals.min() + 1e-10)\n",
    "    \n",
    "    y_jitter = i + np.random.randn(len(shap_vals)) * 0.15\n",
    "    axes[1].scatter(shap_vals, y_jitter, c=norm_feat, cmap='coolwarm', alpha=0.5, s=15)\n",
    "\n",
    "axes[1].set_yticks(range(len(feature_cols)))\n",
    "axes[1].set_yticklabels(importance_df['feature'].values)\n",
    "axes[1].axvline(0, color='gray', linewidth=0.5)\n",
    "axes[1].set_xlabel('SHAP Value')\n",
    "axes[1].set_title('SHAP Summary (Blue=Low, Red=High)', fontweight='bold')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41133a64",
   "metadata": {},
   "source": [
    "## Part 4: Local Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe9f000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# LOCAL EXPLANATION (SINGLE PREDICTION)\n",
    "# ============================================================\n",
    "\n",
    "print(\"LOCAL EXPLANATION (SINGLE PREDICTION)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def explain_prediction(idx):\n",
    "    \"\"\"Explain a single prediction.\"\"\"\n",
    "    sample = X_test[idx:idx+1]\n",
    "    pred_prob = model.predict_proba(sample)[0, 1]\n",
    "    actual = y_test[idx]\n",
    "    sample_shap = shap_values[idx]\n",
    "    \n",
    "    print(f\"\\nSample {idx}:\")\n",
    "    print(f\"  Prediction: {pred_prob:.2%} probability of UP\")\n",
    "    print(f\"  Actual: {'UP' if actual == 1 else 'DOWN'}\")\n",
    "    print(f\"  Base value: {expected:.2%}\")\n",
    "    print(f\"\\n  Feature contributions:\")\n",
    "    \n",
    "    contrib_df = pd.DataFrame({\n",
    "        'feature': feature_cols,\n",
    "        'value': sample[0],\n",
    "        'shap': sample_shap\n",
    "    }).sort_values('shap', key=abs, ascending=False)\n",
    "    \n",
    "    for _, row in contrib_df.iterrows():\n",
    "        direction = '+' if row['shap'] > 0 else '-'\n",
    "        print(f\"    {row['feature']:<12} = {row['value']:>7.3f}  {direction}{abs(row['shap']):.4f}\")\n",
    "    \n",
    "    return contrib_df\n",
    "\n",
    "# Explain a few predictions\n",
    "contrib = explain_prediction(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809863a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# WATERFALL PLOT\n",
    "# ============================================================\n",
    "\n",
    "def waterfall_plot(idx, ax=None):\n",
    "    \"\"\"Create a waterfall plot for prediction explanation.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    sample_shap = shap_values[idx]\n",
    "    pred_prob = model.predict_proba(X_test[idx:idx+1])[0, 1]\n",
    "    \n",
    "    # Sort by absolute contribution\n",
    "    sorted_idx = np.argsort(np.abs(sample_shap))[::-1]\n",
    "    \n",
    "    cumulative = expected\n",
    "    y_positions = []\n",
    "    \n",
    "    # Base\n",
    "    ax.barh(0, expected, color='gray', alpha=0.5, height=0.6)\n",
    "    ax.text(expected/2, 0, f'Base: {expected:.3f}', ha='center', va='center')\n",
    "    \n",
    "    for i, feat_idx in enumerate(sorted_idx[:6]):  # Top 6 features\n",
    "        shap_val = sample_shap[feat_idx]\n",
    "        color = 'green' if shap_val > 0 else 'red'\n",
    "        \n",
    "        ax.barh(i+1, shap_val, left=cumulative, color=color, alpha=0.6, height=0.6)\n",
    "        ax.text(cumulative + shap_val/2, i+1, f'{shap_val:+.3f}', ha='center', va='center', fontsize=9)\n",
    "        \n",
    "        cumulative += shap_val\n",
    "    \n",
    "    # Final prediction\n",
    "    ax.barh(len(sorted_idx[:6])+1, cumulative, color='steelblue', alpha=0.7, height=0.6)\n",
    "    ax.text(cumulative/2, len(sorted_idx[:6])+1, f'Pred: {pred_prob:.3f}', ha='center', va='center')\n",
    "    \n",
    "    labels = ['Base'] + [feature_cols[i] for i in sorted_idx[:6]] + ['Prediction']\n",
    "    ax.set_yticks(range(len(labels)))\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel('Probability')\n",
    "    ax.set_title(f'Prediction Explanation (Sample {idx})', fontweight='bold')\n",
    "    ax.axvline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    return ax\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "waterfall_plot(50, axes[0])\n",
    "waterfall_plot(100, axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332f573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘               DAY 5 COMPLETE: SHAP ANALYSIS                      â•‘\n",
    "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
    "â•‘  âœ“ SHAP concept and game-theoretic foundations                  â•‘\n",
    "â•‘  âœ“ Simplified SHAP implementation                               â•‘\n",
    "â•‘  âœ“ Global explanations (feature importance)                     â•‘\n",
    "â•‘  âœ“ Local explanations (individual predictions)                  â•‘\n",
    "â•‘  âœ“ Summary and waterfall plots                                  â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Tomorrow: Day 6 - Permutation & Partial Dependence\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
