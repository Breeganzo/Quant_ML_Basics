{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e68e2d18",
   "metadata": {},
   "source": [
    "# Day 6: Model Deployment\n",
    "\n",
    "## Learning Objectives\n",
    "- Build inference pipeline\n",
    "- Model monitoring and drift detection\n",
    "- Production-ready architecture\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a90a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from scipy import stats\n",
    "import json\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")\n",
    "print(\"üìö Day 6: Model Deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b61c0",
   "metadata": {},
   "source": [
    "## Part 1: Model Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67822249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAIN AND SAVE MODEL\n",
    "# ============================================================\n",
    "\n",
    "print(\"MODEL TRAINING AND SERIALIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate training data\n",
    "np.random.seed(42)\n",
    "n_days = 1000\n",
    "\n",
    "returns = np.random.normal(0.0003, 0.015, n_days)\n",
    "prices = 100 * np.cumprod(1 + returns)\n",
    "df = pd.DataFrame({'price': prices, 'returns': returns})\n",
    "\n",
    "df['ret_5d'] = df['price'].pct_change(5)\n",
    "df['vol_5d'] = df['returns'].rolling(5).std()\n",
    "df['mom_5d'] = df['returns'].rolling(5).sum()\n",
    "df['target'] = (df['returns'].shift(-1) > 0).astype(int)\n",
    "df = df.dropna()\n",
    "\n",
    "feature_cols = ['ret_5d', 'vol_5d', 'mom_5d']\n",
    "X = df[feature_cols].values\n",
    "y = df['target'].values\n",
    "\n",
    "split = int(len(X) * 0.7)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Scaler and model\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = GradientBoostingClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Model trained with accuracy: {model.score(X_test_scaled, y_test):.3f}\")\n",
    "\n",
    "# Model artifact\n",
    "model_artifact = {\n",
    "    'model': model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': feature_cols,\n",
    "    'training_stats': {\n",
    "        'X_mean': X_train.mean(axis=0).tolist(),\n",
    "        'X_std': X_train.std(axis=0).tolist(),\n",
    "        'n_samples': len(X_train),\n",
    "        'train_date': datetime.datetime.now().isoformat()\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n‚úÖ Model artifact created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8c4cd7",
   "metadata": {},
   "source": [
    "## Part 2: Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0219fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# INFERENCE PIPELINE\n",
    "# ============================================================\n",
    "\n",
    "print(\"INFERENCE PIPELINE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class TradingInference:\n",
    "    \"\"\"Production inference pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_artifact):\n",
    "        self.model = model_artifact['model']\n",
    "        self.scaler = model_artifact['scaler']\n",
    "        self.feature_names = model_artifact['feature_names']\n",
    "        self.training_stats = model_artifact['training_stats']\n",
    "        \n",
    "        self.prediction_log = []\n",
    "        \n",
    "    def predict(self, features, timestamp=None):\n",
    "        \"\"\"\n",
    "        Generate prediction with logging.\n",
    "        \n",
    "        Args:\n",
    "            features: Dict or array of feature values\n",
    "            timestamp: Optional timestamp\n",
    "            \n",
    "        Returns:\n",
    "            Dict with prediction and metadata\n",
    "        \"\"\"\n",
    "        if timestamp is None:\n",
    "            timestamp = datetime.datetime.now()\n",
    "        \n",
    "        # Parse features\n",
    "        if isinstance(features, dict):\n",
    "            X = np.array([[features[f] for f in self.feature_names]])\n",
    "        else:\n",
    "            X = np.array(features).reshape(1, -1)\n",
    "        \n",
    "        # Scale\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        # Predict\n",
    "        pred_class = self.model.predict(X_scaled)[0]\n",
    "        pred_proba = self.model.predict_proba(X_scaled)[0]\n",
    "        \n",
    "        # Build result\n",
    "        result = {\n",
    "            'timestamp': timestamp.isoformat(),\n",
    "            'features': X[0].tolist(),\n",
    "            'prediction': int(pred_class),\n",
    "            'confidence': float(max(pred_proba)),\n",
    "            'prob_up': float(pred_proba[1]),\n",
    "            'signal': 'BUY' if pred_class == 1 else 'SELL'\n",
    "        }\n",
    "        \n",
    "        # Log\n",
    "        self.prediction_log.append(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def get_signal(self, features, threshold=0.55):\n",
    "        \"\"\"\n",
    "        Get trading signal with confidence threshold.\n",
    "        \"\"\"\n",
    "        result = self.predict(features)\n",
    "        \n",
    "        if result['confidence'] < threshold:\n",
    "            result['signal'] = 'HOLD'\n",
    "            result['position_size'] = 0\n",
    "        else:\n",
    "            # Scale position by confidence\n",
    "            edge = abs(result['prob_up'] - 0.5) * 2\n",
    "            result['position_size'] = edge\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Test\n",
    "inference = TradingInference(model_artifact)\n",
    "\n",
    "# Simulate predictions\n",
    "test_features = {\n",
    "    'ret_5d': 0.02,\n",
    "    'vol_5d': 0.012,\n",
    "    'mom_5d': 0.03\n",
    "}\n",
    "\n",
    "result = inference.get_signal(test_features)\n",
    "print(\"\\nPrediction Result:\")\n",
    "for k, v in result.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9831326c",
   "metadata": {},
   "source": [
    "## Part 3: Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df6e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DRIFT DETECTION\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nDRIFT DETECTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class DriftDetector:\n",
    "    \"\"\"Detect data and concept drift.\"\"\"\n",
    "    \n",
    "    def __init__(self, reference_data, feature_names):\n",
    "        self.reference = reference_data\n",
    "        self.feature_names = feature_names\n",
    "        self.reference_stats = self._compute_stats(reference_data)\n",
    "        \n",
    "    def _compute_stats(self, data):\n",
    "        \"\"\"Compute distribution statistics.\"\"\"\n",
    "        return {\n",
    "            'mean': np.mean(data, axis=0),\n",
    "            'std': np.std(data, axis=0),\n",
    "            'min': np.min(data, axis=0),\n",
    "            'max': np.max(data, axis=0)\n",
    "        }\n",
    "    \n",
    "    def detect_drift(self, new_data, threshold=0.05):\n",
    "        \"\"\"\n",
    "        Detect drift using Kolmogorov-Smirnov test.\n",
    "        \n",
    "        Returns:\n",
    "            Dict with drift detection results per feature\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        \n",
    "        for i, feat in enumerate(self.feature_names):\n",
    "            ref_vals = self.reference[:, i]\n",
    "            new_vals = new_data[:, i]\n",
    "            \n",
    "            # KS test\n",
    "            ks_stat, p_value = stats.ks_2samp(ref_vals, new_vals)\n",
    "            \n",
    "            # Population Stability Index\n",
    "            psi = self._compute_psi(ref_vals, new_vals)\n",
    "            \n",
    "            drift_detected = p_value < threshold\n",
    "            \n",
    "            results[feat] = {\n",
    "                'ks_statistic': ks_stat,\n",
    "                'p_value': p_value,\n",
    "                'psi': psi,\n",
    "                'drift': drift_detected\n",
    "            }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _compute_psi(self, expected, actual, n_bins=10):\n",
    "        \"\"\"\n",
    "        Compute Population Stability Index.\n",
    "        \n",
    "        PSI < 0.1: No significant change\n",
    "        PSI 0.1-0.25: Moderate change\n",
    "        PSI > 0.25: Significant change\n",
    "        \"\"\"\n",
    "        # Create bins from expected\n",
    "        bins = np.percentile(expected, np.linspace(0, 100, n_bins + 1))\n",
    "        bins[0] = -np.inf\n",
    "        bins[-1] = np.inf\n",
    "        \n",
    "        # Count in each bin\n",
    "        expected_counts = np.histogram(expected, bins=bins)[0] / len(expected)\n",
    "        actual_counts = np.histogram(actual, bins=bins)[0] / len(actual)\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        expected_counts = np.clip(expected_counts, 0.001, None)\n",
    "        actual_counts = np.clip(actual_counts, 0.001, None)\n",
    "        \n",
    "        psi = np.sum((actual_counts - expected_counts) * np.log(actual_counts / expected_counts))\n",
    "        return psi\n",
    "\n",
    "# Create drift detector\n",
    "drift_detector = DriftDetector(X_train, feature_cols)\n",
    "\n",
    "# Test with test data (should be similar)\n",
    "drift_results = drift_detector.detect_drift(X_test)\n",
    "\n",
    "print(\"\\nDrift Detection Results (Test Data):\")\n",
    "for feat, result in drift_results.items():\n",
    "    status = '‚ö†Ô∏è DRIFT' if result['drift'] else '‚úì OK'\n",
    "    print(f\"  {feat:<10} KS={result['ks_statistic']:.3f}  PSI={result['psi']:.3f}  {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750aa572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with synthetic drifted data\n",
    "print(\"\\nDrift Detection (Synthetic Shifted Data):\")\n",
    "X_drifted = X_test + np.array([0.02, 0.005, 0.01])  # Shift features\n",
    "\n",
    "drift_results_shifted = drift_detector.detect_drift(X_drifted)\n",
    "\n",
    "for feat, result in drift_results_shifted.items():\n",
    "    status = '‚ö†Ô∏è DRIFT' if result['drift'] else '‚úì OK'\n",
    "    print(f\"  {feat:<10} KS={result['ks_statistic']:.3f}  PSI={result['psi']:.3f}  {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c324c8c2",
   "metadata": {},
   "source": [
    "## Part 4: Performance Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182df6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# PERFORMANCE MONITORING\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nPERFORMANCE MONITORING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"Monitor model performance over time.\"\"\"\n",
    "    \n",
    "    def __init__(self, window=50):\n",
    "        self.window = window\n",
    "        self.predictions = []\n",
    "        self.actuals = []\n",
    "        self.timestamps = []\n",
    "        \n",
    "    def log(self, prediction, actual, timestamp=None):\n",
    "        \"\"\"Log a prediction-actual pair.\"\"\"\n",
    "        self.predictions.append(prediction)\n",
    "        self.actuals.append(actual)\n",
    "        self.timestamps.append(timestamp or datetime.datetime.now())\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        \"\"\"Calculate current metrics.\"\"\"\n",
    "        if len(self.predictions) < self.window:\n",
    "            recent_preds = self.predictions\n",
    "            recent_actual = self.actuals\n",
    "        else:\n",
    "            recent_preds = self.predictions[-self.window:]\n",
    "            recent_actual = self.actuals[-self.window:]\n",
    "        \n",
    "        accuracy = np.mean(np.array(recent_preds) == np.array(recent_actual))\n",
    "        \n",
    "        return {\n",
    "            'rolling_accuracy': accuracy,\n",
    "            'total_predictions': len(self.predictions),\n",
    "            'window': self.window\n",
    "        }\n",
    "    \n",
    "    def check_alert(self, accuracy_threshold=0.48):\n",
    "        \"\"\"Check if performance is below threshold.\"\"\"\n",
    "        metrics = self.get_metrics()\n",
    "        if metrics['rolling_accuracy'] < accuracy_threshold:\n",
    "            return {\n",
    "                'alert': True,\n",
    "                'message': f\"Model accuracy {metrics['rolling_accuracy']:.1%} below threshold {accuracy_threshold:.1%}\",\n",
    "                'metrics': metrics\n",
    "            }\n",
    "        return {'alert': False, 'metrics': metrics}\n",
    "\n",
    "# Simulate monitoring\n",
    "monitor = PerformanceMonitor(window=50)\n",
    "\n",
    "# Log predictions from test set\n",
    "for i in range(len(X_test)):\n",
    "    pred = model.predict(X_test_scaled[i:i+1])[0]\n",
    "    actual = y_test[i]\n",
    "    monitor.log(pred, actual)\n",
    "\n",
    "metrics = monitor.get_metrics()\n",
    "alert = monitor.check_alert()\n",
    "\n",
    "print(f\"\\nMonitoring Status:\")\n",
    "print(f\"  Total predictions: {metrics['total_predictions']}\")\n",
    "print(f\"  Rolling accuracy: {metrics['rolling_accuracy']:.1%}\")\n",
    "print(f\"  Alert status: {'‚ö†Ô∏è ALERT' if alert['alert'] else '‚úì OK'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92d808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë              DAY 6 COMPLETE: MODEL DEPLOYMENT                    ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë  ‚úì Model artifact and serialization                             ‚ïë\n",
    "‚ïë  ‚úì Inference pipeline with logging                              ‚ïë\n",
    "‚ïë  ‚úì Data drift detection (KS test, PSI)                          ‚ïë\n",
    "‚ïë  ‚úì Performance monitoring and alerts                            ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Tomorrow: Day 7 - Complete Trading System\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
