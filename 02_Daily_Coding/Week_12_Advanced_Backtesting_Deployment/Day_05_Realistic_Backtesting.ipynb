{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8005db7b",
   "metadata": {},
   "source": [
    "# Day 5: Realistic Backtesting\n",
    "\n",
    "## Learning Objectives\n",
    "- Avoid common backtesting biases\n",
    "- Implement proper validation frameworks\n",
    "- Statistical significance testing\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5897630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries loaded!\")\n",
    "print(\"üìö Day 5: Realistic Backtesting\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee2b2f1",
   "metadata": {},
   "source": [
    "## Part 1: Backtesting Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e4616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DEMONSTRATING LOOK-AHEAD BIAS\n",
    "# ============================================================\n",
    "\n",
    "print(\"LOOK-AHEAD BIAS DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "np.random.seed(42)\n",
    "n_days = 1000\n",
    "\n",
    "# Generate data\n",
    "returns = np.random.normal(0.0003, 0.015, n_days)\n",
    "prices = 100 * np.cumprod(1 + returns)\n",
    "df = pd.DataFrame({'price': prices, 'returns': returns})\n",
    "\n",
    "# Features\n",
    "df['ret_5d'] = df['price'].pct_change(5)\n",
    "df['vol_5d'] = df['returns'].rolling(5).std()\n",
    "df['target'] = (df['returns'].shift(-1) > 0).astype(int)\n",
    "\n",
    "# WRONG: Using future information (scaled with test data)\n",
    "df_wrong = df.dropna()\n",
    "X_wrong = df_wrong[['ret_5d', 'vol_5d']].values\n",
    "y_wrong = df_wrong['target'].values\n",
    "\n",
    "scaler_wrong = StandardScaler()\n",
    "X_scaled_wrong = scaler_wrong.fit_transform(X_wrong)  # Fits on ALL data!\n",
    "\n",
    "split = int(len(X_wrong) * 0.7)\n",
    "model_wrong = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model_wrong.fit(X_scaled_wrong[:split], y_wrong[:split])\n",
    "acc_wrong = model_wrong.score(X_scaled_wrong[split:], y_wrong[split:])\n",
    "\n",
    "# RIGHT: Proper train/test split\n",
    "df_right = df.dropna()\n",
    "X_right = df_right[['ret_5d', 'vol_5d']].values\n",
    "y_right = df_right['target'].values\n",
    "\n",
    "X_train = X_right[:split]\n",
    "X_test = X_right[split:]\n",
    "y_train = y_right[:split]\n",
    "y_test = y_right[split:]\n",
    "\n",
    "scaler_right = StandardScaler()\n",
    "X_train_scaled = scaler_right.fit_transform(X_train)  # Fit only on train\n",
    "X_test_scaled = scaler_right.transform(X_test)  # Transform test\n",
    "\n",
    "model_right = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "model_right.fit(X_train_scaled, y_train)\n",
    "acc_right = model_right.score(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"\\nAccuracy with look-ahead bias: {acc_wrong:.3f}\")\n",
    "print(f\"Accuracy without bias: {acc_right:.3f}\")\n",
    "print(f\"Bias inflation: {(acc_wrong - acc_right) / acc_right * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae256700",
   "metadata": {},
   "source": [
    "## Part 2: Multiple Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f3ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA SNOOPING / MULTIPLE TESTING\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nDATA SNOOPING DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def run_random_strategy(n=100):\n",
    "    \"\"\"Run a random strategy and return Sharpe ratio.\"\"\"\n",
    "    np.random.seed()\n",
    "    signals = np.random.choice([-1, 1], n)\n",
    "    market_returns = np.random.normal(0.0003, 0.015, n)\n",
    "    strategy_returns = signals * market_returns\n",
    "    sharpe = np.sqrt(252) * strategy_returns.mean() / strategy_returns.std()\n",
    "    return sharpe\n",
    "\n",
    "# \"Test\" 1000 random strategies\n",
    "n_strategies = 1000\n",
    "sharpes = [run_random_strategy(500) for _ in range(n_strategies)]\n",
    "\n",
    "# Find \"best\" strategy\n",
    "best_sharpe = max(sharpes)\n",
    "top_5_pct = np.percentile(sharpes, 95)\n",
    "\n",
    "print(f\"Tested {n_strategies} random strategies\")\n",
    "print(f\"Best Sharpe: {best_sharpe:.2f}\")\n",
    "print(f\"Top 5% threshold: {top_5_pct:.2f}\")\n",
    "print(f\"Strategies with Sharpe > 1: {sum(np.array(sharpes) > 1)}\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è WARNING: Even random strategies can look profitable!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c97725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(sharpes, bins=50, density=True, alpha=0.7, color='steelblue')\n",
    "ax.axvline(0, color='gray', linestyle='--', label='Zero')\n",
    "ax.axvline(best_sharpe, color='red', linewidth=2, label=f'Best: {best_sharpe:.2f}')\n",
    "ax.axvline(1, color='green', linestyle='--', label='Sharpe=1')\n",
    "ax.set_xlabel('Sharpe Ratio')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Distribution of Random Strategy Sharpe Ratios', fontweight='bold')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41107c9",
   "metadata": {},
   "source": [
    "## Part 3: Statistical Significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e07c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SHARPE RATIO SIGNIFICANCE TEST\n",
    "# ============================================================\n",
    "\n",
    "print(\"STATISTICAL SIGNIFICANCE TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def sharpe_t_stat(returns, target_sharpe=0):\n",
    "    \"\"\"\n",
    "    Test if Sharpe ratio is significantly different from target.\n",
    "    \n",
    "    Under null hypothesis H0: SR = target_sharpe\n",
    "    t-stat = (SR - target) / SE(SR)\n",
    "    \n",
    "    SE(SR) ‚âà sqrt((1 + SR^2/2) / n)\n",
    "    \"\"\"\n",
    "    n = len(returns)\n",
    "    sr = np.sqrt(252) * returns.mean() / returns.std()\n",
    "    \n",
    "    # Standard error of Sharpe ratio\n",
    "    se = np.sqrt((1 + sr**2/2) / n)\n",
    "    \n",
    "    t_stat = (sr - target_sharpe) / se\n",
    "    p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))\n",
    "    \n",
    "    return sr, t_stat, p_value\n",
    "\n",
    "# Test our strategy\n",
    "np.random.seed(42)\n",
    "strategy_returns = np.random.normal(0.0005, 0.012, 500)  # Slightly positive alpha\n",
    "\n",
    "sr, t_stat, p_val = sharpe_t_stat(strategy_returns)\n",
    "\n",
    "print(f\"Strategy Sharpe: {sr:.2f}\")\n",
    "print(f\"t-statistic: {t_stat:.2f}\")\n",
    "print(f\"p-value: {p_val:.4f}\")\n",
    "print(f\"Significant at 5%: {'Yes ‚úì' if p_val < 0.05 else 'No ‚úó'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e54101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# MINIMUM TRACK RECORD LENGTH\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nMINIMUM TRACK RECORD LENGTH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def min_track_record(target_sharpe, significance=0.05):\n",
    "    \"\"\"\n",
    "    Calculate minimum days needed to confirm Sharpe ratio.\n",
    "    \n",
    "    From Bailey & L√≥pez de Prado (2012):\n",
    "    n* = 1 + (1 + SR^2/2) * (z_alpha / SR)^2\n",
    "    \"\"\"\n",
    "    z_alpha = stats.norm.ppf(1 - significance/2)\n",
    "    n_star = 1 + (1 + target_sharpe**2/2) * (z_alpha / target_sharpe)**2\n",
    "    return int(np.ceil(n_star))\n",
    "\n",
    "print(f\"Minimum days needed to confirm:\")\n",
    "for sr in [0.5, 1.0, 1.5, 2.0, 2.5]:\n",
    "    days = min_track_record(sr)\n",
    "    years = days / 252\n",
    "    print(f\"  Sharpe {sr:.1f}: {days:>4} days ({years:.1f} years)\")\n",
    "\n",
    "print(\"\\nüí° Higher Sharpe requires less data to confirm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7180e5d6",
   "metadata": {},
   "source": [
    "## Part 4: Robust Validation Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed98081b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ROBUST VALIDATION FRAMEWORK\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nROBUST VALIDATION FRAMEWORK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "class RobustValidator:\n",
    "    \"\"\"Comprehensive backtesting validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, returns, benchmark_returns=None):\n",
    "        self.returns = returns\n",
    "        self.benchmark = benchmark_returns\n",
    "        \n",
    "    def performance_metrics(self):\n",
    "        \"\"\"Calculate key metrics.\"\"\"\n",
    "        r = self.returns\n",
    "        n = len(r)\n",
    "        \n",
    "        sharpe = np.sqrt(252) * r.mean() / r.std()\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative = np.cumprod(1 + r)\n",
    "        running_max = np.maximum.accumulate(cumulative)\n",
    "        max_dd = ((cumulative - running_max) / running_max).min()\n",
    "        \n",
    "        # Calmar ratio (return / max drawdown)\n",
    "        annual_return = (cumulative[-1] ** (252/n)) - 1\n",
    "        calmar = annual_return / abs(max_dd) if max_dd != 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'sharpe': sharpe,\n",
    "            'annual_return': annual_return,\n",
    "            'volatility': r.std() * np.sqrt(252),\n",
    "            'max_drawdown': max_dd,\n",
    "            'calmar': calmar,\n",
    "            'n_observations': n\n",
    "        }\n",
    "    \n",
    "    def statistical_tests(self):\n",
    "        \"\"\"Run statistical tests.\"\"\"\n",
    "        r = self.returns\n",
    "        \n",
    "        # Sharpe significance\n",
    "        sr, t_stat, p_val = sharpe_t_stat(r)\n",
    "        \n",
    "        # Normality test\n",
    "        _, normality_p = stats.normaltest(r)\n",
    "        \n",
    "        # Autocorrelation test\n",
    "        autocorr = np.corrcoef(r[:-1], r[1:])[0, 1]\n",
    "        \n",
    "        return {\n",
    "            'sharpe_t_stat': t_stat,\n",
    "            'sharpe_p_value': p_val,\n",
    "            'significant_5pct': p_val < 0.05,\n",
    "            'normality_p': normality_p,\n",
    "            'autocorrelation': autocorr\n",
    "        }\n",
    "    \n",
    "    def bootstrap_sharpe(self, n_bootstrap=1000):\n",
    "        \"\"\"Bootstrap confidence interval for Sharpe.\"\"\"\n",
    "        r = self.returns\n",
    "        bootstrap_sharpes = []\n",
    "        \n",
    "        for _ in range(n_bootstrap):\n",
    "            # Resample with replacement (block bootstrap for time series)\n",
    "            idx = np.random.choice(len(r), len(r), replace=True)\n",
    "            boot_r = r[idx]\n",
    "            boot_sharpe = np.sqrt(252) * boot_r.mean() / boot_r.std()\n",
    "            bootstrap_sharpes.append(boot_sharpe)\n",
    "        \n",
    "        return {\n",
    "            'mean': np.mean(bootstrap_sharpes),\n",
    "            'ci_lower': np.percentile(bootstrap_sharpes, 2.5),\n",
    "            'ci_upper': np.percentile(bootstrap_sharpes, 97.5)\n",
    "        }\n",
    "    \n",
    "    def full_report(self):\n",
    "        \"\"\"Generate comprehensive report.\"\"\"\n",
    "        metrics = self.performance_metrics()\n",
    "        tests = self.statistical_tests()\n",
    "        bootstrap = self.bootstrap_sharpe()\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"VALIDATION REPORT\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(\"\\nPERFORMANCE:\")\n",
    "        print(f\"  Sharpe Ratio: {metrics['sharpe']:.2f}\")\n",
    "        print(f\"  Annual Return: {metrics['annual_return']*100:.1f}%\")\n",
    "        print(f\"  Volatility: {metrics['volatility']*100:.1f}%\")\n",
    "        print(f\"  Max Drawdown: {metrics['max_drawdown']*100:.1f}%\")\n",
    "        print(f\"  Calmar Ratio: {metrics['calmar']:.2f}\")\n",
    "        \n",
    "        print(\"\\nSTATISTICAL TESTS:\")\n",
    "        print(f\"  Sharpe t-stat: {tests['sharpe_t_stat']:.2f}\")\n",
    "        print(f\"  Sharpe p-value: {tests['sharpe_p_value']:.4f}\")\n",
    "        print(f\"  Significant (5%): {tests['significant_5pct']}\")\n",
    "        print(f\"  Autocorrelation: {tests['autocorrelation']:.3f}\")\n",
    "        \n",
    "        print(\"\\nBOOTSTRAP 95% CI:\")\n",
    "        print(f\"  Sharpe: [{bootstrap['ci_lower']:.2f}, {bootstrap['ci_upper']:.2f}]\")\n",
    "        \n",
    "        print(\"=\"*50)\n",
    "\n",
    "# Test\n",
    "np.random.seed(42)\n",
    "test_returns = np.random.normal(0.0004, 0.012, 750)\n",
    "\n",
    "validator = RobustValidator(test_returns)\n",
    "validator.full_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3996a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
    "‚ïë            DAY 5 COMPLETE: REALISTIC BACKTESTING                 ‚ïë\n",
    "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
    "‚ïë  ‚úì Look-ahead bias demonstration                                ‚ïë\n",
    "‚ïë  ‚úì Multiple hypothesis testing / data snooping                  ‚ïë\n",
    "‚ïë  ‚úì Sharpe ratio significance testing                            ‚ïë\n",
    "‚ïë  ‚úì Minimum track record calculation                             ‚ïë\n",
    "‚ïë  ‚úì Robust validation framework                                  ‚ïë\n",
    "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
    "\n",
    "Tomorrow: Day 6 - Model Deployment\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
