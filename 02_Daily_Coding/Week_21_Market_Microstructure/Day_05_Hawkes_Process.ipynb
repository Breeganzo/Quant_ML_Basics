{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b4e436",
   "metadata": {},
   "source": [
    "# Day 05: Hawkes Processes for Order Flow Modeling\n",
    "\n",
    "## Week 21: Market Microstructure\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Understand Hawkes Processes**: Learn the mathematical foundation of self-exciting point processes\n",
    "2. **Simulate Hawkes Processes**: Implement Ogata's thinning algorithm for simulation\n",
    "3. **Estimate Parameters**: Use Maximum Likelihood Estimation (MLE) to fit Hawkes models\n",
    "4. **Model Order Flow**: Apply Hawkes processes to real market microstructure data\n",
    "5. **Analyze Market Dynamics**: Extract insights about order clustering and market activity\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Introduction to Hawkes Processes](#1-introduction)\n",
    "2. [Mathematical Foundation](#2-math-foundation)\n",
    "3. [Simulating Hawkes Processes](#3-simulation)\n",
    "4. [Parameter Estimation](#4-estimation)\n",
    "5. [Order Flow Modeling](#5-order-flow)\n",
    "6. [Multivariate Hawkes for Buy/Sell Orders](#6-multivariate)\n",
    "7. [Market Microstructure Applications](#7-applications)\n",
    "8. [Summary & Interview Questions](#8-summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628d141b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction to Hawkes Processes <a id='1-introduction'></a>\n",
    "\n",
    "### What is a Hawkes Process?\n",
    "\n",
    "A **Hawkes process** is a self-exciting point process where the occurrence of an event increases the probability of future events. This is particularly relevant in financial markets where:\n",
    "\n",
    "- **Order clustering**: One trade often triggers more trades\n",
    "- **News events**: Breaking news causes bursts of trading activity\n",
    "- **Algorithmic trading**: Algorithms react to each other, creating feedback loops\n",
    "- **Market maker behavior**: Inventory adjustments lead to correlated order flow\n",
    "\n",
    "### Why Hawkes Processes for Finance?\n",
    "\n",
    "| Property | Financial Interpretation |\n",
    "|----------|-------------------------|\n",
    "| Self-excitation | One order triggers more orders |\n",
    "| Clustering | Bursts of trading activity |\n",
    "| Memory | Past events influence future arrival rates |\n",
    "| Tractability | Closed-form likelihood for estimation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46925f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import expon, kstest\n",
    "from typing import Tuple, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aa7999",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Mathematical Foundation <a id='2-math-foundation'></a>\n",
    "\n",
    "### Intensity Function\n",
    "\n",
    "The **conditional intensity** of a univariate Hawkes process is:\n",
    "\n",
    "$$\\lambda(t) = \\mu + \\sum_{t_i < t} \\phi(t - t_i)$$\n",
    "\n",
    "where:\n",
    "- $\\mu > 0$: baseline intensity (exogenous rate)\n",
    "- $\\phi(\\cdot)$: kernel function (excitation kernel)\n",
    "- $t_i$: past event times\n",
    "\n",
    "### Exponential Kernel\n",
    "\n",
    "The most common choice is the **exponential kernel**:\n",
    "\n",
    "$$\\phi(t) = \\alpha \\cdot e^{-\\beta t}$$\n",
    "\n",
    "This gives the intensity:\n",
    "\n",
    "$$\\lambda(t) = \\mu + \\alpha \\sum_{t_i < t} e^{-\\beta(t - t_i)}$$\n",
    "\n",
    "### Parameters\n",
    "\n",
    "| Parameter | Description | Interpretation |\n",
    "|-----------|-------------|----------------|\n",
    "| $\\mu$ | Baseline intensity | Rate of exogenous events |\n",
    "| $\\alpha$ | Jump size | Immediate impact of an event |\n",
    "| $\\beta$ | Decay rate | How quickly influence fades |\n",
    "| $\\alpha/\\beta$ | Branching ratio | Average number of offspring per event |\n",
    "\n",
    "### Stationarity Condition\n",
    "\n",
    "For the process to be stationary: $\\frac{\\alpha}{\\beta} < 1$\n",
    "\n",
    "This ensures events don't trigger infinite cascades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f506c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HawkesProcess:\n",
    "    \"\"\"\n",
    "    Univariate Hawkes Process with Exponential Kernel\n",
    "    \n",
    "    Intensity: λ(t) = μ + α * Σ exp(-β(t - t_i))\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mu: float, alpha: float, beta: float):\n",
    "        \"\"\"\n",
    "        Initialize Hawkes process parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        mu : float\n",
    "            Baseline intensity (> 0)\n",
    "        alpha : float\n",
    "            Jump size (> 0)\n",
    "        beta : float\n",
    "            Decay rate (> 0)\n",
    "        \"\"\"\n",
    "        assert mu > 0, \"mu must be positive\"\n",
    "        assert alpha > 0, \"alpha must be positive\"\n",
    "        assert beta > 0, \"beta must be positive\"\n",
    "        \n",
    "        self.mu = mu\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        \n",
    "    @property\n",
    "    def branching_ratio(self) -> float:\n",
    "        \"\"\"Calculate the branching ratio (criticality parameter).\"\"\"\n",
    "        return self.alpha / self.beta\n",
    "    \n",
    "    @property\n",
    "    def is_stationary(self) -> bool:\n",
    "        \"\"\"Check if the process is stationary.\"\"\"\n",
    "        return self.branching_ratio < 1\n",
    "    \n",
    "    @property\n",
    "    def expected_intensity(self) -> float:\n",
    "        \"\"\"Expected intensity in stationary state.\"\"\"\n",
    "        if not self.is_stationary:\n",
    "            return np.inf\n",
    "        return self.mu / (1 - self.branching_ratio)\n",
    "    \n",
    "    def intensity(self, t: float, events: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate intensity at time t given past events.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        t : float\n",
    "            Current time\n",
    "        events : np.ndarray\n",
    "            Array of past event times\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float : Intensity at time t\n",
    "        \"\"\"\n",
    "        past_events = events[events < t]\n",
    "        if len(past_events) == 0:\n",
    "            return self.mu\n",
    "        \n",
    "        excitation = self.alpha * np.sum(np.exp(-self.beta * (t - past_events)))\n",
    "        return self.mu + excitation\n",
    "    \n",
    "    def intensity_path(self, t_grid: np.ndarray, events: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate intensity over a time grid.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        t_grid : np.ndarray\n",
    "            Time points to evaluate intensity\n",
    "        events : np.ndarray\n",
    "            Event times\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        np.ndarray : Intensity values at each time point\n",
    "        \"\"\"\n",
    "        return np.array([self.intensity(t, events) for t in t_grid])\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"HawkesProcess(μ={self.mu:.4f}, α={self.alpha:.4f}, β={self.beta:.4f}, \"\n",
    "                f\"branching_ratio={self.branching_ratio:.4f})\")\n",
    "\n",
    "\n",
    "# Example: Create a Hawkes process\n",
    "hp = HawkesProcess(mu=0.5, alpha=0.8, beta=1.2)\n",
    "print(hp)\n",
    "print(f\"Stationary: {hp.is_stationary}\")\n",
    "print(f\"Expected intensity: {hp.expected_intensity:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d5408c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Simulating Hawkes Processes <a id='3-simulation'></a>\n",
    "\n",
    "### Ogata's Thinning Algorithm\n",
    "\n",
    "The most common method to simulate Hawkes processes is **Ogata's thinning algorithm**:\n",
    "\n",
    "1. Start with current time $t = 0$ and empty event list\n",
    "2. Calculate upper bound $\\lambda^* \\geq \\lambda(t)$ for all $t$ in next interval\n",
    "3. Generate candidate inter-arrival time $\\Delta t \\sim \\text{Exp}(\\lambda^*)$\n",
    "4. Accept the event with probability $\\lambda(t + \\Delta t) / \\lambda^*$\n",
    "5. Update time and repeat\n",
    "\n",
    "### Why Thinning Works\n",
    "\n",
    "- We simulate a homogeneous Poisson process with rate $\\lambda^*$\n",
    "- Then \"thin\" (reject) events to match the true intensity\n",
    "- The upper bound $\\lambda^*$ can be set as $\\lambda(t)$ right after an event (when it's highest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe946d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_hawkes(mu: float, alpha: float, beta: float, \n",
    "                    T: float, seed: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Simulate a univariate Hawkes process using Ogata's thinning algorithm.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mu : float\n",
    "        Baseline intensity\n",
    "    alpha : float\n",
    "        Jump size\n",
    "    beta : float\n",
    "        Decay rate\n",
    "    T : float\n",
    "        End time for simulation\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    np.ndarray : Array of event times\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    events = []\n",
    "    t = 0\n",
    "    \n",
    "    # Initial intensity is just baseline\n",
    "    lambda_current = mu\n",
    "    \n",
    "    while t < T:\n",
    "        # Upper bound on intensity\n",
    "        lambda_bar = lambda_current\n",
    "        \n",
    "        # Generate candidate inter-arrival time\n",
    "        u = np.random.uniform()\n",
    "        dt = -np.log(u) / lambda_bar  # Exponential with rate lambda_bar\n",
    "        \n",
    "        t = t + dt\n",
    "        \n",
    "        if t >= T:\n",
    "            break\n",
    "        \n",
    "        # Calculate actual intensity at new time\n",
    "        # Intensity decays between events\n",
    "        if len(events) == 0:\n",
    "            lambda_t = mu\n",
    "        else:\n",
    "            past_events = np.array(events)\n",
    "            lambda_t = mu + alpha * np.sum(np.exp(-beta * (t - past_events)))\n",
    "        \n",
    "        # Accept with probability lambda_t / lambda_bar\n",
    "        if np.random.uniform() <= lambda_t / lambda_bar:\n",
    "            events.append(t)\n",
    "            # Update current intensity (jumps up by alpha)\n",
    "            lambda_current = lambda_t + alpha\n",
    "        else:\n",
    "            # Update current intensity (continued decay)\n",
    "            lambda_current = lambda_t\n",
    "    \n",
    "    return np.array(events)\n",
    "\n",
    "\n",
    "# Simulate a Hawkes process\n",
    "mu, alpha, beta = 0.5, 0.8, 1.2\n",
    "T = 100\n",
    "\n",
    "events = simulate_hawkes(mu, alpha, beta, T, seed=42)\n",
    "print(f\"Number of events: {len(events)}\")\n",
    "print(f\"First 10 event times: {events[:10].round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96610b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hawkes_simulation(events: np.ndarray, mu: float, alpha: float, \n",
    "                           beta: float, T: float, title: str = \"Hawkes Process Simulation\"):\n",
    "    \"\"\"\n",
    "    Visualize a Hawkes process simulation with intensity.\n",
    "    \"\"\"\n",
    "    hp = HawkesProcess(mu, alpha, beta)\n",
    "    \n",
    "    # Create time grid for intensity\n",
    "    t_grid = np.linspace(0, T, 1000)\n",
    "    intensity = hp.intensity_path(t_grid, events)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8), height_ratios=[2, 1])\n",
    "    \n",
    "    # Plot intensity\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(t_grid, intensity, 'b-', linewidth=1, label='Intensity λ(t)')\n",
    "    ax1.axhline(y=mu, color='gray', linestyle='--', alpha=0.7, label=f'Baseline μ = {mu}')\n",
    "    ax1.axhline(y=hp.expected_intensity, color='red', linestyle=':', \n",
    "                alpha=0.7, label=f'E[λ] = {hp.expected_intensity:.2f}')\n",
    "    \n",
    "    # Mark events on intensity plot\n",
    "    event_intensities = [hp.intensity(t, events) for t in events]\n",
    "    ax1.scatter(events, event_intensities, color='red', s=20, alpha=0.5, zorder=5)\n",
    "    \n",
    "    ax1.set_xlabel('Time')\n",
    "    ax1.set_ylabel('Intensity')\n",
    "    ax1.set_title(title)\n",
    "    ax1.legend(loc='upper right')\n",
    "    ax1.set_xlim(0, T)\n",
    "    \n",
    "    # Plot event arrivals\n",
    "    ax2 = axes[1]\n",
    "    ax2.eventplot([events], colors='blue', lineoffsets=0.5, linelengths=0.8)\n",
    "    ax2.set_xlabel('Time')\n",
    "    ax2.set_ylabel('Events')\n",
    "    ax2.set_yticks([])\n",
    "    ax2.set_xlim(0, T)\n",
    "    ax2.set_title('Event Arrivals')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "# Visualize the simulation\n",
    "fig = plot_hawkes_simulation(events, mu, alpha, beta, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3355d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom into a smaller window to see clustering\n",
    "T_zoom = 20\n",
    "events_zoom = events[events < T_zoom]\n",
    "\n",
    "fig = plot_hawkes_simulation(events_zoom, mu, alpha, beta, T_zoom, \n",
    "                             title=\"Hawkes Process - Zoomed View (Showing Clustering)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e09ff29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different parameter regimes\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 10))\n",
    "\n",
    "params = [\n",
    "    (0.5, 0.3, 1.0, \"Low excitation (α/β = 0.3)\"),\n",
    "    (0.5, 0.7, 1.0, \"Medium excitation (α/β = 0.7)\"),\n",
    "    (0.5, 0.95, 1.0, \"High excitation (α/β = 0.95, near-critical)\"),\n",
    "    (1.0, 0.5, 1.0, \"High baseline (μ = 1.0)\"),\n",
    "    (0.5, 0.8, 0.5, \"Slow decay (β = 0.5)\"),\n",
    "    (0.5, 0.8, 2.0, \"Fast decay (β = 2.0)\"),\n",
    "]\n",
    "\n",
    "T_sim = 50\n",
    "\n",
    "for ax, (mu_i, alpha_i, beta_i, title) in zip(axes.flat, params):\n",
    "    events_i = simulate_hawkes(mu_i, alpha_i, beta_i, T_sim, seed=42)\n",
    "    hp_i = HawkesProcess(mu_i, alpha_i, beta_i)\n",
    "    \n",
    "    t_grid = np.linspace(0, T_sim, 500)\n",
    "    intensity = hp_i.intensity_path(t_grid, events_i)\n",
    "    \n",
    "    ax.plot(t_grid, intensity, 'b-', linewidth=0.8)\n",
    "    ax.axhline(y=mu_i, color='gray', linestyle='--', alpha=0.5)\n",
    "    ax.set_title(f\"{title}\\n({len(events_i)} events)\")\n",
    "    ax.set_xlabel('Time')\n",
    "    ax.set_ylabel('λ(t)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Effect of Different Parameters on Hawkes Process', y=1.02, fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12cf946",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Parameter Estimation <a id='4-estimation'></a>\n",
    "\n",
    "### Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "For a Hawkes process observed over $[0, T]$ with events $\\{t_1, ..., t_n\\}$, the log-likelihood is:\n",
    "\n",
    "$$\\log L = \\sum_{i=1}^{n} \\log \\lambda(t_i) - \\int_0^T \\lambda(s) ds$$\n",
    "\n",
    "For the exponential kernel, the integral has a closed form:\n",
    "\n",
    "$$\\int_0^T \\lambda(s) ds = \\mu T + \\frac{\\alpha}{\\beta} \\sum_{i=1}^{n} \\left(1 - e^{-\\beta(T - t_i)}\\right)$$\n",
    "\n",
    "### Recursive Computation of Intensity\n",
    "\n",
    "Define $R_i = \\sum_{j<i} e^{-\\beta(t_i - t_j)}$, then:\n",
    "\n",
    "$$R_i = e^{-\\beta(t_i - t_{i-1})}(1 + R_{i-1})$$\n",
    "\n",
    "This allows $O(n)$ computation instead of $O(n^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hawkes_log_likelihood(params: np.ndarray, events: np.ndarray, T: float) -> float:\n",
    "    \"\"\"\n",
    "    Compute negative log-likelihood for Hawkes process with exponential kernel.\n",
    "    Uses efficient recursive computation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    params : np.ndarray\n",
    "        Parameters [mu, alpha, beta]\n",
    "    events : np.ndarray\n",
    "        Event times\n",
    "    T : float\n",
    "        Observation window end time\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Negative log-likelihood (for minimization)\n",
    "    \"\"\"\n",
    "    mu, alpha, beta = params\n",
    "    \n",
    "    # Check parameter validity\n",
    "    if mu <= 0 or alpha <= 0 or beta <= 0:\n",
    "        return np.inf\n",
    "    if alpha / beta >= 1:  # Non-stationary\n",
    "        return np.inf\n",
    "    \n",
    "    n = len(events)\n",
    "    if n == 0:\n",
    "        return mu * T  # Just baseline\n",
    "    \n",
    "    # Compute R values recursively (efficient O(n) computation)\n",
    "    R = np.zeros(n)\n",
    "    R[0] = 0\n",
    "    for i in range(1, n):\n",
    "        dt = events[i] - events[i-1]\n",
    "        R[i] = np.exp(-beta * dt) * (1 + R[i-1])\n",
    "    \n",
    "    # Log-likelihood: sum of log(lambda(t_i))\n",
    "    lambda_vals = mu + alpha * R\n",
    "    if np.any(lambda_vals <= 0):\n",
    "        return np.inf\n",
    "    \n",
    "    log_likelihood = np.sum(np.log(lambda_vals))\n",
    "    \n",
    "    # Compensator: integral of lambda from 0 to T\n",
    "    # = mu*T + (alpha/beta) * sum(1 - exp(-beta*(T - t_i)))\n",
    "    compensator = mu * T + (alpha / beta) * np.sum(1 - np.exp(-beta * (T - events)))\n",
    "    \n",
    "    # Negative log-likelihood for minimization\n",
    "    neg_ll = -(log_likelihood - compensator)\n",
    "    \n",
    "    return neg_ll\n",
    "\n",
    "\n",
    "def fit_hawkes_mle(events: np.ndarray, T: float, \n",
    "                  init_params: Optional[np.ndarray] = None) -> Tuple[np.ndarray, float]:\n",
    "    \"\"\"\n",
    "    Fit Hawkes process parameters using MLE.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    events : np.ndarray\n",
    "        Event times\n",
    "    T : float\n",
    "        Observation window end time\n",
    "    init_params : np.ndarray, optional\n",
    "        Initial parameter guess [mu, alpha, beta]\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[np.ndarray, float] : Estimated parameters and negative log-likelihood\n",
    "    \"\"\"\n",
    "    n = len(events)\n",
    "    \n",
    "    # Initial guesses if not provided\n",
    "    if init_params is None:\n",
    "        mu_init = n / (2 * T)  # Half the average rate\n",
    "        alpha_init = 0.5\n",
    "        beta_init = 1.0\n",
    "        init_params = np.array([mu_init, alpha_init, beta_init])\n",
    "    \n",
    "    # Bounds: all positive, alpha/beta < 1 enforced in likelihood\n",
    "    bounds = [(1e-6, None), (1e-6, None), (1e-6, None)]\n",
    "    \n",
    "    result = minimize(\n",
    "        hawkes_log_likelihood,\n",
    "        init_params,\n",
    "        args=(events, T),\n",
    "        method='L-BFGS-B',\n",
    "        bounds=bounds,\n",
    "        options={'disp': False}\n",
    "    )\n",
    "    \n",
    "    return result.x, result.fun\n",
    "\n",
    "\n",
    "# Fit the model to our simulated data\n",
    "true_params = np.array([mu, alpha, beta])\n",
    "estimated_params, neg_ll = fit_hawkes_mle(events, T)\n",
    "\n",
    "print(\"Parameter Estimation Results:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Parameter':<12} {'True':<12} {'Estimated':<12} {'Error %':<12}\")\n",
    "print(\"-\" * 50)\n",
    "param_names = ['mu', 'alpha', 'beta']\n",
    "for name, true, est in zip(param_names, true_params, estimated_params):\n",
    "    error = abs(est - true) / true * 100\n",
    "    print(f\"{name:<12} {true:<12.4f} {est:<12.4f} {error:<12.2f}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Branching ratio: True = {alpha/beta:.4f}, Estimated = {estimated_params[1]/estimated_params[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aace52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness-of-fit: Residual analysis using time transformation\n",
    "def compute_transformed_times(events: np.ndarray, mu: float, \n",
    "                              alpha: float, beta: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Compute transformed times using the compensator.\n",
    "    If model is correct, transformed times should be unit exponential.\n",
    "    \n",
    "    Λ(t_i) - Λ(t_{i-1}) should be Exp(1) distributed.\n",
    "    \"\"\"\n",
    "    n = len(events)\n",
    "    if n == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    # Compute compensator at each event time\n",
    "    compensator = np.zeros(n)\n",
    "    \n",
    "    for i, t in enumerate(events):\n",
    "        # Λ(t) = mu*t + (alpha/beta) * sum_{t_j < t}(1 - exp(-beta*(t - t_j)))\n",
    "        past_events = events[:i]\n",
    "        comp = mu * t\n",
    "        if len(past_events) > 0:\n",
    "            comp += (alpha / beta) * np.sum(1 - np.exp(-beta * (t - past_events)))\n",
    "        compensator[i] = comp\n",
    "    \n",
    "    # Inter-compensator times\n",
    "    transformed = np.diff(compensator)\n",
    "    transformed = np.insert(transformed, 0, compensator[0])  # First interval\n",
    "    \n",
    "    return transformed\n",
    "\n",
    "\n",
    "# Compute transformed times with estimated parameters\n",
    "mu_est, alpha_est, beta_est = estimated_params\n",
    "transformed_times = compute_transformed_times(events, mu_est, alpha_est, beta_est)\n",
    "\n",
    "# Plot QQ-plot against exponential distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1 = axes[0]\n",
    "ax1.hist(transformed_times, bins=30, density=True, alpha=0.7, label='Transformed times')\n",
    "x = np.linspace(0, max(transformed_times), 100)\n",
    "ax1.plot(x, expon.pdf(x), 'r-', linewidth=2, label='Exp(1) PDF')\n",
    "ax1.set_xlabel('Transformed inter-arrival time')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Residual Analysis: Histogram')\n",
    "ax1.legend()\n",
    "\n",
    "# QQ-plot\n",
    "ax2 = axes[1]\n",
    "sorted_transformed = np.sort(transformed_times)\n",
    "theoretical_quantiles = expon.ppf(np.linspace(0.01, 0.99, len(sorted_transformed)))\n",
    "empirical_quantiles = sorted_transformed[:len(theoretical_quantiles)]\n",
    "\n",
    "ax2.scatter(theoretical_quantiles, empirical_quantiles, alpha=0.5, s=10)\n",
    "max_val = max(max(theoretical_quantiles), max(empirical_quantiles))\n",
    "ax2.plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='45° line')\n",
    "ax2.set_xlabel('Theoretical Quantiles (Exp(1))')\n",
    "ax2.set_ylabel('Empirical Quantiles')\n",
    "ax2.set_title('Residual Analysis: QQ-Plot')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# KS test\n",
    "ks_stat, ks_pval = kstest(transformed_times, 'expon')\n",
    "print(f\"\\nKolmogorov-Smirnov test:\")\n",
    "print(f\"  Statistic: {ks_stat:.4f}\")\n",
    "print(f\"  P-value: {ks_pval:.4f}\")\n",
    "print(f\"  Result: {'Good fit' if ks_pval > 0.05 else 'Poor fit'} at 5% significance level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af0486",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Order Flow Modeling <a id='5-order-flow'></a>\n",
    "\n",
    "### Financial Interpretation\n",
    "\n",
    "In market microstructure, Hawkes processes model:\n",
    "\n",
    "1. **Trade arrivals**: Each trade increases the probability of subsequent trades\n",
    "2. **Order submissions**: New orders trigger algorithmic responses\n",
    "3. **Quote updates**: Market makers adjust quotes after trades\n",
    "\n",
    "### Generating Realistic Order Flow Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e66d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_order_flow(T: float, seed: int = 42) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Simulate realistic order flow using Hawkes process.\n",
    "    \n",
    "    Generates trade times, prices, and volumes.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Market parameters\n",
    "    mu_trade = 2.0       # Base trade arrival rate (per second)\n",
    "    alpha_trade = 1.5    # Excitation strength\n",
    "    beta_trade = 2.5     # Decay rate\n",
    "    \n",
    "    # Simulate trade times\n",
    "    trade_times = simulate_hawkes(mu_trade, alpha_trade, beta_trade, T, seed=seed)\n",
    "    n_trades = len(trade_times)\n",
    "    \n",
    "    # Generate trade characteristics\n",
    "    # Side: more likely to be same as previous during clusters\n",
    "    sides = np.zeros(n_trades, dtype=int)\n",
    "    sides[0] = np.random.choice([-1, 1])  # -1 = sell, 1 = buy\n",
    "    \n",
    "    for i in range(1, n_trades):\n",
    "        dt = trade_times[i] - trade_times[i-1]\n",
    "        # Probability of same side increases with clustering\n",
    "        prob_same = 0.5 + 0.3 * np.exp(-2 * dt)\n",
    "        sides[i] = sides[i-1] if np.random.uniform() < prob_same else -sides[i-1]\n",
    "    \n",
    "    # Generate prices (random walk with jumps at trades)\n",
    "    initial_price = 100.0\n",
    "    tick_size = 0.01\n",
    "    \n",
    "    prices = np.zeros(n_trades)\n",
    "    prices[0] = initial_price\n",
    "    \n",
    "    for i in range(1, n_trades):\n",
    "        # Price impact + noise\n",
    "        impact = sides[i] * tick_size * (1 + np.random.exponential(0.5))\n",
    "        noise = np.random.normal(0, tick_size * 0.5)\n",
    "        prices[i] = prices[i-1] + impact + noise\n",
    "    \n",
    "    # Generate volumes (clustered trades have correlated volumes)\n",
    "    base_volume = 100\n",
    "    volumes = np.zeros(n_trades)\n",
    "    volumes[0] = base_volume * np.random.lognormal(0, 0.5)\n",
    "    \n",
    "    for i in range(1, n_trades):\n",
    "        dt = trade_times[i] - trade_times[i-1]\n",
    "        # Volume clustering\n",
    "        if dt < 0.5:  # Clustered\n",
    "            volumes[i] = volumes[i-1] * np.random.lognormal(0, 0.3)\n",
    "        else:\n",
    "            volumes[i] = base_volume * np.random.lognormal(0, 0.5)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': trade_times,\n",
    "        'price': prices,\n",
    "        'volume': volumes.astype(int),\n",
    "        'side': np.where(sides == 1, 'buy', 'sell')\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Generate order flow data\n",
    "T_market = 3600  # 1 hour of trading\n",
    "order_flow = simulate_order_flow(T_market, seed=42)\n",
    "\n",
    "print(f\"Generated {len(order_flow)} trades over {T_market/60:.0f} minutes\")\n",
    "print(f\"\\nFirst 10 trades:\")\n",
    "order_flow.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde43e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the order flow\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Price path\n",
    "ax1 = axes[0]\n",
    "ax1.plot(order_flow['timestamp'], order_flow['price'], 'b-', linewidth=0.5)\n",
    "ax1.set_ylabel('Price')\n",
    "ax1.set_title('Order Flow Simulation (1 Hour)')\n",
    "\n",
    "# Volume\n",
    "ax2 = axes[1]\n",
    "colors = ['green' if s == 'buy' else 'red' for s in order_flow['side']]\n",
    "ax2.bar(order_flow['timestamp'], order_flow['volume'], color=colors, width=2, alpha=0.6)\n",
    "ax2.set_ylabel('Volume')\n",
    "ax2.legend(['Buy', 'Sell'], loc='upper right')\n",
    "\n",
    "# Trade inter-arrival times\n",
    "ax3 = axes[2]\n",
    "inter_arrivals = np.diff(order_flow['timestamp'].values)\n",
    "ax3.scatter(order_flow['timestamp'].values[1:], inter_arrivals, s=1, alpha=0.3)\n",
    "ax3.set_ylabel('Inter-arrival time (s)')\n",
    "ax3.set_xlabel('Time (seconds)')\n",
    "ax3.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Hawkes model to order flow data\n",
    "trade_times = order_flow['timestamp'].values\n",
    "\n",
    "# Fit the model\n",
    "params_order_flow, neg_ll = fit_hawkes_mle(trade_times, T_market)\n",
    "mu_fit, alpha_fit, beta_fit = params_order_flow\n",
    "\n",
    "print(\"Hawkes Process Fit to Order Flow:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Baseline intensity (μ): {mu_fit:.4f} trades/sec\")\n",
    "print(f\"Jump size (α): {alpha_fit:.4f}\")\n",
    "print(f\"Decay rate (β): {beta_fit:.4f}\")\n",
    "print(f\"Branching ratio: {alpha_fit/beta_fit:.4f}\")\n",
    "print(f\"Expected intensity: {mu_fit/(1 - alpha_fit/beta_fit):.4f} trades/sec\")\n",
    "print(f\"\\nHalf-life of excitation: {np.log(2)/beta_fit:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51658dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clustering patterns\n",
    "def analyze_order_clustering(events: np.ndarray, window_sizes: List[float]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyze order clustering at different time scales.\n",
    "    \"\"\"\n",
    "    T = events[-1]\n",
    "    results = []\n",
    "    \n",
    "    for window in window_sizes:\n",
    "        # Count events in each window\n",
    "        n_windows = int(T / window)\n",
    "        counts = np.zeros(n_windows)\n",
    "        \n",
    "        for i in range(n_windows):\n",
    "            start = i * window\n",
    "            end = (i + 1) * window\n",
    "            counts[i] = np.sum((events >= start) & (events < end))\n",
    "        \n",
    "        # Fano factor: var/mean (=1 for Poisson, >1 for clustered)\n",
    "        fano = np.var(counts) / np.mean(counts) if np.mean(counts) > 0 else np.nan\n",
    "        \n",
    "        results.append({\n",
    "            'window_size': window,\n",
    "            'mean_count': np.mean(counts),\n",
    "            'var_count': np.var(counts),\n",
    "            'fano_factor': fano\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Analyze clustering\n",
    "windows = [1, 5, 10, 30, 60, 120, 300]  # seconds\n",
    "clustering_analysis = analyze_order_clustering(trade_times, windows)\n",
    "\n",
    "print(\"Order Clustering Analysis:\")\n",
    "print(\"=\"*60)\n",
    "print(clustering_analysis.to_string(index=False))\n",
    "print(\"\\nFano factor > 1 indicates clustering (over-dispersion)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4894f88f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Multivariate Hawkes for Buy/Sell Orders <a id='6-multivariate'></a>\n",
    "\n",
    "### Bivariate Hawkes Process\n",
    "\n",
    "In practice, buy and sell orders influence each other. A **bivariate Hawkes process** models this:\n",
    "\n",
    "$$\\lambda_1(t) = \\mu_1 + \\alpha_{11} \\sum_{t_j^{(1)} < t} e^{-\\beta(t - t_j^{(1)})} + \\alpha_{12} \\sum_{t_j^{(2)} < t} e^{-\\beta(t - t_j^{(2)})}$$\n",
    "\n",
    "$$\\lambda_2(t) = \\mu_2 + \\alpha_{21} \\sum_{t_j^{(1)} < t} e^{-\\beta(t - t_j^{(1)})} + \\alpha_{22} \\sum_{t_j^{(2)} < t} e^{-\\beta(t - t_j^{(2)})}$$\n",
    "\n",
    "Where:\n",
    "- $\\alpha_{11}, \\alpha_{22}$: self-excitation (same side triggers same side)\n",
    "- $\\alpha_{12}, \\alpha_{21}$: cross-excitation (opposite side triggers this side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68f6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_bivariate_hawkes(\n",
    "    mu: np.ndarray,  # [mu1, mu2]\n",
    "    alpha: np.ndarray,  # [[alpha11, alpha12], [alpha21, alpha22]]\n",
    "    beta: float,\n",
    "    T: float,\n",
    "    seed: int = 42\n",
    ") -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulate bivariate Hawkes process (e.g., buy/sell orders).\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple: (all_events, event_types, event_times_by_type)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    events = []  # (time, type)\n",
    "    t = 0\n",
    "    \n",
    "    # Track cumulative excitation for each dimension\n",
    "    R = np.zeros(2)  # Excitation from each type\n",
    "    last_event_time = 0\n",
    "    \n",
    "    while t < T:\n",
    "        # Calculate current intensities\n",
    "        decay = np.exp(-beta * (t - last_event_time))\n",
    "        lambda_vec = mu + alpha @ (R * decay)\n",
    "        lambda_total = np.sum(lambda_vec)\n",
    "        \n",
    "        # Upper bound\n",
    "        lambda_bar = np.sum(mu) + np.sum(alpha) * np.sum(R)\n",
    "        lambda_bar = max(lambda_bar, lambda_total * 1.1)\n",
    "        \n",
    "        # Candidate time\n",
    "        dt = np.random.exponential(1 / lambda_bar)\n",
    "        t = t + dt\n",
    "        \n",
    "        if t >= T:\n",
    "            break\n",
    "        \n",
    "        # Update R with decay\n",
    "        R = R * np.exp(-beta * dt)\n",
    "        \n",
    "        # Calculate actual intensity\n",
    "        lambda_vec = mu + alpha @ R\n",
    "        lambda_total = np.sum(lambda_vec)\n",
    "        \n",
    "        # Accept/reject\n",
    "        if np.random.uniform() <= lambda_total / lambda_bar:\n",
    "            # Determine which type\n",
    "            probs = lambda_vec / lambda_total\n",
    "            event_type = np.random.choice([0, 1], p=probs)\n",
    "            \n",
    "            events.append((t, event_type))\n",
    "            R[event_type] += 1\n",
    "            last_event_time = t\n",
    "    \n",
    "    # Process output\n",
    "    events = np.array(events)\n",
    "    if len(events) == 0:\n",
    "        return np.array([]), np.array([]), (np.array([]), np.array([]))\n",
    "    \n",
    "    times = events[:, 0]\n",
    "    types = events[:, 1].astype(int)\n",
    "    \n",
    "    times_by_type = (times[types == 0], times[types == 1])\n",
    "    \n",
    "    return times, types, times_by_type\n",
    "\n",
    "\n",
    "# Parameters for buy/sell order flow\n",
    "mu_bi = np.array([1.0, 1.0])  # Baseline rates\n",
    "alpha_bi = np.array([\n",
    "    [0.4, 0.3],  # Buy orders: self-excite 0.4, cross-excite from sells 0.3\n",
    "    [0.3, 0.4]   # Sell orders: cross-excite from buys 0.3, self-excite 0.4\n",
    "])\n",
    "beta_bi = 1.5\n",
    "\n",
    "T_bi = 1000\n",
    "times_bi, types_bi, (buy_times, sell_times) = simulate_bivariate_hawkes(\n",
    "    mu_bi, alpha_bi, beta_bi, T_bi, seed=42\n",
    ")\n",
    "\n",
    "print(f\"Bivariate Hawkes Simulation:\")\n",
    "print(f\"Total events: {len(times_bi)}\")\n",
    "print(f\"Buy orders: {len(buy_times)}\")\n",
    "print(f\"Sell orders: {len(sell_times)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43afdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bivariate process\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Buy orders\n",
    "ax1 = axes[0]\n",
    "ax1.eventplot([buy_times], colors='green', lineoffsets=0.5, linelengths=0.8)\n",
    "ax1.set_ylabel('Buy Orders')\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Bivariate Hawkes Process: Buy and Sell Orders')\n",
    "\n",
    "# Sell orders\n",
    "ax2 = axes[1]\n",
    "ax2.eventplot([sell_times], colors='red', lineoffsets=0.5, linelengths=0.8)\n",
    "ax2.set_ylabel('Sell Orders')\n",
    "ax2.set_yticks([])\n",
    "\n",
    "# Combined order imbalance\n",
    "ax3 = axes[2]\n",
    "window = 5  # 5 second windows\n",
    "n_windows = int(T_bi / window)\n",
    "buy_counts = np.array([np.sum((buy_times >= i*window) & (buy_times < (i+1)*window)) \n",
    "                       for i in range(n_windows)])\n",
    "sell_counts = np.array([np.sum((sell_times >= i*window) & (sell_times < (i+1)*window)) \n",
    "                        for i in range(n_windows)])\n",
    "imbalance = (buy_counts - sell_counts) / (buy_counts + sell_counts + 1)\n",
    "time_bins = np.arange(n_windows) * window + window/2\n",
    "\n",
    "ax3.bar(time_bins, imbalance, width=window*0.8, \n",
    "        color=['green' if x > 0 else 'red' for x in imbalance], alpha=0.6)\n",
    "ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax3.set_ylabel('Order Imbalance')\n",
    "ax3.set_xlabel('Time (seconds)')\n",
    "ax3.set_xlim(0, min(200, T_bi))  # Show first 200 seconds\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a02b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-correlation analysis\n",
    "def compute_cross_intensity(events1: np.ndarray, events2: np.ndarray, \n",
    "                            max_lag: float, n_bins: int = 50) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Compute cross-intensity function between two event sequences.\n",
    "    Shows how events of type 2 cluster around events of type 1.\n",
    "    \"\"\"\n",
    "    lags = []\n",
    "    \n",
    "    for t1 in events1:\n",
    "        # Find events of type 2 within max_lag of t1\n",
    "        nearby = events2[(events2 > t1 - max_lag) & (events2 < t1 + max_lag)]\n",
    "        lags.extend(nearby - t1)\n",
    "    \n",
    "    lags = np.array(lags)\n",
    "    \n",
    "    # Histogram\n",
    "    counts, bins = np.histogram(lags, bins=n_bins, range=(-max_lag, max_lag))\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    # Normalize by number of type 1 events and bin width\n",
    "    bin_width = bins[1] - bins[0]\n",
    "    intensity = counts / (len(events1) * bin_width)\n",
    "    \n",
    "    return bin_centers, intensity\n",
    "\n",
    "\n",
    "# Compute cross-intensities\n",
    "max_lag = 10\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Buy -> Buy (autocorrelation)\n",
    "lags, intensity = compute_cross_intensity(buy_times, buy_times, max_lag)\n",
    "axes[0, 0].bar(lags, intensity, width=lags[1]-lags[0], alpha=0.7, color='green')\n",
    "axes[0, 0].set_title('Buy → Buy (Self-excitation)')\n",
    "axes[0, 0].set_xlabel('Lag (seconds)')\n",
    "axes[0, 0].set_ylabel('Intensity')\n",
    "\n",
    "# Sell -> Sell (autocorrelation)\n",
    "lags, intensity = compute_cross_intensity(sell_times, sell_times, max_lag)\n",
    "axes[0, 1].bar(lags, intensity, width=lags[1]-lags[0], alpha=0.7, color='red')\n",
    "axes[0, 1].set_title('Sell → Sell (Self-excitation)')\n",
    "axes[0, 1].set_xlabel('Lag (seconds)')\n",
    "axes[0, 1].set_ylabel('Intensity')\n",
    "\n",
    "# Buy -> Sell (cross-correlation)\n",
    "lags, intensity = compute_cross_intensity(buy_times, sell_times, max_lag)\n",
    "axes[1, 0].bar(lags, intensity, width=lags[1]-lags[0], alpha=0.7, color='purple')\n",
    "axes[1, 0].set_title('Buy → Sell (Cross-excitation)')\n",
    "axes[1, 0].set_xlabel('Lag (seconds)')\n",
    "axes[1, 0].set_ylabel('Intensity')\n",
    "\n",
    "# Sell -> Buy (cross-correlation)\n",
    "lags, intensity = compute_cross_intensity(sell_times, buy_times, max_lag)\n",
    "axes[1, 1].bar(lags, intensity, width=lags[1]-lags[0], alpha=0.7, color='orange')\n",
    "axes[1, 1].set_title('Sell → Buy (Cross-excitation)')\n",
    "axes[1, 1].set_xlabel('Lag (seconds)')\n",
    "axes[1, 1].set_ylabel('Intensity')\n",
    "\n",
    "plt.suptitle('Cross-Intensity Functions (Order Flow Dynamics)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592fa999",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Market Microstructure Applications <a id='7-applications'></a>\n",
    "\n",
    "### Application 1: Measuring Market Excitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49fea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_market_excitability(events: np.ndarray, window: float, T: float) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Measure how market excitability changes over time.\n",
    "    Fit Hawkes model to rolling windows.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    start_times = np.arange(0, T - window, window / 2)  # 50% overlap\n",
    "    \n",
    "    for start in start_times:\n",
    "        end = start + window\n",
    "        window_events = events[(events >= start) & (events < end)] - start\n",
    "        \n",
    "        if len(window_events) < 10:\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            params, _ = fit_hawkes_mle(window_events, window)\n",
    "            mu, alpha, beta = params\n",
    "            branching = alpha / beta\n",
    "            \n",
    "            results.append({\n",
    "                'time': start + window / 2,\n",
    "                'n_events': len(window_events),\n",
    "                'mu': mu,\n",
    "                'alpha': alpha,\n",
    "                'beta': beta,\n",
    "                'branching_ratio': branching,\n",
    "                'half_life': np.log(2) / beta\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Analyze excitability over time\n",
    "excitability = measure_market_excitability(trade_times, window=600, T=T_market)\n",
    "\n",
    "if len(excitability) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    \n",
    "    axes[0, 0].plot(excitability['time']/60, excitability['branching_ratio'], 'b-o')\n",
    "    axes[0, 0].set_xlabel('Time (minutes)')\n",
    "    axes[0, 0].set_ylabel('Branching Ratio')\n",
    "    axes[0, 0].set_title('Market Excitability Over Time')\n",
    "    axes[0, 0].axhline(y=1, color='red', linestyle='--', label='Critical threshold')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    axes[0, 1].plot(excitability['time']/60, excitability['half_life'], 'g-o')\n",
    "    axes[0, 1].set_xlabel('Time (minutes)')\n",
    "    axes[0, 1].set_ylabel('Half-life (seconds)')\n",
    "    axes[0, 1].set_title('Excitation Decay Speed')\n",
    "    \n",
    "    axes[1, 0].plot(excitability['time']/60, excitability['n_events']/10, 'r-o')\n",
    "    axes[1, 0].set_xlabel('Time (minutes)')\n",
    "    axes[1, 0].set_ylabel('Trade Rate (per minute)')\n",
    "    axes[1, 0].set_title('Trading Activity')\n",
    "    \n",
    "    axes[1, 1].scatter(excitability['n_events']/10, excitability['branching_ratio'], alpha=0.6)\n",
    "    axes[1, 1].set_xlabel('Trade Rate (per minute)')\n",
    "    axes[1, 1].set_ylabel('Branching Ratio')\n",
    "    axes[1, 1].set_title('Activity vs Excitability')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce734dd",
   "metadata": {},
   "source": [
    "### Application 2: Price Impact Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff319ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_hawkes_price_impact(order_flow: pd.DataFrame, \n",
    "                                  horizon: float = 10.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Estimate price impact using Hawkes-based order flow clustering.\n",
    "    \n",
    "    Key insight: Orders during high-intensity periods may have\n",
    "    different price impact than isolated orders.\n",
    "    \"\"\"\n",
    "    # Fit Hawkes to get intensity at each trade\n",
    "    trade_times = order_flow['timestamp'].values\n",
    "    params, _ = fit_hawkes_mle(trade_times, trade_times[-1])\n",
    "    mu, alpha, beta = params\n",
    "    \n",
    "    hp = HawkesProcess(mu, alpha, beta)\n",
    "    \n",
    "    # Calculate intensity at each trade\n",
    "    intensities = hp.intensity_path(trade_times, trade_times)\n",
    "    \n",
    "    # Categorize trades by intensity quintile\n",
    "    order_flow = order_flow.copy()\n",
    "    order_flow['intensity'] = intensities\n",
    "    order_flow['intensity_quintile'] = pd.qcut(order_flow['intensity'], 5, labels=False)\n",
    "    \n",
    "    # Calculate forward returns\n",
    "    order_flow['return_forward'] = order_flow['price'].pct_change().shift(-1) * 10000  # bps\n",
    "    \n",
    "    # Sign the return by trade direction\n",
    "    order_flow['signed_return'] = order_flow['return_forward'] * order_flow['side'].map({'buy': 1, 'sell': -1})\n",
    "    \n",
    "    # Impact by intensity quintile\n",
    "    impact_by_intensity = order_flow.groupby('intensity_quintile').agg({\n",
    "        'signed_return': ['mean', 'std', 'count'],\n",
    "        'intensity': 'mean'\n",
    "    }).round(4)\n",
    "    \n",
    "    return impact_by_intensity, order_flow\n",
    "\n",
    "\n",
    "# Analyze price impact\n",
    "impact_analysis, flow_with_intensity = estimate_hawkes_price_impact(order_flow)\n",
    "\n",
    "print(\"Price Impact by Order Flow Intensity:\")\n",
    "print(\"=\"*60)\n",
    "print(impact_analysis)\n",
    "print(\"\\nInterpretation: Higher intensity periods may show different\")\n",
    "print(\"price impact characteristics due to clustering effects.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1081611d",
   "metadata": {},
   "source": [
    "### Application 3: Detecting Regime Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ca5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_intensity_anomalies(events: np.ndarray, mu: float, alpha: float, \n",
    "                                beta: float, threshold: float = 3.0) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Detect periods of abnormally high intensity (potential flash events).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    threshold : float\n",
    "        Number of standard deviations above mean for anomaly\n",
    "    \"\"\"\n",
    "    hp = HawkesProcess(mu, alpha, beta)\n",
    "    \n",
    "    # Compute intensity at each event\n",
    "    intensities = np.array([hp.intensity(t, events) for t in events])\n",
    "    \n",
    "    # Expected intensity in stationary state\n",
    "    mean_intensity = hp.expected_intensity\n",
    "    std_intensity = np.std(intensities)\n",
    "    \n",
    "    # Find anomalies\n",
    "    anomaly_threshold = mean_intensity + threshold * std_intensity\n",
    "    anomaly_mask = intensities > anomaly_threshold\n",
    "    \n",
    "    return events[anomaly_mask], intensities[anomaly_mask], anomaly_threshold\n",
    "\n",
    "\n",
    "# Detect anomalies in our simulated data\n",
    "anomaly_times, anomaly_intensities, threshold = detect_intensity_anomalies(\n",
    "    trade_times, *params_order_flow, threshold=2.5\n",
    ")\n",
    "\n",
    "print(f\"Detected {len(anomaly_times)} anomalous periods (>{threshold:.2f} intensity)\")\n",
    "print(f\"That's {len(anomaly_times)/len(trade_times)*100:.2f}% of all trades\")\n",
    "\n",
    "# Visualize\n",
    "hp_fitted = HawkesProcess(*params_order_flow)\n",
    "t_grid = np.linspace(0, T_market, 2000)\n",
    "intensity_path = hp_fitted.intensity_path(t_grid, trade_times)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 5))\n",
    "\n",
    "ax.plot(t_grid/60, intensity_path, 'b-', linewidth=0.5, alpha=0.7, label='Intensity')\n",
    "ax.axhline(y=threshold, color='red', linestyle='--', label=f'Anomaly threshold ({threshold:.2f})')\n",
    "ax.scatter(anomaly_times/60, anomaly_intensities, color='red', s=20, alpha=0.5, label='Anomalies')\n",
    "ax.set_xlabel('Time (minutes)')\n",
    "ax.set_ylabel('Intensity')\n",
    "ax.set_title('Intensity Anomaly Detection')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc48f6c",
   "metadata": {},
   "source": [
    "### Application 4: Order Flow Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4c142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_event_time(events: np.ndarray, t_current: float,\n",
    "                            mu: float, alpha: float, beta: float,\n",
    "                            n_samples: int = 1000) -> dict:\n",
    "    \"\"\"\n",
    "    Predict the distribution of time until next event using Monte Carlo.\n",
    "    \"\"\"\n",
    "    hp = HawkesProcess(mu, alpha, beta)\n",
    "    \n",
    "    # Current intensity\n",
    "    lambda_current = hp.intensity(t_current, events)\n",
    "    \n",
    "    # Simulate next arrival times\n",
    "    next_times = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        t = t_current\n",
    "        lambda_t = lambda_current\n",
    "        \n",
    "        while True:\n",
    "            # Upper bound\n",
    "            lambda_bar = lambda_t\n",
    "            \n",
    "            # Candidate time\n",
    "            dt = np.random.exponential(1 / lambda_bar)\n",
    "            t_new = t + dt\n",
    "            \n",
    "            # New intensity (with decay)\n",
    "            past = events[events < t_new]\n",
    "            lambda_new = mu + alpha * np.sum(np.exp(-beta * (t_new - past)))\n",
    "            \n",
    "            # Accept/reject\n",
    "            if np.random.uniform() <= lambda_new / lambda_bar:\n",
    "                next_times.append(t_new - t_current)\n",
    "                break\n",
    "            \n",
    "            t = t_new\n",
    "            lambda_t = lambda_new\n",
    "    \n",
    "    next_times = np.array(next_times)\n",
    "    \n",
    "    return {\n",
    "        'mean': np.mean(next_times),\n",
    "        'median': np.median(next_times),\n",
    "        'std': np.std(next_times),\n",
    "        'quantile_5': np.percentile(next_times, 5),\n",
    "        'quantile_95': np.percentile(next_times, 95),\n",
    "        'samples': next_times\n",
    "    }\n",
    "\n",
    "\n",
    "# Predict next event at different states\n",
    "print(\"Next Event Time Predictions:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# After a cluster (high intensity)\n",
    "t_high = trade_times[100]  # Just after several events\n",
    "pred_high = predict_next_event_time(trade_times[:100], t_high, *params_order_flow, n_samples=500)\n",
    "\n",
    "# During quiet period\n",
    "# Find a time with long inter-arrival\n",
    "inter_arrivals = np.diff(trade_times)\n",
    "quiet_idx = np.argmax(inter_arrivals) + 1\n",
    "t_quiet = trade_times[quiet_idx]\n",
    "pred_quiet = predict_next_event_time(trade_times[:quiet_idx], t_quiet, *params_order_flow, n_samples=500)\n",
    "\n",
    "print(f\"After cluster (high intensity):\")\n",
    "print(f\"  Expected next event in: {pred_high['mean']:.3f} ± {pred_high['std']:.3f} seconds\")\n",
    "print(f\"  90% CI: [{pred_high['quantile_5']:.3f}, {pred_high['quantile_95']:.3f}]\")\n",
    "\n",
    "print(f\"\\nDuring quiet period (low intensity):\")\n",
    "print(f\"  Expected next event in: {pred_quiet['mean']:.3f} ± {pred_quiet['std']:.3f} seconds\")\n",
    "print(f\"  90% CI: [{pred_quiet['quantile_5']:.3f}, {pred_quiet['quantile_95']:.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38e75fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Summary & Interview Questions <a id='8-summary'></a>\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "| Concept | Description |\n",
    "|---------|-------------|\n",
    "| **Self-excitation** | Events trigger more events - fundamental to order flow |\n",
    "| **Branching ratio** | $\\alpha/\\beta$ - criticality parameter (<1 for stability) |\n",
    "| **Exponential kernel** | Tractable, captures decaying influence |\n",
    "| **MLE estimation** | Closed-form compensator enables efficient fitting |\n",
    "| **Multivariate** | Buy/sell cross-excitation reveals market dynamics |\n",
    "\n",
    "### Financial Applications\n",
    "\n",
    "1. **Order flow modeling**: Capture clustering in trade arrivals\n",
    "2. **Market stress detection**: High branching ratio = fragile market\n",
    "3. **Execution algorithms**: Predict when to trade based on intensity\n",
    "4. **Flash crash analysis**: Understand cascading effects\n",
    "5. **Market making**: Adjust quotes based on predicted order flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd38ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Basic Hawkes simulation\n",
    "ax1 = axes[0, 0]\n",
    "events_demo = simulate_hawkes(0.5, 0.8, 1.2, 30, seed=123)\n",
    "hp_demo = HawkesProcess(0.5, 0.8, 1.2)\n",
    "t_demo = np.linspace(0, 30, 300)\n",
    "ax1.plot(t_demo, hp_demo.intensity_path(t_demo, events_demo), 'b-')\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "for t in events_demo:\n",
    "    ax1.axvline(x=t, color='red', alpha=0.2, linewidth=0.5)\n",
    "ax1.set_xlabel('Time')\n",
    "ax1.set_ylabel('Intensity')\n",
    "ax1.set_title('1. Hawkes Process Intensity\\n(Events shown as vertical lines)')\n",
    "\n",
    "# 2. Branching ratio effect\n",
    "ax2 = axes[0, 1]\n",
    "branching_ratios = [0.3, 0.6, 0.9]\n",
    "for br in branching_ratios:\n",
    "    events_br = simulate_hawkes(0.5, br, 1.0, 50, seed=42)\n",
    "    ax2.hist(np.diff(events_br), bins=30, alpha=0.5, density=True, \n",
    "             label=f'α/β = {br}')\n",
    "ax2.set_xlabel('Inter-arrival time')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title('2. Effect of Branching Ratio on\\nInter-arrival Distribution')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Cross-excitation\n",
    "ax3 = axes[1, 0]\n",
    "lags, intensity = compute_cross_intensity(buy_times[:500], sell_times[:500], 5)\n",
    "ax3.bar(lags, intensity, width=0.18, alpha=0.7)\n",
    "ax3.set_xlabel('Lag (seconds)')\n",
    "ax3.set_ylabel('Cross-intensity')\n",
    "ax3.set_title('3. Cross-Excitation: Buy → Sell\\n(How buys trigger sells)')\n",
    "\n",
    "# 4. Market applications\n",
    "ax4 = axes[1, 1]\n",
    "applications = ['Order Flow\\nModeling', 'Flash Crash\\nDetection', \n",
    "                'Execution\\nOptimization', 'Market\\nMaking']\n",
    "importance = [0.9, 0.85, 0.8, 0.75]\n",
    "colors = plt.cm.Blues(np.linspace(0.4, 0.8, 4))\n",
    "bars = ax4.barh(applications, importance, color=colors)\n",
    "ax4.set_xlabel('Relevance')\n",
    "ax4.set_title('4. Hawkes Process Applications\\nin Market Microstructure')\n",
    "ax4.set_xlim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0965d72",
   "metadata": {},
   "source": [
    "### Common Interview Questions\n",
    "\n",
    "**Q1: What is a Hawkes process and why is it used in finance?**\n",
    "> A Hawkes process is a self-exciting point process where each event increases the probability of future events. In finance, it models order flow clustering - one trade often triggers more trades due to algorithmic reactions, market maker adjustments, and information cascades.\n",
    "\n",
    "**Q2: Explain the branching ratio and its significance.**\n",
    "> The branching ratio α/β represents the average number of \"offspring\" events triggered by each event. For stationarity, it must be < 1. Values close to 1 indicate a fragile market prone to cascading events. It's analogous to the reproduction number R in epidemiology.\n",
    "\n",
    "**Q3: How would you detect flash crashes using Hawkes processes?**\n",
    "> Monitor the real-time intensity and branching ratio. Abnormally high intensity or a branching ratio approaching 1 signals potential instability. Additionally, track regime changes in parameters across rolling windows to detect shifts toward critical regimes.\n",
    "\n",
    "**Q4: What are limitations of exponential kernels?**\n",
    "> Exponential kernels assume constant decay rate, but real markets show more complex behavior. Power-law kernels (long memory) may better capture slow-decaying effects. Also, real markets have intraday seasonality that basic Hawkes models don't capture.\n",
    "\n",
    "**Q5: How would you use Hawkes processes for execution optimization?**\n",
    "> Estimate current intensity to predict near-term order flow. Execute during low-intensity periods to minimize market impact. In high-intensity periods, your order gets \"hidden\" among others but may face more price volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a23bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference: Key formulas\n",
    "print(\"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║               HAWKES PROCESS - QUICK REFERENCE                   ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  INTENSITY:     λ(t) = μ + α Σ exp(-β(t - tᵢ))                  ║\n",
    "║                                                                  ║\n",
    "║  PARAMETERS:                                                     ║\n",
    "║    • μ = baseline intensity (exogenous rate)                     ║\n",
    "║    • α = jump size (excitation magnitude)                        ║\n",
    "║    • β = decay rate (how fast influence fades)                   ║\n",
    "║                                                                  ║\n",
    "║  KEY METRICS:                                                    ║\n",
    "║    • Branching ratio: n* = α/β (must be < 1)                     ║\n",
    "║    • Expected intensity: E[λ] = μ/(1 - n*)                       ║\n",
    "║    • Half-life: t₁/₂ = ln(2)/β                                   ║\n",
    "║                                                                  ║\n",
    "║  LOG-LIKELIHOOD:                                                 ║\n",
    "║    log L = Σ log λ(tᵢ) - ∫₀ᵀ λ(s) ds                            ║\n",
    "║                                                                  ║\n",
    "║  COMPENSATOR (closed form):                                      ║\n",
    "║    ∫₀ᵀ λ(s) ds = μT + (α/β) Σ (1 - exp(-β(T - tᵢ)))             ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\n✅ Notebook completed! Key skills learned:\")\n",
    "print(\"   • Hawkes process theory and simulation\")\n",
    "print(\"   • Maximum likelihood estimation\")\n",
    "print(\"   • Order flow modeling and analysis\")\n",
    "print(\"   • Market microstructure applications\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
