{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ea63b4",
   "metadata": {},
   "source": [
    "# Week 18: Cumulative Trading Strategy (Weeks 1-18)\n",
    "\n",
    "## Integration: Foundation through Advanced Portfolio Optimization\n",
    "\n",
    "**New in Week 18:** Mean-Variance, Black-Litterman, Risk Parity, HRP\n",
    "\n",
    "| Week Range | Topics Integrated |\n",
    "|------------|------------------|\n",
    "| 1-4 | Foundation, Statistics, Time Series, ML Basics |\n",
    "| 5-8 | Portfolio Optimization, Linear/Factor Models, Trees, Volatility |\n",
    "| 9-12 | Unsupervised Learning, Forecasting, Feature Engineering, Backtesting |\n",
    "| 13-17 | Neural Networks, RNN/LSTM, Transformers, RL, Options/Hedging |\n",
    "| **18** | **Mean-Variance, Black-Litterman, Risk Parity, HRP** |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8560520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from scipy.optimize import minimize\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "from scipy.spatial.distance import squareform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_RATE = 0.05\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"âœ… Libraries loaded (Weeks 1-18)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff116928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download multi-asset data\n",
    "tickers = ['SPY', 'QQQ', 'IWM', 'EFA', 'EEM', 'GLD', 'TLT', 'IEF', 'VNQ', 'DBC']\n",
    "data = yf.download(tickers, start='2018-01-01', end='2024-01-01', progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "print(f\"âœ… Data: {len(prices)} days, {len(tickers)} assets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb41a2d",
   "metadata": {},
   "source": [
    "## Week 18: Portfolio Optimization Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7174e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PortfolioOptimizer:\n",
    "    \"\"\"Multiple portfolio optimization methods (Week 18).\"\"\"\n",
    "    \n",
    "    def __init__(self, returns):\n",
    "        self.returns = returns\n",
    "        self.n_assets = returns.shape[1]\n",
    "        self.mean_returns = returns.mean() * TRADING_DAYS\n",
    "        self.cov_matrix = returns.cov() * TRADING_DAYS\n",
    "        \n",
    "    def mean_variance(self, target='sharpe'):\n",
    "        \"\"\"Mean-Variance Optimization (Week 5).\"\"\"\n",
    "        def neg_sharpe(w):\n",
    "            ret = np.dot(w, self.mean_returns)\n",
    "            vol = np.sqrt(np.dot(w.T, np.dot(self.cov_matrix, w)))\n",
    "            return -(ret - RISK_FREE_RATE) / vol\n",
    "        \n",
    "        def portfolio_vol(w):\n",
    "            return np.sqrt(np.dot(w.T, np.dot(self.cov_matrix, w)))\n",
    "        \n",
    "        constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]\n",
    "        bounds = tuple((0, 1) for _ in range(self.n_assets))\n",
    "        init = np.ones(self.n_assets) / self.n_assets\n",
    "        \n",
    "        obj = neg_sharpe if target == 'sharpe' else portfolio_vol\n",
    "        result = minimize(obj, init, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        return result.x\n",
    "    \n",
    "    def risk_parity(self):\n",
    "        \"\"\"Risk Parity (Week 18).\"\"\"\n",
    "        def risk_budget_obj(w):\n",
    "            vol = np.sqrt(np.dot(w.T, np.dot(self.cov_matrix, w)))\n",
    "            mrc = np.dot(self.cov_matrix, w) / vol\n",
    "            rc = w * mrc\n",
    "            target_rc = vol / self.n_assets\n",
    "            return np.sum((rc - target_rc)**2)\n",
    "        \n",
    "        constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]\n",
    "        bounds = tuple((0.01, 1) for _ in range(self.n_assets))\n",
    "        init = np.ones(self.n_assets) / self.n_assets\n",
    "        \n",
    "        result = minimize(risk_budget_obj, init, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        return result.x\n",
    "    \n",
    "    def black_litterman(self, views, view_confidences):\n",
    "        \"\"\"Black-Litterman (Week 18).\"\"\"\n",
    "        tau = 0.05\n",
    "        delta = 2.5  # Risk aversion\n",
    "        \n",
    "        # Market equilibrium weights (cap-weighted proxy)\n",
    "        mkt_weights = np.ones(self.n_assets) / self.n_assets\n",
    "        \n",
    "        # Implied returns\n",
    "        pi = delta * np.dot(self.cov_matrix, mkt_weights)\n",
    "        \n",
    "        # Views matrix P and Q\n",
    "        P = np.array(views['matrix'])\n",
    "        Q = np.array(views['returns'])\n",
    "        omega = np.diag(view_confidences)\n",
    "        \n",
    "        # Black-Litterman formula\n",
    "        tau_sigma = tau * self.cov_matrix\n",
    "        M = np.linalg.inv(np.linalg.inv(tau_sigma) + P.T @ np.linalg.inv(omega) @ P)\n",
    "        bl_returns = M @ (np.linalg.inv(tau_sigma) @ pi + P.T @ np.linalg.inv(omega) @ Q)\n",
    "        \n",
    "        # Optimize with BL returns\n",
    "        self.mean_returns = bl_returns\n",
    "        return self.mean_variance(target='sharpe')\n",
    "    \n",
    "    def hierarchical_risk_parity(self):\n",
    "        \"\"\"Hierarchical Risk Parity - HRP (Week 18).\"\"\"\n",
    "        # Correlation-based distance\n",
    "        corr = self.returns.corr()\n",
    "        dist = np.sqrt((1 - corr) / 2)\n",
    "        \n",
    "        # Hierarchical clustering\n",
    "        dist_condensed = squareform(dist.values)\n",
    "        link = linkage(dist_condensed, method='single')\n",
    "        sorted_idx = leaves_list(link)\n",
    "        \n",
    "        # Recursive bisection\n",
    "        def get_cluster_var(cov, items):\n",
    "            cov_slice = cov.iloc[items, items]\n",
    "            ivp = 1 / np.diag(cov_slice)\n",
    "            ivp /= ivp.sum()\n",
    "            return np.dot(ivp, np.dot(cov_slice, ivp))\n",
    "        \n",
    "        def get_recursive_bisection(cov, sorted_idx):\n",
    "            weights = pd.Series(1.0, index=sorted_idx)\n",
    "            clusters = [sorted_idx]\n",
    "            \n",
    "            while len(clusters) > 0:\n",
    "                clusters = [c[j:k] for c in clusters for j, k in \n",
    "                           ((0, len(c)//2), (len(c)//2, len(c))) if len(c) > 1]\n",
    "                for i in range(0, len(clusters), 2):\n",
    "                    c0, c1 = clusters[i], clusters[i+1]\n",
    "                    var0 = get_cluster_var(cov, c0)\n",
    "                    var1 = get_cluster_var(cov, c1)\n",
    "                    alpha = 1 - var0 / (var0 + var1)\n",
    "                    weights[c0] *= alpha\n",
    "                    weights[c1] *= 1 - alpha\n",
    "            return weights\n",
    "        \n",
    "        cov = self.returns.cov() * TRADING_DAYS\n",
    "        hrp_weights = get_recursive_bisection(cov, sorted_idx.tolist())\n",
    "        return hrp_weights.sort_index().values\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = PortfolioOptimizer(returns)\n",
    "\n",
    "# Calculate all portfolios\n",
    "portfolios = {\n",
    "    'Equal Weight': np.ones(len(tickers)) / len(tickers),\n",
    "    'Max Sharpe': optimizer.mean_variance('sharpe'),\n",
    "    'Min Variance': optimizer.mean_variance('minvol'),\n",
    "    'Risk Parity': optimizer.risk_parity(),\n",
    "    'HRP': optimizer.hierarchical_risk_parity()\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ’¼ PORTFOLIO WEIGHTS (Week 18)\")\n",
    "print(\"=\"*80)\n",
    "weights_df = pd.DataFrame(portfolios, index=tickers)\n",
    "print(weights_df.round(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19adf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtest all portfolios\n",
    "print(\"\\nðŸ“Š PORTFOLIO PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = []\n",
    "for name, weights in portfolios.items():\n",
    "    port_returns = (returns * weights).sum(axis=1)\n",
    "    ann_ret = port_returns.mean() * TRADING_DAYS\n",
    "    ann_vol = port_returns.std() * np.sqrt(TRADING_DAYS)\n",
    "    sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol\n",
    "    \n",
    "    cum = (1 + port_returns).cumprod()\n",
    "    max_dd = ((cum - cum.expanding().max()) / cum.expanding().max()).min()\n",
    "    \n",
    "    results.append({\n",
    "        'Portfolio': name,\n",
    "        'Return': ann_ret,\n",
    "        'Volatility': ann_vol,\n",
    "        'Sharpe': sharpe,\n",
    "        'Max DD': max_dd\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).set_index('Portfolio')\n",
    "print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489b9e4d",
   "metadata": {},
   "source": [
    "## Summary: Weeks 1-18 Integration\n",
    "\n",
    "| Week | Concept | Implementation |\n",
    "|------|---------|---------------|\n",
    "| 1-2 | Data & Statistics | Multi-asset returns, correlations |\n",
    "| 5 | Basic Portfolio | Mean-Variance Optimization |\n",
    "| **18** | **Advanced Portfolio** | **Risk Parity, Black-Litterman, HRP** |\n",
    "\n",
    "âœ… Complete portfolio optimization framework with multiple methods!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
