{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf628de",
   "metadata": {},
   "source": [
    "# Day 2: Black-Litterman Model with Investor Views\n",
    "\n",
    "## Week 18 - Portfolio Optimization\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. **Understand** the Black-Litterman model and its advantages over mean-variance optimization\n",
    "2. **Derive** equilibrium returns from market capitalization weights\n",
    "3. **Implement** investor views (absolute and relative) in the model\n",
    "4. **Calculate** posterior expected returns using Bayesian updating\n",
    "5. **Build** optimal portfolios incorporating your market views\n",
    "\n",
    "---\n",
    "\n",
    "## Why Black-Litterman?\n",
    "\n",
    "**Problems with Traditional Mean-Variance Optimization:**\n",
    "- Highly sensitive to expected return inputs\n",
    "- Often produces extreme, concentrated portfolios\n",
    "- Small changes in inputs → large changes in weights\n",
    "- Historical returns are poor predictors of future returns\n",
    "\n",
    "**Black-Litterman Solution:**\n",
    "- Start with equilibrium (market-implied) returns as a neutral baseline\n",
    "- Blend investor views with equilibrium using Bayesian inference\n",
    "- Produces more stable, intuitive portfolio weights\n",
    "- Allows explicit incorporation of confidence in views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d118fec0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Theoretical Foundation\n",
    "\n",
    "### 1.1 The Black-Litterman Model Framework\n",
    "\n",
    "The Black-Litterman model combines two sources of information:\n",
    "\n",
    "1. **Prior (Equilibrium Returns):** Market-implied expected returns derived from CAPM\n",
    "2. **Views:** Investor's subjective expectations about asset returns\n",
    "\n",
    "### Key Equations\n",
    "\n",
    "**Equilibrium Returns (Prior):**\n",
    "$$\\Pi = \\delta \\Sigma w_{mkt}$$\n",
    "\n",
    "Where:\n",
    "- $\\Pi$ = Vector of equilibrium expected excess returns\n",
    "- $\\delta$ = Risk aversion coefficient\n",
    "- $\\Sigma$ = Covariance matrix of returns\n",
    "- $w_{mkt}$ = Market capitalization weights\n",
    "\n",
    "**Investor Views:**\n",
    "$$P \\cdot \\mu = Q + \\epsilon, \\quad \\epsilon \\sim N(0, \\Omega)$$\n",
    "\n",
    "Where:\n",
    "- $P$ = Pick matrix (which assets are involved in each view)\n",
    "- $Q$ = Vector of view returns\n",
    "- $\\Omega$ = Uncertainty matrix for views\n",
    "\n",
    "**Posterior Expected Returns:**\n",
    "$$E[R] = [(\\tau\\Sigma)^{-1} + P'\\Omega^{-1}P]^{-1}[(\\tau\\Sigma)^{-1}\\Pi + P'\\Omega^{-1}Q]$$\n",
    "\n",
    "**Posterior Covariance:**\n",
    "$$\\bar{\\Sigma} = \\Sigma + [(\\tau\\Sigma)^{-1} + P'\\Omega^{-1}P]^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702dcdb",
   "metadata": {},
   "source": [
    "### 1.2 Parameter Definitions\n",
    "\n",
    "| Parameter | Description | Typical Values |\n",
    "|-----------|-------------|----------------|\n",
    "| $\\tau$ | Scaling factor for prior uncertainty | 0.01 - 0.05 |\n",
    "| $\\delta$ | Risk aversion coefficient | 2.5 - 3.5 |\n",
    "| $\\Omega$ | View uncertainty (diagonal matrix) | Proportional to $\\tau \\cdot P\\Sigma P'$ |\n",
    "\n",
    "**Interpretation of $\\tau$:**\n",
    "- Small $\\tau$ → More confidence in equilibrium, views have less impact\n",
    "- Large $\\tau$ → Less confidence in equilibrium, views dominate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5e3757",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Data Collection and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee106fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our investment universe\n",
    "# Using major sector ETFs for diversification\n",
    "tickers = {\n",
    "    'SPY': 'S&P 500',\n",
    "    'QQQ': 'Nasdaq 100',\n",
    "    'IWM': 'Russell 2000',\n",
    "    'EFA': 'Intl Developed',\n",
    "    'EEM': 'Emerging Markets',\n",
    "    'TLT': 'Long-Term Treasury',\n",
    "    'GLD': 'Gold'\n",
    "}\n",
    "\n",
    "# Download historical data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)  # 5 years of data\n",
    "\n",
    "print(\"Downloading price data...\")\n",
    "prices = yf.download(list(tickers.keys()), start=start_date, end=end_date)['Adj Close']\n",
    "prices = prices[list(tickers.keys())]  # Ensure consistent order\n",
    "\n",
    "print(f\"\\nData shape: {prices.shape}\")\n",
    "print(f\"Date range: {prices.index[0].date()} to {prices.index[-1].date()}\")\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ad8d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# Annualized statistics\n",
    "annual_returns = returns.mean() * 252\n",
    "annual_vol = returns.std() * np.sqrt(252)\n",
    "cov_matrix = returns.cov() * 252  # Annualized covariance\n",
    "\n",
    "# Summary statistics\n",
    "stats_df = pd.DataFrame({\n",
    "    'Asset': [tickers[t] for t in returns.columns],\n",
    "    'Ann. Return': annual_returns.values,\n",
    "    'Ann. Volatility': annual_vol.values,\n",
    "    'Sharpe Ratio': (annual_returns.values / annual_vol.values)\n",
    "}, index=returns.columns)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ASSET STATISTICS (Annualized)\")\n",
    "print(\"=\" * 60)\n",
    "print(stats_df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29fbceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Correlation heatmap\n",
    "corr_matrix = returns.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='RdYlGn', center=0,\n",
    "            ax=axes[0], square=True, linewidths=0.5)\n",
    "axes[0].set_title('Correlation Matrix', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Risk-Return scatter\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(tickers)))\n",
    "for i, (ticker, name) in enumerate(tickers.items()):\n",
    "    axes[1].scatter(annual_vol[ticker], annual_returns[ticker], \n",
    "                   s=100, c=[colors[i]], label=name, edgecolors='black')\n",
    "    axes[1].annotate(ticker, (annual_vol[ticker], annual_returns[ticker]),\n",
    "                    xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "axes[1].set_xlabel('Annualized Volatility', fontsize=11)\n",
    "axes[1].set_ylabel('Annualized Return', fontsize=11)\n",
    "axes[1].set_title('Risk-Return Profile', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(loc='upper left', fontsize=8)\n",
    "axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f482697f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Black-Litterman Implementation\n",
    "\n",
    "### 3.1 Calculate Equilibrium Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fe62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackLitterman:\n",
    "    \"\"\"\n",
    "    Black-Litterman Model Implementation\n",
    "    \n",
    "    Combines equilibrium market returns with investor views\n",
    "    to generate optimal portfolio weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cov_matrix, market_caps=None, risk_free_rate=0.04, \n",
    "                 delta=2.5, tau=0.05):\n",
    "        \"\"\"\n",
    "        Initialize Black-Litterman model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        cov_matrix : pd.DataFrame\n",
    "            Annualized covariance matrix of asset returns\n",
    "        market_caps : pd.Series, optional\n",
    "            Market capitalizations for each asset\n",
    "        risk_free_rate : float\n",
    "            Risk-free rate (annualized)\n",
    "        delta : float\n",
    "            Risk aversion coefficient (typically 2.5-3.5)\n",
    "        tau : float\n",
    "            Scaling factor for prior uncertainty (typically 0.01-0.05)\n",
    "        \"\"\"\n",
    "        self.cov_matrix = cov_matrix.values\n",
    "        self.assets = cov_matrix.columns.tolist()\n",
    "        self.n_assets = len(self.assets)\n",
    "        self.risk_free_rate = risk_free_rate\n",
    "        self.delta = delta\n",
    "        self.tau = tau\n",
    "        \n",
    "        # Set market cap weights (equal weight if not provided)\n",
    "        if market_caps is None:\n",
    "            self.market_weights = np.ones(self.n_assets) / self.n_assets\n",
    "        else:\n",
    "            total_cap = market_caps.sum()\n",
    "            self.market_weights = (market_caps / total_cap).values\n",
    "        \n",
    "        # Calculate equilibrium returns\n",
    "        self.equilibrium_returns = self._calculate_equilibrium_returns()\n",
    "        \n",
    "        # Initialize views\n",
    "        self.P = None  # Pick matrix\n",
    "        self.Q = None  # View returns\n",
    "        self.Omega = None  # View uncertainty\n",
    "        \n",
    "    def _calculate_equilibrium_returns(self):\n",
    "        \"\"\"\n",
    "        Calculate implied equilibrium excess returns using reverse optimization.\n",
    "        \n",
    "        Formula: Pi = delta * Sigma * w_mkt\n",
    "        \"\"\"\n",
    "        pi = self.delta * self.cov_matrix @ self.market_weights\n",
    "        return pi\n",
    "    \n",
    "    def add_absolute_view(self, asset, return_view, confidence):\n",
    "        \"\"\"\n",
    "        Add an absolute view: \"Asset X will return Y%\"\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        asset : str\n",
    "            Asset ticker\n",
    "        return_view : float\n",
    "            Expected return (annualized, decimal)\n",
    "        confidence : float\n",
    "            Confidence in view (0-1, where 1 is very confident)\n",
    "        \"\"\"\n",
    "        idx = self.assets.index(asset)\n",
    "        \n",
    "        # Create pick row (1 for the asset, 0 elsewhere)\n",
    "        p_row = np.zeros(self.n_assets)\n",
    "        p_row[idx] = 1\n",
    "        \n",
    "        # Calculate view uncertainty\n",
    "        # Lower confidence = higher uncertainty\n",
    "        omega_val = (1 / confidence - 1) * self.tau * (p_row @ self.cov_matrix @ p_row)\n",
    "        \n",
    "        self._add_view(p_row, return_view, omega_val)\n",
    "        \n",
    "    def add_relative_view(self, long_asset, short_asset, return_diff, confidence):\n",
    "        \"\"\"\n",
    "        Add a relative view: \"Asset X will outperform Asset Y by Z%\"\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        long_asset : str\n",
    "            Asset expected to outperform\n",
    "        short_asset : str\n",
    "            Asset expected to underperform\n",
    "        return_diff : float\n",
    "            Expected return difference (annualized, decimal)\n",
    "        confidence : float\n",
    "            Confidence in view (0-1)\n",
    "        \"\"\"\n",
    "        long_idx = self.assets.index(long_asset)\n",
    "        short_idx = self.assets.index(short_asset)\n",
    "        \n",
    "        # Create pick row (+1 for long, -1 for short)\n",
    "        p_row = np.zeros(self.n_assets)\n",
    "        p_row[long_idx] = 1\n",
    "        p_row[short_idx] = -1\n",
    "        \n",
    "        # Calculate view uncertainty\n",
    "        omega_val = (1 / confidence - 1) * self.tau * (p_row @ self.cov_matrix @ p_row)\n",
    "        \n",
    "        self._add_view(p_row, return_diff, omega_val)\n",
    "        \n",
    "    def _add_view(self, p_row, q_val, omega_val):\n",
    "        \"\"\"Internal method to add a view to the model.\"\"\"\n",
    "        if self.P is None:\n",
    "            self.P = p_row.reshape(1, -1)\n",
    "            self.Q = np.array([q_val])\n",
    "            self.Omega = np.array([[omega_val]])\n",
    "        else:\n",
    "            self.P = np.vstack([self.P, p_row])\n",
    "            self.Q = np.append(self.Q, q_val)\n",
    "            # Expand Omega (diagonal matrix)\n",
    "            new_omega = np.zeros((len(self.Q), len(self.Q)))\n",
    "            new_omega[:-1, :-1] = self.Omega\n",
    "            new_omega[-1, -1] = omega_val\n",
    "            self.Omega = new_omega\n",
    "            \n",
    "    def clear_views(self):\n",
    "        \"\"\"Remove all views.\"\"\"\n",
    "        self.P = None\n",
    "        self.Q = None\n",
    "        self.Omega = None\n",
    "        \n",
    "    def get_posterior_returns(self):\n",
    "        \"\"\"\n",
    "        Calculate posterior expected returns by combining\n",
    "        equilibrium with views using Bayesian updating.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        np.array : Posterior expected returns\n",
    "        \"\"\"\n",
    "        if self.P is None:\n",
    "            return self.equilibrium_returns\n",
    "        \n",
    "        # Prior covariance scaled by tau\n",
    "        tau_sigma = self.tau * self.cov_matrix\n",
    "        tau_sigma_inv = np.linalg.inv(tau_sigma)\n",
    "        \n",
    "        # Omega inverse\n",
    "        omega_inv = np.linalg.inv(self.Omega)\n",
    "        \n",
    "        # Posterior precision (inverse covariance)\n",
    "        posterior_precision = tau_sigma_inv + self.P.T @ omega_inv @ self.P\n",
    "        posterior_cov = np.linalg.inv(posterior_precision)\n",
    "        \n",
    "        # Posterior mean\n",
    "        posterior_mean = posterior_cov @ (\n",
    "            tau_sigma_inv @ self.equilibrium_returns + \n",
    "            self.P.T @ omega_inv @ self.Q\n",
    "        )\n",
    "        \n",
    "        return posterior_mean\n",
    "    \n",
    "    def get_posterior_covariance(self):\n",
    "        \"\"\"\n",
    "        Calculate posterior covariance matrix.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        np.array : Posterior covariance matrix\n",
    "        \"\"\"\n",
    "        if self.P is None:\n",
    "            return self.cov_matrix + self.tau * self.cov_matrix\n",
    "        \n",
    "        tau_sigma = self.tau * self.cov_matrix\n",
    "        tau_sigma_inv = np.linalg.inv(tau_sigma)\n",
    "        omega_inv = np.linalg.inv(self.Omega)\n",
    "        \n",
    "        posterior_precision = tau_sigma_inv + self.P.T @ omega_inv @ self.P\n",
    "        M = np.linalg.inv(posterior_precision)\n",
    "        \n",
    "        return self.cov_matrix + M\n",
    "    \n",
    "    def optimize_portfolio(self, risk_aversion=None, constraints=None):\n",
    "        \"\"\"\n",
    "        Calculate optimal portfolio weights using posterior estimates.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        risk_aversion : float, optional\n",
    "            Risk aversion for optimization (uses self.delta if None)\n",
    "        constraints : dict, optional\n",
    "            Additional constraints for optimization\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        dict : Optimal weights and portfolio statistics\n",
    "        \"\"\"\n",
    "        if risk_aversion is None:\n",
    "            risk_aversion = self.delta\n",
    "            \n",
    "        mu = self.get_posterior_returns()\n",
    "        sigma = self.get_posterior_covariance()\n",
    "        \n",
    "        # Objective: maximize utility = mu'w - (delta/2) * w'Σw\n",
    "        def neg_utility(w):\n",
    "            return -(w @ mu - (risk_aversion / 2) * w @ sigma @ w)\n",
    "        \n",
    "        # Constraints\n",
    "        cons = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]  # Weights sum to 1\n",
    "        \n",
    "        # Bounds (0-1 for long-only, or allow shorts)\n",
    "        if constraints and constraints.get('long_only', True):\n",
    "            bounds = [(0, 1) for _ in range(self.n_assets)]\n",
    "        else:\n",
    "            bounds = [(-1, 2) for _ in range(self.n_assets)]\n",
    "        \n",
    "        # Initial guess\n",
    "        w0 = np.ones(self.n_assets) / self.n_assets\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(neg_utility, w0, method='SLSQP', \n",
    "                         bounds=bounds, constraints=cons)\n",
    "        \n",
    "        optimal_weights = result.x\n",
    "        \n",
    "        # Calculate portfolio statistics\n",
    "        port_return = optimal_weights @ mu\n",
    "        port_vol = np.sqrt(optimal_weights @ sigma @ optimal_weights)\n",
    "        port_sharpe = (port_return - self.risk_free_rate) / port_vol\n",
    "        \n",
    "        return {\n",
    "            'weights': pd.Series(optimal_weights, index=self.assets),\n",
    "            'expected_return': port_return,\n",
    "            'volatility': port_vol,\n",
    "            'sharpe_ratio': port_sharpe\n",
    "        }\n",
    "    \n",
    "    def get_summary(self):\n",
    "        \"\"\"Print model summary.\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"BLACK-LITTERMAN MODEL SUMMARY\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(f\"\\nParameters:\")\n",
    "        print(f\"  Risk Aversion (δ): {self.delta}\")\n",
    "        print(f\"  Tau (τ): {self.tau}\")\n",
    "        print(f\"  Risk-free Rate: {self.risk_free_rate:.2%}\")\n",
    "        \n",
    "        print(f\"\\nEquilibrium Returns:\")\n",
    "        for i, asset in enumerate(self.assets):\n",
    "            print(f\"  {asset}: {self.equilibrium_returns[i]:.2%}\")\n",
    "            \n",
    "        if self.P is not None:\n",
    "            print(f\"\\nNumber of Views: {len(self.Q)}\")\n",
    "            posterior = self.get_posterior_returns()\n",
    "            print(f\"\\nPosterior Returns:\")\n",
    "            for i, asset in enumerate(self.assets):\n",
    "                diff = posterior[i] - self.equilibrium_returns[i]\n",
    "                print(f\"  {asset}: {posterior[i]:.2%} (Δ {diff:+.2%})\")\n",
    "        else:\n",
    "            print(\"\\nNo views added yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdfee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create approximate market cap weights for our ETFs\n",
    "# These are illustrative - in practice, use actual market caps\n",
    "market_caps = pd.Series({\n",
    "    'SPY': 500,   # S&P 500 - largest\n",
    "    'QQQ': 200,   # Nasdaq\n",
    "    'IWM': 50,    # Small caps\n",
    "    'EFA': 100,   # International developed\n",
    "    'EEM': 40,    # Emerging markets\n",
    "    'TLT': 30,    # Treasuries\n",
    "    'GLD': 80     # Gold\n",
    "})  # In billions USD (illustrative)\n",
    "\n",
    "# Initialize Black-Litterman model\n",
    "bl_model = BlackLitterman(\n",
    "    cov_matrix=cov_matrix,\n",
    "    market_caps=market_caps,\n",
    "    risk_free_rate=0.04,  # 4% risk-free rate\n",
    "    delta=2.5,            # Risk aversion\n",
    "    tau=0.05              # Prior uncertainty\n",
    ")\n",
    "\n",
    "# Display equilibrium returns\n",
    "bl_model.get_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de6a71",
   "metadata": {},
   "source": [
    "### 3.2 Compare Equilibrium vs Historical Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare equilibrium returns with historical returns\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Asset': list(tickers.values()),\n",
    "    'Historical Return': annual_returns.values,\n",
    "    'Equilibrium Return': bl_model.equilibrium_returns,\n",
    "    'Difference': annual_returns.values - bl_model.equilibrium_returns\n",
    "}, index=list(tickers.keys()))\n",
    "\n",
    "print(\"Historical vs Equilibrium Returns\")\n",
    "print(\"=\" * 60)\n",
    "print(comparison_df.to_string())\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(tickers))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, annual_returns.values, width, label='Historical', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, bl_model.equilibrium_returns, width, label='Equilibrium (BL)', color='coral')\n",
    "\n",
    "ax.set_xlabel('Asset')\n",
    "ax.set_ylabel('Annualized Return')\n",
    "ax.set_title('Historical vs Black-Litterman Equilibrium Returns', fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(list(tickers.keys()))\n",
    "ax.legend()\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512342c6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Incorporating Investor Views\n",
    "\n",
    "### 4.1 Types of Views\n",
    "\n",
    "**Absolute Views:**\n",
    "- \"Tech stocks (QQQ) will return 15% next year\"\n",
    "- \"Gold (GLD) will return 8%\"\n",
    "\n",
    "**Relative Views:**\n",
    "- \"US stocks (SPY) will outperform Emerging Markets (EEM) by 5%\"\n",
    "- \"Small caps (IWM) will underperform large caps (SPY) by 3%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4879d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fresh model for our views\n",
    "bl_with_views = BlackLitterman(\n",
    "    cov_matrix=cov_matrix,\n",
    "    market_caps=market_caps,\n",
    "    risk_free_rate=0.04,\n",
    "    delta=2.5,\n",
    "    tau=0.05\n",
    ")\n",
    "\n",
    "# Add our investment views\n",
    "print(\"Adding Investor Views:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# View 1: Absolute - Bullish on Tech\n",
    "# \"QQQ will return 15% over the next year\"\n",
    "bl_with_views.add_absolute_view(\n",
    "    asset='QQQ',\n",
    "    return_view=0.15,   # 15% expected return\n",
    "    confidence=0.7      # 70% confident\n",
    ")\n",
    "print(\"View 1: QQQ will return 15% (70% confidence)\")\n",
    "\n",
    "# View 2: Relative - US > EM\n",
    "# \"SPY will outperform EEM by 5%\"\n",
    "bl_with_views.add_relative_view(\n",
    "    long_asset='SPY',\n",
    "    short_asset='EEM',\n",
    "    return_diff=0.05,   # 5% outperformance\n",
    "    confidence=0.8      # 80% confident\n",
    ")\n",
    "print(\"View 2: SPY will outperform EEM by 5% (80% confidence)\")\n",
    "\n",
    "# View 3: Absolute - Bearish on Bonds in rising rate environment\n",
    "bl_with_views.add_absolute_view(\n",
    "    asset='TLT',\n",
    "    return_view=0.02,   # Only 2% expected return\n",
    "    confidence=0.6      # 60% confident\n",
    ")\n",
    "print(\"View 3: TLT will return only 2% (60% confidence)\")\n",
    "\n",
    "# View 4: Relative - Gold as hedge\n",
    "bl_with_views.add_relative_view(\n",
    "    long_asset='GLD',\n",
    "    short_asset='TLT',\n",
    "    return_diff=0.04,   # Gold outperforms bonds by 4%\n",
    "    confidence=0.65\n",
    ")\n",
    "print(\"View 4: GLD will outperform TLT by 4% (65% confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the Pick Matrix (P) and Views (Q)\n",
    "print(\"\\nPick Matrix (P):\")\n",
    "print(\"=\" * 60)\n",
    "P_df = pd.DataFrame(bl_with_views.P, \n",
    "                    columns=bl_with_views.assets,\n",
    "                    index=[f'View {i+1}' for i in range(len(bl_with_views.Q))])\n",
    "print(P_df.to_string())\n",
    "\n",
    "print(\"\\nView Returns (Q):\")\n",
    "for i, q in enumerate(bl_with_views.Q):\n",
    "    print(f\"  View {i+1}: {q:.2%}\")\n",
    "\n",
    "print(\"\\nView Uncertainty Matrix (Ω) - Diagonal:\")\n",
    "for i in range(len(bl_with_views.Q)):\n",
    "    print(f\"  View {i+1}: {bl_with_views.Omega[i,i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03bfacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and display posterior returns\n",
    "bl_with_views.get_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6feae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the impact of views\n",
    "equilibrium = bl_model.equilibrium_returns\n",
    "posterior = bl_with_views.get_posterior_returns()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart comparison\n",
    "x = np.arange(len(tickers))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x - width/2, equilibrium, width, label='Equilibrium (Prior)', color='lightblue', edgecolor='steelblue')\n",
    "axes[0].bar(x + width/2, posterior, width, label='Posterior (w/ Views)', color='coral', edgecolor='darkred')\n",
    "axes[0].set_xlabel('Asset')\n",
    "axes[0].set_ylabel('Expected Return')\n",
    "axes[0].set_title('Impact of Investor Views on Expected Returns', fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(list(tickers.keys()))\n",
    "axes[0].legend()\n",
    "axes[0].yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "# Change in returns\n",
    "changes = posterior - equilibrium\n",
    "colors = ['green' if c > 0 else 'red' for c in changes]\n",
    "axes[1].barh(list(tickers.keys()), changes, color=colors, edgecolor='black')\n",
    "axes[1].set_xlabel('Change in Expected Return')\n",
    "axes[1].set_title('Change from Equilibrium Due to Views', fontweight='bold')\n",
    "axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "axes[1].xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.1%}'.format(x)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63351e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Portfolio Optimization\n",
    "\n",
    "### 5.1 Optimal Weights with and without Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d546282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize portfolios\n",
    "# 1. Market Cap Weights (starting point)\n",
    "market_weights = market_caps / market_caps.sum()\n",
    "\n",
    "# 2. Equilibrium (no views)\n",
    "equil_portfolio = bl_model.optimize_portfolio()\n",
    "\n",
    "# 3. With views\n",
    "views_portfolio = bl_with_views.optimize_portfolio()\n",
    "\n",
    "# Compare weights\n",
    "weights_comparison = pd.DataFrame({\n",
    "    'Market Cap Weights': market_weights.values,\n",
    "    'Equilibrium (No Views)': equil_portfolio['weights'].values,\n",
    "    'With Investor Views': views_portfolio['weights'].values\n",
    "}, index=list(tickers.keys()))\n",
    "\n",
    "print(\"Portfolio Weight Comparison\")\n",
    "print(\"=\" * 60)\n",
    "print(weights_comparison.round(4).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Portfolio Statistics\")\n",
    "print(\"=\" * 60)\n",
    "stats_comparison = pd.DataFrame({\n",
    "    'Equilibrium (No Views)': [\n",
    "        equil_portfolio['expected_return'],\n",
    "        equil_portfolio['volatility'],\n",
    "        equil_portfolio['sharpe_ratio']\n",
    "    ],\n",
    "    'With Investor Views': [\n",
    "        views_portfolio['expected_return'],\n",
    "        views_portfolio['volatility'],\n",
    "        views_portfolio['sharpe_ratio']\n",
    "    ]\n",
    "}, index=['Expected Return', 'Volatility', 'Sharpe Ratio'])\n",
    "print(stats_comparison.round(4).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7edb775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize portfolio weights\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Color palette\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(tickers)))\n",
    "\n",
    "# Market cap weights\n",
    "axes[0].pie(market_weights, labels=list(tickers.keys()), autopct='%1.1f%%',\n",
    "           colors=colors, startangle=90)\n",
    "axes[0].set_title('Market Cap Weights', fontweight='bold')\n",
    "\n",
    "# Equilibrium weights\n",
    "eq_weights = equil_portfolio['weights'].values\n",
    "eq_weights_clean = np.maximum(eq_weights, 0)  # Handle small negatives\n",
    "axes[1].pie(eq_weights_clean, labels=list(tickers.keys()), autopct='%1.1f%%',\n",
    "           colors=colors, startangle=90)\n",
    "axes[1].set_title('Equilibrium (No Views)', fontweight='bold')\n",
    "\n",
    "# With views\n",
    "view_weights = views_portfolio['weights'].values\n",
    "view_weights_clean = np.maximum(view_weights, 0)\n",
    "axes[2].pie(view_weights_clean, labels=list(tickers.keys()), autopct='%1.1f%%',\n",
    "           colors=colors, startangle=90)\n",
    "axes[2].set_title('With Investor Views', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c940b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight change analysis\n",
    "weight_changes = views_portfolio['weights'] - equil_portfolio['weights']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "colors = ['green' if w > 0 else 'red' for w in weight_changes]\n",
    "bars = ax.barh(list(tickers.keys()), weight_changes * 100, color=colors, edgecolor='black')\n",
    "\n",
    "ax.axvline(x=0, color='black', linewidth=0.5)\n",
    "ax.set_xlabel('Weight Change (%)', fontsize=11)\n",
    "ax.set_title('Portfolio Weight Changes Due to Investor Views', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, weight_changes * 100):\n",
    "    if val >= 0:\n",
    "        ax.text(val + 0.3, bar.get_y() + bar.get_height()/2, f'+{val:.1f}%',\n",
    "               va='center', fontsize=10)\n",
    "    else:\n",
    "        ax.text(val - 0.3, bar.get_y() + bar.get_height()/2, f'{val:.1f}%',\n",
    "               va='center', ha='right', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875c8336",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Sensitivity Analysis\n",
    "\n",
    "### 6.1 Impact of Confidence Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how confidence affects posterior returns\n",
    "confidence_levels = [0.3, 0.5, 0.7, 0.9, 0.99]\n",
    "qqq_posteriors = []\n",
    "spy_posteriors = []\n",
    "\n",
    "for conf in confidence_levels:\n",
    "    temp_model = BlackLitterman(\n",
    "        cov_matrix=cov_matrix,\n",
    "        market_caps=market_caps,\n",
    "        risk_free_rate=0.04,\n",
    "        delta=2.5,\n",
    "        tau=0.05\n",
    "    )\n",
    "    \n",
    "    # Add bullish QQQ view with varying confidence\n",
    "    temp_model.add_absolute_view('QQQ', 0.15, conf)\n",
    "    \n",
    "    posterior = temp_model.get_posterior_returns()\n",
    "    qqq_idx = temp_model.assets.index('QQQ')\n",
    "    spy_idx = temp_model.assets.index('SPY')\n",
    "    qqq_posteriors.append(posterior[qqq_idx])\n",
    "    spy_posteriors.append(posterior[spy_idx])\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(confidence_levels, qqq_posteriors, 'o-', color='blue', linewidth=2, \n",
    "        markersize=8, label='QQQ (view asset)')\n",
    "ax.plot(confidence_levels, spy_posteriors, 's--', color='gray', linewidth=2,\n",
    "        markersize=8, label='SPY (no direct view)')\n",
    "\n",
    "# Reference lines\n",
    "ax.axhline(y=bl_model.equilibrium_returns[bl_model.assets.index('QQQ')], \n",
    "          color='blue', linestyle=':', alpha=0.5, label='QQQ Equilibrium')\n",
    "ax.axhline(y=0.15, color='green', linestyle=':', alpha=0.5, label='View (15%)')\n",
    "\n",
    "ax.set_xlabel('Confidence Level', fontsize=11)\n",
    "ax.set_ylabel('Posterior Expected Return', fontsize=11)\n",
    "ax.set_title('Impact of View Confidence on Posterior Returns\\n(View: QQQ = 15%)', \n",
    "            fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "ax.set_xticks(confidence_levels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Higher confidence pulls posterior closer to the view.\")\n",
    "print(\"At low confidence, posterior stays near equilibrium.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c12c20",
   "metadata": {},
   "source": [
    "### 6.2 Impact of Tau (Prior Uncertainty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882d4c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze how tau affects results\n",
    "tau_values = [0.01, 0.025, 0.05, 0.1, 0.25]\n",
    "qqq_posteriors_tau = []\n",
    "\n",
    "for tau in tau_values:\n",
    "    temp_model = BlackLitterman(\n",
    "        cov_matrix=cov_matrix,\n",
    "        market_caps=market_caps,\n",
    "        risk_free_rate=0.04,\n",
    "        delta=2.5,\n",
    "        tau=tau  # Varying tau\n",
    "    )\n",
    "    \n",
    "    temp_model.add_absolute_view('QQQ', 0.15, 0.7)  # Same view\n",
    "    \n",
    "    posterior = temp_model.get_posterior_returns()\n",
    "    qqq_idx = temp_model.assets.index('QQQ')\n",
    "    qqq_posteriors_tau.append(posterior[qqq_idx])\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(tau_values, qqq_posteriors_tau, 'o-', color='purple', linewidth=2, markersize=8)\n",
    "ax.axhline(y=bl_model.equilibrium_returns[bl_model.assets.index('QQQ')], \n",
    "          color='blue', linestyle=':', alpha=0.7, label='Equilibrium')\n",
    "ax.axhline(y=0.15, color='green', linestyle=':', alpha=0.7, label='View (15%)')\n",
    "\n",
    "ax.set_xlabel('Tau (τ)', fontsize=11)\n",
    "ax.set_ylabel('QQQ Posterior Expected Return', fontsize=11)\n",
    "ax.set_title('Impact of Tau on Posterior Returns\\n(Higher τ = Less confidence in equilibrium)', \n",
    "            fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.0%}'.format(y)))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insight: Higher tau means less trust in equilibrium,\")\n",
    "print(\"so views have more impact on the posterior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7059c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: Practical Considerations\n",
    "\n",
    "### 7.1 Common Pitfalls and Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bf686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate conflicting views\n",
    "print(\"Example: What happens with conflicting views?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "conflict_model = BlackLitterman(\n",
    "    cov_matrix=cov_matrix,\n",
    "    market_caps=market_caps,\n",
    "    risk_free_rate=0.04,\n",
    "    delta=2.5,\n",
    "    tau=0.05\n",
    ")\n",
    "\n",
    "# Conflicting views: QQQ bullish but also expect it to underperform SPY\n",
    "conflict_model.add_absolute_view('QQQ', 0.20, 0.8)  # Very bullish on QQQ\n",
    "conflict_model.add_relative_view('SPY', 'QQQ', 0.05, 0.7)  # But SPY > QQQ?\n",
    "\n",
    "posterior = conflict_model.get_posterior_returns()\n",
    "\n",
    "print(\"\\nViews Added:\")\n",
    "print(\"  1. QQQ will return 20% (80% confidence)\")\n",
    "print(\"  2. SPY will outperform QQQ by 5% (70% confidence)\")\n",
    "print(\"\\nThese views are potentially conflicting!\")\n",
    "print(\"\\nPosterior Returns:\")\n",
    "for i, asset in enumerate(conflict_model.assets):\n",
    "    eq = conflict_model.equilibrium_returns[i]\n",
    "    print(f\"  {asset}: {posterior[i]:.2%} (equilibrium: {eq:.2%})\")\n",
    "\n",
    "print(\"\\n→ The model balances conflicting views based on confidence levels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1087c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best practices summary\n",
    "best_practices = \"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════╗\n",
    "║              BLACK-LITTERMAN BEST PRACTICES                      ║\n",
    "╠══════════════════════════════════════════════════════════════════╣\n",
    "║                                                                  ║\n",
    "║  1. START WITH GOOD EQUILIBRIUM                                  ║\n",
    "║     • Use market cap weights from reliable sources               ║\n",
    "║     • Ensure covariance matrix is well-conditioned              ║\n",
    "║     • Consider using shrinkage estimators for covariance        ║\n",
    "║                                                                  ║\n",
    "║  2. FORMULATE VIEWS CAREFULLY                                    ║\n",
    "║     • Views should be forward-looking, not backward-looking     ║\n",
    "║     • Express views you actually have conviction in             ║\n",
    "║     • Relative views are often more reliable than absolute      ║\n",
    "║                                                                  ║\n",
    "║  3. CALIBRATE CONFIDENCE APPROPRIATELY                           ║\n",
    "║     • High confidence (>80%) only for very strong views         ║\n",
    "║     • Default to moderate confidence (50-70%)                   ║\n",
    "║     • Avoid extreme confidence (>95%) - rarely justified        ║\n",
    "║                                                                  ║\n",
    "║  4. CHOOSE TAU WISELY                                           ║\n",
    "║     • τ = 0.025 to 0.05 is typical                              ║\n",
    "║     • Lower τ → more weight on equilibrium                       ║\n",
    "║     • Some practitioners set τ = 1/T (T = sample size)          ║\n",
    "║                                                                  ║\n",
    "║  5. VALIDATE RESULTS                                            ║\n",
    "║     • Check that weights are sensible                           ║\n",
    "║     • Perform sensitivity analysis                              ║\n",
    "║     • Compare to benchmark allocations                          ║\n",
    "║                                                                  ║\n",
    "╚══════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "print(best_practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149e724",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Interview Questions & Key Takeaways\n",
    "\n",
    "### Common Interview Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5792366",
   "metadata": {},
   "outputs": [],
   "source": [
    "interview_questions = {\n",
    "    \"Q1: What problem does Black-Litterman solve?\": \"\"\"\n",
    "    A: Black-Litterman addresses the extreme sensitivity of mean-variance \n",
    "    optimization to expected return inputs. Traditional MVO often produces \n",
    "    concentrated, unstable portfolios because small changes in return estimates \n",
    "    lead to large weight changes. BL solves this by:\n",
    "    1. Starting with a neutral equilibrium (market-implied returns)\n",
    "    2. Allowing investors to express views with uncertainty\n",
    "    3. Using Bayesian inference to blend views with equilibrium\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Q2: How are equilibrium returns calculated?\": \"\"\"\n",
    "    A: Equilibrium returns (Π) are derived through \"reverse optimization\":\n",
    "       Π = δ × Σ × w_mkt\n",
    "    Where:\n",
    "    - δ = risk aversion coefficient (typically 2.5)\n",
    "    - Σ = covariance matrix of returns\n",
    "    - w_mkt = market capitalization weights\n",
    "    \n",
    "    This gives the implied returns that would make the market portfolio optimal.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Q3: What's the difference between absolute and relative views?\": \"\"\"\n",
    "    A: \n",
    "    Absolute View: \"Asset X will return Y%\"\n",
    "       - Pick matrix has 1 in asset position, 0 elsewhere\n",
    "       - Example: \"Tech stocks will return 12%\"\n",
    "    \n",
    "    Relative View: \"Asset X will outperform Asset Y by Z%\"\n",
    "       - Pick matrix has +1 for long asset, -1 for short\n",
    "       - Example: \"US equities will beat emerging markets by 5%\"\n",
    "       - Often more reliable as they cancel out common factors\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Q4: What role does τ (tau) play in the model?\": \"\"\"\n",
    "    A: Tau (τ) represents uncertainty in the equilibrium returns (prior):\n",
    "    - Small τ (0.01): Strong belief in equilibrium, views have less impact\n",
    "    - Large τ (0.10+): Weaker belief in equilibrium, views dominate\n",
    "    - Typical range: 0.025 to 0.05\n",
    "    - Some set τ = 1/T where T = number of observations\n",
    "    - It scales the prior covariance matrix (τΣ)\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Q5: How does confidence in views affect the results?\": \"\"\"\n",
    "    A: View confidence is expressed through the Ω matrix:\n",
    "    - High confidence → small Ω → views pull posterior strongly toward Q\n",
    "    - Low confidence → large Ω → views have minimal impact\n",
    "    - Common formula: ω_i = (1/conf - 1) × τ × P_i × Σ × P_i'\n",
    "    \n",
    "    At 100% confidence, posterior equals the view exactly.\n",
    "    At 0% confidence, posterior equals equilibrium.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"Q6: What are limitations of Black-Litterman?\": \"\"\"\n",
    "    A: Key limitations include:\n",
    "    1. Still requires accurate covariance estimation\n",
    "    2. Assumes normal distribution of returns\n",
    "    3. Single-period model (ignores dynamics)\n",
    "    4. Views are subjective - garbage in, garbage out\n",
    "    5. Doesn't account for transaction costs or constraints\n",
    "    6. Equilibrium assumption may not hold in crisis periods\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "for question, answer in interview_questions.items():\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(question)\n",
    "    print(\"=\" * 70)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a716268",
   "metadata": {},
   "source": [
    "### Key Formulas to Remember\n",
    "\n",
    "| Formula | Description |\n",
    "|---------|-------------|\n",
    "| $\\Pi = \\delta \\Sigma w_{mkt}$ | Equilibrium returns |\n",
    "| $E[R] = [(\\tau\\Sigma)^{-1} + P'\\Omega^{-1}P]^{-1}[(\\tau\\Sigma)^{-1}\\Pi + P'\\Omega^{-1}Q]$ | Posterior returns |\n",
    "| $\\omega_i = \\frac{1-c}{c} \\cdot \\tau \\cdot P_i \\Sigma P_i'$ | View uncertainty (c = confidence) |\n",
    "| $w^* = \\frac{1}{\\delta}\\Sigma^{-1}\\mu$ | Optimal weights (unconstrained) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5292ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "### What We Covered Today\n",
    "\n",
    "1. **Black-Litterman Framework**: Understanding how it combines equilibrium with investor views\n",
    "\n",
    "2. **Equilibrium Returns**: Deriving market-implied returns using reverse optimization\n",
    "\n",
    "3. **Investor Views**: \n",
    "   - Absolute views (\"Asset X returns Y%\")\n",
    "   - Relative views (\"A outperforms B by Z%\")\n",
    "   - Expressing confidence through Ω matrix\n",
    "\n",
    "4. **Posterior Calculation**: Bayesian updating to blend prior and views\n",
    "\n",
    "5. **Sensitivity Analysis**: Impact of τ and confidence on results\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Black-Litterman produces more **stable, intuitive** portfolios than traditional MVO\n",
    "- The model **requires views** - with no views, you get market-cap weights\n",
    "- **Confidence calibration** is crucial - be honest about uncertainty\n",
    "- **Relative views** are often more reliable than absolute views\n",
    "- Always perform **sensitivity analysis** before implementing\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Day 3: Risk Parity and Equal Risk Contribution portfolios\n",
    "- Day 4: Hierarchical Risk Parity (HRP)\n",
    "- Day 5: Transaction costs and portfolio rebalancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary visualization\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL PORTFOLIO COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_comparison = pd.DataFrame({\n",
    "    'Market Cap': market_weights.values,\n",
    "    'Equilibrium BL': equil_portfolio['weights'].values,\n",
    "    'BL + Views': views_portfolio['weights'].values\n",
    "}, index=list(tickers.keys()))\n",
    "\n",
    "print(\"\\nWeights:\")\n",
    "print(final_comparison.round(3).to_string())\n",
    "\n",
    "print(\"\\nPortfolio Metrics (BL with Views):\")\n",
    "print(f\"  Expected Return: {views_portfolio['expected_return']:.2%}\")\n",
    "print(f\"  Volatility:      {views_portfolio['volatility']:.2%}\")\n",
    "print(f\"  Sharpe Ratio:    {views_portfolio['sharpe_ratio']:.2f}\")\n",
    "\n",
    "print(\"\\n✅ Day 2 Complete: Black-Litterman Model with Investor Views\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
