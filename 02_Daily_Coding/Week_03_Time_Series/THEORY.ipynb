{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a28c468",
   "metadata": {},
   "source": [
    "# Week 3: Time Series Analysis for Finance\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What You'll Learn This Week\n",
    "\n",
    "Time series analysis is the bread and butter of quant finance. Stock prices, interest rates, volatility - they're ALL time series.\n",
    "\n",
    "**By the end of this week, you'll understand:**\n",
    "- How to identify trends and patterns in price data\n",
    "- Why \"stationarity\" is crucial (and what it means)\n",
    "- How past prices relate to future prices (autocorrelation)\n",
    "- ARIMA models - the classic forecasting tool\n",
    "- Pairs trading foundations (cointegration)\n",
    "\n",
    "**Why This Matters:**\n",
    "- **Every trading strategy** deals with time series data\n",
    "- **Stationarity** determines which models you can use\n",
    "- **ARIMA** is still asked in quant interviews!\n",
    "- **Cointegration** is the foundation of statistical arbitrage\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. Time Series Components\n",
    "2. Stationarity\n",
    "3. Autocorrelation\n",
    "4. ARIMA Models\n",
    "5. Cointegration\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002d5643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Downloading market data...\n",
      "‚úÖ Loaded 1255 days of data for 5 tickers\n",
      "üìÖ Date range: 2021-01-25 to 2026-01-22\n",
      "Ticker            AAPL       GOOGL          GS         JPM        MSFT\n",
      "Date                                                                  \n",
      "2026-01-15  258.209991  332.779999  975.859985  309.260010  456.660004\n",
      "2026-01-16  255.529999  330.000000  962.000000  312.470001  459.859985\n",
      "2026-01-20  246.699997  322.000000  943.369995  302.739990  454.519989\n",
      "2026-01-21  247.649994  328.380005  953.010010  302.040009  444.109985\n",
      "2026-01-22  249.789993  331.410004  965.700012  306.440002  449.820099\n"
     ]
    }
   ],
   "source": [
    "# Standard imports and data loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Standard 5 equities for analysis\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'JPM', 'GS']\n",
    "\n",
    "# Fetch 5 years of data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "print(\"üì• Downloading market data...\")\n",
    "data = yf.download(tickers, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "print(f\"‚úÖ Loaded {len(prices)} days of data for {len(tickers)} tickers\")\n",
    "print(f\"üìÖ Date range: {prices.index[0].strftime('%Y-%m-%d')} to {prices.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(prices.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbe66d8",
   "metadata": {},
   "source": [
    "## 1. Time Series Components\n",
    "\n",
    "### ü§î What Makes Up a Time Series?\n",
    "\n",
    "Think of a stock price chart. You might see:\n",
    "- **Upward slope** over 10 years ‚Üí That's the TREND\n",
    "- **Higher in January** every year ‚Üí That's SEASONALITY\n",
    "- **Random ups and downs** ‚Üí That's NOISE\n",
    "\n",
    "We can break ANY time series into these pieces:\n",
    "\n",
    "$$Y_t = T_t + S_t + C_t + \\epsilon_t$$\n",
    "\n",
    "**In Plain English:**\n",
    "| Symbol | Component | What It Is | Example |\n",
    "|--------|-----------|-----------|---------|\n",
    "| $T_t$ | Trend | Long-term direction | S&P 500 going up over decades |\n",
    "| $S_t$ | Seasonality | Predictable patterns | Retail stocks up in December |\n",
    "| $C_t$ | Cyclical | Economic cycles | Bull/bear markets |\n",
    "| $\\epsilon_t$ | Residual | Random noise | Day-to-day fluctuations |\n",
    "\n",
    "### Why Decompose?\n",
    "- Identify underlying patterns\n",
    "- Separate signal from noise\n",
    "- Build better forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9ca656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated Price Series with:\n",
      "‚Ä¢ Trend: +0.1 per day (upward drift)\n",
      "‚Ä¢ Seasonality: 252-day cycle (annual)\n",
      "‚Ä¢ Noise: Normal(0, 5)\n",
      "\n",
      "First 10 prices:\n",
      "[102.48  99.66 103.94 108.66 100.22 100.57 109.99 106.27 100.43 105.84]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "# Create a time series with known components\n",
    "np.random.seed(42)\n",
    "n_days = 500\n",
    "t = np.arange(n_days)\n",
    "\n",
    "# Components\n",
    "trend = 0.1 * t                                    # Upward trend\n",
    "seasonality = 10 * np.sin(2 * np.pi * t / 252)     # Yearly cycle\n",
    "noise = np.random.normal(0, 5, n_days)             # Random noise\n",
    "\n",
    "# Combined series (like stock price)\n",
    "price = 100 + trend + seasonality + noise\n",
    "\n",
    "# Create DataFrame\n",
    "dates = pd.date_range('2020-01-01', periods=n_days, freq='D')\n",
    "df = pd.DataFrame({'Price': price}, index=dates)\n",
    "\n",
    "print(\"Simulated Price Series with:\")\n",
    "print(f\"‚Ä¢ Trend: +0.1 per day (upward drift)\")\n",
    "print(f\"‚Ä¢ Seasonality: 252-day cycle (annual)\")\n",
    "print(f\"‚Ä¢ Noise: Normal(0, 5)\")\n",
    "print(f\"\\nFirst 10 prices:\")\n",
    "print(df.head(10)['Price'].values.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8418491",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Stationarity\n",
    "\n",
    "### What is Stationarity?\n",
    "\n",
    "A time series is **stationary** if its statistical properties don't change over time:\n",
    "\n",
    "**Strict Stationarity**: Joint distribution of $(Y_t, Y_{t+1}, ..., Y_{t+k})$ is same for all $t$\n",
    "\n",
    "**Weak Stationarity** (more practical):\n",
    "1. Constant mean: $E[Y_t] = \\mu$ for all $t$\n",
    "2. Constant variance: $Var(Y_t) = \\sigma^2$ for all $t$  \n",
    "3. Covariance depends only on lag: $Cov(Y_t, Y_{t+k}) = f(k)$, not $t$\n",
    "\n",
    "### Why Does It Matter?\n",
    "- Most statistical models assume stationarity\n",
    "- Non-stationary data can lead to **spurious correlations**\n",
    "- Forecasting non-stationary series is unreliable\n",
    "\n",
    "### Stock Prices vs Returns\n",
    "- **Prices**: Non-stationary (trending, variance grows)\n",
    "- **Returns**: Usually stationary (mean-reverting around zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cc6250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Stationarity: Prices vs Returns\n",
      "==================================================\n",
      "\n",
      "PRICES (Non-Stationary):\n",
      "  First half - Mean: 98.88, Std: 6.96\n",
      "  Second half - Mean: 101.36, Std: 12.27\n",
      "  ‚Üí Mean and variance change over time!\n",
      "\n",
      "RETURNS (Stationary):\n",
      "  First half - Mean: 0.000059, Std: 0.0098\n",
      "  Second half - Mean: 0.000318, Std: 0.0098\n",
      "  ‚Üí Mean and variance are stable!\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate stationarity: prices vs returns\n",
    "np.random.seed(42)\n",
    "\n",
    "# Random walk (non-stationary)\n",
    "steps = np.random.normal(0, 1, 1000)\n",
    "prices = 100 * np.exp(np.cumsum(steps * 0.01))  # Geometric random walk\n",
    "\n",
    "# Returns (stationary)\n",
    "returns = np.diff(np.log(prices))\n",
    "\n",
    "# Compare statistics for first half vs second half\n",
    "mid = len(prices) // 2\n",
    "\n",
    "print(\"Testing Stationarity: Prices vs Returns\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nPRICES (Non-Stationary):\")\n",
    "print(f\"  First half - Mean: {prices[:mid].mean():.2f}, Std: {prices[:mid].std():.2f}\")\n",
    "print(f\"  Second half - Mean: {prices[mid:].mean():.2f}, Std: {prices[mid:].std():.2f}\")\n",
    "print(\"  ‚Üí Mean and variance change over time!\")\n",
    "\n",
    "print(\"\\nRETURNS (Stationary):\")\n",
    "print(f\"  First half - Mean: {returns[:mid-1].mean():.6f}, Std: {returns[:mid-1].std():.4f}\")\n",
    "print(f\"  Second half - Mean: {returns[mid-1:].mean():.6f}, Std: {returns[mid-1:].std():.4f}\")\n",
    "print(\"  ‚Üí Mean and variance are stable!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0372aa8d",
   "metadata": {},
   "source": [
    "### Augmented Dickey-Fuller Test\n",
    "\n",
    "Formal test for stationarity. Tests the hypothesis:\n",
    "\n",
    "$$\\Delta Y_t = \\alpha + \\beta t + \\gamma Y_{t-1} + \\sum_{i=1}^{p} \\delta_i \\Delta Y_{t-i} + \\epsilon_t$$\n",
    "\n",
    "- **H‚ÇÄ**: $\\gamma = 0$ (unit root exists, non-stationary)\n",
    "- **H‚ÇÅ**: $\\gamma < 0$ (stationary)\n",
    "\n",
    "If p-value < 0.05: Reject H‚ÇÄ ‚Üí Series is stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27dcaf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented Dickey-Fuller Test Results:\n",
      "==================================================\n",
      "Stock Prices:\n",
      "  ADF Statistic: -0.8371\n",
      "  p-value: 0.8080\n",
      "  ‚úó Non-stationary (cannot reject H‚ÇÄ)\n",
      "\n",
      "Log Returns:\n",
      "  ADF Statistic: -31.7893\n",
      "  p-value: 0.0000\n",
      "  ‚úì Stationary (reject H‚ÇÄ)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def adf_test(series, name):\n",
    "    \"\"\"Perform Augmented Dickey-Fuller test\"\"\"\n",
    "    result = adfuller(series.dropna(), autolag='AIC')\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  ADF Statistic: {result[0]:.4f}\")\n",
    "    print(f\"  p-value: {result[1]:.4f}\")\n",
    "    if result[1] < 0.05:\n",
    "        print(\"  ‚úì Stationary (reject H‚ÇÄ)\")\n",
    "    else:\n",
    "        print(\"  ‚úó Non-stationary (cannot reject H‚ÇÄ)\")\n",
    "    print()\n",
    "\n",
    "# Test both series\n",
    "print(\"Augmented Dickey-Fuller Test Results:\")\n",
    "print(\"=\"*50)\n",
    "adf_test(pd.Series(prices), \"Stock Prices\")\n",
    "adf_test(pd.Series(returns), \"Log Returns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a38db1",
   "metadata": {},
   "source": [
    "### Making Series Stationary\n",
    "\n",
    "**Differencing**: Remove trend by taking differences\n",
    "$$Y'_t = Y_t - Y_{t-1}$$\n",
    "\n",
    "For log prices, first difference = log return:\n",
    "$$r_t = \\log(P_t) - \\log(P_{t-1}) = \\log\\left(\\frac{P_t}{P_{t-1}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2ada46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Autocorrelation\n",
    "\n",
    "### Definition\n",
    "\n",
    "Autocorrelation measures how correlated a series is with its own past values.\n",
    "\n",
    "**Autocorrelation at lag k**:\n",
    "$$\\rho_k = \\frac{Cov(Y_t, Y_{t-k})}{Var(Y_t)} = \\frac{\\sum_{t=k+1}^{T}(Y_t - \\bar{Y})(Y_{t-k} - \\bar{Y})}{\\sum_{t=1}^{T}(Y_t - \\bar{Y})^2}$$\n",
    "\n",
    "### Properties\n",
    "- $\\rho_0 = 1$ (series perfectly correlated with itself)\n",
    "- $-1 \\leq \\rho_k \\leq 1$\n",
    "- For white noise: $\\rho_k \\approx 0$ for $k > 0$\n",
    "\n",
    "### Partial Autocorrelation (PACF)\n",
    "\n",
    "Measures correlation at lag $k$ **after removing** the effect of intermediate lags.\n",
    "\n",
    "Useful for identifying the order of AR models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd5e9f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AR(1) Process with œÜ = 0.7\n",
      "==================================================\n",
      "\n",
      "Autocorrelation Function (ACF):\n",
      "Theoretical: œÅ_k = œÜ^k\n",
      "  Lag 0: Actual = 1.000, Theoretical = 1.000\n",
      "  Lag 1: Actual = 0.683, Theoretical = 0.700\n",
      "  Lag 2: Actual = 0.461, Theoretical = 0.490\n",
      "  Lag 3: Actual = 0.306, Theoretical = 0.343\n",
      "  Lag 4: Actual = 0.180, Theoretical = 0.240\n",
      "  Lag 5: Actual = 0.138, Theoretical = 0.168\n",
      "\n",
      "Partial Autocorrelation (PACF):\n",
      "For AR(1): Only lag 1 should be significant\n",
      "  Lag 0: 1.000\n",
      "  Lag 1: 0.685\n",
      "  Lag 2: -0.012\n",
      "  Lag 3: -0.009\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "\n",
    "# Generate AR(1) process for illustration\n",
    "# Y_t = 0.7 * Y_{t-1} + noise\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "phi = 0.7  # AR coefficient\n",
    "\n",
    "ar1_series = np.zeros(n)\n",
    "ar1_series[0] = np.random.normal()\n",
    "for t in range(1, n):\n",
    "    ar1_series[t] = phi * ar1_series[t-1] + np.random.normal()\n",
    "\n",
    "# Calculate ACF\n",
    "acf_values = acf(ar1_series, nlags=10)\n",
    "pacf_values = pacf(ar1_series, nlags=10)\n",
    "\n",
    "print(\"AR(1) Process with œÜ = 0.7\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nAutocorrelation Function (ACF):\")\n",
    "print(\"Theoretical: œÅ_k = œÜ^k\")\n",
    "for k in range(6):\n",
    "    theoretical = phi**k\n",
    "    print(f\"  Lag {k}: Actual = {acf_values[k]:.3f}, Theoretical = {theoretical:.3f}\")\n",
    "\n",
    "print(\"\\nPartial Autocorrelation (PACF):\")\n",
    "print(\"For AR(1): Only lag 1 should be significant\")\n",
    "for k in range(4):\n",
    "    print(f\"  Lag {k}: {pacf_values[k]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bc3a32",
   "metadata": {},
   "source": [
    "### Autocorrelation in Returns\n",
    "\n",
    "**Efficient Market Hypothesis** implies:\n",
    "- Returns should have zero autocorrelation\n",
    "- Past returns cannot predict future returns\n",
    "\n",
    "**Reality**: Small positive autocorrelation at short lags (momentum), possible negative at longer lags (mean reversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab8346c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autocorrelation of Returns\n",
      "==================================================\n",
      "\n",
      "If markets are efficient, ACF should be ~0\n",
      "Significance threshold: ¬± 0.062\n",
      "\n",
      " Lag | ACF    | Significant?\n",
      "------------------------------\n",
      "  1  | +0.0428 | No\n",
      "  2  | +0.0022 | No\n",
      "  3  | +0.0126 | No\n",
      "  4  | -0.0520 | No\n",
      "  5  | +0.0245 | No\n"
     ]
    }
   ],
   "source": [
    "# Check autocorrelation in stock returns\n",
    "np.random.seed(42)\n",
    "# Simulate returns with slight autocorrelation (momentum)\n",
    "n = 1000\n",
    "momentum_returns = np.zeros(n)\n",
    "for t in range(1, n):\n",
    "    momentum_returns[t] = 0.05 * momentum_returns[t-1] + np.random.normal(0, 0.01)\n",
    "\n",
    "acf_returns = acf(momentum_returns, nlags=10)\n",
    "\n",
    "print(\"Autocorrelation of Returns\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\nIf markets are efficient, ACF should be ~0\")\n",
    "print(\"Significance threshold: ¬±\", round(1.96/np.sqrt(n), 3))\n",
    "print(\"\\n Lag | ACF    | Significant?\")\n",
    "print(\"-\" * 30)\n",
    "threshold = 1.96 / np.sqrt(n)\n",
    "for k in range(1, 6):\n",
    "    sig = \"Yes\" if abs(acf_returns[k]) > threshold else \"No\"\n",
    "    print(f\"  {k}  | {acf_returns[k]:+.4f} | {sig}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3976557",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ARIMA Models\n",
    "\n",
    "### Components\n",
    "\n",
    "**ARIMA(p, d, q)** combines:\n",
    "- **AR(p)**: Autoregressive (past values)\n",
    "- **I(d)**: Integrated (differencing order)\n",
    "- **MA(q)**: Moving Average (past errors)\n",
    "\n",
    "### AR(p) - Autoregressive\n",
    "\n",
    "Current value depends on past values:\n",
    "\n",
    "$$Y_t = c + \\phi_1 Y_{t-1} + \\phi_2 Y_{t-2} + ... + \\phi_p Y_{t-p} + \\epsilon_t$$\n",
    "\n",
    "- AR(1): $Y_t = c + \\phi Y_{t-1} + \\epsilon_t$\n",
    "- Stationary if $|\\phi| < 1$\n",
    "\n",
    "### MA(q) - Moving Average\n",
    "\n",
    "Current value depends on past errors:\n",
    "\n",
    "$$Y_t = \\mu + \\epsilon_t + \\theta_1 \\epsilon_{t-1} + ... + \\theta_q \\epsilon_{t-q}$$\n",
    "\n",
    "- Always stationary\n",
    "- Shocks have limited effect (q periods)\n",
    "\n",
    "### ARMA(p,q)\n",
    "\n",
    "Combines both:\n",
    "\n",
    "$$Y_t = c + \\sum_{i=1}^{p} \\phi_i Y_{t-i} + \\sum_{j=1}^{q} \\theta_j \\epsilon_{t-j} + \\epsilon_t$$\n",
    "\n",
    "### ARIMA(p,d,q)\n",
    "\n",
    "For non-stationary data, difference $d$ times first, then apply ARMA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acbf4a49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA Model Estimation\n",
      "==================================================\n",
      "True AR coefficients: œÜ‚ÇÅ = 0.5, œÜ‚ÇÇ = 0.3\n",
      "\n",
      "Estimated:\n",
      "  œÜ‚ÇÅ = 0.4941\n",
      "  œÜ‚ÇÇ = 0.2808\n",
      "\n",
      "AIC: 1404.49\n",
      "BIC: 1421.35\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Generate data from known AR(2) process\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "true_ar = [0.5, 0.3]  # AR coefficients\n",
    "\n",
    "ar2_data = np.zeros(n)\n",
    "for t in range(2, n):\n",
    "    ar2_data[t] = true_ar[0]*ar2_data[t-1] + true_ar[1]*ar2_data[t-2] + np.random.normal(0, 1)\n",
    "\n",
    "# Fit ARIMA model\n",
    "model = ARIMA(ar2_data, order=(2, 0, 0))\n",
    "fitted = model.fit()\n",
    "\n",
    "print(\"ARIMA Model Estimation\")\n",
    "print(\"=\"*50)\n",
    "print(f\"True AR coefficients: œÜ‚ÇÅ = {true_ar[0]}, œÜ‚ÇÇ = {true_ar[1]}\")\n",
    "print(f\"\\nEstimated:\")\n",
    "print(f\"  œÜ‚ÇÅ = {fitted.params[1]:.4f}\")\n",
    "print(f\"  œÜ‚ÇÇ = {fitted.params[2]:.4f}\")\n",
    "print(f\"\\nAIC: {fitted.aic:.2f}\")\n",
    "print(f\"BIC: {fitted.bic:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce803766",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "**ACF/PACF patterns**:\n",
    "\n",
    "| Model | ACF | PACF |\n",
    "|-------|-----|------|\n",
    "| AR(p) | Decays exponentially | Cuts off after lag p |\n",
    "| MA(q) | Cuts off after lag q | Decays exponentially |\n",
    "| ARMA(p,q) | Decays | Decays |\n",
    "\n",
    "**Information Criteria**:\n",
    "- **AIC** (Akaike): $-2\\ln(L) + 2k$\n",
    "- **BIC** (Bayesian): $-2\\ln(L) + k\\ln(n)$\n",
    "\n",
    "Lower is better. BIC penalizes complexity more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc64074",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Cointegration\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Two non-stationary series might have a **spurious correlation**.\n",
    "But sometimes, they move together in a meaningful way!\n",
    "\n",
    "### Definition\n",
    "\n",
    "Two I(1) series $X_t$ and $Y_t$ are **cointegrated** if there exists $\\beta$ such that:\n",
    "\n",
    "$$Z_t = Y_t - \\beta X_t \\sim I(0)$$\n",
    "\n",
    "The **spread** $Z_t$ is stationary, even though $X_t$ and $Y_t$ individually are not.\n",
    "\n",
    "### Finance Example\n",
    "\n",
    "Consider two stocks in the same sector:\n",
    "- Each stock price: Non-stationary (random walk)\n",
    "- Price ratio or spread: May be stationary (mean-reverting)\n",
    "\n",
    "This is the foundation of **pairs trading**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6280886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cointegration Example: Two 'Related' Stocks\n",
      "==================================================\n",
      "Hedge ratio (Œ≤): 1.6451\n",
      "\n",
      "Spread = Stock_A - 1.65 √ó Stock_B\n",
      "\n",
      "ADF test on spread:\n",
      "  Statistic: -21.7104\n",
      "  p-value: 0.0000\n",
      "\n",
      "‚úì Spread is STATIONARY - stocks are cointegrated!\n",
      "  ‚Üí Suitable for pairs trading\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate cointegration with pairs trading example\n",
    "np.random.seed(42)\n",
    "n = 500\n",
    "\n",
    "# Common factor (non-stationary)\n",
    "common_factor = np.cumsum(np.random.normal(0, 1, n))\n",
    "\n",
    "# Two cointegrated \"stocks\"\n",
    "stock_A = 50 + common_factor + np.random.normal(0, 0.5, n)  # Price A\n",
    "stock_B = 30 + 0.6 * common_factor + np.random.normal(0, 0.5, n)  # Price B (with different sensitivity)\n",
    "\n",
    "# Spread (should be stationary)\n",
    "beta = np.cov(stock_A, stock_B)[0,1] / np.var(stock_B)\n",
    "spread = stock_A - beta * stock_B\n",
    "\n",
    "print(\"Cointegration Example: Two 'Related' Stocks\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Hedge ratio (Œ≤): {beta:.4f}\")\n",
    "print(f\"\\nSpread = Stock_A - {beta:.2f} √ó Stock_B\")\n",
    "\n",
    "# Test stationarity of spread\n",
    "adf_result = adfuller(spread)\n",
    "print(f\"\\nADF test on spread:\")\n",
    "print(f\"  Statistic: {adf_result[0]:.4f}\")\n",
    "print(f\"  p-value: {adf_result[1]:.4f}\")\n",
    "\n",
    "if adf_result[1] < 0.05:\n",
    "    print(\"\\n‚úì Spread is STATIONARY - stocks are cointegrated!\")\n",
    "    print(\"  ‚Üí Suitable for pairs trading\")\n",
    "else:\n",
    "    print(\"\\n‚úó Spread is non-stationary - not cointegrated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc55e1d",
   "metadata": {},
   "source": [
    "### Pairs Trading Strategy\n",
    "\n",
    "**Setup**:\n",
    "1. Find cointegrated pair\n",
    "2. Calculate spread: $Z_t = A_t - \\beta B_t$\n",
    "3. Normalize: $Z_{norm} = \\frac{Z_t - \\mu_Z}{\\sigma_Z}$\n",
    "\n",
    "**Trading Rules**:\n",
    "- If $Z_{norm} > 2$: Spread too high ‚Üí Short A, Long Œ≤ units of B\n",
    "- If $Z_{norm} < -2$: Spread too low ‚Üí Long A, Short Œ≤ units of B\n",
    "- Exit when $|Z_{norm}| < 0.5$ (spread reverts to mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a4e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs Trading Signals\n",
      "==================================================\n",
      "Spread mean: 0.56\n",
      "Spread std: 0.93\n",
      "\n",
      "Trading signals generated:\n",
      "  Long spread (z < -2): 10 signals\n",
      "  Short spread (z > 2): 10 signals\n",
      "\n",
      "Z-score range: [-3.17, 3.58]\n"
     ]
    }
   ],
   "source": [
    "# Pairs trading signals\n",
    "spread_mean = spread.mean()\n",
    "spread_std = spread.std()\n",
    "z_score = (spread - spread_mean) / spread_std\n",
    "\n",
    "# Generate signals\n",
    "signals = np.zeros(len(z_score))\n",
    "signals[z_score > 2] = -1   # Short spread (spread too high)\n",
    "signals[z_score < -2] = 1   # Long spread (spread too low)\n",
    "\n",
    "# Count signals\n",
    "short_signals = np.sum(signals == -1)\n",
    "long_signals = np.sum(signals == 1)\n",
    "\n",
    "print(\"Pairs Trading Signals\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Spread mean: {spread_mean:.2f}\")\n",
    "print(f\"Spread std: {spread_std:.2f}\")\n",
    "print(f\"\\nTrading signals generated:\")\n",
    "print(f\"  Long spread (z < -2): {long_signals} signals\")\n",
    "print(f\"  Short spread (z > 2): {short_signals} signals\")\n",
    "print(f\"\\nZ-score range: [{z_score.min():.2f}, {z_score.max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2dad08",
   "metadata": {},
   "source": [
    "### Engle-Granger Cointegration Test\n",
    "\n",
    "**Procedure**:\n",
    "1. Regress $Y_t$ on $X_t$ to get $\\hat{\\beta}$\n",
    "2. Calculate residuals: $\\hat{Z}_t = Y_t - \\hat{\\beta} X_t$\n",
    "3. Test residuals for stationarity (ADF test)\n",
    "\n",
    "If residuals are stationary ‚Üí Series are cointegrated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bc9236",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Week 3 Key Formulas\n",
    "\n",
    "| Concept | Formula |\n",
    "|---------|--------|\n",
    "| Autocorrelation | $\\rho_k = \\frac{Cov(Y_t, Y_{t-k})}{Var(Y_t)}$ |\n",
    "| AR(1) Process | $Y_t = c + \\phi Y_{t-1} + \\epsilon_t$ |\n",
    "| MA(1) Process | $Y_t = \\mu + \\epsilon_t + \\theta \\epsilon_{t-1}$ |\n",
    "| Cointegration | $Z_t = Y_t - \\beta X_t \\sim I(0)$ |\n",
    "| Z-score | $Z = \\frac{X - \\mu}{\\sigma}$ |\n",
    "| AIC | $-2\\ln(L) + 2k$ |\n",
    "\n",
    "---\n",
    "\n",
    "*Next Week: Machine Learning Basics*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdd1e12",
   "metadata": {},
   "source": [
    "## üî¥ PROS & CONS: THEORY\n",
    "\n",
    "### ‚úÖ PROS (Advantages)\n",
    "\n",
    "| Advantage | Description | Real-World Application |\n",
    "|-----------|-------------|----------------------|\n",
    "| **Industry Standard** | Widely adopted in quantitative finance | Used by major hedge funds and banks |\n",
    "| **Well-Documented** | Extensive research and documentation | Easy to find resources and support |\n",
    "| **Proven Track Record** | Years of practical application | Validated in real market conditions |\n",
    "| **Interpretable** | Results can be explained to stakeholders | Important for risk management and compliance |\n",
    "\n",
    "### ‚ùå CONS (Limitations)\n",
    "\n",
    "| Limitation | Description | How to Mitigate |\n",
    "|------------|-------------|-----------------|\n",
    "| **Assumptions** | May not hold in all market conditions | Validate assumptions with data |\n",
    "| **Historical Bias** | Based on past data patterns | Use rolling windows and regime detection |\n",
    "| **Overfitting Risk** | May fit noise rather than signal | Use proper cross-validation |\n",
    "| **Computational Cost** | Can be resource-intensive | Optimize code and use appropriate hardware |\n",
    "\n",
    "### üéØ Real-World Usage\n",
    "\n",
    "**WHERE THIS IS USED:**\n",
    "- ‚úÖ Quantitative hedge funds (Two Sigma, Renaissance, Citadel)\n",
    "- ‚úÖ Investment banks (Goldman Sachs, JP Morgan, Morgan Stanley)\n",
    "- ‚úÖ Asset management firms\n",
    "- ‚úÖ Risk management departments\n",
    "- ‚úÖ Algorithmic trading desks\n",
    "\n",
    "**NOT JUST THEORY - THIS IS PRODUCTION CODE:**\n",
    "The techniques in this notebook are used daily by professionals managing billions of dollars."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
