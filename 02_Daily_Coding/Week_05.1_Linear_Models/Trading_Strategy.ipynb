{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07896e73",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Week 5.1: Linear Models Trading Strategy\n",
    "\n",
    "## OLS, Ridge, Lasso & Elastic Net for Return Prediction\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Objective\n",
    "Build a comprehensive trading strategy using linear regression models to predict stock returns and generate trading signals. We'll compare multiple regularization techniques and evaluate their effectiveness in a real-world trading context.\n",
    "\n",
    "### ðŸ“š Topics Covered\n",
    "- **Ordinary Least Squares (OLS)**: Baseline linear regression without regularization\n",
    "- **Ridge Regression (L2)**: Shrinks coefficients to reduce overfitting\n",
    "- **Lasso Regression (L1)**: Performs feature selection via sparsity\n",
    "- **Elastic Net**: Combines L1 and L2 penalties for balanced regularization\n",
    "- **Cross-Sectional Regression**: Factor analysis across multiple assets\n",
    "\n",
    "### ðŸ”— Building on Previous Weeks\n",
    "- **Week 1-2**: Python fundamentals, NumPy, Pandas operations\n",
    "- **Week 3**: Time series analysis, returns calculation, volatility\n",
    "- **Week 4**: ML foundations, train/test splits, cross-validation\n",
    "- **Week 5**: Portfolio optimization, risk metrics\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: Quantitative Trading Analyst  \n",
    "**Date**: Week 5.1 - Linear Models Module  \n",
    "**Version**: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42a8763",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Configuration & Setup\n",
    "\n",
    "Define the tickers and parameters for the strategy. You can easily modify these to analyze different assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e01f334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Strategy Configuration\n",
      "==================================================\n",
      "Tickers: ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
      "Period: 2020-01-01 to 2025-12-31\n",
      "Lookback: 20 days\n",
      "Prediction Horizon: 5 days\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - MODIFY THESE PARAMETERS AS NEEDED\n",
    "# ============================================================\n",
    "\n",
    "# Tickers to analyze (dynamic - change as needed)\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
    "\n",
    "# Date range for analysis\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2025-12-31'\n",
    "\n",
    "# Model parameters\n",
    "LOOKBACK_PERIOD = 20  # Days for feature calculation\n",
    "PREDICTION_HORIZON = 5  # Days ahead to predict\n",
    "TEST_SIZE = 0.2  # Proportion for testing\n",
    "N_SPLITS = 5  # Number of time series cross-validation splits\n",
    "\n",
    "# Regularization parameters for grid search\n",
    "ALPHA_RANGE = [0.001, 0.01, 0.1, 1.0, 10.0]\n",
    "L1_RATIO_RANGE = [0.1, 0.3, 0.5, 0.7, 0.9]  # For Elastic Net\n",
    "\n",
    "# Trading parameters\n",
    "TRANSACTION_COST = 0.001  # 10 bps per trade\n",
    "SIGNAL_THRESHOLD = 0.0  # Threshold for long/short signals\n",
    "\n",
    "print(f\"ðŸ“Š Strategy Configuration\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Tickers: {TICKERS}\")\n",
    "print(f\"Period: {START_DATE} to {END_DATE}\")\n",
    "print(f\"Lookback: {LOOKBACK_PERIOD} days\")\n",
    "print(f\"Prediction Horizon: {PREDICTION_HORIZON} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86d012a",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Import Libraries\n",
    "\n",
    "Import all necessary libraries for data processing, modeling, and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c60ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data fetching\n",
    "import yfinance as yf\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Statistical analysis\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"âœ… All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3470b3",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Data Acquisition\n",
    "\n",
    "Fetch historical price data from Yahoo Finance for all specified tickers. We'll download adjusted close prices and volume data for comprehensive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "583ed413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Downloading data for 5 tickers...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 52\u001b[39m\n\u001b[32m     43\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m     44\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mprices\u001b[39m\u001b[33m'\u001b[39m: prices,\n\u001b[32m     45\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mvolume\u001b[39m\u001b[33m'\u001b[39m: volume,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mopen\u001b[39m\u001b[33m'\u001b[39m: open_price\n\u001b[32m     49\u001b[39m     }\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Fetch the data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m stock_data = \u001b[43mfetch_stock_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTICKERS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTART_DATE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_DATE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m prices = stock_data[\u001b[33m'\u001b[39m\u001b[33mprices\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     54\u001b[39m volume = stock_data[\u001b[33m'\u001b[39m\u001b[33mvolume\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mfetch_stock_data\u001b[39m\u001b[34m(tickers, start, end)\u001b[39m\n\u001b[32m     29\u001b[39m     open_price = data[\u001b[33m'\u001b[39m\u001b[33mOpen\u001b[39m\u001b[33m'\u001b[39m].to_frame(name=tickers[\u001b[32m0\u001b[39m])\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m     prices = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mAdj Close\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     32\u001b[39m     volume = data[\u001b[33m'\u001b[39m\u001b[33mVolume\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     33\u001b[39m     high = data[\u001b[33m'\u001b[39m\u001b[33mHigh\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4112\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_single_key:\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4112\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4113\u001b[39m     indexer = \u001b[38;5;28mself\u001b[39m.columns.get_loc(key)\n\u001b[32m   4114\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/pandas/core/frame.py:4170\u001b[39m, in \u001b[36mDataFrame._getitem_multilevel\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   4169\u001b[39m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4170\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np.ndarray)):\n\u001b[32m   4172\u001b[39m         new_columns = \u001b[38;5;28mself\u001b[39m.columns[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/pandas/core/indexes/multi.py:3059\u001b[39m, in \u001b[36mMultiIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3056\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m mask\n\u001b[32m   3058\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m3059\u001b[39m     loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_level_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   3060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _maybe_to_slice(loc)\n\u001b[32m   3062\u001b[39m keylen = \u001b[38;5;28mlen\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/pandas/core/indexes/multi.py:3410\u001b[39m, in \u001b[36mMultiIndex._get_level_indexer\u001b[39m\u001b[34m(self, key, level, indexer)\u001b[39m\n\u001b[32m   3407\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[32m   3409\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3410\u001b[39m     idx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_loc_single_level_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3412\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m level > \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lexsort_depth == \u001b[32m0\u001b[39m:\n\u001b[32m   3413\u001b[39m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[32m   3414\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[32m   3415\u001b[39m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/pandas/core/indexes/multi.py:2999\u001b[39m, in \u001b[36mMultiIndex._get_loc_single_level_index\u001b[39m\u001b[34m(self, level_index, key)\u001b[39m\n\u001b[32m   2997\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m -\u001b[32m1\u001b[39m\n\u001b[32m   2998\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2999\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlevel_index\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Learning_Trading_ML/.venv/lib/python3.14/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "def fetch_stock_data(tickers: list, start: str, end: str) -> dict:\n",
    "    \"\"\"\n",
    "    Fetch historical stock data for multiple tickers.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tickers : list\n",
    "        List of stock ticker symbols\n",
    "    start : str\n",
    "        Start date in 'YYYY-MM-DD' format\n",
    "    end : str\n",
    "        End date in 'YYYY-MM-DD' format\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary with 'prices' and 'volume' DataFrames\n",
    "    \"\"\"\n",
    "    print(f\"ðŸ“¥ Downloading data for {len(tickers)} tickers...\")\n",
    "    \n",
    "    # Download all data at once\n",
    "    data = yf.download(tickers, start=start, end=end, progress=False)\n",
    "    \n",
    "    # Extract adjusted close and volume\n",
    "    if len(tickers) == 1:\n",
    "        prices = data['Adj Close'].to_frame(name=tickers[0])\n",
    "        volume = data['Volume'].to_frame(name=tickers[0])\n",
    "        high = data['High'].to_frame(name=tickers[0])\n",
    "        low = data['Low'].to_frame(name=tickers[0])\n",
    "        open_price = data['Open'].to_frame(name=tickers[0])\n",
    "    else:\n",
    "        prices = data['Adj Close']\n",
    "        volume = data['Volume']\n",
    "        high = data['High']\n",
    "        low = data['Low']\n",
    "        open_price = data['Open']\n",
    "    \n",
    "    # Drop any rows with missing data\n",
    "    prices = prices.dropna()\n",
    "    \n",
    "    print(f\"âœ… Downloaded {len(prices)} trading days of data\")\n",
    "    print(f\"ðŸ“… Date range: {prices.index[0].strftime('%Y-%m-%d')} to {prices.index[-1].strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    return {\n",
    "        'prices': prices,\n",
    "        'volume': volume,\n",
    "        'high': high,\n",
    "        'low': low,\n",
    "        'open': open_price\n",
    "    }\n",
    "\n",
    "# Fetch the data\n",
    "stock_data = fetch_stock_data(TICKERS, START_DATE, END_DATE)\n",
    "prices = stock_data['prices']\n",
    "volume = stock_data['volume']\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nðŸ“Š Sample Price Data:\")\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e897566",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Feature Engineering\n",
    "\n",
    "Create predictive features from price and volume data. These features capture various market dynamics:\n",
    "\n",
    "### Feature Categories:\n",
    "1. **Return Features**: Past returns at various horizons\n",
    "2. **Momentum Indicators**: RSI, moving average ratios\n",
    "3. **Volatility Features**: Rolling standard deviation, ATR-like measures\n",
    "4. **Volume Features**: Volume trends and ratios\n",
    "5. **Technical Indicators**: Bollinger Band position, price momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366d073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(prices_df: pd.DataFrame, volume_df: pd.DataFrame, \n",
    "                    lookback: int = 20) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create comprehensive feature set for return prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prices_df : pd.DataFrame\n",
    "        DataFrame with adjusted close prices\n",
    "    volume_df : pd.DataFrame\n",
    "        DataFrame with trading volume\n",
    "    lookback : int\n",
    "        Lookback period for rolling calculations\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Feature matrix for each ticker\n",
    "    \"\"\"\n",
    "    all_features = {}\n",
    "    \n",
    "    for ticker in prices_df.columns:\n",
    "        price = prices_df[ticker]\n",
    "        vol = volume_df[ticker]\n",
    "        \n",
    "        features = pd.DataFrame(index=prices_df.index)\n",
    "        \n",
    "        # =====================\n",
    "        # RETURN FEATURES\n",
    "        # =====================\n",
    "        # Daily returns\n",
    "        features['ret_1d'] = price.pct_change(1)\n",
    "        features['ret_5d'] = price.pct_change(5)\n",
    "        features['ret_10d'] = price.pct_change(10)\n",
    "        features['ret_20d'] = price.pct_change(20)\n",
    "        \n",
    "        # Log returns (for better statistical properties)\n",
    "        features['log_ret_1d'] = np.log(price / price.shift(1))\n",
    "        features['log_ret_5d'] = np.log(price / price.shift(5))\n",
    "        \n",
    "        # =====================\n",
    "        # MOMENTUM FEATURES\n",
    "        # =====================\n",
    "        # Moving average ratios\n",
    "        features['ma_ratio_5_20'] = price.rolling(5).mean() / price.rolling(20).mean()\n",
    "        features['ma_ratio_10_50'] = price.rolling(10).mean() / price.rolling(50).mean()\n",
    "        \n",
    "        # Price relative to moving averages\n",
    "        features['price_to_ma20'] = price / price.rolling(20).mean()\n",
    "        features['price_to_ma50'] = price / price.rolling(50).mean()\n",
    "        \n",
    "        # RSI (Relative Strength Index)\n",
    "        delta = price.diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "        rs = gain / loss\n",
    "        features['rsi_14'] = 100 - (100 / (1 + rs))\n",
    "        \n",
    "        # Momentum\n",
    "        features['momentum_10'] = price / price.shift(10) - 1\n",
    "        features['momentum_20'] = price / price.shift(20) - 1\n",
    "        \n",
    "        # =====================\n",
    "        # VOLATILITY FEATURES\n",
    "        # =====================\n",
    "        # Rolling volatility\n",
    "        features['volatility_10'] = features['ret_1d'].rolling(10).std()\n",
    "        features['volatility_20'] = features['ret_1d'].rolling(20).std()\n",
    "        features['volatility_60'] = features['ret_1d'].rolling(60).std()\n",
    "        \n",
    "        # Volatility ratio (short-term vs long-term)\n",
    "        features['vol_ratio'] = features['volatility_10'] / features['volatility_60']\n",
    "        \n",
    "        # High-Low range (proxy for intraday volatility)\n",
    "        features['range_pct'] = (stock_data['high'][ticker] - stock_data['low'][ticker]) / price\n",
    "        features['avg_range_10'] = features['range_pct'].rolling(10).mean()\n",
    "        \n",
    "        # =====================\n",
    "        # VOLUME FEATURES\n",
    "        # =====================\n",
    "        # Volume ratios\n",
    "        features['vol_ratio_5_20'] = vol.rolling(5).mean() / vol.rolling(20).mean()\n",
    "        features['vol_ma_ratio'] = vol / vol.rolling(20).mean()\n",
    "        \n",
    "        # Volume trend\n",
    "        features['vol_trend'] = vol.pct_change(5)\n",
    "        \n",
    "        # =====================\n",
    "        # TECHNICAL INDICATORS\n",
    "        # =====================\n",
    "        # Bollinger Band position\n",
    "        ma20 = price.rolling(20).mean()\n",
    "        std20 = price.rolling(20).std()\n",
    "        features['bb_position'] = (price - ma20) / (2 * std20)\n",
    "        \n",
    "        # Distance from 52-week high/low\n",
    "        features['dist_52w_high'] = price / price.rolling(252).max() - 1\n",
    "        features['dist_52w_low'] = price / price.rolling(252).min() - 1\n",
    "        \n",
    "        # Rate of change\n",
    "        features['roc_10'] = (price - price.shift(10)) / price.shift(10)\n",
    "        \n",
    "        # =====================\n",
    "        # MEAN REVERSION FEATURES\n",
    "        # =====================\n",
    "        features['zscore_20'] = (price - price.rolling(20).mean()) / price.rolling(20).std()\n",
    "        features['zscore_60'] = (price - price.rolling(60).mean()) / price.rolling(60).std()\n",
    "        \n",
    "        all_features[ticker] = features\n",
    "    \n",
    "    return all_features\n",
    "\n",
    "# Create features for all tickers\n",
    "print(\"ðŸ”§ Engineering features...\")\n",
    "features_dict = create_features(prices, volume, LOOKBACK_PERIOD)\n",
    "\n",
    "# Display feature summary\n",
    "sample_ticker = TICKERS[0]\n",
    "print(f\"\\nâœ… Created {len(features_dict[sample_ticker].columns)} features per ticker\")\n",
    "print(f\"\\nðŸ“‹ Feature List:\")\n",
    "for i, col in enumerate(features_dict[sample_ticker].columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef121b7",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Target Variable Construction\n",
    "\n",
    "Create the target variable: **Forward Returns** over the prediction horizon.\n",
    "\n",
    "We predict the return over the next `N` days, where `N = PREDICTION_HORIZON`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c610c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(prices_df: pd.DataFrame, horizon: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Create forward return targets for prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prices_df : pd.DataFrame\n",
    "        DataFrame with adjusted close prices\n",
    "    horizon : int\n",
    "        Number of days ahead to predict\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary of target series for each ticker\n",
    "    \"\"\"\n",
    "    targets = {}\n",
    "    \n",
    "    for ticker in prices_df.columns:\n",
    "        # Forward return: (P_t+h - P_t) / P_t\n",
    "        targets[ticker] = prices_df[ticker].pct_change(horizon).shift(-horizon)\n",
    "        # Alternative: log returns\n",
    "        # targets[ticker] = np.log(prices_df[ticker].shift(-horizon) / prices_df[ticker])\n",
    "    \n",
    "    return targets\n",
    "\n",
    "# Create targets\n",
    "targets_dict = create_target(prices, PREDICTION_HORIZON)\n",
    "\n",
    "print(f\"ðŸŽ¯ Target: {PREDICTION_HORIZON}-day forward return\")\n",
    "print(f\"\\nðŸ“Š Target Statistics for {sample_ticker}:\")\n",
    "target_stats = targets_dict[sample_ticker].dropna().describe()\n",
    "print(target_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b338dd",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Data Preparation for Modeling\n",
    "\n",
    "Prepare clean datasets for model training:\n",
    "1. Combine features and targets\n",
    "2. Remove rows with missing values\n",
    "3. Apply time series train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_modeling_data(features_dict: dict, targets_dict: dict, \n",
    "                          test_size: float = 0.2) -> dict:\n",
    "    \"\"\"\n",
    "    Prepare data for modeling with train/test split.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    features_dict : dict\n",
    "        Dictionary of feature DataFrames\n",
    "    targets_dict : dict\n",
    "        Dictionary of target Series\n",
    "    test_size : float\n",
    "        Proportion of data for testing\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Prepared data for each ticker\n",
    "    \"\"\"\n",
    "    prepared_data = {}\n",
    "    \n",
    "    for ticker in features_dict.keys():\n",
    "        # Combine features and target\n",
    "        df = features_dict[ticker].copy()\n",
    "        df['target'] = targets_dict[ticker]\n",
    "        \n",
    "        # Drop missing values\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Split data (time series - no shuffling!)\n",
    "        split_idx = int(len(df) * (1 - test_size))\n",
    "        \n",
    "        train_df = df.iloc[:split_idx]\n",
    "        test_df = df.iloc[split_idx:]\n",
    "        \n",
    "        # Separate features and target\n",
    "        feature_cols = [col for col in df.columns if col != 'target']\n",
    "        \n",
    "        X_train = train_df[feature_cols]\n",
    "        y_train = train_df['target']\n",
    "        X_test = test_df[feature_cols]\n",
    "        y_test = test_df['target']\n",
    "        \n",
    "        prepared_data[ticker] = {\n",
    "            'X_train': X_train,\n",
    "            'y_train': y_train,\n",
    "            'X_test': X_test,\n",
    "            'y_test': y_test,\n",
    "            'feature_cols': feature_cols,\n",
    "            'train_dates': train_df.index,\n",
    "            'test_dates': test_df.index,\n",
    "            'full_df': df\n",
    "        }\n",
    "        \n",
    "        print(f\"  {ticker}: Train={len(X_train)}, Test={len(X_test)} samples\")\n",
    "    \n",
    "    return prepared_data\n",
    "\n",
    "print(\"ðŸ“¦ Preparing modeling data...\")\n",
    "model_data = prepare_modeling_data(features_dict, targets_dict, TEST_SIZE)\n",
    "print(\"\\nâœ… Data preparation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb3fe67",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Model Training: OLS, Ridge, Lasso, Elastic Net\n",
    "\n",
    "### Model Comparison Framework\n",
    "\n",
    "| Model | Regularization | Key Property | Best For |\n",
    "|-------|---------------|--------------|----------|\n",
    "| **OLS** | None | Unbiased estimates | Baseline, interpretability |\n",
    "| **Ridge** | L2 (squared) | Shrinks all coefficients | Multicollinearity, many features |\n",
    "| **Lasso** | L1 (absolute) | Sparse solutions | Feature selection |\n",
    "| **Elastic Net** | L1 + L2 | Best of both | Correlated features, selection |\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "**OLS**: $\\min_\\beta \\|y - X\\beta\\|_2^2$\n",
    "\n",
    "**Ridge**: $\\min_\\beta \\|y - X\\beta\\|_2^2 + \\alpha\\|\\beta\\|_2^2$\n",
    "\n",
    "**Lasso**: $\\min_\\beta \\|y - X\\beta\\|_2^2 + \\alpha\\|\\beta\\|_1$\n",
    "\n",
    "**Elastic Net**: $\\min_\\beta \\|y - X\\beta\\|_2^2 + \\alpha\\rho\\|\\beta\\|_1 + \\frac{\\alpha(1-\\rho)}{2}\\|\\beta\\|_2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_models(X_train: pd.DataFrame, y_train: pd.Series, \n",
    "                     n_splits: int = 5) -> dict:\n",
    "    \"\"\"\n",
    "    Train all linear models with hyperparameter tuning.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train : pd.DataFrame\n",
    "        Training features\n",
    "    y_train : pd.Series\n",
    "        Training target\n",
    "    n_splits : int\n",
    "        Number of time series CV splits\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Trained models and their CV scores\n",
    "    \"\"\"\n",
    "    # Initialize time series cross-validator\n",
    "    tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    models = {}\n",
    "    \n",
    "    # 1. OLS (Ordinary Least Squares)\n",
    "    print(\"  Training OLS...\")\n",
    "    ols = LinearRegression()\n",
    "    ols.fit(X_scaled, y_train)\n",
    "    models['OLS'] = {\n",
    "        'model': ols,\n",
    "        'scaler': scaler,\n",
    "        'best_params': None\n",
    "    }\n",
    "    \n",
    "    # 2. Ridge Regression\n",
    "    print(\"  Training Ridge with CV...\")\n",
    "    ridge_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('ridge', Ridge())\n",
    "    ])\n",
    "    ridge_params = {'ridge__alpha': ALPHA_RANGE}\n",
    "    ridge_cv = GridSearchCV(ridge_pipe, ridge_params, cv=tscv, \n",
    "                            scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    ridge_cv.fit(X_train, y_train)\n",
    "    models['Ridge'] = {\n",
    "        'model': ridge_cv.best_estimator_,\n",
    "        'scaler': None,  # Included in pipeline\n",
    "        'best_params': ridge_cv.best_params_,\n",
    "        'cv_score': -ridge_cv.best_score_\n",
    "    }\n",
    "    \n",
    "    # 3. Lasso Regression\n",
    "    print(\"  Training Lasso with CV...\")\n",
    "    lasso_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('lasso', Lasso(max_iter=10000))\n",
    "    ])\n",
    "    lasso_params = {'lasso__alpha': ALPHA_RANGE}\n",
    "    lasso_cv = GridSearchCV(lasso_pipe, lasso_params, cv=tscv,\n",
    "                            scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    lasso_cv.fit(X_train, y_train)\n",
    "    models['Lasso'] = {\n",
    "        'model': lasso_cv.best_estimator_,\n",
    "        'scaler': None,\n",
    "        'best_params': lasso_cv.best_params_,\n",
    "        'cv_score': -lasso_cv.best_score_\n",
    "    }\n",
    "    \n",
    "    # 4. Elastic Net\n",
    "    print(\"  Training Elastic Net with CV...\")\n",
    "    enet_pipe = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('enet', ElasticNet(max_iter=10000))\n",
    "    ])\n",
    "    enet_params = {\n",
    "        'enet__alpha': ALPHA_RANGE,\n",
    "        'enet__l1_ratio': L1_RATIO_RANGE\n",
    "    }\n",
    "    enet_cv = GridSearchCV(enet_pipe, enet_params, cv=tscv,\n",
    "                           scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    enet_cv.fit(X_train, y_train)\n",
    "    models['ElasticNet'] = {\n",
    "        'model': enet_cv.best_estimator_,\n",
    "        'scaler': None,\n",
    "        'best_params': enet_cv.best_params_,\n",
    "        'cv_score': -enet_cv.best_score_\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Train models for all tickers\n",
    "all_models = {}\n",
    "print(\"ðŸ¤– Training models for each ticker...\\n\")\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    print(f\"ðŸ“ˆ {ticker}:\")\n",
    "    data = model_data[ticker]\n",
    "    all_models[ticker] = train_all_models(\n",
    "        data['X_train'], data['y_train'], N_SPLITS\n",
    "    )\n",
    "    print()\n",
    "\n",
    "print(\"âœ… All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff49c6",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Model Evaluation & Comparison\n",
    "\n",
    "Evaluate all models on the test set using multiple metrics:\n",
    "- **MSE**: Mean Squared Error (lower is better)\n",
    "- **MAE**: Mean Absolute Error (lower is better)  \n",
    "- **RÂ²**: Coefficient of Determination (higher is better)\n",
    "- **IC**: Information Coefficient (correlation with actual returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0ee890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models: dict, X_test: pd.DataFrame, \n",
    "                    y_test: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate all models and return performance metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : dict\n",
    "        Dictionary of trained models\n",
    "    X_test : pd.DataFrame\n",
    "        Test features\n",
    "    y_test : pd.Series\n",
    "        Test target\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Performance metrics for each model\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    predictions = {}\n",
    "    \n",
    "    for model_name, model_info in models.items():\n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Make predictions\n",
    "        if model_name == 'OLS':\n",
    "            scaler = model_info['scaler']\n",
    "            X_scaled = scaler.transform(X_test)\n",
    "            y_pred = model.predict(X_scaled)\n",
    "        else:\n",
    "            y_pred = model.predict(X_test)\n",
    "        \n",
    "        predictions[model_name] = y_pred\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        # Information Coefficient (Spearman correlation)\n",
    "        ic, _ = stats.spearmanr(y_test, y_pred)\n",
    "        \n",
    "        # Directional accuracy\n",
    "        direction_correct = np.mean(np.sign(y_test) == np.sign(y_pred))\n",
    "        \n",
    "        results.append({\n",
    "            'Model': model_name,\n",
    "            'MSE': mse,\n",
    "            'RMSE': np.sqrt(mse),\n",
    "            'MAE': mae,\n",
    "            'RÂ²': r2,\n",
    "            'IC': ic,\n",
    "            'Direction Accuracy': direction_correct,\n",
    "            'Best Params': str(model_info.get('best_params', 'N/A'))\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results), predictions\n",
    "\n",
    "# Evaluate all models for each ticker\n",
    "all_results = {}\n",
    "all_predictions = {}\n",
    "\n",
    "print(\"ðŸ“Š Evaluating models on test data...\\n\")\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    data = model_data[ticker]\n",
    "    results_df, preds = evaluate_models(\n",
    "        all_models[ticker], data['X_test'], data['y_test']\n",
    "    )\n",
    "    all_results[ticker] = results_df\n",
    "    all_predictions[ticker] = preds\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ðŸ“ˆ {ticker} - Model Performance Comparison\")\n",
    "    print(f\"{'='*60}\")\n",
    "    display_df = results_df[['Model', 'RMSE', 'MAE', 'RÂ²', 'IC', 'Direction Accuracy']].copy()\n",
    "    display_df['RMSE'] = display_df['RMSE'].apply(lambda x: f\"{x:.6f}\")\n",
    "    display_df['MAE'] = display_df['MAE'].apply(lambda x: f\"{x:.6f}\")\n",
    "    display_df['RÂ²'] = display_df['RÂ²'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_df['IC'] = display_df['IC'].apply(lambda x: f\"{x:.4f}\")\n",
    "    display_df['Direction Accuracy'] = display_df['Direction Accuracy'].apply(lambda x: f\"{x:.2%}\")\n",
    "    print(display_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b029c5",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Visualization: Model Performance Comparison\n",
    "\n",
    "Create comprehensive visualizations to compare model performance across all tickers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1586db78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate results across all tickers\n",
    "combined_results = []\n",
    "for ticker in TICKERS:\n",
    "    df = all_results[ticker].copy()\n",
    "    df['Ticker'] = ticker\n",
    "    combined_results.append(df)\n",
    "\n",
    "combined_df = pd.concat(combined_results, ignore_index=True)\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. RMSE Comparison\n",
    "ax1 = axes[0, 0]\n",
    "pivot_rmse = combined_df.pivot(index='Ticker', columns='Model', values='RMSE')\n",
    "pivot_rmse.plot(kind='bar', ax=ax1, width=0.8)\n",
    "ax1.set_title('ðŸ“‰ RMSE by Model and Ticker (Lower is Better)', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('RMSE')\n",
    "ax1.set_xlabel('')\n",
    "ax1.legend(title='Model', loc='upper right')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. Information Coefficient (IC)\n",
    "ax2 = axes[0, 1]\n",
    "pivot_ic = combined_df.pivot(index='Ticker', columns='Model', values='IC')\n",
    "pivot_ic.plot(kind='bar', ax=ax2, width=0.8)\n",
    "ax2.set_title('ðŸ“Š Information Coefficient by Model and Ticker (Higher is Better)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('IC (Spearman Correlation)')\n",
    "ax2.set_xlabel('')\n",
    "ax2.legend(title='Model', loc='upper right')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# 3. RÂ² Score\n",
    "ax3 = axes[1, 0]\n",
    "pivot_r2 = combined_df.pivot(index='Ticker', columns='Model', values='RÂ²')\n",
    "pivot_r2.plot(kind='bar', ax=ax3, width=0.8)\n",
    "ax3.set_title('ðŸ“ˆ RÂ² Score by Model and Ticker', fontsize=14, fontweight='bold')\n",
    "ax3.set_ylabel('RÂ² Score')\n",
    "ax3.set_xlabel('')\n",
    "ax3.legend(title='Model', loc='upper right')\n",
    "ax3.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 4. Direction Accuracy\n",
    "ax4 = axes[1, 1]\n",
    "pivot_dir = combined_df.pivot(index='Ticker', columns='Model', values='Direction Accuracy')\n",
    "pivot_dir.plot(kind='bar', ax=ax4, width=0.8)\n",
    "ax4.set_title('ðŸŽ¯ Directional Accuracy by Model and Ticker', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('Accuracy')\n",
    "ax4.set_xlabel('')\n",
    "ax4.legend(title='Model', loc='upper right')\n",
    "ax4.tick_params(axis='x', rotation=0)\n",
    "ax4.axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='Random (50%)')\n",
    "ax4.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.0%}'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Linear Models Performance Comparison', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7d034",
   "metadata": {},
   "source": [
    "## ðŸ”Ÿ Feature Importance Analysis\n",
    "\n",
    "Analyze which features are most important for predictions. Lasso naturally performs feature selection, making it ideal for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(models: dict, feature_names: list, ticker: str):\n",
    "    \"\"\"\n",
    "    Plot feature importance for all models.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : dict\n",
    "        Trained models dictionary\n",
    "    feature_names : list\n",
    "        List of feature names\n",
    "    ticker : str\n",
    "        Ticker symbol for title\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    model_names = ['OLS', 'Ridge', 'Lasso', 'ElasticNet']\n",
    "    \n",
    "    for idx, (model_name, ax) in enumerate(zip(model_names, axes.flat)):\n",
    "        model_info = models[model_name]\n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Extract coefficients\n",
    "        if model_name == 'OLS':\n",
    "            coefs = model.coef_\n",
    "        else:\n",
    "            # For pipeline models\n",
    "            coefs = model.named_steps[model_name.lower()].coef_\n",
    "        \n",
    "        # Create DataFrame for plotting\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': coefs\n",
    "        })\n",
    "        coef_df['Abs_Coef'] = np.abs(coef_df['Coefficient'])\n",
    "        coef_df = coef_df.sort_values('Abs_Coef', ascending=True).tail(15)\n",
    "        \n",
    "        # Plot\n",
    "        colors = ['green' if c > 0 else 'red' for c in coef_df['Coefficient']]\n",
    "        ax.barh(coef_df['Feature'], coef_df['Coefficient'], color=colors, alpha=0.7)\n",
    "        ax.set_title(f'{model_name} - Top 15 Features', fontsize=12, fontweight='bold')\n",
    "        ax.axvline(x=0, color='gray', linestyle='-', linewidth=0.5)\n",
    "        ax.set_xlabel('Coefficient Value')\n",
    "        \n",
    "        # Count non-zero features (for Lasso/ElasticNet)\n",
    "        non_zero = np.sum(np.abs(coefs) > 1e-10)\n",
    "        ax.text(0.95, 0.05, f'Non-zero: {non_zero}/{len(coefs)}', \n",
    "                transform=ax.transAxes, ha='right', fontsize=10,\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.suptitle(f'Feature Importance Analysis - {ticker}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot feature importance for first ticker\n",
    "sample_ticker = TICKERS[0]\n",
    "feature_names = model_data[sample_ticker]['feature_cols']\n",
    "plot_feature_importance(all_models[sample_ticker], feature_names, sample_ticker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79127302",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ Cross-Sectional Regression Analysis\n",
    "\n",
    "Perform cross-sectional regression to analyze factor exposures across all assets simultaneously. This is commonly used in factor investing to determine:\n",
    "- Factor risk premiums\n",
    "- Stock-specific alpha\n",
    "- Cross-sectional factor loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2140c23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_sectional_regression(prices_df: pd.DataFrame, \n",
    "                                features_dict: dict,\n",
    "                                lookback: int = 60) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform cross-sectional regression analysis.\n",
    "    \n",
    "    For each time period, regress returns across assets on their factor exposures.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    prices_df : pd.DataFrame\n",
    "        Price data for all tickers\n",
    "    features_dict : dict\n",
    "        Features for each ticker\n",
    "    lookback : int\n",
    "        Number of periods for rolling regression\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Factor premium time series\n",
    "    \"\"\"\n",
    "    # Calculate forward returns\n",
    "    returns = prices_df.pct_change(5).shift(-5)\n",
    "    \n",
    "    # Select common factors for cross-sectional analysis\n",
    "    factor_names = ['momentum_20', 'volatility_20', 'rsi_14', 'vol_ratio_5_20', 'zscore_20']\n",
    "    \n",
    "    # Get common dates\n",
    "    common_dates = returns.dropna().index\n",
    "    \n",
    "    factor_premiums = []\n",
    "    \n",
    "    for date in common_dates[-lookback:]:\n",
    "        # Cross-sectional data for this date\n",
    "        ret_cross = returns.loc[date]\n",
    "        \n",
    "        factor_cross = pd.DataFrame(index=prices_df.columns)\n",
    "        for factor in factor_names:\n",
    "            for ticker in prices_df.columns:\n",
    "                if factor in features_dict[ticker].columns:\n",
    "                    if date in features_dict[ticker].index:\n",
    "                        factor_cross.loc[ticker, factor] = features_dict[ticker].loc[date, factor]\n",
    "        \n",
    "        # Drop rows with missing data\n",
    "        factor_cross = factor_cross.dropna()\n",
    "        ret_cross = ret_cross.loc[factor_cross.index]\n",
    "        \n",
    "        if len(factor_cross) >= 3:  # Need at least 3 assets\n",
    "            # Run cross-sectional regression\n",
    "            X = sm.add_constant(factor_cross.astype(float))\n",
    "            y = ret_cross.astype(float)\n",
    "            \n",
    "            try:\n",
    "                model = sm.OLS(y, X).fit()\n",
    "                \n",
    "                premium_dict = {'Date': date}\n",
    "                premium_dict['Intercept'] = model.params.get('const', 0)\n",
    "                for factor in factor_names:\n",
    "                    if factor in model.params:\n",
    "                        premium_dict[factor] = model.params[factor]\n",
    "                        premium_dict[f'{factor}_tstat'] = model.tvalues.get(factor, 0)\n",
    "                \n",
    "                factor_premiums.append(premium_dict)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return pd.DataFrame(factor_premiums)\n",
    "\n",
    "# Perform cross-sectional analysis\n",
    "print(\"ðŸ”¬ Running cross-sectional regression analysis...\")\n",
    "cs_results = cross_sectional_regression(prices, features_dict)\n",
    "\n",
    "if len(cs_results) > 0:\n",
    "    cs_results = cs_results.set_index('Date')\n",
    "    \n",
    "    # Display summary statistics\n",
    "    factor_cols = ['momentum_20', 'volatility_20', 'rsi_14', 'vol_ratio_5_20', 'zscore_20']\n",
    "    \n",
    "    print(\"\\nðŸ“Š Factor Premium Summary Statistics:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    summary_data = []\n",
    "    for factor in factor_cols:\n",
    "        if factor in cs_results.columns:\n",
    "            mean_premium = cs_results[factor].mean()\n",
    "            std_premium = cs_results[factor].std()\n",
    "            t_stat = mean_premium / (std_premium / np.sqrt(len(cs_results)))\n",
    "            pct_positive = (cs_results[factor] > 0).mean()\n",
    "            \n",
    "            summary_data.append({\n",
    "                'Factor': factor,\n",
    "                'Mean Premium': f\"{mean_premium:.6f}\",\n",
    "                'Std Dev': f\"{std_premium:.6f}\",\n",
    "                'T-Stat': f\"{t_stat:.2f}\",\n",
    "                '% Positive': f\"{pct_positive:.1%}\"\n",
    "            })\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    print(summary_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"âš ï¸ Insufficient data for cross-sectional analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3232b61f",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ Trading Signal Generation\n",
    "\n",
    "Generate trading signals based on model predictions:\n",
    "- **Long Signal**: Predicted return > threshold\n",
    "- **Short Signal**: Predicted return < -threshold  \n",
    "- **Neutral**: Within threshold band\n",
    "\n",
    "We'll use the best-performing model for each ticker based on IC (Information Coefficient)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2325756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trading_signals(models: dict, X: pd.DataFrame, \n",
    "                              threshold: float = 0.0) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate trading signals from model predictions.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    models : dict\n",
    "        Trained models\n",
    "    X : pd.DataFrame\n",
    "        Feature data\n",
    "    threshold : float\n",
    "        Signal threshold\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Predictions and signals for each model\n",
    "    \"\"\"\n",
    "    signals = pd.DataFrame(index=X.index)\n",
    "    \n",
    "    for model_name, model_info in models.items():\n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Make predictions\n",
    "        if model_name == 'OLS':\n",
    "            scaler = model_info['scaler']\n",
    "            X_scaled = scaler.transform(X)\n",
    "            pred = model.predict(X_scaled)\n",
    "        else:\n",
    "            pred = model.predict(X)\n",
    "        \n",
    "        signals[f'{model_name}_Prediction'] = pred\n",
    "        signals[f'{model_name}_Signal'] = np.where(\n",
    "            pred > threshold, 1,  # Long\n",
    "            np.where(pred < -threshold, -1, 0)  # Short or Neutral\n",
    "        )\n",
    "    \n",
    "    return signals\n",
    "\n",
    "# Generate signals for all tickers\n",
    "all_signals = {}\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    data = model_data[ticker]\n",
    "    signals = generate_trading_signals(\n",
    "        all_models[ticker], \n",
    "        data['X_test'],\n",
    "        SIGNAL_THRESHOLD\n",
    "    )\n",
    "    signals['Actual_Return'] = data['y_test']\n",
    "    all_signals[ticker] = signals\n",
    "\n",
    "# Display latest signals\n",
    "print(\"ðŸ“¡ Latest Trading Signals (Test Period):\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    latest = all_signals[ticker].iloc[-1]\n",
    "    print(f\"\\nðŸ“ˆ {ticker}:\")\n",
    "    for model in ['OLS', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "        pred = latest[f'{model}_Prediction']\n",
    "        sig = latest[f'{model}_Signal']\n",
    "        signal_text = 'ðŸŸ¢ LONG' if sig == 1 else ('ðŸ”´ SHORT' if sig == -1 else 'âšª NEUTRAL')\n",
    "        print(f\"  {model:12s}: Pred={pred:+.4f} â†’ {signal_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0379b7",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£3ï¸âƒ£ Backtesting Trading Strategy\n",
    "\n",
    "Backtest the trading signals to evaluate strategy performance:\n",
    "- Calculate strategy returns based on signals\n",
    "- Account for transaction costs\n",
    "- Compare to buy-and-hold benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(signals_df: pd.DataFrame, prices: pd.Series,\n",
    "                      model_name: str, transaction_cost: float = 0.001) -> dict:\n",
    "    \"\"\"\n",
    "    Backtest trading strategy for a single model.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals_df : pd.DataFrame\n",
    "        DataFrame with signals and predictions\n",
    "    prices : pd.Series\n",
    "        Price series for the asset\n",
    "    model_name : str\n",
    "        Name of the model to backtest\n",
    "    transaction_cost : float\n",
    "        Transaction cost per trade (as fraction)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Backtest results\n",
    "    \"\"\"\n",
    "    # Get signals for the test period\n",
    "    signal_col = f'{model_name}_Signal'\n",
    "    signals = signals_df[signal_col]\n",
    "    \n",
    "    # Calculate daily returns (using actual returns from test data)\n",
    "    actual_returns = signals_df['Actual_Return'] / PREDICTION_HORIZON  # Approximate daily\n",
    "    \n",
    "    # Strategy returns (signal * return)\n",
    "    strategy_returns = signals.shift(1) * actual_returns\n",
    "    strategy_returns = strategy_returns.fillna(0)\n",
    "    \n",
    "    # Transaction costs (when signal changes)\n",
    "    signal_changes = signals.diff().abs()\n",
    "    costs = signal_changes * transaction_cost\n",
    "    \n",
    "    # Net returns\n",
    "    net_returns = strategy_returns - costs\n",
    "    \n",
    "    # Calculate cumulative returns\n",
    "    cumulative_strategy = (1 + net_returns).cumprod()\n",
    "    cumulative_benchmark = (1 + actual_returns).cumprod()\n",
    "    \n",
    "    # Performance metrics\n",
    "    total_return = cumulative_strategy.iloc[-1] - 1\n",
    "    benchmark_return = cumulative_benchmark.iloc[-1] - 1\n",
    "    \n",
    "    # Annualized metrics (assuming 252 trading days)\n",
    "    n_days = len(net_returns)\n",
    "    ann_return = (1 + total_return) ** (252 / n_days) - 1\n",
    "    ann_vol = net_returns.std() * np.sqrt(252)\n",
    "    sharpe = ann_return / ann_vol if ann_vol > 0 else 0\n",
    "    \n",
    "    # Max drawdown\n",
    "    rolling_max = cumulative_strategy.cummax()\n",
    "    drawdown = (cumulative_strategy - rolling_max) / rolling_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Win rate\n",
    "    winning_trades = (strategy_returns > 0).sum()\n",
    "    total_trades = (strategy_returns != 0).sum()\n",
    "    win_rate = winning_trades / total_trades if total_trades > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'cumulative_returns': cumulative_strategy,\n",
    "        'cumulative_benchmark': cumulative_benchmark,\n",
    "        'total_return': total_return,\n",
    "        'benchmark_return': benchmark_return,\n",
    "        'ann_return': ann_return,\n",
    "        'ann_volatility': ann_vol,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'win_rate': win_rate,\n",
    "        'n_trades': total_trades\n",
    "    }\n",
    "\n",
    "# Backtest all models for all tickers\n",
    "backtest_results = {}\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    backtest_results[ticker] = {}\n",
    "    for model_name in ['OLS', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "        results = backtest_strategy(\n",
    "            all_signals[ticker],\n",
    "            prices[ticker].loc[all_signals[ticker].index],\n",
    "            model_name,\n",
    "            TRANSACTION_COST\n",
    "        )\n",
    "        backtest_results[ticker][model_name] = results\n",
    "\n",
    "# Display backtest summary\n",
    "print(\"ðŸ“Š Backtest Performance Summary\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    print(f\"\\nðŸ“ˆ {ticker}:\")\n",
    "    print(\"-\"*90)\n",
    "    print(f\"{'Model':<12} {'Total Ret':>12} {'Ann. Ret':>12} {'Ann. Vol':>12} {'Sharpe':>10} {'MaxDD':>10} {'Win Rate':>10}\")\n",
    "    print(\"-\"*90)\n",
    "    \n",
    "    for model_name in ['OLS', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "        r = backtest_results[ticker][model_name]\n",
    "        print(f\"{model_name:<12} {r['total_return']:>+11.2%} {r['ann_return']:>+11.2%} \"\n",
    "              f\"{r['ann_volatility']:>11.2%} {r['sharpe_ratio']:>10.2f} \"\n",
    "              f\"{r['max_drawdown']:>10.2%} {r['win_rate']:>10.2%}\")\n",
    "    \n",
    "    # Benchmark\n",
    "    bench = backtest_results[ticker]['OLS']['benchmark_return']\n",
    "    print(f\"{'Buy & Hold':<12} {bench:>+11.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83837368",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£4ï¸âƒ£ Strategy Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43150f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cumulative returns for each ticker\n",
    "fig, axes = plt.subplots(len(TICKERS), 1, figsize=(14, 4*len(TICKERS)))\n",
    "if len(TICKERS) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "colors = {'OLS': '#1f77b4', 'Ridge': '#ff7f0e', 'Lasso': '#2ca02c', \n",
    "          'ElasticNet': '#d62728', 'Benchmark': '#7f7f7f'}\n",
    "\n",
    "for idx, ticker in enumerate(TICKERS):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    for model_name in ['OLS', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "        cum_ret = backtest_results[ticker][model_name]['cumulative_returns']\n",
    "        ax.plot(cum_ret.index, cum_ret.values, label=model_name, \n",
    "                color=colors[model_name], linewidth=1.5)\n",
    "    \n",
    "    # Benchmark\n",
    "    bench = backtest_results[ticker]['OLS']['cumulative_benchmark']\n",
    "    ax.plot(bench.index, bench.values, label='Buy & Hold', \n",
    "            color=colors['Benchmark'], linewidth=2, linestyle='--')\n",
    "    \n",
    "    ax.set_title(f'{ticker} - Cumulative Strategy Returns', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Cumulative Return')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.axhline(y=1, color='gray', linestyle='-', alpha=0.3)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Trading Strategy Backtest Results', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3ae2e",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£5ï¸âƒ£ Model Selection & Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bce31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_model(backtest_results: dict, metric: str = 'sharpe_ratio') -> dict:\n",
    "    \"\"\"\n",
    "    Select the best performing model for each ticker.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    backtest_results : dict\n",
    "        Backtest results for all models and tickers\n",
    "    metric : str\n",
    "        Metric to use for selection\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Best model for each ticker\n",
    "    \"\"\"\n",
    "    best_models = {}\n",
    "    \n",
    "    for ticker in backtest_results.keys():\n",
    "        best_metric = -np.inf\n",
    "        best_model = None\n",
    "        \n",
    "        for model_name, results in backtest_results[ticker].items():\n",
    "            if results[metric] > best_metric:\n",
    "                best_metric = results[metric]\n",
    "                best_model = model_name\n",
    "        \n",
    "        best_models[ticker] = {\n",
    "            'model': best_model,\n",
    "            metric: best_metric,\n",
    "            'results': backtest_results[ticker][best_model]\n",
    "        }\n",
    "    \n",
    "    return best_models\n",
    "\n",
    "# Select best models\n",
    "best_models = select_best_model(backtest_results, 'sharpe_ratio')\n",
    "\n",
    "print(\"ðŸ† Best Model Selection (by Sharpe Ratio)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    best = best_models[ticker]\n",
    "    r = best['results']\n",
    "    print(f\"\\nðŸ“ˆ {ticker}:\")\n",
    "    print(f\"   Best Model: {best['model']}\")\n",
    "    print(f\"   Sharpe Ratio: {r['sharpe_ratio']:.2f}\")\n",
    "    print(f\"   Annual Return: {r['ann_return']:+.2%}\")\n",
    "    print(f\"   Max Drawdown: {r['max_drawdown']:.2%}\")\n",
    "    print(f\"   Win Rate: {r['win_rate']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38653cb6",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£6ï¸âƒ£ Current Signals & Recommendations\n",
    "\n",
    "Generate current trading signals using the most recent data and the best-performing models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc20328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_signals(features_dict: dict, all_models: dict, \n",
    "                         best_models: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate current trading signals using the best model for each ticker.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    features_dict : dict\n",
    "        Feature data for all tickers\n",
    "    all_models : dict\n",
    "        All trained models\n",
    "    best_models : dict\n",
    "        Best model selection for each ticker\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame : Current signals and recommendations\n",
    "    \"\"\"\n",
    "    current_signals = []\n",
    "    \n",
    "    for ticker in features_dict.keys():\n",
    "        # Get latest feature data\n",
    "        features = features_dict[ticker].dropna()\n",
    "        if len(features) == 0:\n",
    "            continue\n",
    "            \n",
    "        latest_features = features.iloc[[-1]]\n",
    "        latest_date = features.index[-1]\n",
    "        \n",
    "        # Get best model\n",
    "        best_model_name = best_models[ticker]['model']\n",
    "        model_info = all_models[ticker][best_model_name]\n",
    "        model = model_info['model']\n",
    "        \n",
    "        # Make prediction\n",
    "        if best_model_name == 'OLS':\n",
    "            scaler = model_info['scaler']\n",
    "            X_scaled = scaler.transform(latest_features)\n",
    "            prediction = model.predict(X_scaled)[0]\n",
    "        else:\n",
    "            prediction = model.predict(latest_features)[0]\n",
    "        \n",
    "        # Generate signal\n",
    "        if prediction > SIGNAL_THRESHOLD:\n",
    "            signal = 'LONG'\n",
    "            emoji = 'ðŸŸ¢'\n",
    "        elif prediction < -SIGNAL_THRESHOLD:\n",
    "            signal = 'SHORT'\n",
    "            emoji = 'ðŸ”´'\n",
    "        else:\n",
    "            signal = 'NEUTRAL'\n",
    "            emoji = 'âšª'\n",
    "        \n",
    "        # Confidence (based on prediction magnitude)\n",
    "        confidence = min(abs(prediction) / 0.05 * 100, 100)  # Scale to 100%\n",
    "        \n",
    "        current_signals.append({\n",
    "            'Ticker': ticker,\n",
    "            'Date': latest_date.strftime('%Y-%m-%d'),\n",
    "            'Best Model': best_model_name,\n",
    "            'Predicted Return': prediction,\n",
    "            'Signal': signal,\n",
    "            'Signal Emoji': emoji,\n",
    "            'Confidence': confidence\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(current_signals)\n",
    "\n",
    "# Generate current signals\n",
    "current_signals_df = get_current_signals(features_dict, all_models, best_models)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸš¦ CURRENT TRADING SIGNALS & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nðŸ“… Signal Date: {current_signals_df['Date'].iloc[0]}\")\n",
    "print(f\"â±ï¸  Prediction Horizon: {PREDICTION_HORIZON} trading days\")\n",
    "print(\"\\n\")\n",
    "\n",
    "for _, row in current_signals_df.iterrows():\n",
    "    print(f\"{row['Signal Emoji']} {row['Ticker']:6s} | {row['Signal']:8s} | \"\n",
    "          f\"Pred: {row['Predicted Return']:+.4f} | Model: {row['Best Model']:10s} | \"\n",
    "          f\"Confidence: {row['Confidence']:.0f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"ðŸ“ SIGNAL INTERPRETATION:\")\n",
    "print(\"   ðŸŸ¢ LONG  = Model predicts positive returns - Consider buying\")\n",
    "print(\"   ðŸ”´ SHORT = Model predicts negative returns - Consider selling/shorting\")\n",
    "print(\"   âšª NEUTRAL = Model prediction near zero - Hold/No action\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fb4338",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£7ï¸âƒ£ Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary visualization\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# 1. Signal Summary (top left)\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "signal_colors = {'LONG': 'green', 'SHORT': 'red', 'NEUTRAL': 'gray'}\n",
    "colors = [signal_colors[s] for s in current_signals_df['Signal']]\n",
    "bars = ax1.barh(current_signals_df['Ticker'], current_signals_df['Predicted Return'], color=colors, alpha=0.7)\n",
    "ax1.axvline(x=0, color='black', linewidth=1)\n",
    "ax1.set_title('Current Predicted Returns by Ticker', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Predicted Return')\n",
    "\n",
    "# Add signal labels\n",
    "for i, (bar, signal) in enumerate(zip(bars, current_signals_df['Signal'])):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "             signal, ha='left', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "# 2. Model Performance Heatmap (top right)\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "sharpe_data = []\n",
    "for ticker in TICKERS:\n",
    "    row = []\n",
    "    for model in ['OLS', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "        row.append(backtest_results[ticker][model]['sharpe_ratio'])\n",
    "    sharpe_data.append(row)\n",
    "\n",
    "sharpe_df = pd.DataFrame(sharpe_data, index=TICKERS, columns=['OLS', 'Ridge', 'Lasso', 'ElasticNet'])\n",
    "sns.heatmap(sharpe_df, annot=True, fmt='.2f', cmap='RdYlGn', center=0, ax=ax2)\n",
    "ax2.set_title('Sharpe Ratio Heatmap (Model x Ticker)', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Best Model Distribution (bottom left)\n",
    "ax3 = plt.subplot(2, 2, 3)\n",
    "best_model_counts = current_signals_df['Best Model'].value_counts()\n",
    "ax3.pie(best_model_counts.values, labels=best_model_counts.index, autopct='%1.0f%%',\n",
    "        colors=plt.cm.Set2.colors[:len(best_model_counts)])\n",
    "ax3.set_title('Best Model Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 4. Signal Distribution (bottom right)\n",
    "ax4 = plt.subplot(2, 2, 4)\n",
    "signal_counts = current_signals_df['Signal'].value_counts()\n",
    "colors_pie = [signal_colors.get(s, 'gray') for s in signal_counts.index]\n",
    "ax4.pie(signal_counts.values, labels=signal_counts.index, autopct='%1.0f%%',\n",
    "        colors=colors_pie, explode=[0.05]*len(signal_counts))\n",
    "ax4.set_title('Current Signal Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('ðŸ“Š Linear Models Trading Strategy Dashboard', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5377574",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£8ï¸âƒ£ Final Recommendations & Conclusions\n",
    "\n",
    "### Summary of Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f238c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“‹ FINAL ANALYSIS & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate aggregate statistics\n",
    "avg_ic = combined_df.groupby('Model')['IC'].mean()\n",
    "avg_sharpe = pd.DataFrame(sharpe_data, columns=['OLS', 'Ridge', 'Lasso', 'ElasticNet']).mean()\n",
    "\n",
    "print(\"\\nðŸ“Š AGGREGATE MODEL PERFORMANCE:\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Model':<15} {'Avg IC':>12} {'Avg Sharpe':>12}\")\n",
    "print(\"-\"*50)\n",
    "for model in ['OLS', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "    print(f\"{model:<15} {avg_ic[model]:>12.4f} {avg_sharpe[model]:>12.2f}\")\n",
    "\n",
    "# Best overall model\n",
    "best_overall = avg_sharpe.idxmax()\n",
    "print(f\"\\nðŸ† BEST OVERALL MODEL: {best_overall} (Avg Sharpe: {avg_sharpe[best_overall]:.2f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ’¡ KEY INSIGHTS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "1. REGULARIZATION IMPACT:\n",
    "   â€¢ Ridge/Lasso often outperform OLS by reducing overfitting\n",
    "   â€¢ Elastic Net provides a balance between L1 and L2 regularization\n",
    "   â€¢ Feature selection from Lasso helps identify key predictors\n",
    "\n",
    "2. FEATURE IMPORTANCE:\n",
    "   â€¢ Momentum and mean-reversion features typically show significance\n",
    "   â€¢ Volatility features help predict return magnitude\n",
    "   â€¢ Volume-based features capture liquidity effects\n",
    "\n",
    "3. TRADING CONSIDERATIONS:\n",
    "   â€¢ Transaction costs significantly impact net returns\n",
    "   â€¢ Signal stability varies by model - regularized models often more stable\n",
    "   â€¢ Directional accuracy is often modest (~50-55%) but profitable due to return magnitude\n",
    "\n",
    "4. RISK MANAGEMENT:\n",
    "   â€¢ Always use position sizing based on prediction confidence\n",
    "   â€¢ Monitor rolling Sharpe ratio for regime changes\n",
    "   â€¢ Diversify across multiple tickers to reduce idiosyncratic risk\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"âš ï¸  DISCLAIMER:\")\n",
    "print(\"=\"*80)\n",
    "print(\"\"\"\n",
    "This analysis is for EDUCATIONAL PURPOSES ONLY. Past performance does not guarantee\n",
    "future results. Always perform your own due diligence and consider consulting a\n",
    "financial advisor before making investment decisions. Model predictions are based\n",
    "on historical patterns which may not persist in the future.\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… Analysis Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b4f8b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“š References & Further Reading\n",
    "\n",
    "### Linear Models in Finance:\n",
    "- Hastie, Tibshirani, Friedman - \"The Elements of Statistical Learning\"\n",
    "- James, Witten, Hastie, Tibshirani - \"An Introduction to Statistical Learning\"\n",
    "\n",
    "### Quantitative Finance:\n",
    "- Lopez de Prado - \"Advances in Financial Machine Learning\"\n",
    "- Chan - \"Quantitative Trading\"\n",
    "- Narang - \"Inside the Black Box\"\n",
    "\n",
    "### sklearn Documentation:\n",
    "- [Linear Models](https://scikit-learn.org/stable/modules/linear_model.html)\n",
    "- [Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "\n",
    "---\n",
    "\n",
    "**End of Week 5.1 - Linear Models Trading Strategy Notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
