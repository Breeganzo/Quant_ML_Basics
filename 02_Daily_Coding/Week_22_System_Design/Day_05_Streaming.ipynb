{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58585c1",
   "metadata": {},
   "source": [
    "# Day 05: Streaming Data Processing for Trading Systems\n",
    "\n",
    "## Week 22: System Design\n",
    "\n",
    "This notebook covers streaming data processing techniques essential for building real-time trading systems. We'll explore:\n",
    "\n",
    "- **Stream generators** for simulating market data feeds\n",
    "- **Sliding window processors** for efficient data buffering\n",
    "- **Real-time calculations** (moving averages, VWAP, etc.)\n",
    "- **Anomaly detection** on streaming data\n",
    "- **Async processing** for concurrent data handling\n",
    "\n",
    "### Why Streaming Matters in Finance\n",
    "\n",
    "Trading systems require real-time data processing with:\n",
    "- **Low latency**: Milliseconds matter for price updates\n",
    "- **High throughput**: Thousands of ticks per second\n",
    "- **Memory efficiency**: Can't store all historical data in RAM\n",
    "- **Continuous computation**: Rolling statistics, signals, risk metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a41ffbb",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220d5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Streaming Data Processing Libraries\n",
    "====================================\n",
    "Core libraries for building streaming data pipelines in Python.\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import random\n",
    "import time\n",
    "from collections import deque\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "from typing import (\n",
    "    AsyncGenerator,\n",
    "    Callable,\n",
    "    Deque,\n",
    "    Dict,\n",
    "    Generator,\n",
    "    List,\n",
    "    Optional,\n",
    "    Tuple,\n",
    "    TypeVar,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For Jupyter async support\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900e5a9e",
   "metadata": {},
   "source": [
    "## 2. Data Structures for Streaming\n",
    "\n",
    "### Tick Data Structure\n",
    "\n",
    "First, let's define a standard data structure for market data ticks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Tick:\n",
    "    \"\"\"\n",
    "    Represents a single market data tick.\n",
    "    \n",
    "    Attributes:\n",
    "        timestamp: When the tick occurred\n",
    "        symbol: Trading instrument identifier\n",
    "        price: Trade/quote price\n",
    "        volume: Trade size or quote quantity\n",
    "        side: 'bid', 'ask', or 'trade'\n",
    "    \"\"\"\n",
    "    timestamp: datetime\n",
    "    symbol: str\n",
    "    price: float\n",
    "    volume: float\n",
    "    side: str = 'trade'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Tick({self.symbol} @ {self.price:.2f} x {self.volume:.0f})\"\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class OHLCV:\n",
    "    \"\"\"\n",
    "    OHLCV bar for aggregated price data.\n",
    "    \"\"\"\n",
    "    timestamp: datetime\n",
    "    symbol: str\n",
    "    open: float\n",
    "    high: float\n",
    "    low: float\n",
    "    close: float\n",
    "    volume: float\n",
    "    trade_count: int = 0\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"OHLCV({self.symbol} O:{self.open:.2f} H:{self.high:.2f} L:{self.low:.2f} C:{self.close:.2f} V:{self.volume:.0f})\"\n",
    "\n",
    "\n",
    "# Example tick\n",
    "tick = Tick(\n",
    "    timestamp=datetime.now(),\n",
    "    symbol=\"AAPL\",\n",
    "    price=185.50,\n",
    "    volume=100,\n",
    "    side='trade'\n",
    ")\n",
    "print(f\"Example tick: {tick}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41459982",
   "metadata": {},
   "source": [
    "## 3. Simple Data Stream Generator\n",
    "\n",
    "A generator function that yields simulated price ticks. Generators are memory-efficient as they produce data on-demand rather than storing everything in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a2751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def price_tick_generator(\n",
    "    symbol: str = \"AAPL\",\n",
    "    initial_price: float = 100.0,\n",
    "    volatility: float = 0.02,\n",
    "    num_ticks: int = 1000,\n",
    "    ticks_per_second: float = 10.0\n",
    ") -> Generator[Tick, None, None]:\n",
    "    \"\"\"\n",
    "    Generate simulated price ticks using geometric Brownian motion.\n",
    "    \n",
    "    Parameters:\n",
    "        symbol: Trading symbol\n",
    "        initial_price: Starting price\n",
    "        volatility: Price volatility (std dev of returns)\n",
    "        num_ticks: Number of ticks to generate\n",
    "        ticks_per_second: Simulated tick frequency\n",
    "        \n",
    "    Yields:\n",
    "        Tick objects with timestamp, price, and volume\n",
    "    \"\"\"\n",
    "    price = initial_price\n",
    "    base_time = datetime.now()\n",
    "    \n",
    "    for i in range(num_ticks):\n",
    "        # Simulate price movement (GBM-like)\n",
    "        returns = np.random.normal(0, volatility)\n",
    "        price = price * (1 + returns)\n",
    "        \n",
    "        # Simulate volume (log-normal distribution)\n",
    "        volume = int(np.exp(np.random.normal(5, 1)))  # ~150 avg volume\n",
    "        \n",
    "        # Create timestamp\n",
    "        timestamp = base_time + timedelta(seconds=i / ticks_per_second)\n",
    "        \n",
    "        yield Tick(\n",
    "            timestamp=timestamp,\n",
    "            symbol=symbol,\n",
    "            price=price,\n",
    "            volume=volume,\n",
    "            side=random.choice(['trade', 'bid', 'ask'])\n",
    "        )\n",
    "\n",
    "\n",
    "# Test the generator\n",
    "print(\"First 10 ticks from generator:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "gen = price_tick_generator(num_ticks=10)\n",
    "for tick in gen:\n",
    "    print(f\"{tick.timestamp.strftime('%H:%M:%S.%f')[:-3]} | {tick}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6989475e",
   "metadata": {},
   "source": [
    "## 4. Sliding Window Processor\n",
    "\n",
    "A sliding window maintains a fixed-size buffer of the most recent data points. Using `deque` with `maxlen` provides O(1) append and automatic eviction of old data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = TypeVar('T')\n",
    "\n",
    "class SlidingWindow:\n",
    "    \"\"\"\n",
    "    Fixed-size sliding window using deque for O(1) operations.\n",
    "    \n",
    "    Features:\n",
    "    - Automatic eviction when window is full\n",
    "    - Memory-efficient for streaming data\n",
    "    - Supports iteration and indexing\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size: int):\n",
    "        \"\"\"\n",
    "        Initialize sliding window.\n",
    "        \n",
    "        Parameters:\n",
    "            window_size: Maximum number of elements in window\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self._buffer: Deque = deque(maxlen=window_size)\n",
    "        \n",
    "    def add(self, item) -> Optional[object]:\n",
    "        \"\"\"\n",
    "        Add item to window. Returns evicted item if window was full.\n",
    "        \"\"\"\n",
    "        evicted = None\n",
    "        if len(self._buffer) == self.window_size:\n",
    "            evicted = self._buffer[0]  # Will be evicted\n",
    "        self._buffer.append(item)\n",
    "        return evicted\n",
    "    \n",
    "    def is_full(self) -> bool:\n",
    "        \"\"\"Check if window has reached capacity.\"\"\"\n",
    "        return len(self._buffer) == self.window_size\n",
    "    \n",
    "    def get_data(self) -> List:\n",
    "        \"\"\"Return copy of window data as list.\"\"\"\n",
    "        return list(self._buffer)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._buffer)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self._buffer[index]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self._buffer)\n",
    "\n",
    "\n",
    "# Demonstrate sliding window\n",
    "print(\"Sliding Window Demo (size=5):\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "window = SlidingWindow(window_size=5)\n",
    "\n",
    "for i in range(8):\n",
    "    evicted = window.add(i * 10)\n",
    "    print(f\"Added: {i*10:3d} | Window: {window.get_data()} | Evicted: {evicted}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74492139",
   "metadata": {},
   "source": [
    "## 5. Real-Time Moving Average Calculator\n",
    "\n",
    "An efficient incremental SMA that updates with each new data point without recalculating the entire window. This is crucial for low-latency systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05d1394",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingSMA:\n",
    "    \"\"\"\n",
    "    Streaming Simple Moving Average with O(1) update complexity.\n",
    "    \n",
    "    Instead of recalculating sum each time, we:\n",
    "    1. Subtract the oldest value (being evicted)\n",
    "    2. Add the new value\n",
    "    3. Divide by window size\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size: int):\n",
    "        self.window_size = window_size\n",
    "        self._window: Deque[float] = deque(maxlen=window_size)\n",
    "        self._sum: float = 0.0\n",
    "        \n",
    "    def update(self, value: float) -> Optional[float]:\n",
    "        \"\"\"\n",
    "        Add new value and return updated SMA.\n",
    "        \n",
    "        Returns:\n",
    "            Current SMA, or None if window not yet full\n",
    "        \"\"\"\n",
    "        # Subtract evicted value if window is full\n",
    "        if len(self._window) == self.window_size:\n",
    "            self._sum -= self._window[0]\n",
    "            \n",
    "        # Add new value\n",
    "        self._window.append(value)\n",
    "        self._sum += value\n",
    "        \n",
    "        # Return SMA only when window is full\n",
    "        if len(self._window) == self.window_size:\n",
    "            return self._sum / self.window_size\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def current_sma(self) -> Optional[float]:\n",
    "        \"\"\"Get current SMA value.\"\"\"\n",
    "        if len(self._window) == self.window_size:\n",
    "            return self._sum / self.window_size\n",
    "        return None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"StreamingSMA(window={self.window_size}, sma={self.current_sma})\"\n",
    "\n",
    "\n",
    "# Demo: Streaming SMA on price data\n",
    "print(\"Streaming SMA Demo (window=5):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "sma = StreamingSMA(window_size=5)\n",
    "prices = [100, 102, 101, 103, 105, 104, 106, 108, 107, 109]\n",
    "\n",
    "for i, price in enumerate(prices):\n",
    "    result = sma.update(price)\n",
    "    status = f\"{result:.2f}\" if result else \"warming up...\"\n",
    "    print(f\"Tick {i+1:2d}: Price={price:6.2f} | SMA={status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f3a5f",
   "metadata": {},
   "source": [
    "## 6. Exponential Moving Average Stream Processor\n",
    "\n",
    "EMA applies exponential weighting to streaming data. It's stateless (no window storage needed) and responds faster to recent price changes.\n",
    "\n",
    "**Formula**: $EMA_t = \\alpha \\cdot price_t + (1 - \\alpha) \\cdot EMA_{t-1}$\n",
    "\n",
    "Where $\\alpha = \\frac{2}{span + 1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015f06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingEMA:\n",
    "    \"\"\"\n",
    "    Streaming Exponential Moving Average.\n",
    "    \n",
    "    Advantages over SMA:\n",
    "    - No window storage needed (memory efficient)\n",
    "    - Responds faster to recent changes\n",
    "    - O(1) time and O(1) space complexity\n",
    "    \n",
    "    Parameters:\n",
    "        span: EMA span (similar to SMA window)\n",
    "        alpha: Smoothing factor (calculated from span if not provided)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, span: int = None, alpha: float = None):\n",
    "        if alpha is not None:\n",
    "            self.alpha = alpha\n",
    "        elif span is not None:\n",
    "            self.alpha = 2.0 / (span + 1)\n",
    "        else:\n",
    "            raise ValueError(\"Either span or alpha must be provided\")\n",
    "            \n",
    "        self.span = span\n",
    "        self._ema: Optional[float] = None\n",
    "        self._count: int = 0\n",
    "        \n",
    "    def update(self, value: float) -> float:\n",
    "        \"\"\"\n",
    "        Update EMA with new value.\n",
    "        \n",
    "        Returns:\n",
    "            Updated EMA value\n",
    "        \"\"\"\n",
    "        self._count += 1\n",
    "        \n",
    "        if self._ema is None:\n",
    "            # First value: EMA = value\n",
    "            self._ema = value\n",
    "        else:\n",
    "            # EMA update formula\n",
    "            self._ema = self.alpha * value + (1 - self.alpha) * self._ema\n",
    "            \n",
    "        return self._ema\n",
    "    \n",
    "    @property\n",
    "    def current_ema(self) -> Optional[float]:\n",
    "        return self._ema\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"StreamingEMA(alpha={self.alpha:.4f}, ema={self._ema})\"\n",
    "\n",
    "\n",
    "# Demo: Compare SMA and EMA\n",
    "print(\"SMA vs EMA Comparison (span=5):\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "sma = StreamingSMA(window_size=5)\n",
    "ema = StreamingEMA(span=5)\n",
    "\n",
    "prices = [100, 102, 101, 103, 105, 104, 106, 108, 107, 109]\n",
    "\n",
    "print(f\"{'Tick':>4} | {'Price':>8} | {'SMA':>10} | {'EMA':>10}\")\n",
    "print(\"-\" * 48)\n",
    "\n",
    "for i, price in enumerate(prices):\n",
    "    sma_val = sma.update(price)\n",
    "    ema_val = ema.update(price)\n",
    "    \n",
    "    sma_str = f\"{sma_val:.2f}\" if sma_val else \"---\"\n",
    "    print(f\"{i+1:4d} | {price:8.2f} | {sma_str:>10} | {ema_val:10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254262df",
   "metadata": {},
   "source": [
    "## 7. Stream Buffer with Batching\n",
    "\n",
    "For improved throughput, we can batch incoming data points and process them in chunks. This reduces per-tick overhead and enables vectorized operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a34294",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchedStreamProcessor:\n",
    "    \"\"\"\n",
    "    Buffers incoming data and processes in batches.\n",
    "    \n",
    "    Benefits:\n",
    "    - Reduced function call overhead\n",
    "    - Enables vectorized (NumPy) operations\n",
    "    - Configurable batch size for latency vs throughput tradeoff\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        batch_size: int, \n",
    "        processor: Callable[[List], any],\n",
    "        flush_on_incomplete: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            batch_size: Number of items per batch\n",
    "            processor: Function to process each batch\n",
    "            flush_on_incomplete: Whether to process incomplete final batch\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.processor = processor\n",
    "        self.flush_on_incomplete = flush_on_incomplete\n",
    "        self._buffer: List = []\n",
    "        self._results: List = []\n",
    "        \n",
    "    def add(self, item) -> Optional[any]:\n",
    "        \"\"\"\n",
    "        Add item to buffer. Process batch when full.\n",
    "        \n",
    "        Returns:\n",
    "            Batch result if batch was processed, None otherwise\n",
    "        \"\"\"\n",
    "        self._buffer.append(item)\n",
    "        \n",
    "        if len(self._buffer) >= self.batch_size:\n",
    "            return self._process_batch()\n",
    "        return None\n",
    "    \n",
    "    def _process_batch(self) -> any:\n",
    "        \"\"\"Process current buffer and clear it.\"\"\"\n",
    "        batch = self._buffer[:self.batch_size]\n",
    "        self._buffer = self._buffer[self.batch_size:]\n",
    "        \n",
    "        result = self.processor(batch)\n",
    "        self._results.append(result)\n",
    "        return result\n",
    "    \n",
    "    def flush(self) -> Optional[any]:\n",
    "        \"\"\"Process any remaining items in buffer.\"\"\"\n",
    "        if self._buffer and self.flush_on_incomplete:\n",
    "            result = self.processor(self._buffer)\n",
    "            self._results.append(result)\n",
    "            self._buffer = []\n",
    "            return result\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def results(self) -> List:\n",
    "        return self._results\n",
    "\n",
    "\n",
    "# Demo: Batch processing with statistics\n",
    "def compute_batch_stats(batch: List[float]) -> Dict:\n",
    "    \"\"\"Compute statistics for a batch of prices.\"\"\"\n",
    "    arr = np.array(batch)\n",
    "    return {\n",
    "        'count': len(batch),\n",
    "        'mean': np.mean(arr),\n",
    "        'std': np.std(arr),\n",
    "        'min': np.min(arr),\n",
    "        'max': np.max(arr)\n",
    "    }\n",
    "\n",
    "print(\"Batched Stream Processing Demo (batch_size=5):\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "processor = BatchedStreamProcessor(\n",
    "    batch_size=5,\n",
    "    processor=compute_batch_stats\n",
    ")\n",
    "\n",
    "# Simulate streaming data\n",
    "prices = [100, 102, 101, 103, 105, 104, 106, 108, 107, 109, 110, 112]\n",
    "\n",
    "for i, price in enumerate(prices):\n",
    "    result = processor.add(price)\n",
    "    if result:\n",
    "        print(f\"Batch processed at tick {i+1}: {result}\")\n",
    "\n",
    "# Flush remaining\n",
    "final = processor.flush()\n",
    "if final:\n",
    "    print(f\"Final batch flushed: {final}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad22a4",
   "metadata": {},
   "source": [
    "## 8. VWAP Stream Processor\n",
    "\n",
    "Volume Weighted Average Price (VWAP) is a key benchmark in trading. We implement an incremental VWAP calculator that processes streaming price and volume data.\n",
    "\n",
    "**Formula**: $VWAP = \\frac{\\sum_{i=1}^{n} Price_i \\times Volume_i}{\\sum_{i=1}^{n} Volume_i}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88ed894",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingVWAP:\n",
    "    \"\"\"\n",
    "    Streaming Volume Weighted Average Price calculator.\n",
    "    \n",
    "    Supports:\n",
    "    - Cumulative VWAP (since market open)\n",
    "    - Rolling VWAP (fixed window)\n",
    "    - Anchored VWAP (from specific point)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_size: Optional[int] = None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            window_size: If None, compute cumulative VWAP.\n",
    "                        Otherwise, rolling VWAP over window.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        if window_size:\n",
    "            # Rolling VWAP with sliding window\n",
    "            self._prices: Deque[float] = deque(maxlen=window_size)\n",
    "            self._volumes: Deque[float] = deque(maxlen=window_size)\n",
    "            self._pv_sum: float = 0.0  # Price * Volume sum\n",
    "            self._v_sum: float = 0.0   # Volume sum\n",
    "        else:\n",
    "            # Cumulative VWAP\n",
    "            self._pv_sum: float = 0.0\n",
    "            self._v_sum: float = 0.0\n",
    "            \n",
    "        self._tick_count: int = 0\n",
    "        \n",
    "    def update(self, price: float, volume: float) -> float:\n",
    "        \"\"\"\n",
    "        Add new tick and return updated VWAP.\n",
    "        \n",
    "        Parameters:\n",
    "            price: Trade price\n",
    "            volume: Trade volume\n",
    "            \n",
    "        Returns:\n",
    "            Current VWAP\n",
    "        \"\"\"\n",
    "        self._tick_count += 1\n",
    "        pv = price * volume\n",
    "        \n",
    "        if self.window_size:\n",
    "            # Rolling VWAP: adjust for evicted data\n",
    "            if len(self._prices) == self.window_size:\n",
    "                old_pv = self._prices[0] * self._volumes[0]\n",
    "                old_v = self._volumes[0]\n",
    "                self._pv_sum -= old_pv\n",
    "                self._v_sum -= old_v\n",
    "                \n",
    "            self._prices.append(price)\n",
    "            self._volumes.append(volume)\n",
    "            self._pv_sum += pv\n",
    "            self._v_sum += volume\n",
    "        else:\n",
    "            # Cumulative VWAP\n",
    "            self._pv_sum += pv\n",
    "            self._v_sum += volume\n",
    "            \n",
    "        if self._v_sum > 0:\n",
    "            return self._pv_sum / self._v_sum\n",
    "        return price\n",
    "    \n",
    "    @property\n",
    "    def current_vwap(self) -> float:\n",
    "        if self._v_sum > 0:\n",
    "            return self._pv_sum / self._v_sum\n",
    "        return 0.0\n",
    "    \n",
    "    @property\n",
    "    def total_volume(self) -> float:\n",
    "        return self._v_sum\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset VWAP (e.g., for new trading day).\"\"\"\n",
    "        if self.window_size:\n",
    "            self._prices.clear()\n",
    "            self._volumes.clear()\n",
    "        self._pv_sum = 0.0\n",
    "        self._v_sum = 0.0\n",
    "        self._tick_count = 0\n",
    "\n",
    "\n",
    "# Demo: Streaming VWAP\n",
    "print(\"Streaming VWAP Demo:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create cumulative and rolling VWAP calculators\n",
    "vwap_cumulative = StreamingVWAP(window_size=None)\n",
    "vwap_rolling = StreamingVWAP(window_size=5)\n",
    "\n",
    "# Simulated trade data\n",
    "trades = [\n",
    "    (100.00, 1000), (100.50, 500), (99.75, 2000), (100.25, 800),\n",
    "    (100.75, 1500), (101.00, 600), (100.50, 1200), (101.25, 900),\n",
    "    (100.80, 1100), (101.50, 700)\n",
    "]\n",
    "\n",
    "print(f\"{'Trade':>5} | {'Price':>8} | {'Volume':>8} | {'VWAP(cum)':>10} | {'VWAP(5)':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, (price, volume) in enumerate(trades):\n",
    "    vc = vwap_cumulative.update(price, volume)\n",
    "    vr = vwap_rolling.update(price, volume)\n",
    "    print(f\"{i+1:5d} | {price:8.2f} | {volume:8d} | {vc:10.4f} | {vr:10.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5decae88",
   "metadata": {},
   "source": [
    "## 9. Streaming Anomaly Detection\n",
    "\n",
    "Detect outliers in real-time using rolling z-score. Useful for identifying unusual price movements, potential data errors, or trading opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02bd1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingAnomalyDetector:\n",
    "    \"\"\"\n",
    "    Real-time anomaly detection using rolling statistics.\n",
    "    \n",
    "    Methods:\n",
    "    - Z-score: Flag values > k standard deviations from mean\n",
    "    - IQR: Flag values outside Q1 - 1.5*IQR to Q3 + 1.5*IQR\n",
    "    - Adaptive threshold: Dynamic threshold based on recent volatility\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        window_size: int = 20,\n",
    "        z_threshold: float = 3.0,\n",
    "        method: str = 'zscore'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "            window_size: Lookback window for statistics\n",
    "            z_threshold: Number of std devs for anomaly\n",
    "            method: 'zscore' or 'iqr'\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.z_threshold = z_threshold\n",
    "        self.method = method\n",
    "        \n",
    "        self._window: Deque[float] = deque(maxlen=window_size)\n",
    "        \n",
    "        # Welford's algorithm for online variance\n",
    "        self._count: int = 0\n",
    "        self._mean: float = 0.0\n",
    "        self._M2: float = 0.0  # Sum of squared differences\n",
    "        \n",
    "        self._anomalies: List[Tuple[int, float, float]] = []\n",
    "        \n",
    "    def update(self, value: float) -> Tuple[bool, Optional[float]]:\n",
    "        \"\"\"\n",
    "        Check if value is anomaly and update statistics.\n",
    "        \n",
    "        Returns:\n",
    "            (is_anomaly, z_score)\n",
    "        \"\"\"\n",
    "        is_anomaly = False\n",
    "        z_score = None\n",
    "        \n",
    "        if len(self._window) >= self.window_size:\n",
    "            # Calculate z-score against current window\n",
    "            mean = np.mean(self._window)\n",
    "            std = np.std(self._window)\n",
    "            \n",
    "            if std > 0:\n",
    "                z_score = (value - mean) / std\n",
    "                \n",
    "                if self.method == 'zscore':\n",
    "                    is_anomaly = abs(z_score) > self.z_threshold\n",
    "                elif self.method == 'iqr':\n",
    "                    q1, q3 = np.percentile(list(self._window), [25, 75])\n",
    "                    iqr = q3 - q1\n",
    "                    lower = q1 - 1.5 * iqr\n",
    "                    upper = q3 + 1.5 * iqr\n",
    "                    is_anomaly = value < lower or value > upper\n",
    "                    \n",
    "        # Update window\n",
    "        self._window.append(value)\n",
    "        self._count += 1\n",
    "        \n",
    "        if is_anomaly:\n",
    "            self._anomalies.append((self._count, value, z_score))\n",
    "            \n",
    "        return is_anomaly, z_score\n",
    "    \n",
    "    @property\n",
    "    def anomaly_count(self) -> int:\n",
    "        return len(self._anomalies)\n",
    "    \n",
    "    @property\n",
    "    def anomalies(self) -> List[Tuple[int, float, float]]:\n",
    "        return self._anomalies\n",
    "\n",
    "\n",
    "# Demo: Anomaly detection on streaming data\n",
    "print(\"Streaming Anomaly Detection Demo:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "detector = StreamingAnomalyDetector(window_size=10, z_threshold=2.5)\n",
    "\n",
    "# Generate data with some anomalies\n",
    "np.random.seed(42)\n",
    "normal_prices = 100 + np.cumsum(np.random.normal(0, 0.5, 50))\n",
    "\n",
    "# Inject anomalies\n",
    "anomaly_indices = [15, 25, 40]\n",
    "for idx in anomaly_indices:\n",
    "    normal_prices[idx] += np.random.choice([-1, 1]) * 5  # Big spike\n",
    "\n",
    "print(f\"{'Tick':>4} | {'Price':>8} | {'Z-Score':>10} | {'Anomaly':>8}\")\n",
    "print(\"-\" * 42)\n",
    "\n",
    "for i, price in enumerate(normal_prices):\n",
    "    is_anomaly, z_score = detector.update(price)\n",
    "    z_str = f\"{z_score:.2f}\" if z_score else \"---\"\n",
    "    anomaly_flag = \"‚ö†Ô∏è YES\" if is_anomaly else \"\"\n",
    "    \n",
    "    if is_anomaly or i < 5 or i in anomaly_indices:\n",
    "        print(f\"{i+1:4d} | {price:8.2f} | {z_str:>10} | {anomaly_flag}\")\n",
    "\n",
    "print(f\"\\nüìä Total anomalies detected: {detector.anomaly_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1e4250",
   "metadata": {},
   "source": [
    "## 10. OHLCV Bar Aggregator\n",
    "\n",
    "Aggregate streaming tick data into OHLCV bars. Supports time-based (1min, 5min) and volume-based (1000 shares) bars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6fb378",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OHLCVAggregator:\n",
    "    \"\"\"\n",
    "    Aggregate streaming ticks into OHLCV bars.\n",
    "    \n",
    "    Supports multiple bar types:\n",
    "    - Time bars: Fixed time intervals (1min, 5min, etc.)\n",
    "    - Volume bars: Fixed volume threshold\n",
    "    - Tick bars: Fixed number of ticks\n",
    "    - Dollar bars: Fixed dollar volume\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        symbol: str,\n",
    "        bar_type: str = 'time',  # 'time', 'volume', 'tick', 'dollar'\n",
    "        bar_size: int = 60,      # seconds for time, shares for volume, etc.\n",
    "    ):\n",
    "        self.symbol = symbol\n",
    "        self.bar_type = bar_type\n",
    "        self.bar_size = bar_size\n",
    "        \n",
    "        self._bars: List[OHLCV] = []\n",
    "        self._reset_current_bar()\n",
    "        \n",
    "    def _reset_current_bar(self, timestamp: datetime = None):\n",
    "        \"\"\"Reset current bar accumulator.\"\"\"\n",
    "        self._bar_start = timestamp\n",
    "        self._open: Optional[float] = None\n",
    "        self._high: float = float('-inf')\n",
    "        self._low: float = float('inf')\n",
    "        self._close: float = 0.0\n",
    "        self._volume: float = 0.0\n",
    "        self._dollar_volume: float = 0.0\n",
    "        self._tick_count: int = 0\n",
    "        \n",
    "    def _should_close_bar(self, tick: Tick) -> bool:\n",
    "        \"\"\"Check if current bar should be closed.\"\"\"\n",
    "        if self._open is None:\n",
    "            return False\n",
    "            \n",
    "        if self.bar_type == 'time':\n",
    "            elapsed = (tick.timestamp - self._bar_start).total_seconds()\n",
    "            return elapsed >= self.bar_size\n",
    "        elif self.bar_type == 'volume':\n",
    "            return self._volume >= self.bar_size\n",
    "        elif self.bar_type == 'tick':\n",
    "            return self._tick_count >= self.bar_size\n",
    "        elif self.bar_type == 'dollar':\n",
    "            return self._dollar_volume >= self.bar_size\n",
    "        return False\n",
    "    \n",
    "    def _create_bar(self) -> OHLCV:\n",
    "        \"\"\"Create OHLCV bar from current accumulator.\"\"\"\n",
    "        return OHLCV(\n",
    "            timestamp=self._bar_start,\n",
    "            symbol=self.symbol,\n",
    "            open=self._open,\n",
    "            high=self._high,\n",
    "            low=self._low,\n",
    "            close=self._close,\n",
    "            volume=self._volume,\n",
    "            trade_count=self._tick_count\n",
    "        )\n",
    "        \n",
    "    def update(self, tick: Tick) -> Optional[OHLCV]:\n",
    "        \"\"\"\n",
    "        Process new tick. Returns completed bar if bar closed.\n",
    "        \"\"\"\n",
    "        completed_bar = None\n",
    "        \n",
    "        # Check if we should close current bar\n",
    "        if self._should_close_bar(tick):\n",
    "            completed_bar = self._create_bar()\n",
    "            self._bars.append(completed_bar)\n",
    "            self._reset_current_bar(tick.timestamp)\n",
    "            \n",
    "        # Update current bar\n",
    "        if self._open is None:\n",
    "            self._bar_start = tick.timestamp\n",
    "            self._open = tick.price\n",
    "            \n",
    "        self._high = max(self._high, tick.price)\n",
    "        self._low = min(self._low, tick.price)\n",
    "        self._close = tick.price\n",
    "        self._volume += tick.volume\n",
    "        self._dollar_volume += tick.price * tick.volume\n",
    "        self._tick_count += 1\n",
    "        \n",
    "        return completed_bar\n",
    "    \n",
    "    def flush(self) -> Optional[OHLCV]:\n",
    "        \"\"\"Force close current bar (e.g., end of session).\"\"\"\n",
    "        if self._open is not None:\n",
    "            bar = self._create_bar()\n",
    "            self._bars.append(bar)\n",
    "            self._reset_current_bar()\n",
    "            return bar\n",
    "        return None\n",
    "    \n",
    "    @property\n",
    "    def bars(self) -> List[OHLCV]:\n",
    "        return self._bars\n",
    "\n",
    "\n",
    "# Demo: Tick to OHLCV aggregation\n",
    "print(\"Tick to OHLCV Bar Aggregation Demo:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Create aggregators for different bar types\n",
    "tick_agg = OHLCVAggregator(\"AAPL\", bar_type='tick', bar_size=10)\n",
    "volume_agg = OHLCVAggregator(\"AAPL\", bar_type='volume', bar_size=500)\n",
    "\n",
    "# Generate ticks\n",
    "gen = price_tick_generator(symbol=\"AAPL\", num_ticks=50)\n",
    "\n",
    "print(\"\\nTick Bars (10 ticks each):\")\n",
    "print(\"-\" * 60)\n",
    "for tick in gen:\n",
    "    bar = tick_agg.update(tick)\n",
    "    if bar:\n",
    "        print(bar)\n",
    "\n",
    "# Flush remaining\n",
    "final_bar = tick_agg.flush()\n",
    "if final_bar:\n",
    "    print(f\"Final bar: {final_bar}\")\n",
    "    \n",
    "print(f\"\\nüìä Total bars created: {len(tick_agg.bars)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058dfeb1",
   "metadata": {},
   "source": [
    "## 11. Async Stream Consumer\n",
    "\n",
    "Asynchronous stream processing using `asyncio` for handling multiple concurrent data streams. Essential for real-world trading systems that consume from multiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da069b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def async_price_stream(\n",
    "    symbol: str,\n",
    "    initial_price: float = 100.0,\n",
    "    num_ticks: int = 10,\n",
    "    delay_ms: float = 100\n",
    ") -> AsyncGenerator[Tick, None]:\n",
    "    \"\"\"\n",
    "    Async generator for simulated price stream.\n",
    "    \n",
    "    Parameters:\n",
    "        symbol: Trading symbol\n",
    "        initial_price: Starting price\n",
    "        num_ticks: Number of ticks to generate\n",
    "        delay_ms: Milliseconds between ticks\n",
    "    \"\"\"\n",
    "    price = initial_price\n",
    "    \n",
    "    for i in range(num_ticks):\n",
    "        # Simulate network/exchange delay\n",
    "        await asyncio.sleep(delay_ms / 1000)\n",
    "        \n",
    "        # Price movement\n",
    "        price *= (1 + np.random.normal(0, 0.01))\n",
    "        volume = int(np.exp(np.random.normal(5, 1)))\n",
    "        \n",
    "        yield Tick(\n",
    "            timestamp=datetime.now(),\n",
    "            symbol=symbol,\n",
    "            price=price,\n",
    "            volume=volume\n",
    "        )\n",
    "\n",
    "\n",
    "async def process_single_stream(symbol: str, num_ticks: int = 5):\n",
    "    \"\"\"Process a single async price stream.\"\"\"\n",
    "    print(f\"\\nüì° Starting stream for {symbol}...\")\n",
    "    \n",
    "    async for tick in async_price_stream(symbol, num_ticks=num_ticks):\n",
    "        print(f\"  [{symbol}] {tick.timestamp.strftime('%H:%M:%S.%f')[:-3]} | \"\n",
    "              f\"Price: {tick.price:.2f} | Vol: {tick.volume}\")\n",
    "        \n",
    "    print(f\"  [{symbol}] Stream ended\")\n",
    "\n",
    "\n",
    "async def process_multiple_streams():\n",
    "    \"\"\"\n",
    "    Process multiple price streams concurrently.\n",
    "    Demonstrates parallel data consumption.\n",
    "    \"\"\"\n",
    "    print(\"üöÄ Processing multiple streams concurrently...\")\n",
    "    \n",
    "    # Create tasks for multiple symbols\n",
    "    tasks = [\n",
    "        process_single_stream(\"AAPL\", num_ticks=3),\n",
    "        process_single_stream(\"GOOGL\", num_ticks=3),\n",
    "        process_single_stream(\"MSFT\", num_ticks=3),\n",
    "    ]\n",
    "    \n",
    "    # Run all streams concurrently\n",
    "    await asyncio.gather(*tasks)\n",
    "    \n",
    "    print(\"\\n‚úÖ All streams completed!\")\n",
    "\n",
    "\n",
    "# Run the async demo\n",
    "print(\"Async Stream Processing Demo:\")\n",
    "print(\"-\" * 60)\n",
    "asyncio.run(process_multiple_streams())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
