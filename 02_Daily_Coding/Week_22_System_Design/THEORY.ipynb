{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27a7c4cb",
   "metadata": {},
   "source": [
    "# Week 22: System Design for Quantitative Trading - Theory\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "\n",
    "By the end of this week, you will understand:\n",
    "- **Trading System Architecture**: Components, patterns, and principles\n",
    "- **Low-Latency Design**: Techniques for microsecond-level performance\n",
    "- **Data Infrastructure**: Time-series databases, streaming, and storage\n",
    "- **Distributed Systems**: Scalability, fault tolerance, and consistency\n",
    "- **Production Deployment**: Monitoring, alerting, and incident response\n",
    "\n",
    "---\n",
    "\n",
    "## Why System Design for Quant?\n",
    "\n",
    "> \"In quantitative trading, system design is as important as the alpha itself.\"\n",
    "\n",
    "- Alpha decay is fast â†’ need rapid iteration\n",
    "- Market changes â†’ need adaptable systems\n",
    "- Competition is fierce â†’ latency matters\n",
    "- Capital at risk â†’ reliability is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65220b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded!\n",
      "ğŸ“š Week 22: System Design Theory\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Any\n",
    "from enum import Enum, auto\n",
    "from abc import ABC, abstractmethod\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"âœ… Libraries loaded!\")\n",
    "print(\"ğŸ“š Week 22: System Design Theory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8a591c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Trading System Architecture\n",
    "\n",
    "### 1.1 Core Components\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    TRADING SYSTEM ARCHITECTURE                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                                  â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚\n",
    "â”‚  â”‚ DATA LAYER  â”‚â”€â”€â”€â–¶â”‚ STRATEGY    â”‚â”€â”€â”€â–¶â”‚ EXECUTION   â”‚          â”‚\n",
    "â”‚  â”‚             â”‚    â”‚ LAYER       â”‚    â”‚ LAYER       â”‚          â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚\n",
    "â”‚        â”‚                  â”‚                  â”‚                   â”‚\n",
    "â”‚        â–¼                  â–¼                  â–¼                   â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚\n",
    "â”‚  â”‚              INFRASTRUCTURE LAYER                        â”‚    â”‚\n",
    "â”‚  â”‚  (Messaging, Databases, Monitoring, Risk)               â”‚    â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚\n",
    "â”‚                                                                  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "### Component Breakdown\n",
    "\n",
    "| Component | Responsibility | Latency Requirement |\n",
    "|-----------|---------------|---------------------|\n",
    "| Market Data Handler | Ingest, normalize, distribute | < 100Î¼s |\n",
    "| Strategy Engine | Signal generation | < 1ms |\n",
    "| Risk Manager | Pre/post-trade checks | < 50Î¼s |\n",
    "| Order Management | Order lifecycle | < 100Î¼s |\n",
    "| Execution Engine | Smart routing | < 500Î¼s |\n",
    "| Portfolio Manager | P&L, positions | < 10ms |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c201d1",
   "metadata": {},
   "source": [
    "### 1.2 Architecture Patterns\n",
    "\n",
    "#### Event-Driven Architecture (EDA)\n",
    "\n",
    "```\n",
    "MARKET_DATA â†’ SIGNAL â†’ ORDER â†’ FILL â†’ PORTFOLIO_UPDATE\n",
    "     â”‚          â”‚        â”‚       â”‚           â”‚\n",
    "     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                     EVENT BUS\n",
    "```\n",
    "\n",
    "**Benefits:**\n",
    "- Loose coupling between components\n",
    "- Easy to add new consumers\n",
    "- Natural audit trail\n",
    "- Replay capability for backtesting\n",
    "\n",
    "**Drawbacks:**\n",
    "- Added latency from serialization\n",
    "- Complexity in debugging\n",
    "- Eventual consistency challenges\n",
    "\n",
    "#### Shared Memory Architecture\n",
    "\n",
    "Used by HFT firms for ultra-low latency:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚            SHARED MEMORY REGION             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚\n",
    "â”‚  â”‚ Order   â”‚ Market  â”‚ Positionâ”‚ Risk   â”‚  â”‚\n",
    "â”‚  â”‚ Book    â”‚ Data    â”‚ Cache   â”‚ Limits â”‚  â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "         â”‚        â”‚        â”‚        â”‚\n",
    "    Strategy  Execution  Risk   Portfolio\n",
    "```\n",
    "\n",
    "**Key Techniques:**\n",
    "- Memory-mapped files\n",
    "- Lock-free data structures\n",
    "- CPU pinning and NUMA awareness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c5009b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¨ Received MARKET_DATA: {'symbol': 'AAPL', 'price': 150.25}\n",
      "ğŸ“¨ Received SIGNAL: {'symbol': 'AAPL', 'direction': 'LONG'}\n",
      "\n",
      "âœ… Total events processed: 2\n"
     ]
    }
   ],
   "source": [
    "# Event-Driven Architecture Example\n",
    "\n",
    "class EventType(Enum):\n",
    "    MARKET_DATA = auto()\n",
    "    SIGNAL = auto()\n",
    "    ORDER = auto()\n",
    "    FILL = auto()\n",
    "    PORTFOLIO_UPDATE = auto()\n",
    "\n",
    "@dataclass\n",
    "class Event:\n",
    "    \"\"\"Base event class\"\"\"\n",
    "    event_type: EventType\n",
    "    timestamp: int  # nanoseconds\n",
    "    data: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "class EventBus:\n",
    "    \"\"\"Central event dispatcher\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.subscribers: Dict[EventType, List] = {}\n",
    "        self.event_count = 0\n",
    "    \n",
    "    def subscribe(self, event_type: EventType, handler):\n",
    "        if event_type not in self.subscribers:\n",
    "            self.subscribers[event_type] = []\n",
    "        self.subscribers[event_type].append(handler)\n",
    "    \n",
    "    def publish(self, event: Event):\n",
    "        self.event_count += 1\n",
    "        for handler in self.subscribers.get(event.event_type, []):\n",
    "            handler(event)\n",
    "\n",
    "# Demo\n",
    "bus = EventBus()\n",
    "\n",
    "def log_handler(event):\n",
    "    print(f\"ğŸ“¨ Received {event.event_type.name}: {event.data}\")\n",
    "\n",
    "bus.subscribe(EventType.MARKET_DATA, log_handler)\n",
    "bus.subscribe(EventType.SIGNAL, log_handler)\n",
    "\n",
    "# Simulate event flow\n",
    "bus.publish(Event(EventType.MARKET_DATA, time.time_ns(), {'symbol': 'AAPL', 'price': 150.25}))\n",
    "bus.publish(Event(EventType.SIGNAL, time.time_ns(), {'symbol': 'AAPL', 'direction': 'LONG'}))\n",
    "\n",
    "print(f\"\\nâœ… Total events processed: {bus.event_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034ef5a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Low-Latency Design Principles\n",
    "\n",
    "### 2.1 The Latency Ladder\n",
    "\n",
    "| Operation | Latency | Context |\n",
    "|-----------|---------|----------|\n",
    "| L1 cache access | 1 ns | Best case |\n",
    "| L2 cache access | 4 ns | Still fast |\n",
    "| L3 cache access | 40 ns | Shared across cores |\n",
    "| Main memory | 100 ns | RAM access |\n",
    "| SSD read | 100 Î¼s | 1000x slower than RAM |\n",
    "| Network (same DC) | 500 Î¼s | Add serialization |\n",
    "| Network (cross DC) | 50 ms | Avoid for hot path |\n",
    "\n",
    "### 2.2 Key Optimization Techniques\n",
    "\n",
    "1. **Minimize Allocations**\n",
    "   - Object pooling\n",
    "   - Pre-allocated buffers\n",
    "   - Avoid garbage collection pauses\n",
    "\n",
    "2. **Reduce Serialization**\n",
    "   - Binary protocols (FlatBuffers, Cap'n Proto)\n",
    "   - Shared memory for intra-process\n",
    "\n",
    "3. **Cache Optimization**\n",
    "   - Data locality (keep related data together)\n",
    "   - Cache-line alignment\n",
    "   - Avoid false sharing\n",
    "\n",
    "4. **Lock-Free Algorithms**\n",
    "   - Compare-and-swap (CAS)\n",
    "   - SPSC queues (single producer/consumer)\n",
    "   - Disruptor pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "982b683e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency Comparison (Î¼s)\n",
      "==================================================\n",
      "Metric     Dict         Array        Ratio\n",
      "--------------------------------------------------\n",
      "mean       0.104        0.123        0.8x\n",
      "median     0.084        0.125        0.7x\n",
      "p99        0.250        0.167        1.5x\n"
     ]
    }
   ],
   "source": [
    "# Latency Measurement Utilities\n",
    "\n",
    "import statistics\n",
    "\n",
    "def measure_latency(func, iterations=10000):\n",
    "    \"\"\"Measure function latency in microseconds\"\"\"\n",
    "    latencies = []\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        start = time.perf_counter_ns()\n",
    "        func()\n",
    "        end = time.perf_counter_ns()\n",
    "        latencies.append((end - start) / 1000)  # Convert to Î¼s\n",
    "    \n",
    "    return {\n",
    "        'mean': statistics.mean(latencies),\n",
    "        'median': statistics.median(latencies),\n",
    "        'p99': np.percentile(latencies, 99),\n",
    "        'p999': np.percentile(latencies, 99.9),\n",
    "        'max': max(latencies)\n",
    "    }\n",
    "\n",
    "# Compare dict vs pre-allocated array access\n",
    "test_dict = {f'key_{i}': i for i in range(1000)}\n",
    "test_array = np.arange(1000)\n",
    "\n",
    "def dict_access():\n",
    "    return test_dict['key_500']\n",
    "\n",
    "def array_access():\n",
    "    return test_array[500]\n",
    "\n",
    "print(\"Latency Comparison (Î¼s)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "dict_stats = measure_latency(dict_access)\n",
    "array_stats = measure_latency(array_access)\n",
    "\n",
    "print(f\"{'Metric':<10} {'Dict':<12} {'Array':<12} {'Ratio'}\")\n",
    "print(\"-\"*50)\n",
    "for metric in ['mean', 'median', 'p99']:\n",
    "    ratio = dict_stats[metric] / array_stats[metric] if array_stats[metric] > 0 else float('inf')\n",
    "    print(f\"{metric:<10} {dict_stats[metric]:<12.3f} {array_stats[metric]:<12.3f} {ratio:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c00e62",
   "metadata": {},
   "source": [
    "### 2.3 Object Pooling Pattern\n",
    "\n",
    "Avoid allocation overhead by reusing objects:\n",
    "\n",
    "```\n",
    "WITHOUT POOLING:                WITH POOLING:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "request â†’ allocate â†’ use       request â†’ get from pool â†’ use\n",
    "         â†’ GC (pause!)                  â†’ return to pool\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb98f4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object Pool Statistics\n",
      "========================================\n",
      "pool_size: 50\n",
      "allocations: 0\n",
      "reuses: 1000\n",
      "reuse_rate: 100.00%\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "@dataclass\n",
    "class Order:\n",
    "    \"\"\"Order object that can be pooled\"\"\"\n",
    "    symbol: str = \"\"\n",
    "    side: str = \"\"\n",
    "    quantity: int = 0\n",
    "    price: float = 0.0\n",
    "    timestamp: int = 0\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset for reuse\"\"\"\n",
    "        self.symbol = \"\"\n",
    "        self.side = \"\"\n",
    "        self.quantity = 0\n",
    "        self.price = 0.0\n",
    "        self.timestamp = 0\n",
    "\n",
    "class ObjectPool:\n",
    "    \"\"\"Generic object pool for reducing allocations\"\"\"\n",
    "    \n",
    "    def __init__(self, factory, initial_size=100):\n",
    "        self.factory = factory\n",
    "        self.pool = deque(factory() for _ in range(initial_size))\n",
    "        self.allocations = 0\n",
    "        self.reuses = 0\n",
    "    \n",
    "    def acquire(self):\n",
    "        \"\"\"Get an object from pool\"\"\"\n",
    "        if self.pool:\n",
    "            self.reuses += 1\n",
    "            return self.pool.popleft()\n",
    "        self.allocations += 1\n",
    "        return self.factory()\n",
    "    \n",
    "    def release(self, obj):\n",
    "        \"\"\"Return object to pool\"\"\"\n",
    "        if hasattr(obj, 'reset'):\n",
    "            obj.reset()\n",
    "        self.pool.append(obj)\n",
    "    \n",
    "    def stats(self):\n",
    "        return {\n",
    "            'pool_size': len(self.pool),\n",
    "            'allocations': self.allocations,\n",
    "            'reuses': self.reuses,\n",
    "            'reuse_rate': self.reuses / (self.allocations + self.reuses) if (self.allocations + self.reuses) > 0 else 0\n",
    "        }\n",
    "\n",
    "# Demo\n",
    "order_pool = ObjectPool(Order, initial_size=50)\n",
    "\n",
    "# Simulate order flow\n",
    "for i in range(1000):\n",
    "    order = order_pool.acquire()\n",
    "    order.symbol = \"AAPL\"\n",
    "    order.quantity = 100\n",
    "    # ... process order ...\n",
    "    order_pool.release(order)\n",
    "\n",
    "stats = order_pool.stats()\n",
    "print(\"Object Pool Statistics\")\n",
    "print(\"=\"*40)\n",
    "for k, v in stats.items():\n",
    "    print(f\"{k}: {v:.2%}\" if 'rate' in k else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e244cf4e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Data Infrastructure\n",
    "\n",
    "### 3.1 Time-Series Databases\n",
    "\n",
    "| Database | Use Case | Write Speed | Query Speed |\n",
    "|----------|----------|-------------|-------------|\n",
    "| InfluxDB | Metrics, monitoring | Fast | Good |\n",
    "| TimescaleDB | OHLCV, trades | Good | Excellent (SQL) |\n",
    "| QuestDB | Tick data | Excellent | Excellent |\n",
    "| Arctic | Research, backtesting | Good | Good |\n",
    "| kdb+/q | HFT, real-time | Excellent | Excellent |\n",
    "\n",
    "### 3.2 Data Hierarchy\n",
    "\n",
    "```\n",
    "HOT DATA (Real-time)           WARM DATA (Recent)         COLD DATA (Historical)\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "- In-memory (Redis)            - SSD (Time-series DB)     - Object Storage (S3)\n",
    "- Shared memory                - Compressed columns       - Parquet files\n",
    "- Sub-millisecond access       - Second-level queries     - Batch processing\n",
    "```\n",
    "\n",
    "### 3.3 Message Queues for Trading\n",
    "\n",
    "| Queue | Latency | Throughput | Durability | Use Case |\n",
    "|-------|---------|------------|------------|----------|\n",
    "| Aeron | 1-10 Î¼s | 100M/s | Optional | Ultra-low latency |\n",
    "| LMAX Disruptor | 10 Î¼s | 10M/s | No | In-process |\n",
    "| Kafka | 1-10 ms | 1M/s | Yes | Event sourcing |\n",
    "| Redis Streams | 100 Î¼s | 100K/s | Yes | General purpose |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc2b5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ring buffer size: 1024\n",
      "Items in buffer: 100\n",
      "\n",
      "First 5 items:\n",
      "  {'seq': 0, 'price': 100.49671415301123}\n",
      "  {'seq': 1, 'price': 99.86173569882881}\n",
      "  {'seq': 2, 'price': 100.6476885381007}\n",
      "  {'seq': 3, 'price': 101.52302985640803}\n",
      "  {'seq': 4, 'price': 99.76584662527667}\n"
     ]
    }
   ],
   "source": [
    "# Ring Buffer (Disruptor-like) Implementation\n",
    "\n",
    "class RingBuffer:\n",
    "    \"\"\"\n",
    "    Lock-free ring buffer for single producer/consumer.\n",
    "    Used in low-latency trading systems.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, size: int):\n",
    "        # Size must be power of 2 for efficient modulo\n",
    "        self.size = 1 << (size - 1).bit_length()  # Round up to power of 2\n",
    "        self.mask = self.size - 1\n",
    "        self.buffer = [None] * self.size\n",
    "        self.write_pos = 0\n",
    "        self.read_pos = 0\n",
    "    \n",
    "    def write(self, item) -> bool:\n",
    "        \"\"\"Write item to buffer. Returns False if full.\"\"\"\n",
    "        next_write = (self.write_pos + 1) & self.mask\n",
    "        if next_write == self.read_pos:\n",
    "            return False  # Buffer full\n",
    "        self.buffer[self.write_pos] = item\n",
    "        self.write_pos = next_write\n",
    "        return True\n",
    "    \n",
    "    def read(self):\n",
    "        \"\"\"Read item from buffer. Returns None if empty.\"\"\"\n",
    "        if self.read_pos == self.write_pos:\n",
    "            return None  # Buffer empty\n",
    "        item = self.buffer[self.read_pos]\n",
    "        self.read_pos = (self.read_pos + 1) & self.mask\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return (self.write_pos - self.read_pos) & self.mask\n",
    "\n",
    "# Demo\n",
    "rb = RingBuffer(1024)\n",
    "\n",
    "# Simulate market data flow\n",
    "for i in range(100):\n",
    "    rb.write({'seq': i, 'price': 100 + np.random.randn()})\n",
    "\n",
    "print(f\"Ring buffer size: {rb.size}\")\n",
    "print(f\"Items in buffer: {len(rb)}\")\n",
    "print(f\"\\nFirst 5 items:\")\n",
    "for _ in range(5):\n",
    "    print(f\"  {rb.read()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17f960",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Distributed Systems Concepts\n",
    "\n",
    "### 4.1 CAP Theorem\n",
    "\n",
    "**Choose 2 of 3:**\n",
    "- **Consistency**: All nodes see the same data\n",
    "- **Availability**: Every request gets a response\n",
    "- **Partition Tolerance**: System works despite network failures\n",
    "\n",
    "```\n",
    "Trading System Trade-offs:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Order Book â†’ CP (Consistency + Partition Tolerance)\n",
    "             Can't have stale order book state!\n",
    "\n",
    "Market Data Cache â†’ AP (Availability + Partition Tolerance)\n",
    "             Stale is OK, unavailable is not\n",
    "\n",
    "P&L Calculation â†’ CP\n",
    "             Must be accurate for risk management\n",
    "```\n",
    "\n",
    "### 4.2 Consensus Algorithms\n",
    "\n",
    "| Algorithm | Use Case | Latency | Complexity |\n",
    "|-----------|----------|---------|------------|\n",
    "| Raft | Leader election | Medium | Low |\n",
    "| Paxos | Distributed state | Medium | High |\n",
    "| ZAB (ZooKeeper) | Configuration | Medium | Medium |\n",
    "\n",
    "### 4.3 Replication Strategies\n",
    "\n",
    "```\n",
    "SYNCHRONOUS REPLICATION:        ASYNCHRONOUS REPLICATION:\n",
    "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "Client â†’ Primary â†’ Replica     Client â†’ Primary\n",
    "              â†“    â†“                         â†“\n",
    "          Wait for ACK              ACK (async to replica)\n",
    "              â†“\n",
    "           ACK to client\n",
    "\n",
    "Pros: Strong consistency        Pros: Lower latency\n",
    "Cons: Higher latency            Cons: Potential data loss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e91de5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raft Leader Election Simulation\n",
      "==================================================\n",
      "Node 2 starting election for term 1\n",
      "Node 2 elected LEADER with 3 votes\n",
      "\n",
      "Final states: [Node(0, state=FOLLOWER, term=0), Node(1, state=FOLLOWER, term=0), Node(2, state=LEADER, term=1), Node(3, state=FOLLOWER, term=0), Node(4, state=FOLLOWER, term=0)]\n"
     ]
    }
   ],
   "source": [
    "# Simple Raft-like Leader Election Simulation\n",
    "\n",
    "import random\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, node_id: int, total_nodes: int):\n",
    "        self.node_id = node_id\n",
    "        self.total_nodes = total_nodes\n",
    "        self.state = \"FOLLOWER\"  # FOLLOWER, CANDIDATE, LEADER\n",
    "        self.term = 0\n",
    "        self.voted_for = None\n",
    "        self.votes_received = 0\n",
    "    \n",
    "    def start_election(self):\n",
    "        \"\"\"Become candidate and request votes\"\"\"\n",
    "        self.state = \"CANDIDATE\"\n",
    "        self.term += 1\n",
    "        self.voted_for = self.node_id\n",
    "        self.votes_received = 1  # Vote for self\n",
    "        return f\"Node {self.node_id} starting election for term {self.term}\"\n",
    "    \n",
    "    def receive_vote(self):\n",
    "        \"\"\"Receive a vote from another node\"\"\"\n",
    "        self.votes_received += 1\n",
    "        if self.votes_received > self.total_nodes // 2:\n",
    "            self.state = \"LEADER\"\n",
    "            return f\"Node {self.node_id} elected LEADER with {self.votes_received} votes\"\n",
    "        return None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"Node({self.node_id}, state={self.state}, term={self.term})\"\n",
    "\n",
    "# Simulate election\n",
    "print(\"Raft Leader Election Simulation\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "nodes = [Node(i, 5) for i in range(5)]\n",
    "\n",
    "# Simulate timeout on node 2\n",
    "candidate = nodes[2]\n",
    "print(candidate.start_election())\n",
    "\n",
    "# Other nodes vote\n",
    "for i in [0, 1, 4]:  # 3 votes + self = 4 votes (majority)\n",
    "    result = candidate.receive_vote()\n",
    "    if result:\n",
    "        print(result)\n",
    "        break\n",
    "\n",
    "print(f\"\\nFinal states: {nodes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9c4254",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Reliability & Fault Tolerance\n",
    "\n",
    "### 5.1 Failure Modes\n",
    "\n",
    "| Failure Type | Detection | Mitigation |\n",
    "|--------------|-----------|------------|\n",
    "| Network partition | Heartbeat timeout | Primary/secondary failover |\n",
    "| Process crash | Health checks | Automatic restart |\n",
    "| Data corruption | Checksums | WAL, replicas |\n",
    "| Slow degradation | Latency monitoring | Circuit breaker |\n",
    "\n",
    "### 5.2 Circuit Breaker Pattern\n",
    "\n",
    "```\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚    CLOSED    â”‚  Normal operation\n",
    "         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚ Failures > threshold\n",
    "                â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚     OPEN     â”‚  Fast fail, no requests\n",
    "         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚ Timeout expires\n",
    "                â–¼\n",
    "         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â”‚  HALF-OPEN   â”‚  Allow test request\n",
    "         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                â”‚\n",
    "       Success? â”‚ Failure?\n",
    "          â–¼     â”‚     â–¼\n",
    "       CLOSED   â”‚   OPEN\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f194d820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit Breaker Demo\n",
      "========================================\n",
      "Call 1: Success! [State: CLOSED]\n",
      "Call 2: Success! [State: CLOSED]\n",
      "Call 3: Success! [State: CLOSED]\n",
      "Call 4: Service unavailable [State: CLOSED]\n",
      "Call 5: Service unavailable [State: CLOSED]\n",
      "Call 6: Success! [State: CLOSED]\n",
      "Call 7: Service unavailable [State: OPEN]\n",
      "Call 8: Circuit OPEN - request rejected [State: OPEN]\n",
      "Call 9: Circuit OPEN - request rejected [State: OPEN]\n",
      "Call 10: Circuit OPEN - request rejected [State: OPEN]\n"
     ]
    }
   ],
   "source": [
    "# Circuit Breaker Implementation\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class CircuitState(Enum):\n",
    "    CLOSED = \"CLOSED\"\n",
    "    OPEN = \"OPEN\"\n",
    "    HALF_OPEN = \"HALF_OPEN\"\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"\n",
    "    Circuit breaker for protecting against cascading failures.\n",
    "    Essential for trading system resilience.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 5, \n",
    "                 recovery_timeout: float = 30.0,\n",
    "                 success_threshold: int = 3):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.recovery_timeout = recovery_timeout\n",
    "        self.success_threshold = success_threshold\n",
    "        \n",
    "        self.state = CircuitState.CLOSED\n",
    "        self.failure_count = 0\n",
    "        self.success_count = 0\n",
    "        self.last_failure_time = 0\n",
    "    \n",
    "    def call(self, func, *args, **kwargs):\n",
    "        \"\"\"Execute function through circuit breaker\"\"\"\n",
    "        if not self._can_execute():\n",
    "            raise Exception(\"Circuit OPEN - request rejected\")\n",
    "        \n",
    "        try:\n",
    "            result = func(*args, **kwargs)\n",
    "            self._on_success()\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            self._on_failure()\n",
    "            raise\n",
    "    \n",
    "    def _can_execute(self) -> bool:\n",
    "        if self.state == CircuitState.CLOSED:\n",
    "            return True\n",
    "        \n",
    "        if self.state == CircuitState.OPEN:\n",
    "            if time.time() - self.last_failure_time >= self.recovery_timeout:\n",
    "                self.state = CircuitState.HALF_OPEN\n",
    "                return True\n",
    "            return False\n",
    "        \n",
    "        return True  # HALF_OPEN allows test requests\n",
    "    \n",
    "    def _on_success(self):\n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            self.success_count += 1\n",
    "            if self.success_count >= self.success_threshold:\n",
    "                self.state = CircuitState.CLOSED\n",
    "                self.failure_count = 0\n",
    "                self.success_count = 0\n",
    "    \n",
    "    def _on_failure(self):\n",
    "        self.failure_count += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        \n",
    "        if self.state == CircuitState.HALF_OPEN:\n",
    "            self.state = CircuitState.OPEN\n",
    "        elif self.failure_count >= self.failure_threshold:\n",
    "            self.state = CircuitState.OPEN\n",
    "\n",
    "# Demo\n",
    "cb = CircuitBreaker(failure_threshold=3, recovery_timeout=1.0)\n",
    "\n",
    "def unreliable_service():\n",
    "    if random.random() < 0.5:\n",
    "        raise Exception(\"Service unavailable\")\n",
    "    return \"Success!\"\n",
    "\n",
    "print(\"Circuit Breaker Demo\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "for i in range(10):\n",
    "    try:\n",
    "        result = cb.call(unreliable_service)\n",
    "        print(f\"Call {i+1}: {result} [State: {cb.state.value}]\")\n",
    "    except Exception as e:\n",
    "        print(f\"Call {i+1}: {e} [State: {cb.state.value}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e09d0cd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Production Monitoring\n",
    "\n",
    "### 6.1 Key Metrics for Trading Systems\n",
    "\n",
    "| Metric Category | Examples | Alert Threshold |\n",
    "|-----------------|----------|------------------|\n",
    "| **Latency** | P50, P99, P999 | P99 > 10ms |\n",
    "| **Throughput** | Messages/sec, Orders/sec | Drop > 20% |\n",
    "| **Error Rate** | Failed orders, Rejections | > 1% |\n",
    "| **Resource** | CPU, Memory, Network | > 80% |\n",
    "| **Business** | P&L, Position, Risk | Breach limits |\n",
    "\n",
    "### 6.2 The Four Golden Signals (Google SRE)\n",
    "\n",
    "1. **Latency**: Time to service a request\n",
    "2. **Traffic**: Demand on the system\n",
    "3. **Errors**: Rate of failed requests\n",
    "4. **Saturation**: System utilization\n",
    "\n",
    "### 6.3 Observability Stack\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚                    OBSERVABILITY STACK                       â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                                              â”‚\n",
    "â”‚  METRICS          LOGS              TRACES                   â”‚\n",
    "â”‚  â”€â”€â”€â”€â”€â”€â”€â”€         â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€                   â”‚\n",
    "â”‚  Prometheus       ELK Stack         Jaeger                   â”‚\n",
    "â”‚  Grafana          Splunk            Zipkin                   â”‚\n",
    "â”‚  InfluxDB         CloudWatch        OpenTelemetry            â”‚\n",
    "â”‚                                                              â”‚\n",
    "â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚\n",
    "â”‚              â”‚    ALERTING         â”‚                         â”‚\n",
    "â”‚              â”‚  PagerDuty/OpsGenie â”‚                         â”‚\n",
    "â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚\n",
    "â”‚                                                              â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b353885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š METRICS REPORT\n",
      "==================================================\n",
      "\n",
      "Counters:\n",
      "  orders_processed: 1000\n",
      "  order_errors: 16\n",
      "\n",
      "Gauges:\n",
      "  position_aapl: 1500.00\n",
      "  unrealized_pnl: 25000.50\n",
      "\n",
      "Histograms (Latency):\n",
      "  order_latency:\n",
      "    P50: 69.86Î¼s\n",
      "    P99: 440.20Î¼s\n",
      "    P999: 618.42Î¼s\n"
     ]
    }
   ],
   "source": [
    "# Metrics Collection System\n",
    "\n",
    "from collections import defaultdict\n",
    "import statistics\n",
    "\n",
    "class MetricsCollector:\n",
    "    \"\"\"\n",
    "    Simple metrics collector for trading systems.\n",
    "    In production, use Prometheus/StatsD.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.counters: Dict[str, int] = defaultdict(int)\n",
    "        self.gauges: Dict[str, float] = {}\n",
    "        self.histograms: Dict[str, List[float]] = defaultdict(list)\n",
    "    \n",
    "    def increment(self, name: str, value: int = 1):\n",
    "        \"\"\"Increment a counter\"\"\"\n",
    "        self.counters[name] += value\n",
    "    \n",
    "    def set_gauge(self, name: str, value: float):\n",
    "        \"\"\"Set a gauge value\"\"\"\n",
    "        self.gauges[name] = value\n",
    "    \n",
    "    def observe(self, name: str, value: float):\n",
    "        \"\"\"Record histogram observation\"\"\"\n",
    "        self.histograms[name].append(value)\n",
    "    \n",
    "    def get_percentile(self, name: str, percentile: float) -> float:\n",
    "        \"\"\"Get percentile from histogram\"\"\"\n",
    "        if name not in self.histograms:\n",
    "            return 0.0\n",
    "        return np.percentile(self.histograms[name], percentile)\n",
    "    \n",
    "    def report(self):\n",
    "        \"\"\"Generate metrics report\"\"\"\n",
    "        print(\"\\nğŸ“Š METRICS REPORT\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        print(\"\\nCounters:\")\n",
    "        for name, value in self.counters.items():\n",
    "            print(f\"  {name}: {value}\")\n",
    "        \n",
    "        print(\"\\nGauges:\")\n",
    "        for name, value in self.gauges.items():\n",
    "            print(f\"  {name}: {value:.2f}\")\n",
    "        \n",
    "        print(\"\\nHistograms (Latency):\")\n",
    "        for name, values in self.histograms.items():\n",
    "            if values:\n",
    "                print(f\"  {name}:\")\n",
    "                print(f\"    P50: {np.percentile(values, 50):.2f}Î¼s\")\n",
    "                print(f\"    P99: {np.percentile(values, 99):.2f}Î¼s\")\n",
    "                print(f\"    P999: {np.percentile(values, 99.9):.2f}Î¼s\")\n",
    "\n",
    "# Demo\n",
    "metrics = MetricsCollector()\n",
    "\n",
    "# Simulate trading activity\n",
    "for _ in range(1000):\n",
    "    # Record latencies\n",
    "    latency = np.random.exponential(100)  # Î¼s\n",
    "    metrics.observe('order_latency', latency)\n",
    "    \n",
    "    # Count events\n",
    "    metrics.increment('orders_processed')\n",
    "    if random.random() < 0.02:  # 2% error rate\n",
    "        metrics.increment('order_errors')\n",
    "\n",
    "# Set current state\n",
    "metrics.set_gauge('position_aapl', 1500)\n",
    "metrics.set_gauge('unrealized_pnl', 25000.50)\n",
    "\n",
    "metrics.report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160fd6d6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Questions\n",
    "\n",
    "### Conceptual\n",
    "1. What's the difference between event-driven and request-response architecture?\n",
    "2. How would you handle a market data feed failure?\n",
    "3. Explain CAP theorem in the context of order management.\n",
    "\n",
    "### Technical\n",
    "1. How do you achieve sub-millisecond latency?\n",
    "2. Design a lock-free order book.\n",
    "3. How would you implement exactly-once processing?\n",
    "\n",
    "### Design\n",
    "1. Design a market data distribution system.\n",
    "2. Design an order management system for multi-asset trading.\n",
    "3. How would you handle 10M messages per second?\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Concept | Key Points |\n",
    "|---------|------------|\n",
    "| Architecture | Event-driven for flexibility, shared-memory for speed |\n",
    "| Latency | Minimize allocations, use binary protocols |\n",
    "| Data | Hot/warm/cold tiers, time-series DBs |\n",
    "| Distributed | CAP trade-offs, consensus for coordination |\n",
    "| Reliability | Circuit breakers, failover, monitoring |\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "- *Designing Data-Intensive Applications* - Martin Kleppmann\n",
    "- *Building Trading Systems* - Harris\n",
    "- *Site Reliability Engineering* - Google\n",
    "- *LMAX Architecture* - Martin Fowler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
