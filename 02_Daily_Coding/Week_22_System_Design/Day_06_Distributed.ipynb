{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e39f62f",
   "metadata": {},
   "source": [
    "# Day 6: Distributed Systems Basics\n",
    "\n",
    "## Week 22: System Design for Quantitative Finance\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand CAP theorem and its implications for trading systems\n",
    "- Implement hash-based and consistent hashing for data partitioning\n",
    "- Build leader election algorithms for distributed coordination\n",
    "- Create message passing systems between distributed nodes\n",
    "- Implement CRDTs (Conflict-free Replicated Data Types)\n",
    "- Master load balancing strategies for high availability\n",
    "- Implement fault-tolerant retry logic with exponential backoff\n",
    "\n",
    "### Why Distributed Systems Matter in Quant Finance\n",
    "- **Scalability**: Process massive amounts of market data across multiple nodes\n",
    "- **Low Latency**: Distribute computation closer to data sources\n",
    "- **Fault Tolerance**: Ensure trading systems remain operational during failures\n",
    "- **High Availability**: 24/7 market coverage requires redundant systems\n",
    "- **Data Distribution**: Efficiently partition and replicate financial data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bd8802",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f52cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully!\n",
      "\n",
      "Key components for distributed systems:\n",
      "- hashlib: For consistent hashing\n",
      "- threading: For concurrent node simulation\n",
      "- queue: For message passing between nodes\n",
      "- collections: For distributed data structures\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Distributed Systems Basics - Core Libraries\n",
    "\"\"\"\n",
    "import hashlib\n",
    "import random\n",
    "import time\n",
    "import threading\n",
    "import queue\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Optional, Tuple, Any, Callable\n",
    "from abc import ABC, abstractmethod\n",
    "import bisect\n",
    "from enum import Enum\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import heapq\n",
    "\n",
    "# For visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")\n",
    "print(\"\\nKey components for distributed systems:\")\n",
    "print(\"- hashlib: For consistent hashing\")\n",
    "print(\"- threading: For concurrent node simulation\")\n",
    "print(\"- queue: For message passing between nodes\")\n",
    "print(\"- collections: For distributed data structures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9583ee6",
   "metadata": {},
   "source": [
    "## 2. Understanding CAP Theorem\n",
    "\n",
    "The **CAP Theorem** states that a distributed system can only guarantee two of three properties:\n",
    "\n",
    "- **Consistency (C)**: Every read receives the most recent write\n",
    "- **Availability (A)**: Every request receives a response (success or failure)\n",
    "- **Partition Tolerance (P)**: System continues to operate despite network partitions\n",
    "\n",
    "### Trade-offs in Trading Systems:\n",
    "| System Type | Priority | Example |\n",
    "|------------|----------|---------|\n",
    "| **CP** | Consistency + Partition Tolerance | Order matching engines, position tracking |\n",
    "| **AP** | Availability + Partition Tolerance | Market data distribution, analytics |\n",
    "| **CA** | Consistency + Availability | Single-node databases (no partition tolerance) |\n",
    "\n",
    "In practice, network partitions are inevitable, so we choose between **CP** and **AP**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a1ecf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CAP THEOREM DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "üìä CP SYSTEM (Consistency + Partition Tolerance)\n",
      "--------------------------------------------------\n",
      "Write AAPL_price=150.25: SUCCESS: Written to 3 nodes with version 1\n",
      "Read AAPL_price: CONSISTENT READ: value=150.25, version=1\n",
      "\n",
      "üî¥ Creating network partition (1 node isolated)...\n",
      "Status: Mode: Consistency + Partition Tolerance | Available: 2/3 nodes\n",
      "Write during partition: SUCCESS: Written to 2 nodes with version 2\n",
      "\n",
      "üî¥ Extending partition (2 nodes isolated)...\n",
      "Status: Mode: Consistency + Partition Tolerance | Available: 1/3 nodes\n",
      "Write during majority partition: UNAVAILABLE: Only 1/3 nodes reachable (need 2)\n",
      "Read during majority partition: UNAVAILABLE: Cannot guarantee consistency\n",
      "\n",
      "üü¢ Healing partition...\n",
      "Status: Mode: Consistency + Partition Tolerance | Available: 3/3 nodes\n",
      "\n",
      "======================================================================\n",
      "üìä AP SYSTEM (Availability + Partition Tolerance)\n",
      "--------------------------------------------------\n",
      "Write GOOGL_price=2800.50: SUCCESS: Written to 3 available nodes (may be inconsistent)\n",
      "\n",
      "üî¥ Creating network partition (2 nodes isolated)...\n",
      "Status: Mode: Availability + Partition Tolerance | Available: 1/3 nodes\n",
      "Write during partition: SUCCESS: Written to 1 available nodes (may be inconsistent)\n",
      "‚ö†Ô∏è  Note: Only node_0 has new value, others have stale data!\n",
      "Read during partition: AVAILABLE READ: value=2850.0 (may be stale)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CAP Theorem Simulation - Distributed Key-Value Store\n",
    "Demonstrates trade-offs between Consistency and Availability during partitions\n",
    "\"\"\"\n",
    "\n",
    "class CAPMode(Enum):\n",
    "    CP = \"Consistency + Partition Tolerance\"\n",
    "    AP = \"Availability + Partition Tolerance\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    \"\"\"Represents a node in distributed system\"\"\"\n",
    "    node_id: str\n",
    "    data: Dict[str, Tuple[Any, int]] = field(default_factory=dict)  # key -> (value, version)\n",
    "    is_partitioned: bool = False\n",
    "    \n",
    "    def write(self, key: str, value: Any, version: int) -> bool:\n",
    "        \"\"\"Write data to node\"\"\"\n",
    "        if key not in self.data or self.data[key][1] < version:\n",
    "            self.data[key] = (value, version)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def read(self, key: str) -> Optional[Tuple[Any, int]]:\n",
    "        \"\"\"Read data from node\"\"\"\n",
    "        return self.data.get(key)\n",
    "\n",
    "\n",
    "class DistributedKVStore:\n",
    "    \"\"\"\n",
    "    Distributed Key-Value Store demonstrating CAP theorem trade-offs\n",
    "    \"\"\"\n",
    "    def __init__(self, num_nodes: int = 3, mode: CAPMode = CAPMode.CP):\n",
    "        self.nodes = {f\"node_{i}\": Node(f\"node_{i}\") for i in range(num_nodes)}\n",
    "        self.mode = mode\n",
    "        self.version_counter = 0\n",
    "        self.leader = \"node_0\"  # Simple leader election\n",
    "        \n",
    "    def write(self, key: str, value: Any) -> Tuple[bool, str]:\n",
    "        \"\"\"\n",
    "        Write to distributed store\n",
    "        - CP mode: Requires majority consensus, fails during partition\n",
    "        - AP mode: Writes to available nodes, may have inconsistency\n",
    "        \"\"\"\n",
    "        self.version_counter += 1\n",
    "        version = self.version_counter\n",
    "        \n",
    "        available_nodes = [n for n in self.nodes.values() if not n.is_partitioned]\n",
    "        total_nodes = len(self.nodes)\n",
    "        majority = total_nodes // 2 + 1\n",
    "        \n",
    "        if self.mode == CAPMode.CP:\n",
    "            # CP: Require majority consensus\n",
    "            if len(available_nodes) < majority:\n",
    "                return False, f\"UNAVAILABLE: Only {len(available_nodes)}/{total_nodes} nodes reachable (need {majority})\"\n",
    "            \n",
    "            # Write to majority\n",
    "            success_count = 0\n",
    "            for node in available_nodes[:majority]:\n",
    "                if node.write(key, value, version):\n",
    "                    success_count += 1\n",
    "            \n",
    "            if success_count >= majority:\n",
    "                # Replicate to remaining available nodes asynchronously\n",
    "                for node in available_nodes[majority:]:\n",
    "                    node.write(key, value, version)\n",
    "                return True, f\"SUCCESS: Written to {len(available_nodes)} nodes with version {version}\"\n",
    "            return False, \"FAILED: Could not achieve consensus\"\n",
    "            \n",
    "        else:  # AP mode\n",
    "            # AP: Write to any available node, accept potential inconsistency\n",
    "            if not available_nodes:\n",
    "                return False, \"UNAVAILABLE: No nodes reachable\"\n",
    "            \n",
    "            for node in available_nodes:\n",
    "                node.write(key, value, version)\n",
    "            \n",
    "            return True, f\"SUCCESS: Written to {len(available_nodes)} available nodes (may be inconsistent)\"\n",
    "    \n",
    "    def read(self, key: str) -> Tuple[Optional[Any], str]:\n",
    "        \"\"\"\n",
    "        Read from distributed store\n",
    "        - CP mode: Read from leader/majority, fail if unavailable\n",
    "        - AP mode: Read from any available node\n",
    "        \"\"\"\n",
    "        available_nodes = [n for n in self.nodes.values() if not n.is_partitioned]\n",
    "        \n",
    "        if self.mode == CAPMode.CP:\n",
    "            # CP: Require quorum read\n",
    "            majority = len(self.nodes) // 2 + 1\n",
    "            if len(available_nodes) < majority:\n",
    "                return None, f\"UNAVAILABLE: Cannot guarantee consistency\"\n",
    "            \n",
    "            # Read from multiple nodes and return highest version\n",
    "            values = []\n",
    "            for node in available_nodes:\n",
    "                result = node.read(key)\n",
    "                if result:\n",
    "                    values.append(result)\n",
    "            \n",
    "            if values:\n",
    "                # Return value with highest version (most recent)\n",
    "                latest = max(values, key=lambda x: x[1])\n",
    "                return latest[0], f\"CONSISTENT READ: value={latest[0]}, version={latest[1]}\"\n",
    "            return None, \"KEY NOT FOUND\"\n",
    "            \n",
    "        else:  # AP mode\n",
    "            # AP: Return first available value (may be stale)\n",
    "            for node in available_nodes:\n",
    "                result = node.read(key)\n",
    "                if result:\n",
    "                    return result[0], f\"AVAILABLE READ: value={result[0]} (may be stale)\"\n",
    "            return None, \"KEY NOT FOUND or NO NODES AVAILABLE\"\n",
    "    \n",
    "    def create_partition(self, partitioned_nodes: List[str]):\n",
    "        \"\"\"Simulate network partition\"\"\"\n",
    "        for node_id in partitioned_nodes:\n",
    "            if node_id in self.nodes:\n",
    "                self.nodes[node_id].is_partitioned = True\n",
    "                \n",
    "    def heal_partition(self):\n",
    "        \"\"\"Heal network partition\"\"\"\n",
    "        for node in self.nodes.values():\n",
    "            node.is_partitioned = False\n",
    "    \n",
    "    def get_status(self) -> str:\n",
    "        \"\"\"Get cluster status\"\"\"\n",
    "        available = sum(1 for n in self.nodes.values() if not n.is_partitioned)\n",
    "        return f\"Mode: {self.mode.value} | Available: {available}/{len(self.nodes)} nodes\"\n",
    "\n",
    "\n",
    "# Demonstrate CAP trade-offs\n",
    "print(\"=\" * 70)\n",
    "print(\"CAP THEOREM DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# CP System Demo\n",
    "print(\"\\nüìä CP SYSTEM (Consistency + Partition Tolerance)\")\n",
    "print(\"-\" * 50)\n",
    "cp_store = DistributedKVStore(num_nodes=3, mode=CAPMode.CP)\n",
    "\n",
    "# Normal operation\n",
    "success, msg = cp_store.write(\"AAPL_price\", 150.25)\n",
    "print(f\"Write AAPL_price=150.25: {msg}\")\n",
    "\n",
    "value, msg = cp_store.read(\"AAPL_price\")\n",
    "print(f\"Read AAPL_price: {msg}\")\n",
    "\n",
    "# Create partition (minority)\n",
    "print(\"\\nüî¥ Creating network partition (1 node isolated)...\")\n",
    "cp_store.create_partition([\"node_2\"])\n",
    "print(f\"Status: {cp_store.get_status()}\")\n",
    "\n",
    "success, msg = cp_store.write(\"AAPL_price\", 151.00)\n",
    "print(f\"Write during partition: {msg}\")\n",
    "\n",
    "# Create partition (majority)\n",
    "print(\"\\nüî¥ Extending partition (2 nodes isolated)...\")\n",
    "cp_store.create_partition([\"node_1\", \"node_2\"])\n",
    "print(f\"Status: {cp_store.get_status()}\")\n",
    "\n",
    "success, msg = cp_store.write(\"AAPL_price\", 152.00)\n",
    "print(f\"Write during majority partition: {msg}\")\n",
    "\n",
    "value, msg = cp_store.read(\"AAPL_price\")\n",
    "print(f\"Read during majority partition: {msg}\")\n",
    "\n",
    "# Heal and show consistency\n",
    "print(\"\\nüü¢ Healing partition...\")\n",
    "cp_store.heal_partition()\n",
    "print(f\"Status: {cp_store.get_status()}\")\n",
    "\n",
    "# AP System Demo\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä AP SYSTEM (Availability + Partition Tolerance)\")\n",
    "print(\"-\" * 50)\n",
    "ap_store = DistributedKVStore(num_nodes=3, mode=CAPMode.AP)\n",
    "\n",
    "# Normal operation\n",
    "success, msg = ap_store.write(\"GOOGL_price\", 2800.50)\n",
    "print(f\"Write GOOGL_price=2800.50: {msg}\")\n",
    "\n",
    "# Create partition\n",
    "print(\"\\nüî¥ Creating network partition (2 nodes isolated)...\")\n",
    "ap_store.create_partition([\"node_1\", \"node_2\"])\n",
    "print(f\"Status: {ap_store.get_status()}\")\n",
    "\n",
    "success, msg = ap_store.write(\"GOOGL_price\", 2850.00)\n",
    "print(f\"Write during partition: {msg}\")\n",
    "print(\"‚ö†Ô∏è  Note: Only node_0 has new value, others have stale data!\")\n",
    "\n",
    "value, msg = ap_store.read(\"GOOGL_price\")\n",
    "print(f\"Read during partition: {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df569a59",
   "metadata": {},
   "source": [
    "## 3. Hash-Based Partitioning (Sharding)\n",
    "\n",
    "**Data Partitioning** distributes data across multiple nodes to achieve:\n",
    "- **Horizontal Scalability**: Handle more data by adding nodes\n",
    "- **Parallel Processing**: Distribute computation across nodes\n",
    "- **Load Distribution**: Balance workload evenly\n",
    "\n",
    "### Simple Hash Partitioning\n",
    "```\n",
    "partition = hash(key) % num_partitions\n",
    "```\n",
    "\n",
    "**Use Case in Trading**: Partition order books by symbol hash for parallel processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bee1c16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "HASH-BASED PARTITIONING - TRADING SYMBOLS\n",
      "======================================================================\n",
      "\n",
      "Distributing symbols across 4 partitions:\n",
      "--------------------------------------------------\n",
      "\n",
      "Partition assignments:\n",
      "  Partition 0: ['NVDA', 'WMT', 'MA', 'BAC', 'INTC', 'PFE', 'ABBV', 'AVGO', 'COST']\n",
      "  Partition 1: ['AMZN', 'PG', 'UNH', 'CSCO', 'PEP', 'TMO']\n",
      "  Partition 2: ['AAPL', 'MSFT', 'V', 'ADBE', 'KO', 'AMD']\n",
      "  Partition 3: ['GOOGL', 'META', 'TSLA', 'JPM', 'JNJ', 'HD', 'DIS', 'XOM', 'CRM', 'NFLX', 'MRK', 'ACN', 'MCD', 'NKE', 'LLY']\n",
      "\n",
      "üìä Distribution: {0: 9, 1: 6, 2: 6, 3: 15}\n",
      "   Min: 6, Max: 15, Std: 3.67\n",
      "\n",
      "======================================================================\n",
      "‚ö†Ô∏è  PROBLEM: Rehashing when partitions change\n",
      "======================================================================\n",
      "\n",
      "Original (4 partitions):\n",
      "  AAPL -> Partition 2\n",
      "  GOOGL -> Partition 3\n",
      "  MSFT -> Partition 2\n",
      "  AMZN -> Partition 1\n",
      "  META -> Partition 3\n",
      "  NVDA -> Partition 0\n",
      "  TSLA -> Partition 3\n",
      "  JPM -> Partition 3\n",
      "\n",
      "After adding 1 partition (5 total):\n",
      "  AAPL: 2 -> 0 üî¥ MOVED!\n",
      "  GOOGL: 3 -> 1 üî¥ MOVED!\n",
      "  MSFT: 2 -> 0 üî¥ MOVED!\n",
      "  AMZN: 1 -> 3 üî¥ MOVED!\n",
      "  META: 3 -> 4 üî¥ MOVED!\n",
      "  NVDA: 0 -> 4 üî¥ MOVED!\n",
      "  TSLA: 3 -> 3 \n",
      "  JPM: 3 -> 3 \n",
      "\n",
      "‚ö†Ô∏è  6/8 symbols (75%) need to be relocated!\n",
      "This is expensive! Consistent Hashing solves this problem.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple Hash-Based Partitioning for Financial Data\n",
    "\"\"\"\n",
    "\n",
    "class HashPartitioner:\n",
    "    \"\"\"\n",
    "    Simple modulo-based hash partitioner\n",
    "    Distributes data across N partitions using hash(key) % N\n",
    "    \"\"\"\n",
    "    def __init__(self, num_partitions: int):\n",
    "        self.num_partitions = num_partitions\n",
    "        self.partitions: Dict[int, List[Tuple[str, Any]]] = {\n",
    "            i: [] for i in range(num_partitions)\n",
    "        }\n",
    "        \n",
    "    def _hash(self, key: str) -> int:\n",
    "        \"\"\"Generate hash value for key\"\"\"\n",
    "        return int(hashlib.md5(key.encode()).hexdigest(), 16)\n",
    "    \n",
    "    def get_partition(self, key: str) -> int:\n",
    "        \"\"\"Determine which partition a key belongs to\"\"\"\n",
    "        return self._hash(key) % self.num_partitions\n",
    "    \n",
    "    def put(self, key: str, value: Any) -> int:\n",
    "        \"\"\"Store key-value pair in appropriate partition\"\"\"\n",
    "        partition_id = self.get_partition(key)\n",
    "        self.partitions[partition_id].append((key, value))\n",
    "        return partition_id\n",
    "    \n",
    "    def get_partition_data(self, partition_id: int) -> List[Tuple[str, Any]]:\n",
    "        \"\"\"Get all data from a partition\"\"\"\n",
    "        return self.partitions.get(partition_id, [])\n",
    "    \n",
    "    def get_distribution(self) -> Dict[int, int]:\n",
    "        \"\"\"Get count of items per partition\"\"\"\n",
    "        return {pid: len(data) for pid, data in self.partitions.items()}\n",
    "\n",
    "\n",
    "# Example: Partition trading symbols across nodes\n",
    "print(\"=\" * 70)\n",
    "print(\"HASH-BASED PARTITIONING - TRADING SYMBOLS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create partitioner with 4 partitions (simulating 4 nodes)\n",
    "partitioner = HashPartitioner(num_partitions=4)\n",
    "\n",
    "# Sample trading symbols\n",
    "symbols = [\n",
    "    \"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"META\", \"NVDA\", \"TSLA\", \"JPM\",\n",
    "    \"V\", \"JNJ\", \"WMT\", \"PG\", \"MA\", \"UNH\", \"HD\", \"DIS\", \"BAC\", \"XOM\",\n",
    "    \"CSCO\", \"ADBE\", \"CRM\", \"NFLX\", \"INTC\", \"PFE\", \"KO\", \"PEP\", \"MRK\",\n",
    "    \"ABBV\", \"TMO\", \"ACN\", \"AVGO\", \"COST\", \"MCD\", \"NKE\", \"LLY\", \"AMD\"\n",
    "]\n",
    "\n",
    "# Distribute symbols\n",
    "print(\"\\nDistributing symbols across 4 partitions:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "symbol_partitions = {}\n",
    "for symbol in symbols:\n",
    "    partition = partitioner.put(symbol, {\"price\": random.uniform(50, 500)})\n",
    "    symbol_partitions[symbol] = partition\n",
    "\n",
    "# Show distribution\n",
    "print(\"\\nPartition assignments:\")\n",
    "for pid in range(4):\n",
    "    partition_symbols = [s for s, p in symbol_partitions.items() if p == pid]\n",
    "    print(f\"  Partition {pid}: {partition_symbols}\")\n",
    "\n",
    "# Visualize distribution\n",
    "distribution = partitioner.get_distribution()\n",
    "print(f\"\\nüìä Distribution: {distribution}\")\n",
    "\n",
    "# Check balance\n",
    "counts = list(distribution.values())\n",
    "print(f\"   Min: {min(counts)}, Max: {max(counts)}, Std: {np.std(counts):.2f}\")\n",
    "\n",
    "# Problem: What happens when we add/remove a partition?\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚ö†Ô∏è  PROBLEM: Rehashing when partitions change\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Original assignments\n",
    "print(\"\\nOriginal (4 partitions):\")\n",
    "for symbol in symbols[:8]:\n",
    "    print(f\"  {symbol} -> Partition {partitioner.get_partition(symbol)}\")\n",
    "\n",
    "# New partitioner with 5 partitions\n",
    "new_partitioner = HashPartitioner(num_partitions=5)\n",
    "print(\"\\nAfter adding 1 partition (5 total):\")\n",
    "changes = 0\n",
    "for symbol in symbols[:8]:\n",
    "    old_part = partitioner.get_partition(symbol)\n",
    "    new_part = new_partitioner.get_partition(symbol)\n",
    "    changed = \"üî¥ MOVED!\" if old_part != new_part else \"\"\n",
    "    if changed:\n",
    "        changes += 1\n",
    "    print(f\"  {symbol}: {old_part} -> {new_part} {changed}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  {changes}/8 symbols ({changes/8*100:.0f}%) need to be relocated!\")\n",
    "print(\"This is expensive! Consistent Hashing solves this problem.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5370fb63",
   "metadata": {},
   "source": [
    "## 4. Consistent Hashing\n",
    "\n",
    "**Consistent Hashing** minimizes data movement when nodes are added or removed.\n",
    "\n",
    "### How it works:\n",
    "1. Both nodes and keys are hashed onto a circular ring (0 to 2^n)\n",
    "2. Each key is assigned to the first node clockwise from its position\n",
    "3. When a node is added/removed, only keys adjacent to it need to move\n",
    "\n",
    "### Benefits:\n",
    "- **Minimal Redistribution**: Only K/N keys move (K=keys, N=nodes)\n",
    "- **Virtual Nodes**: Improve balance by adding multiple points per node\n",
    "- **Hot Spot Prevention**: Even distribution across physical nodes\n",
    "\n",
    "**Trading Use Case**: Distribute market data feeds across cache servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea396bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CONSISTENT HASHING DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "üìä Ring created with 3 nodes (50 virtual nodes each)\n",
      "   Total ring positions: 150\n",
      "\n",
      "üîó Symbol -> Node Assignments:\n",
      "   Distribution: {'cache_server_1': 11, 'cache_server_2': 3, 'cache_server_3': 2}\n",
      "\n",
      "üìã Replication (3 replicas per key):\n",
      "   AAPL: ['cache_server_1', 'cache_server_3', 'cache_server_2']\n",
      "   GOOGL: ['cache_server_2', 'cache_server_3', 'cache_server_1']\n",
      "   MSFT: ['cache_server_1', 'cache_server_3', 'cache_server_2']\n",
      "   AMZN: ['cache_server_1', 'cache_server_2', 'cache_server_3']\n",
      "\n",
      "======================================================================\n",
      "üì• ADDING NEW NODE: cache_server_4\n",
      "======================================================================\n",
      "\n",
      "Key reassignments:\n",
      "   üîÑ AAPL: cache_server_1 -> cache_server_4\n",
      "   üîÑ GOOGL: cache_server_2 -> cache_server_4\n",
      "   üîÑ AMZN: cache_server_1 -> cache_server_4\n",
      "   üîÑ TSLA: cache_server_1 -> cache_server_4\n",
      "   üîÑ MA: cache_server_3 -> cache_server_4\n",
      "   üîÑ UNH: cache_server_2 -> cache_server_4\n",
      "   üîÑ HD: cache_server_1 -> cache_server_4\n",
      "\n",
      "‚úÖ Only 7/16 keys (43.8%) needed to move!\n",
      "   (With simple hash partitioning, ~75% would have moved)\n",
      "   New distribution: {'cache_server_4': 7, 'cache_server_1': 7, 'cache_server_2': 1, 'cache_server_3': 1}\n",
      "\n",
      "======================================================================\n",
      "üì§ REMOVING NODE: cache_server_2\n",
      "======================================================================\n",
      "\n",
      "Key reassignments from removed node:\n",
      "   üîÑ META: cache_server_2 -> cache_server_4\n",
      "\n",
      "‚úÖ 1 keys from the removed node redistributed to remaining nodes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Consistent Hashing Implementation with Virtual Nodes\n",
    "\"\"\"\n",
    "\n",
    "class ConsistentHashRing:\n",
    "    \"\"\"\n",
    "    Consistent Hashing Ring Implementation\n",
    "    \n",
    "    Features:\n",
    "    - Virtual nodes for better load distribution\n",
    "    - O(log N) lookup using binary search\n",
    "    - Minimal key redistribution on node changes\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, virtual_nodes: int = 100):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            virtual_nodes: Number of virtual nodes per physical node\n",
    "        \"\"\"\n",
    "        self.virtual_nodes = virtual_nodes\n",
    "        self.ring: Dict[int, str] = {}  # hash position -> node_id\n",
    "        self.sorted_keys: List[int] = []  # sorted hash positions\n",
    "        self.nodes: set = set()\n",
    "        \n",
    "    def _hash(self, key: str) -> int:\n",
    "        \"\"\"Generate hash value in range [0, 2^32)\"\"\"\n",
    "        return int(hashlib.sha256(key.encode()).hexdigest()[:8], 16)\n",
    "    \n",
    "    def add_node(self, node_id: str) -> List[int]:\n",
    "        \"\"\"\n",
    "        Add a node to the ring with virtual nodes\n",
    "        Returns: List of hash positions added\n",
    "        \"\"\"\n",
    "        if node_id in self.nodes:\n",
    "            return []\n",
    "            \n",
    "        self.nodes.add(node_id)\n",
    "        positions = []\n",
    "        \n",
    "        for i in range(self.virtual_nodes):\n",
    "            # Create unique virtual node identifier\n",
    "            virtual_key = f\"{node_id}#vn{i}\"\n",
    "            hash_val = self._hash(virtual_key)\n",
    "            \n",
    "            self.ring[hash_val] = node_id\n",
    "            positions.append(hash_val)\n",
    "            \n",
    "            # Maintain sorted order for binary search\n",
    "            bisect.insort(self.sorted_keys, hash_val)\n",
    "        \n",
    "        return positions\n",
    "    \n",
    "    def remove_node(self, node_id: str) -> List[int]:\n",
    "        \"\"\"\n",
    "        Remove a node from the ring\n",
    "        Returns: List of hash positions removed\n",
    "        \"\"\"\n",
    "        if node_id not in self.nodes:\n",
    "            return []\n",
    "            \n",
    "        self.nodes.remove(node_id)\n",
    "        positions_removed = []\n",
    "        \n",
    "        for i in range(self.virtual_nodes):\n",
    "            virtual_key = f\"{node_id}#vn{i}\"\n",
    "            hash_val = self._hash(virtual_key)\n",
    "            \n",
    "            if hash_val in self.ring:\n",
    "                del self.ring[hash_val]\n",
    "                self.sorted_keys.remove(hash_val)\n",
    "                positions_removed.append(hash_val)\n",
    "        \n",
    "        return positions_removed\n",
    "    \n",
    "    def get_node(self, key: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Get the node responsible for a key\n",
    "        Uses binary search to find first node clockwise from key's hash\n",
    "        \"\"\"\n",
    "        if not self.ring:\n",
    "            return None\n",
    "            \n",
    "        hash_val = self._hash(key)\n",
    "        \n",
    "        # Binary search for first position >= hash_val\n",
    "        idx = bisect.bisect_left(self.sorted_keys, hash_val)\n",
    "        \n",
    "        # Wrap around to first node if past the end\n",
    "        if idx >= len(self.sorted_keys):\n",
    "            idx = 0\n",
    "            \n",
    "        return self.ring[self.sorted_keys[idx]]\n",
    "    \n",
    "    def get_nodes_for_key(self, key: str, num_replicas: int = 3) -> List[str]:\n",
    "        \"\"\"\n",
    "        Get multiple nodes for replication\n",
    "        Returns N distinct physical nodes for a key\n",
    "        \"\"\"\n",
    "        if not self.ring or num_replicas > len(self.nodes):\n",
    "            return list(self.nodes)[:num_replicas]\n",
    "            \n",
    "        hash_val = self._hash(key)\n",
    "        idx = bisect.bisect_left(self.sorted_keys, hash_val)\n",
    "        \n",
    "        nodes = []\n",
    "        seen = set()\n",
    "        \n",
    "        for i in range(len(self.sorted_keys)):\n",
    "            pos = (idx + i) % len(self.sorted_keys)\n",
    "            node = self.ring[self.sorted_keys[pos]]\n",
    "            \n",
    "            if node not in seen:\n",
    "                nodes.append(node)\n",
    "                seen.add(node)\n",
    "                \n",
    "            if len(nodes) >= num_replicas:\n",
    "                break\n",
    "                \n",
    "        return nodes\n",
    "\n",
    "\n",
    "# Demonstrate Consistent Hashing\n",
    "print(\"=\" * 70)\n",
    "print(\"CONSISTENT HASHING DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create ring with 50 virtual nodes per physical node\n",
    "ring = ConsistentHashRing(virtual_nodes=50)\n",
    "\n",
    "# Add initial nodes\n",
    "initial_nodes = [\"cache_server_1\", \"cache_server_2\", \"cache_server_3\"]\n",
    "for node in initial_nodes:\n",
    "    ring.add_node(node)\n",
    "    \n",
    "print(f\"\\nüìä Ring created with {len(initial_nodes)} nodes ({ring.virtual_nodes} virtual nodes each)\")\n",
    "print(f\"   Total ring positions: {len(ring.sorted_keys)}\")\n",
    "\n",
    "# Assign symbols to nodes\n",
    "symbols = [\"AAPL\", \"GOOGL\", \"MSFT\", \"AMZN\", \"META\", \"NVDA\", \"TSLA\", \"JPM\",\n",
    "           \"V\", \"JNJ\", \"WMT\", \"PG\", \"MA\", \"UNH\", \"HD\", \"DIS\"]\n",
    "\n",
    "print(\"\\nüîó Symbol -> Node Assignments:\")\n",
    "original_assignments = {}\n",
    "for symbol in symbols:\n",
    "    node = ring.get_node(symbol)\n",
    "    original_assignments[symbol] = node\n",
    "\n",
    "# Count per node\n",
    "node_counts = defaultdict(int)\n",
    "for node in original_assignments.values():\n",
    "    node_counts[node] += 1\n",
    "    \n",
    "print(f\"   Distribution: {dict(node_counts)}\")\n",
    "\n",
    "# Show replication\n",
    "print(\"\\nüìã Replication (3 replicas per key):\")\n",
    "for symbol in symbols[:4]:\n",
    "    replicas = ring.get_nodes_for_key(symbol, num_replicas=3)\n",
    "    print(f\"   {symbol}: {replicas}\")\n",
    "\n",
    "# Add a new node\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üì• ADDING NEW NODE: cache_server_4\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "ring.add_node(\"cache_server_4\")\n",
    "\n",
    "# Check reassignments\n",
    "moved = 0\n",
    "print(\"\\nKey reassignments:\")\n",
    "for symbol in symbols:\n",
    "    old_node = original_assignments[symbol]\n",
    "    new_node = ring.get_node(symbol)\n",
    "    if old_node != new_node:\n",
    "        moved += 1\n",
    "        print(f\"   üîÑ {symbol}: {old_node} -> {new_node}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Only {moved}/{len(symbols)} keys ({moved/len(symbols)*100:.1f}%) needed to move!\")\n",
    "print(\"   (With simple hash partitioning, ~75% would have moved)\")\n",
    "\n",
    "# Show new distribution\n",
    "new_counts = defaultdict(int)\n",
    "for symbol in symbols:\n",
    "    new_counts[ring.get_node(symbol)] += 1\n",
    "print(f\"   New distribution: {dict(new_counts)}\")\n",
    "\n",
    "# Remove a node\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üì§ REMOVING NODE: cache_server_2\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get current assignments before removal\n",
    "pre_removal = {s: ring.get_node(s) for s in symbols}\n",
    "ring.remove_node(\"cache_server_2\")\n",
    "\n",
    "# Check reassignments\n",
    "moved = 0\n",
    "print(\"\\nKey reassignments from removed node:\")\n",
    "for symbol in symbols:\n",
    "    old_node = pre_removal[symbol]\n",
    "    new_node = ring.get_node(symbol)\n",
    "    if old_node != new_node:\n",
    "        moved += 1\n",
    "        print(f\"   üîÑ {symbol}: {old_node} -> {new_node}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {moved} keys from the removed node redistributed to remaining nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c829235d",
   "metadata": {},
   "source": [
    "## 5. Leader Election - Bully Algorithm\n",
    "\n",
    "**Leader Election** determines which node coordinates distributed operations.\n",
    "\n",
    "### Bully Algorithm:\n",
    "1. When a node detects the leader has failed, it starts an election\n",
    "2. It sends ELECTION messages to all nodes with higher IDs\n",
    "3. If no higher node responds, it becomes the leader\n",
    "4. The node with the highest ID that responds wins\n",
    "\n",
    "### Trading System Use Cases:\n",
    "- **Order Matching**: Single leader ensures consistent order matching\n",
    "- **Position Aggregation**: Leader coordinates position calculations\n",
    "- **Failover**: Automatic leader election when primary fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a957ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "BULLY ALGORITHM - LEADER ELECTION\n",
      "======================================================================\n",
      "\n",
      "üèÅ INITIAL ELECTION\n",
      "--------------------------------------------------\n",
      "  üì¢ Node 0: Starting election...\n",
      "  üì§ Node 0: Sending ELECTION to nodes [1, 2, 3, 4]\n",
      "  üì• Node 1: Received ELECTION from Node 0. Sending OK.\n",
      "  üì¢ Node 1: Starting election...\n",
      "  üì§ Node 1: Sending ELECTION to nodes [2, 3, 4]\n",
      "  üì• Node 2: Received ELECTION from Node 1. Sending OK.\n",
      "  üì¢ Node 2: Starting election...\n",
      "  üì§ Node 2: Sending ELECTION to nodes [3, 4]\n",
      "  üì• Node 3: Received ELECTION from Node 2. Sending OK.\n",
      "  üì¢ Node 3: Starting election...\n",
      "  üì§ Node 3: Sending ELECTION to nodes [4]\n",
      "  üì• Node 4: Received ELECTION from Node 3. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 3: Received OK from nodes [4]. Waiting...\n",
      "  üì• Node 4: Received ELECTION from Node 2. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 2: Received OK from nodes [3, 4]. Waiting...\n",
      "  üì• Node 3: Received ELECTION from Node 1. Sending OK.\n",
      "  üì¢ Node 3: Starting election...\n",
      "  üì§ Node 3: Sending ELECTION to nodes [4]\n",
      "  üì• Node 4: Received ELECTION from Node 3. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 3: Received OK from nodes [4]. Waiting...\n",
      "  üì• Node 4: Received ELECTION from Node 1. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 1: Received OK from nodes [2, 3, 4]. Waiting...\n",
      "  üì• Node 2: Received ELECTION from Node 0. Sending OK.\n",
      "  üì¢ Node 2: Starting election...\n",
      "  üì§ Node 2: Sending ELECTION to nodes [3, 4]\n",
      "  üì• Node 3: Received ELECTION from Node 2. Sending OK.\n",
      "  üì¢ Node 3: Starting election...\n",
      "  üì§ Node 3: Sending ELECTION to nodes [4]\n",
      "  üì• Node 4: Received ELECTION from Node 3. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 3: Received OK from nodes [4]. Waiting...\n",
      "  üì• Node 4: Received ELECTION from Node 2. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 2: Received OK from nodes [3, 4]. Waiting...\n",
      "  üì• Node 3: Received ELECTION from Node 0. Sending OK.\n",
      "  üì¢ Node 3: Starting election...\n",
      "  üì§ Node 3: Sending ELECTION to nodes [4]\n",
      "  üì• Node 4: Received ELECTION from Node 3. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 3: Received OK from nodes [4]. Waiting...\n",
      "  üì• Node 4: Received ELECTION from Node 0. Sending OK.\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 3: Acknowledged Node 4 as leader\n",
      "  üì• Node 0: Received OK from nodes [1, 2, 3, 4]. Waiting...\n",
      "\n",
      "‚úÖ Leader: Node 4\n",
      "\n",
      "======================================================================\n",
      "üíÄ LEADER FAILURE SCENARIO\n",
      "======================================================================\n",
      "\n",
      "Node 4 (leader) fails...\n",
      "  üíÄ Node 4: FAILED!\n",
      "\n",
      "Node 2 detects failure and starts election:\n",
      "--------------------------------------------------\n",
      "  üì¢ Node 2: Starting election...\n",
      "  üì§ Node 2: Sending ELECTION to nodes [3]\n",
      "  üì• Node 3: Received ELECTION from Node 2. Sending OK.\n",
      "  üì¢ Node 3: Starting election...\n",
      "  üëë Node 3: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 3 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 3 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 3 as leader\n",
      "  üì• Node 2: Received OK from nodes [3]. Waiting...\n",
      "\n",
      "‚úÖ New Leader: Node 3\n",
      "\n",
      "======================================================================\n",
      "üíÄ CASCADING FAILURE\n",
      "======================================================================\n",
      "\n",
      "Node 3 (current leader) also fails...\n",
      "  üíÄ Node 3: FAILED!\n",
      "\n",
      "Node 1 detects failure and starts election:\n",
      "--------------------------------------------------\n",
      "  üì¢ Node 1: Starting election...\n",
      "  üì§ Node 1: Sending ELECTION to nodes [2]\n",
      "  üì• Node 2: Received ELECTION from Node 1. Sending OK.\n",
      "  üì¢ Node 2: Starting election...\n",
      "  üëë Node 2: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 2 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 2 as leader\n",
      "  üì• Node 1: Received OK from nodes [2]. Waiting...\n",
      "\n",
      "‚úÖ New Leader: Node 2\n",
      "\n",
      "======================================================================\n",
      "üîÑ NODE RECOVERY\n",
      "======================================================================\n",
      "\n",
      "Node 4 recovers and starts election:\n",
      "--------------------------------------------------\n",
      "  üîÑ Node 4: RECOVERED!\n",
      "  üì¢ Node 4: Starting election...\n",
      "  üëë Node 4: No higher nodes responding. I am the leader!\n",
      "  üì¢ Node 0: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 1: Acknowledged Node 4 as leader\n",
      "  üì¢ Node 2: Acknowledged Node 4 as leader\n",
      "\n",
      "‚úÖ Leader after recovery: Node 4\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bully Algorithm for Leader Election\n",
    "\"\"\"\n",
    "\n",
    "class BullyNode:\n",
    "    \"\"\"\n",
    "    Node implementing the Bully Algorithm for leader election\n",
    "    \"\"\"\n",
    "    def __init__(self, node_id: int, cluster: 'BullyCluster'):\n",
    "        self.node_id = node_id\n",
    "        self.cluster = cluster\n",
    "        self.is_alive = True\n",
    "        self.current_leader: Optional[int] = None\n",
    "        self.election_in_progress = False\n",
    "        \n",
    "    def start_election(self) -> int:\n",
    "        \"\"\"\n",
    "        Start an election process\n",
    "        Returns the ID of the elected leader\n",
    "        \"\"\"\n",
    "        print(f\"  üì¢ Node {self.node_id}: Starting election...\")\n",
    "        self.election_in_progress = True\n",
    "        \n",
    "        # Find all nodes with higher IDs\n",
    "        higher_nodes = [\n",
    "            node for node in self.cluster.get_alive_nodes()\n",
    "            if node.node_id > self.node_id\n",
    "        ]\n",
    "        \n",
    "        if not higher_nodes:\n",
    "            # No higher nodes, I am the leader!\n",
    "            print(f\"  üëë Node {self.node_id}: No higher nodes responding. I am the leader!\")\n",
    "            self.become_leader()\n",
    "            return self.node_id\n",
    "        \n",
    "        # Send election message to higher nodes\n",
    "        print(f\"  üì§ Node {self.node_id}: Sending ELECTION to nodes {[n.node_id for n in higher_nodes]}\")\n",
    "        \n",
    "        responses = []\n",
    "        for node in higher_nodes:\n",
    "            response = node.receive_election(self.node_id)\n",
    "            if response:\n",
    "                responses.append(node.node_id)\n",
    "        \n",
    "        if not responses:\n",
    "            # No responses, I am the leader\n",
    "            print(f\"  üëë Node {self.node_id}: No responses received. I am the leader!\")\n",
    "            self.become_leader()\n",
    "            return self.node_id\n",
    "        else:\n",
    "            # Higher node(s) responded, wait for leader announcement\n",
    "            print(f\"  üì• Node {self.node_id}: Received OK from nodes {responses}. Waiting...\")\n",
    "            # The highest responding node should become leader\n",
    "            return max(responses)\n",
    "    \n",
    "    def receive_election(self, from_node: int) -> bool:\n",
    "        \"\"\"\n",
    "        Receive election message from lower node\n",
    "        Returns True (OK) if alive\n",
    "        \"\"\"\n",
    "        if not self.is_alive:\n",
    "            return False\n",
    "            \n",
    "        print(f\"  üì• Node {self.node_id}: Received ELECTION from Node {from_node}. Sending OK.\")\n",
    "        \n",
    "        # Start my own election since I have higher ID\n",
    "        if not self.election_in_progress:\n",
    "            self.start_election()\n",
    "            \n",
    "        return True\n",
    "    \n",
    "    def become_leader(self):\n",
    "        \"\"\"Announce leadership to all nodes\"\"\"\n",
    "        self.current_leader = self.node_id\n",
    "        self.election_in_progress = False\n",
    "        \n",
    "        # Broadcast to all nodes\n",
    "        for node in self.cluster.get_alive_nodes():\n",
    "            node.receive_leader_announcement(self.node_id)\n",
    "    \n",
    "    def receive_leader_announcement(self, leader_id: int):\n",
    "        \"\"\"Receive leader announcement\"\"\"\n",
    "        self.current_leader = leader_id\n",
    "        self.election_in_progress = False\n",
    "        if self.node_id != leader_id:\n",
    "            print(f\"  üì¢ Node {self.node_id}: Acknowledged Node {leader_id} as leader\")\n",
    "    \n",
    "    def fail(self):\n",
    "        \"\"\"Simulate node failure\"\"\"\n",
    "        self.is_alive = False\n",
    "        print(f\"  üíÄ Node {self.node_id}: FAILED!\")\n",
    "    \n",
    "    def recover(self):\n",
    "        \"\"\"Recover a failed node\"\"\"\n",
    "        self.is_alive = True\n",
    "        print(f\"  üîÑ Node {self.node_id}: RECOVERED!\")\n",
    "\n",
    "\n",
    "class BullyCluster:\n",
    "    \"\"\"Cluster of nodes using Bully Algorithm\"\"\"\n",
    "    \n",
    "    def __init__(self, num_nodes: int):\n",
    "        self.nodes = {}\n",
    "        for i in range(num_nodes):\n",
    "            self.nodes[i] = BullyNode(i, self)\n",
    "            \n",
    "    def get_alive_nodes(self) -> List[BullyNode]:\n",
    "        \"\"\"Get list of alive nodes\"\"\"\n",
    "        return [n for n in self.nodes.values() if n.is_alive]\n",
    "    \n",
    "    def get_leader(self) -> Optional[int]:\n",
    "        \"\"\"Get current leader ID\"\"\"\n",
    "        alive = self.get_alive_nodes()\n",
    "        if alive:\n",
    "            return alive[0].current_leader\n",
    "        return None\n",
    "    \n",
    "    def initial_election(self):\n",
    "        \"\"\"Run initial election from lowest node\"\"\"\n",
    "        lowest_alive = min(self.get_alive_nodes(), key=lambda n: n.node_id)\n",
    "        lowest_alive.start_election()\n",
    "\n",
    "\n",
    "# Demonstrate Bully Algorithm\n",
    "print(\"=\" * 70)\n",
    "print(\"BULLY ALGORITHM - LEADER ELECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create cluster with 5 nodes (IDs: 0, 1, 2, 3, 4)\n",
    "cluster = BullyCluster(num_nodes=5)\n",
    "\n",
    "print(\"\\nüèÅ INITIAL ELECTION\")\n",
    "print(\"-\" * 50)\n",
    "cluster.initial_election()\n",
    "print(f\"\\n‚úÖ Leader: Node {cluster.get_leader()}\")\n",
    "\n",
    "# Simulate leader failure\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üíÄ LEADER FAILURE SCENARIO\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNode 4 (leader) fails...\")\n",
    "cluster.nodes[4].fail()\n",
    "\n",
    "print(\"\\nNode 2 detects failure and starts election:\")\n",
    "print(\"-\" * 50)\n",
    "cluster.nodes[2].start_election()\n",
    "print(f\"\\n‚úÖ New Leader: Node {cluster.get_leader()}\")\n",
    "\n",
    "# Another failure\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üíÄ CASCADING FAILURE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNode 3 (current leader) also fails...\")\n",
    "cluster.nodes[3].fail()\n",
    "\n",
    "print(\"\\nNode 1 detects failure and starts election:\")\n",
    "print(\"-\" * 50)\n",
    "cluster.nodes[1].start_election()\n",
    "print(f\"\\n‚úÖ New Leader: Node {cluster.get_leader()}\")\n",
    "\n",
    "# Node recovery\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîÑ NODE RECOVERY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nNode 4 recovers and starts election:\")\n",
    "print(\"-\" * 50)\n",
    "cluster.nodes[4].recover()\n",
    "cluster.nodes[4].start_election()\n",
    "print(f\"\\n‚úÖ Leader after recovery: Node {cluster.get_leader()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6845c63",
   "metadata": {},
   "source": [
    "## 6. Message Passing Between Nodes\n",
    "\n",
    "**Message Passing** is fundamental to distributed systems communication.\n",
    "\n",
    "### Common Patterns:\n",
    "- **Request-Response**: Synchronous communication\n",
    "- **Publish-Subscribe**: Asynchronous, decoupled messaging\n",
    "- **Fire-and-Forget**: Async without acknowledgment\n",
    "\n",
    "### Trading System Applications:\n",
    "- Market data distribution (pub-sub)\n",
    "- Order routing (request-response)\n",
    "- Risk alerts (fire-and-forget with retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe9d8a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MESSAGE PASSING SYSTEM DEMONSTRATION\n",
      "======================================================================\n",
      "\n",
      "üìã SETTING UP SUBSCRIPTIONS\n",
      "--------------------------------------------------\n",
      "  ‚úÖ Strategy_Alpha subscribed to 'market_data.AAPL'\n",
      "  ‚úÖ Strategy_Beta subscribed to 'market_data.AAPL'\n",
      "  ‚úÖ Strategy_Alpha subscribed to 'market_data.GOOGL'\n",
      "\n",
      "üìä PUBLISHING MARKET DATA (Pub-Sub)\n",
      "--------------------------------------------------\n",
      "  üì§ MarketDataFeed: Published AAPL update to 2 subscribers\n",
      "  üì§ MarketDataFeed: Published GOOGL update to 1 subscribers\n",
      "\n",
      "üì• PROCESSING RECEIVED MESSAGES\n",
      "--------------------------------------------------\n",
      "  üì• Strategy_Alpha: Received market_data from MarketDataFeed\n",
      "  üì• Strategy_Alpha: Received market_data from MarketDataFeed\n",
      "  üì• Strategy_Beta: Received market_data from MarketDataFeed\n",
      "\n",
      "üì§ DIRECT ORDER ROUTING (Point-to-Point)\n",
      "--------------------------------------------------\n",
      "  ‚ùå Message Strategy_Alpha-1 LOST\n",
      "  üì§ Strategy_Alpha: Sent order to OrderRouter - ‚ùå Failed\n",
      "  üì§ Strategy_Beta: Sent order to OrderRouter - ‚úÖ Delivered\n",
      "  üì• OrderRouter: Received order from Strategy_Beta\n",
      "\n",
      "üìä Message Statistics:\n",
      "   Total messages logged: 3\n",
      "   Strategy_Alpha received: 2\n",
      "   Strategy_Beta received: 1\n",
      "   OrderRouter received: 1\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Message Passing System Simulation\n",
    "Demonstrates distributed communication patterns\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class Message:\n",
    "    \"\"\"Message structure for inter-node communication\"\"\"\n",
    "    msg_id: str\n",
    "    msg_type: str  # 'market_data', 'order', 'ack', 'heartbeat'\n",
    "    sender: str\n",
    "    receiver: str\n",
    "    payload: Dict[str, Any]\n",
    "    timestamp: float = field(default_factory=time.time)\n",
    "    \n",
    "    def to_dict(self) -> dict:\n",
    "        return {\n",
    "            'msg_id': self.msg_id,\n",
    "            'msg_type': self.msg_type,\n",
    "            'sender': self.sender,\n",
    "            'receiver': self.receiver,\n",
    "            'payload': self.payload,\n",
    "            'timestamp': self.timestamp\n",
    "        }\n",
    "\n",
    "\n",
    "class MessageBroker:\n",
    "    \"\"\"\n",
    "    Simple message broker for pub-sub and point-to-point messaging\n",
    "    \"\"\"\n",
    "    def __init__(self, failure_rate: float = 0.0, latency_ms: Tuple[int, int] = (1, 10)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            failure_rate: Probability of message loss (0-1)\n",
    "            latency_ms: Range of simulated network latency\n",
    "        \"\"\"\n",
    "        self.queues: Dict[str, queue.Queue] = defaultdict(queue.Queue)\n",
    "        self.topics: Dict[str, List[str]] = defaultdict(list)  # topic -> subscribers\n",
    "        self.failure_rate = failure_rate\n",
    "        self.latency_ms = latency_ms\n",
    "        self.message_log: List[Dict] = []\n",
    "        \n",
    "    def subscribe(self, topic: str, subscriber_id: str):\n",
    "        \"\"\"Subscribe to a topic\"\"\"\n",
    "        if subscriber_id not in self.topics[topic]:\n",
    "            self.topics[topic].append(subscriber_id)\n",
    "            print(f\"  ‚úÖ {subscriber_id} subscribed to '{topic}'\")\n",
    "    \n",
    "    def unsubscribe(self, topic: str, subscriber_id: str):\n",
    "        \"\"\"Unsubscribe from a topic\"\"\"\n",
    "        if subscriber_id in self.topics[topic]:\n",
    "            self.topics[topic].remove(subscriber_id)\n",
    "            \n",
    "    def publish(self, topic: str, message: Message) -> int:\n",
    "        \"\"\"\n",
    "        Publish message to all subscribers of a topic\n",
    "        Returns number of successful deliveries\n",
    "        \"\"\"\n",
    "        subscribers = self.topics.get(topic, [])\n",
    "        delivered = 0\n",
    "        \n",
    "        for subscriber in subscribers:\n",
    "            # Simulate network conditions\n",
    "            if random.random() < self.failure_rate:\n",
    "                print(f\"  ‚ùå Message {message.msg_id} LOST to {subscriber}\")\n",
    "                continue\n",
    "                \n",
    "            # Simulate latency\n",
    "            latency = random.randint(*self.latency_ms) / 1000\n",
    "            time.sleep(latency)\n",
    "            \n",
    "            # Deliver message\n",
    "            self.queues[subscriber].put(message)\n",
    "            delivered += 1\n",
    "            \n",
    "        self.message_log.append({\n",
    "            'action': 'publish',\n",
    "            'topic': topic,\n",
    "            'msg_id': message.msg_id,\n",
    "            'delivered': delivered,\n",
    "            'total_subscribers': len(subscribers)\n",
    "        })\n",
    "        \n",
    "        return delivered\n",
    "    \n",
    "    def send_direct(self, message: Message) -> bool:\n",
    "        \"\"\"\n",
    "        Send message directly to a specific receiver\n",
    "        Returns True if delivered\n",
    "        \"\"\"\n",
    "        if random.random() < self.failure_rate:\n",
    "            print(f\"  ‚ùå Message {message.msg_id} LOST\")\n",
    "            return False\n",
    "            \n",
    "        latency = random.randint(*self.latency_ms) / 1000\n",
    "        time.sleep(latency)\n",
    "        \n",
    "        self.queues[message.receiver].put(message)\n",
    "        self.message_log.append({\n",
    "            'action': 'direct',\n",
    "            'msg_id': message.msg_id,\n",
    "            'from': message.sender,\n",
    "            'to': message.receiver,\n",
    "            'delivered': True\n",
    "        })\n",
    "        return True\n",
    "    \n",
    "    def receive(self, receiver_id: str, timeout: float = 1.0) -> Optional[Message]:\n",
    "        \"\"\"Receive a message (blocking with timeout)\"\"\"\n",
    "        try:\n",
    "            return self.queues[receiver_id].get(timeout=timeout)\n",
    "        except queue.Empty:\n",
    "            return None\n",
    "    \n",
    "    def receive_all(self, receiver_id: str) -> List[Message]:\n",
    "        \"\"\"Receive all pending messages\"\"\"\n",
    "        messages = []\n",
    "        while not self.queues[receiver_id].empty():\n",
    "            messages.append(self.queues[receiver_id].get())\n",
    "        return messages\n",
    "\n",
    "\n",
    "class TradingNode:\n",
    "    \"\"\"Simulated trading system node\"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str, broker: MessageBroker):\n",
    "        self.node_id = node_id\n",
    "        self.broker = broker\n",
    "        self.received_messages: List[Message] = []\n",
    "        self.msg_counter = 0\n",
    "        \n",
    "    def create_message(self, msg_type: str, receiver: str, payload: dict) -> Message:\n",
    "        \"\"\"Create a new message\"\"\"\n",
    "        self.msg_counter += 1\n",
    "        return Message(\n",
    "            msg_id=f\"{self.node_id}-{self.msg_counter}\",\n",
    "            msg_type=msg_type,\n",
    "            sender=self.node_id,\n",
    "            receiver=receiver,\n",
    "            payload=payload\n",
    "        )\n",
    "    \n",
    "    def send_market_data(self, symbol: str, price: float, volume: int):\n",
    "        \"\"\"Publish market data update\"\"\"\n",
    "        msg = self.create_message(\n",
    "            msg_type='market_data',\n",
    "            receiver='broadcast',\n",
    "            payload={'symbol': symbol, 'price': price, 'volume': volume}\n",
    "        )\n",
    "        delivered = self.broker.publish(f'market_data.{symbol}', msg)\n",
    "        print(f\"  üì§ {self.node_id}: Published {symbol} update to {delivered} subscribers\")\n",
    "        \n",
    "    def send_order(self, order: dict, target_node: str):\n",
    "        \"\"\"Send order to specific node\"\"\"\n",
    "        msg = self.create_message(\n",
    "            msg_type='order',\n",
    "            receiver=target_node,\n",
    "            payload=order\n",
    "        )\n",
    "        success = self.broker.send_direct(msg)\n",
    "        status = \"‚úÖ Delivered\" if success else \"‚ùå Failed\"\n",
    "        print(f\"  üì§ {self.node_id}: Sent order to {target_node} - {status}\")\n",
    "        \n",
    "    def process_messages(self):\n",
    "        \"\"\"Process all pending messages\"\"\"\n",
    "        messages = self.broker.receive_all(self.node_id)\n",
    "        for msg in messages:\n",
    "            self.received_messages.append(msg)\n",
    "            print(f\"  üì• {self.node_id}: Received {msg.msg_type} from {msg.sender}\")\n",
    "            \n",
    "\n",
    "# Demonstrate Message Passing\n",
    "print(\"=\" * 70)\n",
    "print(\"MESSAGE PASSING SYSTEM DEMONSTRATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Create broker with some simulated failures\n",
    "broker = MessageBroker(failure_rate=0.1, latency_ms=(1, 5))\n",
    "\n",
    "# Create nodes\n",
    "market_data_feed = TradingNode(\"MarketDataFeed\", broker)\n",
    "strategy_1 = TradingNode(\"Strategy_Alpha\", broker)\n",
    "strategy_2 = TradingNode(\"Strategy_Beta\", broker)\n",
    "order_router = TradingNode(\"OrderRouter\", broker)\n",
    "\n",
    "# Setup subscriptions (pub-sub pattern)\n",
    "print(\"\\nüìã SETTING UP SUBSCRIPTIONS\")\n",
    "print(\"-\" * 50)\n",
    "broker.subscribe(\"market_data.AAPL\", strategy_1.node_id)\n",
    "broker.subscribe(\"market_data.AAPL\", strategy_2.node_id)\n",
    "broker.subscribe(\"market_data.GOOGL\", strategy_1.node_id)\n",
    "\n",
    "# Publish market data\n",
    "print(\"\\nüìä PUBLISHING MARKET DATA (Pub-Sub)\")\n",
    "print(\"-\" * 50)\n",
    "market_data_feed.send_market_data(\"AAPL\", 150.25, 10000)\n",
    "market_data_feed.send_market_data(\"GOOGL\", 2800.50, 5000)\n",
    "\n",
    "# Process received messages\n",
    "print(\"\\nüì• PROCESSING RECEIVED MESSAGES\")\n",
    "print(\"-\" * 50)\n",
    "strategy_1.process_messages()\n",
    "strategy_2.process_messages()\n",
    "\n",
    "# Direct messaging (point-to-point)\n",
    "print(\"\\nüì§ DIRECT ORDER ROUTING (Point-to-Point)\")\n",
    "print(\"-\" * 50)\n",
    "strategy_1.send_order(\n",
    "    {'symbol': 'AAPL', 'side': 'BUY', 'qty': 100, 'price': 150.00},\n",
    "    order_router.node_id\n",
    ")\n",
    "strategy_2.send_order(\n",
    "    {'symbol': 'GOOGL', 'side': 'SELL', 'qty': 50, 'price': 2805.00},\n",
    "    order_router.node_id\n",
    ")\n",
    "\n",
    "# Order router processes orders\n",
    "order_router.process_messages()\n",
    "\n",
    "print(f\"\\nüìä Message Statistics:\")\n",
    "print(f\"   Total messages logged: {len(broker.message_log)}\")\n",
    "print(f\"   Strategy_Alpha received: {len(strategy_1.received_messages)}\")\n",
    "print(f\"   Strategy_Beta received: {len(strategy_2.received_messages)}\")\n",
    "print(f\"   OrderRouter received: {len(order_router.received_messages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e0d2f",
   "metadata": {},
   "source": [
    "## 7. CRDTs - Conflict-free Replicated Data Types\n",
    "\n",
    "**CRDTs** are data structures that can be replicated across multiple nodes and merged without conflicts.\n",
    "\n",
    "### Key Property:\n",
    "- All replicas converge to the same state regardless of message ordering\n",
    "- No coordination needed (eventually consistent)\n",
    "\n",
    "### Types:\n",
    "- **G-Counter**: Grow-only counter (increment only)\n",
    "- **PN-Counter**: Positive-Negative counter (increment and decrement)\n",
    "- **G-Set**: Grow-only set (add only)\n",
    "- **OR-Set**: Observed-Remove set (add and remove)\n",
    "\n",
    "### Trading Use Case: \n",
    "Distributed trade counters, volume aggregation across data centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1db850c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CRDT DEMONSTRATION - DISTRIBUTED TRADE COUNTERS\n",
      "======================================================================\n",
      "\n",
      "üìä G-Counter: Distributed Trade Counter\n",
      "--------------------------------------------------\n",
      "\n",
      "Processing trades at each data center...\n",
      "  NYC:    GCounter(NYC, counts={'NYC': 150}, total=150)\n",
      "  London: GCounter(London, counts={'London': 120}, total=120)\n",
      "  Tokyo:  GCounter(Tokyo, counts={'Tokyo': 180}, total=180)\n",
      "\n",
      "Merging counters (any order produces same result)...\n",
      "  NYC after merge with London: GCounter(NYC, counts={'NYC': 150, 'London': 120}, total=270)\n",
      "  NYC after merge with Tokyo: GCounter(NYC, counts={'NYC': 150, 'London': 120, 'Tokyo': 180}, total=450)\n",
      "  Tokyo after merges: GCounter(Tokyo, counts={'Tokyo': 180, 'London': 120, 'NYC': 150}, total=450)\n",
      "\n",
      "‚úÖ Both converge to same total: 450 trades\n",
      "\n",
      "======================================================================\n",
      "üìä PN-Counter: Net Position Tracking\n",
      "--------------------------------------------------\n",
      "Node A - Bought 100, Sold 30: PNCounter(Algo_A, value=70, P=100, N=30)\n",
      "Node B - Bought 50, Sold 80: PNCounter(Algo_B, value=-30, P=50, N=80)\n",
      "\n",
      "After merge: PNCounter(Algo_A, value=40, P=150, N=110)\n",
      "Net position: 40 (150 buys - 110 sells)\n",
      "\n",
      "======================================================================\n",
      "üìä LWW-Register: Last Price Update Wins\n",
      "--------------------------------------------------\n",
      "Feed 1 sets price at t=1.0: LWWRegister(value=150.25, ts=1.000)\n",
      "Feed 2 sets price at t=2.0: LWWRegister(value=150.3, ts=2.000)\n",
      "Feed 1 sets price at t=1.5: LWWRegister(value=150.2, ts=1.500)\n",
      "\n",
      "Merging (latest timestamp wins)...\n",
      "Feed 1 after merge: LWWRegister(value=150.3, ts=2.000)\n",
      "Feed 2 after merge: LWWRegister(value=150.3, ts=2.000)\n",
      "\n",
      "‚úÖ Both show price: $150.3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CRDT Implementations - Conflict-free Replicated Data Types\n",
    "\"\"\"\n",
    "\n",
    "class GCounter:\n",
    "    \"\"\"\n",
    "    G-Counter (Grow-only Counter) CRDT\n",
    "    \n",
    "    Each node maintains its own counter. Total value is sum of all node counters.\n",
    "    Merge operation takes maximum of each node's counter.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str):\n",
    "        self.node_id = node_id\n",
    "        self.counts: Dict[str, int] = defaultdict(int)\n",
    "        \n",
    "    def increment(self, amount: int = 1):\n",
    "        \"\"\"Increment this node's counter\"\"\"\n",
    "        self.counts[self.node_id] += amount\n",
    "        \n",
    "    def value(self) -> int:\n",
    "        \"\"\"Get total count across all nodes\"\"\"\n",
    "        return sum(self.counts.values())\n",
    "    \n",
    "    def merge(self, other: 'GCounter'):\n",
    "        \"\"\"\n",
    "        Merge with another G-Counter\n",
    "        Takes maximum of each node's count\n",
    "        \"\"\"\n",
    "        all_nodes = set(self.counts.keys()) | set(other.counts.keys())\n",
    "        for node in all_nodes:\n",
    "            self.counts[node] = max(self.counts[node], other.counts[node])\n",
    "    \n",
    "    def get_state(self) -> Dict[str, int]:\n",
    "        \"\"\"Get current state for serialization\"\"\"\n",
    "        return dict(self.counts)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"GCounter({self.node_id}, counts={dict(self.counts)}, total={self.value()})\"\n",
    "\n",
    "\n",
    "class PNCounter:\n",
    "    \"\"\"\n",
    "    PN-Counter (Positive-Negative Counter) CRDT\n",
    "    \n",
    "    Uses two G-Counters: one for increments, one for decrements.\n",
    "    Value = P_counter - N_counter\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str):\n",
    "        self.node_id = node_id\n",
    "        self.p_counter = GCounter(node_id)  # Positive increments\n",
    "        self.n_counter = GCounter(node_id)  # Negative increments (decrements)\n",
    "        \n",
    "    def increment(self, amount: int = 1):\n",
    "        \"\"\"Increment the counter\"\"\"\n",
    "        self.p_counter.increment(amount)\n",
    "        \n",
    "    def decrement(self, amount: int = 1):\n",
    "        \"\"\"Decrement the counter\"\"\"\n",
    "        self.n_counter.increment(amount)\n",
    "        \n",
    "    def value(self) -> int:\n",
    "        \"\"\"Get net value\"\"\"\n",
    "        return self.p_counter.value() - self.n_counter.value()\n",
    "    \n",
    "    def merge(self, other: 'PNCounter'):\n",
    "        \"\"\"Merge with another PN-Counter\"\"\"\n",
    "        self.p_counter.merge(other.p_counter)\n",
    "        self.n_counter.merge(other.n_counter)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"PNCounter({self.node_id}, value={self.value()}, P={self.p_counter.value()}, N={self.n_counter.value()})\"\n",
    "\n",
    "\n",
    "class LWWRegister:\n",
    "    \"\"\"\n",
    "    Last-Write-Wins Register CRDT\n",
    "    \n",
    "    Each write includes a timestamp. On merge, the value with the highest timestamp wins.\n",
    "    Useful for single-value storage that can be updated.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, node_id: str):\n",
    "        self.node_id = node_id\n",
    "        self.value: Any = None\n",
    "        self.timestamp: float = 0.0\n",
    "        \n",
    "    def set(self, value: Any, timestamp: Optional[float] = None):\n",
    "        \"\"\"Set value with timestamp\"\"\"\n",
    "        ts = timestamp or time.time()\n",
    "        if ts >= self.timestamp:\n",
    "            self.value = value\n",
    "            self.timestamp = ts\n",
    "            \n",
    "    def get(self) -> Any:\n",
    "        \"\"\"Get current value\"\"\"\n",
    "        return self.value\n",
    "    \n",
    "    def merge(self, other: 'LWWRegister'):\n",
    "        \"\"\"Merge with another register - highest timestamp wins\"\"\"\n",
    "        if other.timestamp > self.timestamp:\n",
    "            self.value = other.value\n",
    "            self.timestamp = other.timestamp\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f\"LWWRegister(value={self.value}, ts={self.timestamp:.3f})\"\n",
    "\n",
    "\n",
    "# Demonstrate CRDTs\n",
    "print(\"=\" * 70)\n",
    "print(\"CRDT DEMONSTRATION - DISTRIBUTED TRADE COUNTERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Scenario: Counting trades across multiple data centers\n",
    "print(\"\\nüìä G-Counter: Distributed Trade Counter\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Create counters at different data centers\n",
    "nyc_counter = GCounter(\"NYC\")\n",
    "london_counter = GCounter(\"London\")\n",
    "tokyo_counter = GCounter(\"Tokyo\")\n",
    "\n",
    "# Each data center processes trades independently\n",
    "print(\"\\nProcessing trades at each data center...\")\n",
    "nyc_counter.increment(150)      # 150 trades in NYC\n",
    "london_counter.increment(120)   # 120 trades in London\n",
    "tokyo_counter.increment(180)    # 180 trades in Tokyo\n",
    "\n",
    "print(f\"  NYC:    {nyc_counter}\")\n",
    "print(f\"  London: {london_counter}\")\n",
    "print(f\"  Tokyo:  {tokyo_counter}\")\n",
    "\n",
    "# Merge counters (simulating eventual consistency)\n",
    "print(\"\\nMerging counters (any order produces same result)...\")\n",
    "\n",
    "# NYC receives London's state\n",
    "nyc_counter.merge(london_counter)\n",
    "print(f\"  NYC after merge with London: {nyc_counter}\")\n",
    "\n",
    "# NYC receives Tokyo's state\n",
    "nyc_counter.merge(tokyo_counter)\n",
    "print(f\"  NYC after merge with Tokyo: {nyc_counter}\")\n",
    "\n",
    "# Tokyo also merges (different order)\n",
    "tokyo_counter.merge(london_counter)\n",
    "tokyo_counter.merge(nyc_counter)\n",
    "print(f\"  Tokyo after merges: {tokyo_counter}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Both converge to same total: {nyc_counter.value()} trades\")\n",
    "\n",
    "# PN-Counter Demo\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä PN-Counter: Net Position Tracking\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Track net position (buys - sells) across nodes\n",
    "node_a = PNCounter(\"Algo_A\")\n",
    "node_b = PNCounter(\"Algo_B\")\n",
    "\n",
    "# Node A: 100 buys, 30 sells\n",
    "node_a.increment(100)\n",
    "node_a.decrement(30)\n",
    "print(f\"Node A - Bought 100, Sold 30: {node_a}\")\n",
    "\n",
    "# Node B: 50 buys, 80 sells\n",
    "node_b.increment(50)\n",
    "node_b.decrement(80)\n",
    "print(f\"Node B - Bought 50, Sold 80: {node_b}\")\n",
    "\n",
    "# Merge\n",
    "node_a.merge(node_b)\n",
    "print(f\"\\nAfter merge: {node_a}\")\n",
    "print(f\"Net position: {node_a.value()} (150 buys - 110 sells)\")\n",
    "\n",
    "# LWW Register Demo\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä LWW-Register: Last Price Update Wins\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Track latest price across nodes\n",
    "reg_1 = LWWRegister(\"Feed_1\")\n",
    "reg_2 = LWWRegister(\"Feed_2\")\n",
    "\n",
    "# Simulate price updates with timestamps\n",
    "reg_1.set(150.25, timestamp=1.0)\n",
    "print(f\"Feed 1 sets price at t=1.0: {reg_1}\")\n",
    "\n",
    "reg_2.set(150.30, timestamp=2.0)\n",
    "print(f\"Feed 2 sets price at t=2.0: {reg_2}\")\n",
    "\n",
    "reg_1.set(150.20, timestamp=1.5)  # Earlier timestamp, should be ignored on merge\n",
    "print(f\"Feed 1 sets price at t=1.5: {reg_1}\")\n",
    "\n",
    "# Merge\n",
    "print(\"\\nMerging (latest timestamp wins)...\")\n",
    "reg_1.merge(reg_2)\n",
    "print(f\"Feed 1 after merge: {reg_1}\")\n",
    "\n",
    "reg_2.merge(reg_1)\n",
    "print(f\"Feed 2 after merge: {reg_2}\")\n",
    "print(f\"\\n‚úÖ Both show price: ${reg_1.get()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
