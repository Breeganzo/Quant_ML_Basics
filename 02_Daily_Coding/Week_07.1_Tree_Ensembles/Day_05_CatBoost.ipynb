{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91602971",
   "metadata": {},
   "source": [
    "# Day 5: CatBoost for Trading\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "- Understand CatBoost innovations\n",
    "- Handle categorical features natively\n",
    "- Apply ordered boosting\n",
    "- Compare with XGBoost and LightGBM\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Theory: CatBoost\n",
    "\n",
    "### What Makes CatBoost Different\n",
    "\n",
    "| Feature | CatBoost Innovation |\n",
    "|---------|--------------------|\n",
    "| Categorical | Target encoding with ordered statistics |\n",
    "| Boosting | Ordered boosting (reduces overfitting) |\n",
    "| Trees | Symmetric (oblivious) trees |\n",
    "| GPU | Excellent GPU support |\n",
    "\n",
    "### Ordered Target Statistics\n",
    "Traditional target encoding leaks information. CatBoost uses:\n",
    "$$\\hat{x}_k = \\frac{\\sum_{j<i} [x_j = x_i] \\cdot y_j + a \\cdot p}{\\sum_{j<i} [x_j = x_i] + a}$$\n",
    "\n",
    "Where:\n",
    "- Only uses samples **before** current sample\n",
    "- $a$: smoothing parameter\n",
    "- $p$: prior (target mean)\n",
    "\n",
    "### Ordered Boosting\n",
    "- Standard boosting: Use all data for residuals\n",
    "- Ordered boosting: Use random permutation, predict with trees built on preceding samples\n",
    "- Reduces prediction shift (target leakage)\n",
    "\n",
    "### Symmetric Trees\n",
    "- Same feature and threshold at each level\n",
    "- Faster inference\n",
    "- Natural regularization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5052ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import lightgbm as lgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_RATE = 0.05\n",
    "\n",
    "# Download data\n",
    "ticker = 'AAPL'\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "print(\"üì• Downloading data...\")\n",
    "data = yf.download(ticker, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close']\n",
    "volume = data['Volume']\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(f\"‚úÖ Data: {len(prices)} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a890af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features with categorical variables\n",
    "df = pd.DataFrame(index=prices.index)\n",
    "df['price'] = prices\n",
    "df['return'] = returns\n",
    "\n",
    "# Numerical features\n",
    "for lag in [1, 5, 10, 20]:\n",
    "    df[f'momentum_{lag}'] = prices.pct_change(lag)\n",
    "\n",
    "for window in [5, 10, 20]:\n",
    "    df[f'volatility_{window}'] = returns.rolling(window).std()\n",
    "\n",
    "df['volume_ratio'] = volume / volume.rolling(20).mean()\n",
    "df['ma_5_20'] = prices.rolling(5).mean() / prices.rolling(20).mean() - 1\n",
    "\n",
    "# RSI\n",
    "delta = prices.diff()\n",
    "gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "df['rsi'] = 100 - (100 / (1 + gain / loss))\n",
    "\n",
    "# Categorical features\n",
    "df['day_of_week'] = df.index.dayofweek.astype(str)  # Keep as string for CatBoost\n",
    "df['month'] = df.index.month.astype(str)\n",
    "\n",
    "# Volatility regime (categorical)\n",
    "vol_20 = returns.rolling(20).std()\n",
    "vol_quantiles = pd.qcut(vol_20.dropna(), q=3, labels=['low', 'medium', 'high'])\n",
    "df['vol_regime'] = vol_quantiles.astype(str)\n",
    "\n",
    "# Target\n",
    "df['next_return'] = returns.shift(-1)\n",
    "df['target'] = (df['next_return'] > 0).astype(int)\n",
    "\n",
    "df = df.dropna()\n",
    "print(f\"üìä Samples: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6dee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "feature_cols = [c for c in df.columns if c not in ['price', 'return', 'next_return', 'target']]\n",
    "categorical_cols = ['day_of_week', 'month', 'vol_regime']\n",
    "numerical_cols = [c for c in feature_cols if c not in categorical_cols]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['target']\n",
    "\n",
    "# Split\n",
    "split_idx = int(len(df) * 0.8)\n",
    "X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "returns_test = df['next_return'].iloc[split_idx:]\n",
    "\n",
    "# Get categorical indices for CatBoost\n",
    "cat_indices = [X.columns.get_loc(c) for c in categorical_cols]\n",
    "\n",
    "print(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "print(f\"Categorical indices: {cat_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de727b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost with native categorical handling\n",
    "train_pool = Pool(X_train, y_train, cat_features=cat_indices)\n",
    "test_pool = Pool(X_test, y_test, cat_features=cat_indices)\n",
    "\n",
    "cat = CatBoostClassifier(\n",
    "    iterations=200,\n",
    "    depth=5,\n",
    "    learning_rate=0.1,\n",
    "    cat_features=cat_indices,\n",
    "    random_seed=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "start = time.time()\n",
    "cat.fit(train_pool, eval_set=test_pool)\n",
    "cat_time = time.time() - start\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CATBOOST TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training time: {cat_time:.2f} seconds\")\n",
    "print(f\"Best iteration: {cat.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577789fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three boosting methods\n",
    "# For fair comparison, encode categoricals for XGBoost/LightGBM\n",
    "X_encoded = X.copy()\n",
    "for col in categorical_cols:\n",
    "    X_encoded[col] = X_encoded[col].astype('category').cat.codes\n",
    "\n",
    "X_train_enc = X_encoded.iloc[:split_idx]\n",
    "X_test_enc = X_encoded.iloc[split_idx:]\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.1,\n",
    "                   random_state=42, eval_metric='logloss')\n",
    "start = time.time()\n",
    "xgb.fit(X_train_enc, y_train)\n",
    "xgb_time = time.time() - start\n",
    "\n",
    "# LightGBM\n",
    "lgbm = lgb.LGBMClassifier(n_estimators=200, max_depth=5, learning_rate=0.1,\n",
    "                          random_state=42, verbosity=-1)\n",
    "start = time.time()\n",
    "lgbm.fit(X_train_enc, y_train)\n",
    "lgbm_time = time.time() - start\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"BOOSTING METHOD COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = []\n",
    "for name, model, test_data, train_time in [\n",
    "    ('XGBoost', xgb, X_test_enc, xgb_time),\n",
    "    ('LightGBM', lgbm, X_test_enc, lgbm_time),\n",
    "    ('CatBoost', cat, X_test, cat_time)\n",
    "]:\n",
    "    y_pred = model.predict(test_data)\n",
    "    y_proba = model.predict_proba(test_data)[:, 1]\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Train Time': f'{train_time:.2f}s',\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'F1': f1_score(y_test, y_pred),\n",
    "        'AUC': roc_auc_score(y_test, y_proba)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9516f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance from CatBoost\n",
    "importance = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Importance': cat.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['coral' if f in categorical_cols else 'steelblue' for f in importance['Feature']]\n",
    "plt.barh(importance['Feature'], importance['Importance'], color=colors)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('CatBoost Feature Importance (Orange = Categorical)')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734bb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trading Strategy Backtest\n",
    "y_pred = cat.predict(X_test)\n",
    "y_proba = cat.predict_proba(X_test)[:, 1]\n",
    "\n",
    "backtest = pd.DataFrame(index=y_test.index)\n",
    "backtest['actual_return'] = returns_test.values\n",
    "\n",
    "# Strategies\n",
    "backtest['signal'] = y_pred\n",
    "backtest['strategy_return'] = backtest['signal'] * backtest['actual_return']\n",
    "backtest['strategy_cum'] = (1 + backtest['strategy_return']).cumprod()\n",
    "\n",
    "backtest['prob_signal'] = y_proba\n",
    "backtest['prob_return'] = backtest['prob_signal'] * backtest['actual_return']\n",
    "backtest['prob_cum'] = (1 + backtest['prob_return']).cumprod()\n",
    "\n",
    "backtest['buy_hold_cum'] = (1 + backtest['actual_return']).cumprod()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(backtest.index, backtest['buy_hold_cum'], label='Buy & Hold', linewidth=2)\n",
    "plt.plot(backtest.index, backtest['strategy_cum'], label='CatBoost Binary', linewidth=2)\n",
    "plt.plot(backtest.index, backtest['prob_cum'], label='CatBoost Probability', linewidth=2)\n",
    "plt.title(f'CatBoost Trading Strategies ({ticker})', fontsize=14)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Return')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa30304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance\n",
    "def calc_metrics(returns, cumulative):\n",
    "    total = cumulative.iloc[-1] - 1\n",
    "    sharpe = (returns.mean() * TRADING_DAYS - RISK_FREE_RATE) / (returns.std() * np.sqrt(TRADING_DAYS)) if returns.std() > 0 else 0\n",
    "    peak = cumulative.cummax()\n",
    "    mdd = ((cumulative - peak) / peak).min()\n",
    "    return total, sharpe, mdd\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STRATEGY PERFORMANCE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "strategies = [\n",
    "    ('Buy & Hold', 'actual_return', 'buy_hold_cum'),\n",
    "    ('CatBoost Binary', 'strategy_return', 'strategy_cum'),\n",
    "    ('CatBoost Probability', 'prob_return', 'prob_cum')\n",
    "]\n",
    "\n",
    "print(f\"\\n{'Strategy':<25} {'Total Ret':>12} {'Sharpe':>10} {'Max DD':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for name, ret_col, cum_col in strategies:\n",
    "    total, sharpe, mdd = calc_metrics(backtest[ret_col], backtest[cum_col])\n",
    "    print(f\"{name:<25} {total:>12.2%} {sharpe:>10.2f} {mdd:>10.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546a7817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next day prediction\n",
    "latest = X.iloc[-1:]\n",
    "pred = cat.predict(latest)[0]\n",
    "proba = cat.predict_proba(latest)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"üìä NEXT DAY PREDICTION FOR {ticker}\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDate: {df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"\\nCategorical Context:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"  {col}: {latest[col].values[0]}\")\n",
    "print(f\"\\nPrediction: {'üìà UP' if pred == 1 else 'üìâ DOWN'}\")\n",
    "print(f\"Probability (Down/Up): [{proba[0]:.2%}, {proba[1]:.2%}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5588577",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üè¢ Real-World Applications\n",
    "\n",
    "| Company | CatBoost Use Case |\n",
    "|---------|------------------|\n",
    "| Yandex | Web search ranking |\n",
    "| CloudFlare | Security classification |\n",
    "| Finance | Many categorical features |\n",
    "| Retail | Customer segmentation |\n",
    "\n",
    "### Key Interview Points\n",
    "1. **Why CatBoost for categoricals?** - Ordered target statistics prevent leakage\n",
    "2. **Ordered boosting?** - Reduces overfitting by using different data for residuals\n",
    "3. **Symmetric trees?** - Same split at each level, faster inference\n",
    "4. **When to use?** - Many categorical features, robust out-of-box performance\n",
    "\n",
    "---\n",
    "## üìÖ Tomorrow: Ensemble Stacking"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
