{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "902d54e1",
   "metadata": {},
   "source": [
    "# Week 2: Statistics and Probability for Finance\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What You'll Learn This Week\n",
    "\n",
    "Statistics is the language of risk management. Every time a portfolio manager says \"there's a 5% chance we lose more than $1M\", they're using these concepts.\n",
    "\n",
    "**By the end of this week, you'll understand:**\n",
    "- How to model uncertainty in financial markets\n",
    "- The famous \"bell curve\" and why it's both useful AND dangerous\n",
    "- How to test if a trading strategy actually works (or just got lucky)\n",
    "- How assets move together (correlation) - crucial for diversification!\n",
    "\n",
    "**Why This Matters for Trading:**\n",
    "- **Risk managers** use distributions to calculate potential losses\n",
    "- **Quants** test strategies using hypothesis testing to avoid \"data snooping\"\n",
    "- **Portfolio managers** use correlation to build diversified portfolios\n",
    "- **Interviewers** love asking about distributions and statistical tests!\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. Probability Distributions\n",
    "2. The Normal Distribution\n",
    "3. Hypothesis Testing\n",
    "4. Linear Regression\n",
    "5. Covariance and Correlation Matrices\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae48dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports and data loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Standard 5 equities for analysis\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'JPM', 'GS']\n",
    "\n",
    "# Fetch 5 years of data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "print(\"üì• Downloading market data...\")\n",
    "data = yf.download(tickers, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "print(f\"‚úÖ Loaded {len(prices)} days of data for {len(tickers)} tickers\")\n",
    "print(f\"üìÖ Date range: {prices.index[0].strftime('%Y-%m-%d')} to {prices.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(prices.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9196a66",
   "metadata": {},
   "source": [
    "## 1. Probability Distributions\n",
    "\n",
    "### ü§î What is a Probability Distribution? (Simple Explanation)\n",
    "\n",
    "Think of it like a weather forecast, but for stock returns:\n",
    "- \"70% chance of sun\" ‚Üí \"70% chance the stock goes up\"\n",
    "- \"20% chance of rain\" ‚Üí \"20% chance the stock goes down\"\n",
    "- \"10% chance of storm\" ‚Üí \"10% chance of a market crash\"\n",
    "\n",
    "A probability distribution tells us ALL the possible outcomes and how likely each one is.\n",
    "\n",
    "### Why Traders Care About This\n",
    "\n",
    "**Real-world example:** You're a risk manager at a bank. Your boss asks: \"What's the worst-case scenario for our portfolio tomorrow?\" \n",
    "\n",
    "You can't know the future, but you CAN use probability distributions to say: \"There's a 95% chance we won't lose more than $1 million.\"\n",
    "\n",
    "### Key Concepts (Don't Worry, We'll Make This Easy!)\n",
    "\n",
    "**Probability Density Function (PDF)**: A fancy way of drawing a curve that shows which outcomes are more likely.\n",
    "- Tall curve at a point = that outcome is very likely\n",
    "- Short curve = that outcome is rare\n",
    "\n",
    "**Cumulative Distribution Function (CDF)**: Answers the question \"What's the probability we get less than X?\"\n",
    "\n",
    "$$F(x) = P(X \\leq x) = \\int_{-\\infty}^{x} f(t) dt$$\n",
    "\n",
    "*Translation: This formula just adds up all the probabilities from negative infinity to x*\n",
    "\n",
    "**Expected Value (Mean)**: If you played this game 1,000 times, what would you get on average?\n",
    "\n",
    "$$E[X] = \\int_{-\\infty}^{\\infty} x \\cdot f(x) dx$$\n",
    "\n",
    "*Translation: Multiply each outcome by its probability, then add them all up*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e424c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of return < -2%: 0.0859 = 8.59%\n",
      "\n",
      "This means: On about 21.6 days per year, we expect losses > 2%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: What's the probability that tomorrow's return is less than -2%?\n",
    "# Assume returns are normally distributed with mean=0.05%, std=1.5%\n",
    "\n",
    "mean_return = 0.0005  # 0.05% daily\n",
    "std_return = 0.015    # 1.5% daily\n",
    "\n",
    "# Create normal distribution\n",
    "return_dist = stats.norm(loc=mean_return, scale=std_return)\n",
    "\n",
    "# Probability of return < -2%\n",
    "prob_below_minus2 = return_dist.cdf(-0.02)\n",
    "\n",
    "print(f\"Probability of return < -2%: {prob_below_minus2:.4f} = {prob_below_minus2*100:.2f}%\")\n",
    "print(f\"\\nThis means: On about {prob_below_minus2*252:.1f} days per year, we expect losses > 2%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f3978c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. The Normal Distribution\n",
    "\n",
    "### Why Normal?\n",
    "The normal (Gaussian) distribution is fundamental because:\n",
    "1. **Central Limit Theorem**: Sum of many random variables ‚Üí normal\n",
    "2. **Mathematical tractability**: Easy to work with analytically\n",
    "3. **Two-parameter simplicity**: Fully described by mean and variance\n",
    "\n",
    "### Formula\n",
    "\n",
    "$$f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n",
    "\n",
    "Where:\n",
    "- $\\mu$ = mean (center of distribution)\n",
    "- $\\sigma$ = standard deviation (spread)\n",
    "\n",
    "### Standard Normal Distribution\n",
    "\n",
    "When $\\mu = 0$ and $\\sigma = 1$, we call it the **standard normal**.\n",
    "\n",
    "Any normal variable can be standardized:\n",
    "$$Z = \\frac{X - \\mu}{\\sigma}$$\n",
    "\n",
    "### The 68-95-99.7 Rule\n",
    "\n",
    "For a normal distribution:\n",
    "- 68% of values fall within 1œÉ of the mean\n",
    "- 95% of values fall within 2œÉ of the mean\n",
    "- 99.7% of values fall within 3œÉ of the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff1b7950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 68-95-99.7 Rule:\n",
      "Within 1œÉ: 0.6827 = 68.27%\n",
      "Within 2œÉ: 0.9545 = 95.45%\n",
      "Within 3œÉ: 0.9973 = 99.73%\n",
      "\n",
      "For our stock (Œº=0.05%, œÉ=1.50%):\n",
      "68% of days: returns between -1.45% and 1.55%\n",
      "95% of days: returns between -2.95% and 3.05%\n",
      "99.7% of days: returns between -4.45% and 4.55%\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate the 68-95-99.7 rule with stock returns\n",
    "daily_mean = 0.0005  # 0.05%\n",
    "daily_std = 0.015    # 1.5%\n",
    "\n",
    "# Standard normal for calculations\n",
    "standard_normal = stats.norm(0, 1)\n",
    "\n",
    "# Calculate probabilities within 1, 2, 3 standard deviations\n",
    "prob_1std = standard_normal.cdf(1) - standard_normal.cdf(-1)\n",
    "prob_2std = standard_normal.cdf(2) - standard_normal.cdf(-2)\n",
    "prob_3std = standard_normal.cdf(3) - standard_normal.cdf(-3)\n",
    "\n",
    "print(\"The 68-95-99.7 Rule:\")\n",
    "print(f\"Within 1œÉ: {prob_1std:.4f} = {prob_1std*100:.2f}%\")\n",
    "print(f\"Within 2œÉ: {prob_2std:.4f} = {prob_2std*100:.2f}%\")\n",
    "print(f\"Within 3œÉ: {prob_3std:.4f} = {prob_3std*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nFor our stock (Œº={daily_mean:.2%}, œÉ={daily_std:.2%}):\")\n",
    "print(f\"68% of days: returns between {daily_mean - daily_std:.2%} and {daily_mean + daily_std:.2%}\")\n",
    "print(f\"95% of days: returns between {daily_mean - 2*daily_std:.2%} and {daily_mean + 2*daily_std:.2%}\")\n",
    "print(f\"99.7% of days: returns between {daily_mean - 3*daily_std:.2%} and {daily_mean + 3*daily_std:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b68598b",
   "metadata": {},
   "source": [
    "### Reality Check: Fat Tails\n",
    "\n",
    "**Important**: Real financial returns are NOT perfectly normal!\n",
    "\n",
    "They exhibit:\n",
    "- **Fat tails** (leptokurtosis): Extreme events more common than normal predicts\n",
    "- **Negative skewness**: Large negative returns more common than large positive\n",
    "- **Volatility clustering**: High volatility tends to follow high volatility\n",
    "\n",
    "The normal distribution **underestimates** tail risk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "499f4466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extreme Events (|return| > 4.5%):\n",
      "Normal distribution: 28 events out of 10,000 (0.28%)\n",
      "Fat-tail distribution: 169 events out of 10,000 (1.69%)\n",
      "\n",
      "Fat tails produce 6.0x more extreme events!\n",
      "\n",
      "‚ö†Ô∏è This is why VaR and risk models failed in 2008!\n"
     ]
    }
   ],
   "source": [
    "# Compare theoretical normal with real market behavior\n",
    "# Under normal distribution, 3-sigma events happen 0.3% of the time (about 0.75 days/year)\n",
    "\n",
    "# Simulate \"real\" returns with fat tails using Student's t-distribution\n",
    "np.random.seed(42)\n",
    "normal_returns = np.random.normal(0, 0.015, 10000)\n",
    "fat_tail_returns = stats.t.rvs(df=4, loc=0, scale=0.012, size=10000)  # t-distribution with 4 df\n",
    "\n",
    "# Count extreme events (beyond 3 sigma)\n",
    "threshold = 3 * 0.015  # 3 sigma\n",
    "normal_extremes = np.sum(np.abs(normal_returns) > threshold)\n",
    "fat_tail_extremes = np.sum(np.abs(fat_tail_returns) > threshold)\n",
    "\n",
    "print(\"Extreme Events (|return| > 4.5%):\")\n",
    "print(f\"Normal distribution: {normal_extremes} events out of 10,000 ({normal_extremes/100:.2f}%)\")\n",
    "print(f\"Fat-tail distribution: {fat_tail_extremes} events out of 10,000 ({fat_tail_extremes/100:.2f}%)\")\n",
    "print(f\"\\nFat tails produce {fat_tail_extremes/max(normal_extremes,1):.1f}x more extreme events!\")\n",
    "print(\"\\n‚ö†Ô∏è This is why VaR and risk models failed in 2008!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f1dc9e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Hypothesis Testing\n",
    "\n",
    "### Why Hypothesis Testing in Finance?\n",
    "- Is this trading strategy's return statistically significant?\n",
    "- Does adding a factor improve the model?\n",
    "- Is this stock's beta different from 1?\n",
    "\n",
    "### The Framework\n",
    "\n",
    "1. **Null Hypothesis (H‚ÇÄ)**: The default assumption (e.g., \"strategy has no alpha\")\n",
    "2. **Alternative Hypothesis (H‚ÇÅ)**: What we're testing for (e.g., \"strategy has positive alpha\")\n",
    "3. **Test Statistic**: A number calculated from data\n",
    "4. **P-value**: Probability of observing our result if H‚ÇÄ is true\n",
    "5. **Decision**: Reject H‚ÇÄ if p-value < significance level (typically 0.05)\n",
    "\n",
    "### t-Test for Strategy Returns\n",
    "\n",
    "**Question**: Is the mean return significantly different from zero?\n",
    "\n",
    "$$t = \\frac{\\bar{r} - 0}{s / \\sqrt{n}}$$\n",
    "\n",
    "Where:\n",
    "- $\\bar{r}$ = sample mean return\n",
    "- $s$ = sample standard deviation\n",
    "- $n$ = number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac977349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing H‚ÇÄ: Mean return = 0 (no alpha)\n",
      "==================================================\n",
      "Sample mean return: -0.0054% daily\n",
      "Annualized return: -1.36%\n",
      "Sample std dev: 1.0018%\n",
      "\n",
      "t-statistic: -0.121\n",
      "p-value: 0.9039\n",
      "\n",
      "‚úó Result: Cannot reject H‚ÇÄ\n",
      "  Insufficient evidence that strategy has real alpha\n"
     ]
    }
   ],
   "source": [
    "# Example: Testing if a trading strategy has positive returns\n",
    "np.random.seed(123)\n",
    "\n",
    "# Simulate 2 years of daily strategy returns\n",
    "n_days = 504  # 2 years\n",
    "true_alpha = 0.0003  # Strategy actually has 0.03% daily alpha\n",
    "strategy_returns = np.random.normal(true_alpha, 0.01, n_days)\n",
    "\n",
    "# Calculate t-statistic manually\n",
    "mean_ret = np.mean(strategy_returns)\n",
    "std_ret = np.std(strategy_returns, ddof=1)\n",
    "n = len(strategy_returns)\n",
    "\n",
    "t_stat = mean_ret / (std_ret / np.sqrt(n))\n",
    "\n",
    "# Get p-value (two-tailed test)\n",
    "p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df=n-1))\n",
    "\n",
    "print(\"Testing H‚ÇÄ: Mean return = 0 (no alpha)\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Sample mean return: {mean_ret:.4%} daily\")\n",
    "print(f\"Annualized return: {mean_ret * 252:.2%}\")\n",
    "print(f\"Sample std dev: {std_ret:.4%}\")\n",
    "print(f\"\\nt-statistic: {t_stat:.3f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\n‚úì Result: REJECT H‚ÇÄ at 5% significance level\")\n",
    "    print(\"  The strategy return is statistically significant!\")\n",
    "else:\n",
    "    print(\"\\n‚úó Result: Cannot reject H‚ÇÄ\")\n",
    "    print(\"  Insufficient evidence that strategy has real alpha\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ac6a43",
   "metadata": {},
   "source": [
    "### Information Ratio and Significance\n",
    "\n",
    "The **Information Ratio (IR)** is related to the t-statistic:\n",
    "\n",
    "$$IR = \\frac{\\text{Excess Return}}{\\text{Tracking Error}} = \\frac{\\bar{r}}{\\sigma}$$\n",
    "\n",
    "$$t = IR \\times \\sqrt{n}$$\n",
    "\n",
    "This tells us: A small but consistent alpha can be significant with enough observations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1f0fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Ratio: 0.0200 daily = 0.32 annualized\n",
      "\n",
      "How many observations needed for significance?\n",
      "(Need t-stat > 1.96 for 5% significance)\n",
      "\n",
      "0.5 years (126 days): t = 0.22 ‚úó\n",
      "1 years (252 days): t = 0.32 ‚úó\n",
      "2 years (504 days): t = 0.45 ‚úó\n",
      "3 years (756 days): t = 0.55 ‚úó\n",
      "5 years (1260 days): t = 0.71 ‚úó\n"
     ]
    }
   ],
   "source": [
    "# How long to detect alpha?\n",
    "daily_alpha = 0.0002  # 0.02% daily (about 5% annual)\n",
    "daily_vol = 0.01      # 1% daily tracking error\n",
    "IR = daily_alpha / daily_vol\n",
    "\n",
    "print(f\"Information Ratio: {IR:.4f} daily = {IR * np.sqrt(252):.2f} annualized\")\n",
    "print(\"\\nHow many observations needed for significance?\")\n",
    "print(\"(Need t-stat > 1.96 for 5% significance)\\n\")\n",
    "\n",
    "for years in [0.5, 1, 2, 3, 5]:\n",
    "    n = int(years * 252)\n",
    "    t_stat = IR * np.sqrt(n)\n",
    "    significant = \"‚úì\" if t_stat > 1.96 else \"‚úó\"\n",
    "    print(f\"{years} years ({n} days): t = {t_stat:.2f} {significant}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d5a21b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Linear Regression\n",
    "\n",
    "### Ordinary Least Squares (OLS)\n",
    "\n",
    "Linear regression finds the best-fit line:\n",
    "\n",
    "$$Y = \\alpha + \\beta X + \\epsilon$$\n",
    "\n",
    "Where:\n",
    "- $Y$ = dependent variable (e.g., stock return)\n",
    "- $X$ = independent variable (e.g., market return)\n",
    "- $\\alpha$ = intercept (alpha in CAPM)\n",
    "- $\\beta$ = slope coefficient (beta in CAPM)\n",
    "- $\\epsilon$ = error term\n",
    "\n",
    "### OLS Formulas\n",
    "\n",
    "**Slope (Beta)**:\n",
    "$$\\beta = \\frac{Cov(X, Y)}{Var(X)} = \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum(X_i - \\bar{X})^2}$$\n",
    "\n",
    "**Intercept (Alpha)**:\n",
    "$$\\alpha = \\bar{Y} - \\beta \\bar{X}$$\n",
    "\n",
    "### R-squared\n",
    "\n",
    "Measures how much of Y's variance is explained by X:\n",
    "\n",
    "$$R^2 = 1 - \\frac{SS_{res}}{SS_{tot}} = 1 - \\frac{\\sum(Y_i - \\hat{Y}_i)^2}{\\sum(Y_i - \\bar{Y})^2}$$\n",
    "\n",
    "- $R^2 = 1$: Perfect fit\n",
    "- $R^2 = 0$: Model explains nothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3d86397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Regression: Stock Returns vs Market Returns\n",
      "==================================================\n",
      "True parameters: Œ± = 0.0200%, Œ≤ = 1.30\n",
      "Estimated:       Œ± = 0.0397%, Œ≤ = 1.32\n",
      "\n",
      "R-squared: 0.7838\n",
      "‚Üí 78.4% of stock's variance explained by market\n"
     ]
    }
   ],
   "source": [
    "# Example: Calculate stock's beta vs market\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate market returns\n",
    "n_days = 252\n",
    "market_returns = np.random.normal(0.0004, 0.012, n_days)\n",
    "\n",
    "# Stock with beta = 1.3 and alpha = 0.02% daily\n",
    "true_beta = 1.3\n",
    "true_alpha = 0.0002\n",
    "noise = np.random.normal(0, 0.008, n_days)\n",
    "stock_returns = true_alpha + true_beta * market_returns + noise\n",
    "\n",
    "# Calculate beta manually\n",
    "covariance = np.cov(market_returns, stock_returns)[0, 1]\n",
    "market_variance = np.var(market_returns, ddof=1)\n",
    "\n",
    "beta_calc = covariance / market_variance\n",
    "alpha_calc = np.mean(stock_returns) - beta_calc * np.mean(market_returns)\n",
    "\n",
    "# Calculate R-squared\n",
    "predicted = alpha_calc + beta_calc * market_returns\n",
    "ss_res = np.sum((stock_returns - predicted)**2)\n",
    "ss_tot = np.sum((stock_returns - np.mean(stock_returns))**2)\n",
    "r_squared = 1 - ss_res / ss_tot\n",
    "\n",
    "print(\"OLS Regression: Stock Returns vs Market Returns\")\n",
    "print(\"=\"*50)\n",
    "print(f\"True parameters: Œ± = {true_alpha:.4%}, Œ≤ = {true_beta:.2f}\")\n",
    "print(f\"Estimated:       Œ± = {alpha_calc:.4%}, Œ≤ = {beta_calc:.2f}\")\n",
    "print(f\"\\nR-squared: {r_squared:.4f}\")\n",
    "print(f\"‚Üí {r_squared*100:.1f}% of stock's variance explained by market\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab62d3b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Covariance and Correlation Matrices\n",
    "\n",
    "### Why Matrices?\n",
    "With multiple assets, we need to track all pairwise relationships. This is essential for:\n",
    "- Portfolio optimization\n",
    "- Risk management\n",
    "- Factor models\n",
    "\n",
    "### Covariance Matrix\n",
    "\n",
    "For assets A, B, C:\n",
    "\n",
    "$$\\Sigma = \\begin{bmatrix} \\sigma_A^2 & Cov(A,B) & Cov(A,C) \\\\ Cov(B,A) & \\sigma_B^2 & Cov(B,C) \\\\ Cov(C,A) & Cov(C,B) & \\sigma_C^2 \\end{bmatrix}$$\n",
    "\n",
    "**Properties**:\n",
    "- Symmetric: $Cov(A,B) = Cov(B,A)$\n",
    "- Diagonal = variances\n",
    "- Off-diagonal = covariances\n",
    "- Must be positive semi-definite\n",
    "\n",
    "### Correlation Matrix\n",
    "\n",
    "Normalized covariance:\n",
    "\n",
    "$$\\rho_{ij} = \\frac{Cov(i,j)}{\\sigma_i \\sigma_j}$$\n",
    "\n",
    "$$P = \\begin{bmatrix} 1 & \\rho_{AB} & \\rho_{AC} \\\\ \\rho_{BA} & 1 & \\rho_{BC} \\\\ \\rho_{CA} & \\rho_{CB} & 1 \\end{bmatrix}$$\n",
    "\n",
    "**Property**: Diagonal is always 1 (asset perfectly correlated with itself)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "343fc0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix (√ó10,000 for readability):\n",
      "           Tech  Utility    Gold\n",
      "Tech     3.7362   1.0619  0.0283\n",
      "Utility  1.0619   0.6393  0.0158\n",
      "Gold     0.0283   0.0158  0.8757\n",
      "\n",
      "Correlation Matrix:\n",
      "          Tech  Utility   Gold\n",
      "Tech     1.000    0.687  0.016\n",
      "Utility  0.687    1.000  0.021\n",
      "Gold     0.016    0.021  1.000\n",
      "\n",
      "Interpretation:\n",
      "‚Ä¢ Tech & Utility: œÅ = 0.69 (both exposed to market)\n",
      "‚Ä¢ Tech & Gold: œÅ = 0.02 (diversification benefit!)\n"
     ]
    }
   ],
   "source": [
    "# Create covariance and correlation matrices\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate 3 correlated assets\n",
    "n_days = 252\n",
    "market = np.random.normal(0, 0.012, n_days)\n",
    "\n",
    "# Different exposures to market\n",
    "tech_stock = 1.5 * market + np.random.normal(0, 0.008, n_days)  # High beta tech\n",
    "utility = 0.5 * market + np.random.normal(0, 0.005, n_days)     # Low beta utility\n",
    "gold = np.random.normal(0, 0.01, n_days)                        # Uncorrelated\n",
    "\n",
    "# Create DataFrame\n",
    "returns_df = pd.DataFrame({\n",
    "    'Tech': tech_stock,\n",
    "    'Utility': utility,\n",
    "    'Gold': gold\n",
    "})\n",
    "\n",
    "# Covariance matrix\n",
    "cov_matrix = returns_df.cov()\n",
    "print(\"Covariance Matrix (√ó10,000 for readability):\")\n",
    "print((cov_matrix * 10000).round(4))\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = returns_df.corr()\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(corr_matrix.round(3))\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(f\"‚Ä¢ Tech & Utility: œÅ = {corr_matrix.loc['Tech', 'Utility']:.2f} (both exposed to market)\")\n",
    "print(f\"‚Ä¢ Tech & Gold: œÅ = {corr_matrix.loc['Tech', 'Gold']:.2f} (diversification benefit!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6de35d5",
   "metadata": {},
   "source": [
    "### Portfolio Variance Using Covariance Matrix\n",
    "\n",
    "For a portfolio with weights $w = [w_1, w_2, ..., w_n]$:\n",
    "\n",
    "$$\\sigma_p^2 = w^T \\Sigma w = \\sum_{i}\\sum_{j} w_i w_j \\sigma_{ij}$$\n",
    "\n",
    "This is the fundamental formula for portfolio risk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c5f4df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio weights: Tech=50%, Utility=30%, Gold=20%\n",
      "\n",
      "Individual asset volatilities (daily):\n",
      "  Tech: 1.9329%\n",
      "  Utility: 0.7995%\n",
      "  Gold: 0.9358%\n",
      "\n",
      "Portfolio volatility: 1.1631%\n",
      "If perfectly correlated: 1.3935%\n",
      "\n",
      "Diversification benefit: 16.5% risk reduction!\n"
     ]
    }
   ],
   "source": [
    "# Calculate portfolio risk using covariance matrix\n",
    "weights = np.array([0.5, 0.3, 0.2])  # 50% Tech, 30% Utility, 20% Gold\n",
    "\n",
    "# Portfolio variance: w^T * Œ£ * w\n",
    "port_variance = weights @ cov_matrix.values @ weights\n",
    "port_std = np.sqrt(port_variance)\n",
    "\n",
    "# Compare to weighted average of individual volatilities (if perfectly correlated)\n",
    "individual_stds = np.sqrt(np.diag(cov_matrix.values))\n",
    "max_possible_std = weights @ individual_stds\n",
    "\n",
    "print(f\"Portfolio weights: Tech={weights[0]:.0%}, Utility={weights[1]:.0%}, Gold={weights[2]:.0%}\")\n",
    "print(f\"\\nIndividual asset volatilities (daily):\")\n",
    "for name, std in zip(returns_df.columns, individual_stds):\n",
    "    print(f\"  {name}: {std:.4%}\")\n",
    "\n",
    "print(f\"\\nPortfolio volatility: {port_std:.4%}\")\n",
    "print(f\"If perfectly correlated: {max_possible_std:.4%}\")\n",
    "print(f\"\\nDiversification benefit: {(max_possible_std - port_std)/max_possible_std:.1%} risk reduction!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a80afc3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Week 2 Key Formulas\n",
    "\n",
    "| Concept | Formula |\n",
    "|---------|--------|\n",
    "| Normal PDF | $f(x) = \\frac{1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$ |\n",
    "| Standardization | $Z = \\frac{X - \\mu}{\\sigma}$ |\n",
    "| t-statistic | $t = \\frac{\\bar{r}}{s / \\sqrt{n}}$ |\n",
    "| OLS Beta | $\\beta = \\frac{Cov(X,Y)}{Var(X)}$ |\n",
    "| R-squared | $R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}$ |\n",
    "| Portfolio Variance | $\\sigma_p^2 = w^T \\Sigma w$ |\n",
    "\n",
    "---\n",
    "\n",
    "*Next Week: Time Series Analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591aa1b1",
   "metadata": {},
   "source": [
    "## üî¥ PROS & CONS: THEORY\n",
    "\n",
    "### ‚úÖ PROS (Advantages)\n",
    "\n",
    "| Advantage | Description | Real-World Application |\n",
    "|-----------|-------------|----------------------|\n",
    "| **Industry Standard** | Widely adopted in quantitative finance | Used by major hedge funds and banks |\n",
    "| **Well-Documented** | Extensive research and documentation | Easy to find resources and support |\n",
    "| **Proven Track Record** | Years of practical application | Validated in real market conditions |\n",
    "| **Interpretable** | Results can be explained to stakeholders | Important for risk management and compliance |\n",
    "\n",
    "### ‚ùå CONS (Limitations)\n",
    "\n",
    "| Limitation | Description | How to Mitigate |\n",
    "|------------|-------------|-----------------|\n",
    "| **Assumptions** | May not hold in all market conditions | Validate assumptions with data |\n",
    "| **Historical Bias** | Based on past data patterns | Use rolling windows and regime detection |\n",
    "| **Overfitting Risk** | May fit noise rather than signal | Use proper cross-validation |\n",
    "| **Computational Cost** | Can be resource-intensive | Optimize code and use appropriate hardware |\n",
    "\n",
    "### üéØ Real-World Usage\n",
    "\n",
    "**WHERE THIS IS USED:**\n",
    "- ‚úÖ Quantitative hedge funds (Two Sigma, Renaissance, Citadel)\n",
    "- ‚úÖ Investment banks (Goldman Sachs, JP Morgan, Morgan Stanley)\n",
    "- ‚úÖ Asset management firms\n",
    "- ‚úÖ Risk management departments\n",
    "- ‚úÖ Algorithmic trading desks\n",
    "\n",
    "**NOT JUST THEORY - THIS IS PRODUCTION CODE:**\n",
    "The techniques in this notebook are used daily by professionals managing billions of dollars."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
