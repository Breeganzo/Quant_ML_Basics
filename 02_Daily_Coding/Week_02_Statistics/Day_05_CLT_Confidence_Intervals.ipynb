{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bed57a",
   "metadata": {},
   "source": [
    "# Day 5: Central Limit Theorem & Confidence Intervals\n",
    "## Week 2: Statistics & Probability for Finance\n",
    "\n",
    "---\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand CLT and why it matters for finance\n",
    "- Construct confidence intervals for returns and Sharpe ratios\n",
    "- Apply bootstrap methods for robust estimation\n",
    "- Quantify estimation uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9692fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 5 Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Load market data\n",
    "df = pd.read_csv('../datasets/raw_data/combined_adjusted_close.csv', \n",
    "                 index_col='Date', parse_dates=True)\n",
    "prices = df[['AAPL', 'MSFT', 'SPY', 'JPM']].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CLT & CONFIDENCE INTERVALS - DAY 5\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f461ec66",
   "metadata": {},
   "source": [
    "## 1. Central Limit Theorem Demonstration\n",
    "\n",
    "**CLT States:** The distribution of sample means approaches Normal as n â†’ âˆž, regardless of the underlying distribution.\n",
    "\n",
    "$$\\bar{X} \\xrightarrow{d} N\\left(\\mu, \\frac{\\sigma^2}{n}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93e91ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLT Demonstration with SPY returns\n",
    "print(\"=\" * 60)\n",
    "print(\"CENTRAL LIMIT THEOREM DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "spy_returns = returns['SPY'].values\n",
    "true_mean = np.mean(spy_returns)\n",
    "true_std = np.std(spy_returns, ddof=1)\n",
    "\n",
    "print(f\"\\nPopulation: SPY Daily Returns (n={len(spy_returns)})\")\n",
    "print(f\"True mean: {true_mean:.6f}\")\n",
    "print(f\"True std:  {true_std:.6f}\")\n",
    "\n",
    "# Simulate sampling distributions\n",
    "np.random.seed(42)\n",
    "sample_sizes = [5, 20, 50, 250]\n",
    "n_simulations = 10000\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, n in enumerate(sample_sizes):\n",
    "    # Generate sample means\n",
    "    sample_means = [np.mean(np.random.choice(spy_returns, n, replace=True)) \n",
    "                    for _ in range(n_simulations)]\n",
    "    \n",
    "    # Expected std error\n",
    "    expected_se = true_std / np.sqrt(n)\n",
    "    \n",
    "    # Plot\n",
    "    axes[i].hist(sample_means, bins=50, density=True, alpha=0.7, \n",
    "                 color='steelblue', edgecolor='white')\n",
    "    \n",
    "    # Normal fit\n",
    "    x = np.linspace(min(sample_means), max(sample_means), 200)\n",
    "    axes[i].plot(x, stats.norm.pdf(x, true_mean, expected_se), 'r-', lw=2, \n",
    "                 label=f'N(Î¼, Ïƒ/âˆšn)')\n",
    "    axes[i].axvline(true_mean, color='green', lw=2, linestyle='--', label='True Î¼')\n",
    "    \n",
    "    axes[i].set_xlabel('Sample Mean', fontsize=10)\n",
    "    axes[i].set_ylabel('Density', fontsize=10)\n",
    "    axes[i].set_title(f'n = {n}, SE = {expected_se:.6f}', fontsize=11, fontweight='bold')\n",
    "    axes[i].legend(fontsize=8)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Central Limit Theorem: Distribution of Sample Means', fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š CLT Implications:\")\n",
    "print(\"   - Larger samples â†’ narrower distribution â†’ more precise estimates\")\n",
    "print(\"   - Standard Error = Ïƒ/âˆšn\")\n",
    "print(\"   - Works even though returns have fat tails!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cfbd4f",
   "metadata": {},
   "source": [
    "## 2. Confidence Intervals for Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea52d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confidence Intervals\n",
    "print(\"=\" * 60)\n",
    "print(\"CONFIDENCE INTERVALS FOR RETURNS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "spy_returns = returns['SPY'].values\n",
    "n = len(spy_returns)\n",
    "\n",
    "# Point estimates\n",
    "mean_daily = np.mean(spy_returns)\n",
    "std_daily = np.std(spy_returns, ddof=1)\n",
    "se_mean = std_daily / np.sqrt(n)\n",
    "\n",
    "# Confidence levels\n",
    "confidence_levels = [0.90, 0.95, 0.99]\n",
    "\n",
    "print(f\"\\nSample: n = {n}\")\n",
    "print(f\"Daily mean: {mean_daily:.6f}\")\n",
    "print(f\"Standard error: {se_mean:.6f}\")\n",
    "print(\"\\n\" + \"-\" * 60)\n",
    "\n",
    "for conf in confidence_levels:\n",
    "    alpha = 1 - conf\n",
    "    t_critical = stats.t.ppf(1 - alpha/2, df=n-1)\n",
    "    margin = t_critical * se_mean\n",
    "    ci_lower = mean_daily - margin\n",
    "    ci_upper = mean_daily + margin\n",
    "    \n",
    "    # Annualize\n",
    "    ci_lower_ann = ci_lower * 252\n",
    "    ci_upper_ann = ci_upper * 252\n",
    "    \n",
    "    print(f\"\\n{conf:.0%} Confidence Interval:\")\n",
    "    print(f\"  Daily:    [{ci_lower:.6f}, {ci_upper:.6f}]\")\n",
    "    print(f\"  Annual:   [{ci_lower_ann:.2%}, {ci_upper_ann:.2%}]\")\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Rolling mean with confidence bands\n",
    "window = 252\n",
    "rolling_mean = returns['SPY'].rolling(window).mean() * 252\n",
    "rolling_std = returns['SPY'].rolling(window).std() * np.sqrt(252)\n",
    "rolling_se = rolling_std / np.sqrt(window)\n",
    "\n",
    "rolling_mean.plot(ax=ax, color='blue', lw=1.5, label='Rolling Mean (Annualized)')\n",
    "ax.fill_between(rolling_mean.index, \n",
    "                rolling_mean - 1.96 * rolling_se, \n",
    "                rolling_mean + 1.96 * rolling_se, \n",
    "                alpha=0.3, color='blue', label='95% CI')\n",
    "ax.axhline(0, color='black', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Date', fontsize=11)\n",
    "ax.set_ylabel('Annualized Return', fontsize=11)\n",
    "ax.set_title('SPY Rolling Mean Return with 95% Confidence Interval', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574600e0",
   "metadata": {},
   "source": [
    "## 3. Bootstrap Methods - Robust Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ffa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap Confidence Intervals\n",
    "print(\"=\" * 60)\n",
    "print(\"BOOTSTRAP CONFIDENCE INTERVALS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "np.random.seed(42)\n",
    "spy_returns = returns['SPY'].values\n",
    "n_bootstrap = 10000\n",
    "\n",
    "def bootstrap_ci(data, statistic_func, n_bootstrap=10000, confidence=0.95):\n",
    "    \"\"\"Calculate bootstrap confidence interval for any statistic.\"\"\"\n",
    "    n = len(data)\n",
    "    bootstrap_stats = []\n",
    "    \n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, n, replace=True)\n",
    "        bootstrap_stats.append(statistic_func(sample))\n",
    "    \n",
    "    alpha = 1 - confidence\n",
    "    lower = np.percentile(bootstrap_stats, alpha/2 * 100)\n",
    "    upper = np.percentile(bootstrap_stats, (1 - alpha/2) * 100)\n",
    "    \n",
    "    return np.array(bootstrap_stats), lower, upper\n",
    "\n",
    "# Bootstrap for various statistics\n",
    "print(f\"\\nBootstrap Simulation: {n_bootstrap:,} iterations\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Mean\n",
    "boot_means, mean_lower, mean_upper = bootstrap_ci(spy_returns, np.mean)\n",
    "print(f\"\\nMean Return (daily):\")\n",
    "print(f\"  Point estimate: {np.mean(spy_returns):.6f}\")\n",
    "print(f\"  95% Bootstrap CI: [{mean_lower:.6f}, {mean_upper:.6f}]\")\n",
    "\n",
    "# Sharpe Ratio\n",
    "def sharpe_ratio(r, rf=0.05/252):\n",
    "    return (np.mean(r) - rf) / np.std(r, ddof=1) * np.sqrt(252)\n",
    "\n",
    "boot_sharpes, sharpe_lower, sharpe_upper = bootstrap_ci(spy_returns, sharpe_ratio)\n",
    "print(f\"\\nSharpe Ratio:\")\n",
    "print(f\"  Point estimate: {sharpe_ratio(spy_returns):.3f}\")\n",
    "print(f\"  95% Bootstrap CI: [{sharpe_lower:.3f}, {sharpe_upper:.3f}]\")\n",
    "\n",
    "# Visualize bootstrap distributions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Mean bootstrap\n",
    "axes[0].hist(boot_means * 252 * 100, bins=50, density=True, alpha=0.7, \n",
    "             color='steelblue', edgecolor='white')\n",
    "axes[0].axvline(np.mean(spy_returns) * 252 * 100, color='red', lw=2, label='Point Estimate')\n",
    "axes[0].axvline(mean_lower * 252 * 100, color='orange', lw=2, linestyle='--', label='95% CI')\n",
    "axes[0].axvline(mean_upper * 252 * 100, color='orange', lw=2, linestyle='--')\n",
    "axes[0].set_xlabel('Annualized Return (%)', fontsize=11)\n",
    "axes[0].set_ylabel('Density', fontsize=11)\n",
    "axes[0].set_title('Bootstrap Distribution: Mean Return', fontsize=12, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sharpe bootstrap\n",
    "axes[1].hist(boot_sharpes, bins=50, density=True, alpha=0.7, \n",
    "             color='steelblue', edgecolor='white')\n",
    "axes[1].axvline(sharpe_ratio(spy_returns), color='red', lw=2, label='Point Estimate')\n",
    "axes[1].axvline(sharpe_lower, color='orange', lw=2, linestyle='--', label='95% CI')\n",
    "axes[1].axvline(sharpe_upper, color='orange', lw=2, linestyle='--')\n",
    "axes[1].axvline(0, color='black', lw=1.5, linestyle=':', label='Sharpe = 0')\n",
    "axes[1].set_xlabel('Sharpe Ratio', fontsize=11)\n",
    "axes[1].set_ylabel('Density', fontsize=11)\n",
    "axes[1].set_title('Bootstrap Distribution: Sharpe Ratio', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Bootstrap Advantage: No distributional assumptions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2d84c",
   "metadata": {},
   "source": [
    "## 4. How Many Observations Do We Need?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073913c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Size Analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"SAMPLE SIZE ANALYSIS: How Long to Detect Signal?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Given a true Sharpe ratio, how many years to detect it?\n",
    "def years_to_detect(true_sharpe, confidence=0.95, power=0.80):\n",
    "    \"\"\"Calculate years needed to detect a given Sharpe ratio.\"\"\"\n",
    "    z_alpha = stats.norm.ppf(1 - (1 - confidence)/2)\n",
    "    z_beta = stats.norm.ppf(power)\n",
    "    \n",
    "    # Standard error of Sharpe â‰ˆ sqrt((1 + 0.5*SR^2) / n)\n",
    "    # Solve for n: n = (z_alpha + z_beta)^2 * (1 + 0.5*SR^2) / SR^2\n",
    "    n_days = ((z_alpha + z_beta)**2 * (1 + 0.5 * true_sharpe**2)) / true_sharpe**2\n",
    "    n_years = n_days / 252\n",
    "    \n",
    "    return n_years\n",
    "\n",
    "sharpe_values = [0.5, 1.0, 1.5, 2.0, 3.0]\n",
    "print(f\"\\nYears needed to detect Sharpe ratio (95% CI, 80% power):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'True Sharpe':<15} {'Years Needed':<15}\")\n",
    "print(\"-\" * 40)\n",
    "for sr in sharpe_values:\n",
    "    years = years_to_detect(sr)\n",
    "    print(f\"{sr:<15.1f} {years:<15.1f}\")\n",
    "\n",
    "# Visualize CI width vs sample size\n",
    "sample_sizes = np.arange(21, 2520, 21)  # 1 month to 10 years\n",
    "ci_widths = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    se = np.std(spy_returns) / np.sqrt(n)\n",
    "    width = 2 * 1.96 * se * 252 * 100  # Annualized percentage\n",
    "    ci_widths.append(width)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(sample_sizes / 252, ci_widths, 'b-', lw=2)\n",
    "ax.axhline(10, color='red', linestyle='--', label='Â±10% target')\n",
    "ax.axhline(5, color='green', linestyle='--', label='Â±5% target')\n",
    "ax.set_xlabel('Years of Data', fontsize=11)\n",
    "ax.set_ylabel('95% CI Width (%)', fontsize=11)\n",
    "ax.set_title('Confidence Interval Width vs Sample Size', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(0, 10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâš ï¸ Key Insight: Need ~4 years of daily data for reasonably precise estimates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ecb3e",
   "metadata": {},
   "source": [
    "## ðŸ“ Key Takeaways - Day 5\n",
    "\n",
    "### Central Limit Theorem:\n",
    "- Sample means â†’ Normal as n increases\n",
    "- Standard Error = Ïƒ / âˆšn\n",
    "- Works even for non-Normal returns\n",
    "\n",
    "### Confidence Intervals:\n",
    "- Parametric: Assume underlying distribution\n",
    "- Bootstrap: No distributional assumptions\n",
    "- Wider CI = more uncertainty\n",
    "\n",
    "### Sample Size Rules of Thumb:\n",
    "- Sharpe 0.5 â†’ ~16 years to detect\n",
    "- Sharpe 1.0 â†’ ~4 years to detect\n",
    "- Sharpe 2.0 â†’ ~1 year to detect\n",
    "\n",
    "### Interview Questions:\n",
    "- \"How long would you backtest a strategy?\"\n",
    "- \"What's the standard error of the Sharpe ratio?\"\n",
    "- \"When would you use bootstrap vs parametric CI?\"\n",
    "- \"How does sample size affect estimation precision?\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
