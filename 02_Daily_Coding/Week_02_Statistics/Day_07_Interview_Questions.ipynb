{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f79db7a",
   "metadata": {},
   "source": [
    "# Day 7: Statistics Interview Questions & Practice\n",
    "## Week 2: Statistics & Probability for Finance\n",
    "\n",
    "---\n",
    "\n",
    "**This Day Covers:**\n",
    "- Common interview questions on statistics\n",
    "- Brain teasers and probability puzzles\n",
    "- Practical coding challenges\n",
    "- Review of Week 2 concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f335a0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 7 Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Load market data\n",
    "df = pd.read_csv('../datasets/raw_data/combined_adjusted_close.csv', \n",
    "                 index_col='Date', parse_dates=True)\n",
    "prices = df[['AAPL', 'MSFT', 'SPY', 'JPM', 'GLD', 'TLT']].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WEEK 2 REVIEW: INTERVIEW QUESTIONS - DAY 7\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93758acd",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 1: Distribution Analysis\n",
    "\n",
    "**\"You have daily returns for a stock. How would you determine if they follow a Normal distribution? What are the implications if they don't?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02be07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: Testing Normality\n",
    "print(\"=\" * 60)\n",
    "print(\"QUESTION 1: Testing Normality of Returns\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "spy_ret = returns['SPY'].values\n",
    "\n",
    "# Multiple tests for normality\n",
    "# 1. Shapiro-Wilk test\n",
    "shapiro_stat, shapiro_p = stats.shapiro(spy_ret[:5000])  # Limited sample\n",
    "\n",
    "# 2. D'Agostino-Pearson test\n",
    "dagostino_stat, dagostino_p = stats.normaltest(spy_ret)\n",
    "\n",
    "# 3. Jarque-Bera test\n",
    "jb_stat, jb_p = stats.jarque_bera(spy_ret)\n",
    "\n",
    "# 4. Visual: Skewness and Kurtosis\n",
    "skewness = stats.skew(spy_ret)\n",
    "kurtosis = stats.kurtosis(spy_ret)\n",
    "\n",
    "print(f\"\\n1. FORMAL TESTS:\")\n",
    "print(f\"   Shapiro-Wilk:      p = {shapiro_p:.2e} {'‚úó Not Normal' if shapiro_p < 0.05 else '‚úì'}\")\n",
    "print(f\"   D'Agostino-Pearson: p = {dagostino_p:.2e} {'‚úó Not Normal' if dagostino_p < 0.05 else '‚úì'}\")\n",
    "print(f\"   Jarque-Bera:       p = {jb_p:.2e} {'‚úó Not Normal' if jb_p < 0.05 else '‚úì'}\")\n",
    "\n",
    "print(f\"\\n2. DESCRIPTIVE STATISTICS:\")\n",
    "print(f\"   Skewness:  {skewness:.3f} (Normal = 0)\")\n",
    "print(f\"   Kurtosis:  {kurtosis:.3f} (Normal = 0, excess)\")\n",
    "\n",
    "print(f\"\\n3. IMPLICATIONS IF NOT NORMAL:\")\n",
    "print(\"   - VaR calculations using Normal assumption will underestimate risk\")\n",
    "print(\"   - Option pricing models (Black-Scholes) may be inaccurate\")\n",
    "print(\"   - Mean-variance optimization may be suboptimal\")\n",
    "print(\"   - Use Student-t, Historical simulation, or EVT instead\")\n",
    "\n",
    "# Visual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Histogram with Normal fit\n",
    "axes[0].hist(spy_ret, bins=60, density=True, alpha=0.7, color='steelblue', edgecolor='white')\n",
    "x = np.linspace(spy_ret.min(), spy_ret.max(), 200)\n",
    "axes[0].plot(x, stats.norm.pdf(x, np.mean(spy_ret), np.std(spy_ret)), 'r-', lw=2, label='Normal fit')\n",
    "axes[0].set_title(f'SPY Returns\\nSkew={skewness:.2f}, Kurt={kurtosis:.1f}', fontsize=11, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q Plot\n",
    "stats.probplot(spy_ret, dist=\"norm\", plot=axes[1])\n",
    "axes[1].set_title('Q-Q Plot vs Normal', fontsize=11, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d15cc4",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2: Sharpe Ratio Inference\n",
    "\n",
    "**\"A backtest shows a Sharpe ratio of 1.5 over 2 years. How confident are you that the true Sharpe is above 1.0?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d90eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: Sharpe Ratio Inference\n",
    "print(\"=\" * 60)\n",
    "print(\"QUESTION 2: Sharpe Ratio Confidence\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Given parameters\n",
    "observed_sharpe = 1.5\n",
    "n_years = 2\n",
    "n_days = int(n_years * 252)\n",
    "\n",
    "# Standard error of Sharpe ratio (approximation)\n",
    "# SE(SR) ‚âà sqrt((1 + 0.5*SR^2) / n)\n",
    "se_sharpe = np.sqrt((1 + 0.5 * observed_sharpe**2) / n_days) * np.sqrt(252)\n",
    "\n",
    "# Test H0: SR <= 1.0\n",
    "target_sharpe = 1.0\n",
    "z_stat = (observed_sharpe - target_sharpe) / se_sharpe\n",
    "p_value = 1 - stats.norm.cdf(z_stat)\n",
    "\n",
    "# Confidence interval\n",
    "ci_lower = observed_sharpe - 1.96 * se_sharpe\n",
    "ci_upper = observed_sharpe + 1.96 * se_sharpe\n",
    "\n",
    "print(f\"\\nObserved Sharpe: {observed_sharpe}\")\n",
    "print(f\"Sample size: {n_days} days ({n_years} years)\")\n",
    "print(f\"\\nStandard Error of Sharpe: {se_sharpe:.3f}\")\n",
    "print(f\"95% Confidence Interval: [{ci_lower:.2f}, {ci_upper:.2f}]\")\n",
    "print(f\"\\nTest: H0: True SR ‚â§ 1.0\")\n",
    "print(f\"z-statistic: {z_stat:.2f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"\\nConclusion: {'Can reject H0 - likely SR > 1' if p_value < 0.05 else 'Cannot reject H0'}\")\n",
    "print(f\"Confidence that true SR > 1.0: {(1-p_value)*100:.1f}%\")\n",
    "\n",
    "# Visual\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.linspace(observed_sharpe - 4*se_sharpe, observed_sharpe + 4*se_sharpe, 200)\n",
    "ax.plot(x, stats.norm.pdf(x, observed_sharpe, se_sharpe), 'b-', lw=2)\n",
    "ax.fill_between(x, stats.norm.pdf(x, observed_sharpe, se_sharpe), \n",
    "                where=x >= target_sharpe, alpha=0.3, color='green', label=f'P(SR>1.0)={1-p_value:.1%}')\n",
    "ax.axvline(observed_sharpe, color='blue', lw=2, linestyle='--', label=f'Observed: {observed_sharpe}')\n",
    "ax.axvline(target_sharpe, color='red', lw=2, linestyle='--', label=f'Target: {target_sharpe}')\n",
    "ax.axvline(ci_lower, color='gray', lw=1.5, linestyle=':')\n",
    "ax.axvline(ci_upper, color='gray', lw=1.5, linestyle=':', label='95% CI')\n",
    "ax.set_xlabel('Sharpe Ratio', fontsize=11)\n",
    "ax.set_ylabel('Density', fontsize=11)\n",
    "ax.set_title('Sharpe Ratio Distribution\\n(Given 2 Years of Data)', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9b0f39",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 3: Correlation Problem\n",
    "\n",
    "**\"Two stocks have a correlation of 0.8 during normal markets. What would you expect during a crash?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03342076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: Conditional Correlation\n",
    "print(\"=\" * 60)\n",
    "print(\"QUESTION 3: Correlation During Crashes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Demonstrate with AAPL and MSFT\n",
    "aapl = returns['AAPL']\n",
    "msft = returns['MSFT']\n",
    "\n",
    "# Overall correlation\n",
    "overall_corr = aapl.corr(msft)\n",
    "\n",
    "# Define market regimes\n",
    "spy_ret = returns['SPY']\n",
    "threshold = spy_ret.quantile(0.10)  # Bottom 10%\n",
    "\n",
    "crash_days = spy_ret <= threshold\n",
    "normal_days = spy_ret > threshold\n",
    "\n",
    "crash_corr = aapl[crash_days].corr(msft[crash_days])\n",
    "normal_corr = aapl[normal_days].corr(msft[normal_days])\n",
    "\n",
    "print(f\"\\nAAPL-MSFT Correlation:\")\n",
    "print(f\"  Overall:      {overall_corr:.3f}\")\n",
    "print(f\"  Normal days:  {normal_corr:.3f} (SPY > 10th percentile)\")\n",
    "print(f\"  Crash days:   {crash_corr:.3f} (SPY ‚â§ 10th percentile)\")\n",
    "\n",
    "print(f\"\\nKEY INSIGHT:\")\n",
    "print(\"  Correlations tend to INCREASE during market stress!\")\n",
    "print(\"  This is known as 'correlation breakdown' or 'contagion'\")\n",
    "print(\"  Diversification fails when you need it most.\")\n",
    "\n",
    "print(f\"\\nIMPLICATIONS:\")\n",
    "print(\"  1. Portfolio VaR should account for stress correlations\")\n",
    "print(\"  2. Tail-risk hedging is more important than diversification\")\n",
    "print(\"  3. Consider copula models for tail dependence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad03d721",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 4: Multiple Testing\n",
    "\n",
    "**\"You test 100 trading strategies and find 7 with p-values < 0.05. How many are likely false positives?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2b13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: Multiple Testing Problem\n",
    "print(\"=\" * 60)\n",
    "print(\"QUESTION 4: Multiple Testing Problem\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_tests = 100\n",
    "n_significant = 7\n",
    "alpha = 0.05\n",
    "\n",
    "# Expected false positives under null\n",
    "expected_fp = n_tests * alpha\n",
    "\n",
    "print(f\"\\nScenario:\")\n",
    "print(f\"  Tests run: {n_tests}\")\n",
    "print(f\"  Significant (p < {alpha}): {n_significant}\")\n",
    "\n",
    "print(f\"\\nANALYSIS:\")\n",
    "print(f\"  If ALL strategies have no edge (H0 true for all):\")\n",
    "print(f\"    Expected false positives: {n_tests} √ó {alpha} = {expected_fp}\")\n",
    "print(f\"    You found: {n_significant}\")\n",
    "print(f\"    Ratio: {n_significant}/{expected_fp:.0f} = {n_significant/expected_fp:.1f}x expected\")\n",
    "\n",
    "# Bonferroni correction\n",
    "alpha_bonf = alpha / n_tests\n",
    "print(f\"\\nCORRECTIONS:\")\n",
    "print(f\"  Bonferroni Œ±: {alpha_bonf:.4f} (very conservative)\")\n",
    "print(f\"  Only strategies with p < {alpha_bonf:.4f} should be trusted\")\n",
    "\n",
    "# FDR (Benjamini-Hochberg)\n",
    "print(f\"\\n  Benjamini-Hochberg (FDR control):\")\n",
    "print(f\"    If you accept 7 strategies at FDR = 5%\")\n",
    "print(f\"    Expected false discoveries ‚âà 7 √ó 0.05 = 0.35\")\n",
    "print(f\"    So ~6-7 might be real (if FDR procedure was used)\")\n",
    "\n",
    "print(f\"\\nBOTTOM LINE:\")\n",
    "print(f\"  Without any correction: Likely 5 of 7 are false positives\")\n",
    "print(f\"  Use out-of-sample validation to verify!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534f4c1",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 5: Brain Teaser - Birthday Problem Variant\n",
    "\n",
    "**\"In a portfolio of 23 stocks, what's the probability that at least two have their highest return on the same day of the year?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: Birthday Problem\n",
    "print(\"=\" * 60)\n",
    "print(\"QUESTION 5: Birthday Problem Variant\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_stocks = 23\n",
    "n_days = 252  # Trading days\n",
    "\n",
    "# Probability that ALL have different peak days\n",
    "p_all_different = 1.0\n",
    "for i in range(n_stocks):\n",
    "    p_all_different *= (n_days - i) / n_days\n",
    "\n",
    "p_at_least_two = 1 - p_all_different\n",
    "\n",
    "print(f\"\\nPortfolio: {n_stocks} stocks\")\n",
    "print(f\"Days per year: {n_days}\")\n",
    "print(f\"\\nP(all have different peak days): {p_all_different:.4f}\")\n",
    "print(f\"P(at least two share peak day):  {p_at_least_two:.4f}\")\n",
    "print(f\"\\nAnswer: {p_at_least_two:.1%} probability!\")\n",
    "\n",
    "# Find threshold\n",
    "for n in range(1, 100):\n",
    "    p = 1.0\n",
    "    for i in range(n):\n",
    "        p *= (n_days - i) / n_days\n",
    "    if 1 - p > 0.5:\n",
    "        print(f\"\\nWith {n} stocks, probability exceeds 50%!\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ae9694",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 6: VaR Backtest\n",
    "\n",
    "**\"Your 99% VaR was breached 15 times in 1000 trading days. Is your model broken?\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1c7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER: VaR Backtest\n",
    "print(\"=\" * 60)\n",
    "print(\"QUESTION 6: VaR Model Validation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "n_days = 1000\n",
    "n_breaches = 15\n",
    "var_level = 0.99\n",
    "expected_breaches = n_days * (1 - var_level)  # 10 expected\n",
    "\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Trading days: {n_days}\")\n",
    "print(f\"  VaR breaches: {n_breaches}\")\n",
    "print(f\"  Expected (99% VaR): {expected_breaches}\")\n",
    "\n",
    "# Kupiec POF Test (Proportion of Failures)\n",
    "# Under H0: breaches ~ Binomial(n, 1-VaR_level)\n",
    "p_value = 1 - stats.binom.cdf(n_breaches - 1, n_days, 1 - var_level)\n",
    "\n",
    "print(f\"\\nKupiec POF Test:\")\n",
    "print(f\"  H0: Model is correctly specified\")\n",
    "print(f\"  P(‚â•{n_breaches} breaches | correct model): {p_value:.4f}\")\n",
    "print(f\"  Conclusion: {'Reject H0 - Model underestimates risk' if p_value < 0.05 else 'Cannot reject H0'}\")\n",
    "\n",
    "# Visual\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "x = np.arange(0, 30)\n",
    "pmf = stats.binom.pmf(x, n_days, 1 - var_level)\n",
    "colors = ['green' if xi <= expected_breaches + 2*np.sqrt(n_days*0.01*0.99) else 'red' for xi in x]\n",
    "ax.bar(x, pmf, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax.axvline(n_breaches, color='red', lw=3, label=f'Observed: {n_breaches}')\n",
    "ax.axvline(expected_breaches, color='blue', lw=2, linestyle='--', label=f'Expected: {expected_breaches}')\n",
    "ax.set_xlabel('Number of VaR Breaches', fontsize=11)\n",
    "ax.set_ylabel('Probability', fontsize=11)\n",
    "ax.set_title('VaR Breach Distribution Under Correct Model', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nINTERPRETATION:\")\n",
    "print(f\"  15 breaches is {(n_breaches - expected_breaches) / np.sqrt(n_days * 0.01 * 0.99):.1f} std above expected\")\n",
    "print(f\"  Model likely underestimates tail risk (fat tails not captured)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a364982d",
   "metadata": {},
   "source": [
    "---\n",
    "## Quick-Fire Review Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff088b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"QUICK-FIRE REVIEW\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "qa_pairs = [\n",
    "    (\"Q: What does excess kurtosis measure?\",\n",
    "     \"A: Tail thickness relative to Normal. >0 = fat tails.\"),\n",
    "    \n",
    "    (\"Q: Why use ddof=1 for sample variance?\",\n",
    "     \"A: Bessel's correction - makes estimator unbiased.\"),\n",
    "    \n",
    "    (\"Q: What's the Sharpe ratio formula?\",\n",
    "     \"A: (Return - Risk-free) / Volatility\"),\n",
    "    \n",
    "    (\"Q: Why correlate returns, not prices?\",\n",
    "     \"A: Prices are non-stationary ‚Üí spurious correlations.\"),\n",
    "    \n",
    "    (\"Q: What does p-value = 0.03 mean?\",\n",
    "     \"A: 3% chance of seeing data this extreme if H0 is true.\"),\n",
    "    \n",
    "    (\"Q: Difference between Type I and Type II error?\",\n",
    "     \"A: Type I = False positive (reject true H0)\\n   Type II = False negative (fail to reject false H0)\"),\n",
    "    \n",
    "    (\"Q: What's the CLT and why does it matter?\",\n",
    "     \"A: Sample means ‚Üí Normal as n‚Üí‚àû. Enables hypothesis testing.\"),\n",
    "    \n",
    "    (\"Q: Confidence vs Credible interval?\",\n",
    "     \"A: Confidence = 95% of intervals contain true value\\n   Credible = 95% probability true value is in interval\"),\n",
    "    \n",
    "    (\"Q: What is tail dependence?\",\n",
    "     \"A: Tendency for extreme events to occur together (correlations increase in crashes).\"),\n",
    "    \n",
    "    (\"Q: Annualize daily volatility?\",\n",
    "     \"A: Multiply by ‚àö252\")\n",
    "]\n",
    "\n",
    "for q, a in qa_pairs:\n",
    "    print(f\"\\n{q}\")\n",
    "    print(f\"{a}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b1f897",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Week 2 Summary\n",
    "\n",
    "### Day 1: Probability Distributions\n",
    "- Normal, Student-t, Log-Normal\n",
    "- Fat tails in finance\n",
    "- VaR under different assumptions\n",
    "\n",
    "### Day 2: Moments & Descriptive Statistics\n",
    "- Mean, Variance, Skewness, Kurtosis\n",
    "- Rolling statistics for regime detection\n",
    "- Risk-adjusted metrics (Sharpe, Sortino)\n",
    "\n",
    "### Day 3: Hypothesis Testing\n",
    "- t-tests, chi-square tests\n",
    "- Testing strategy significance\n",
    "- Multiple testing problem\n",
    "\n",
    "### Day 4: Correlation & Dependence\n",
    "- Pearson, Spearman, Kendall\n",
    "- Rolling correlation\n",
    "- Tail dependence\n",
    "\n",
    "### Day 5: CLT & Confidence Intervals\n",
    "- Central Limit Theorem\n",
    "- Bootstrap methods\n",
    "- Sample size requirements\n",
    "\n",
    "### Day 6: Bayesian Thinking\n",
    "- Bayes' theorem\n",
    "- Prior, Likelihood, Posterior\n",
    "- Bayesian vs Frequentist\n",
    "\n",
    "### Day 7: Interview Prep\n",
    "- Common questions\n",
    "- Problem-solving approaches\n",
    "- Quick-fire review"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
