{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42d55c37",
   "metadata": {},
   "source": [
    "# Day 04: A/B Testing for Trading Strategies\n",
    "\n",
    "## Production ML - Week 23\n",
    "\n",
    "**Objective:** Learn how to rigorously compare trading strategies using statistical A/B testing frameworks, enabling data-driven decisions about strategy deployment.\n",
    "\n",
    "### Why A/B Testing for Trading?\n",
    "\n",
    "In production trading systems, we need to answer critical questions:\n",
    "- Is the new strategy variant actually better than the existing one?\n",
    "- How confident are we in the observed performance difference?\n",
    "- When can we stop testing and make a deployment decision?\n",
    "\n",
    "### Key Differences from Web A/B Testing\n",
    "\n",
    "| Aspect | Web A/B Testing | Trading A/B Testing |\n",
    "|--------|-----------------|---------------------|\n",
    "| Samples | Independent users | Correlated time-series |\n",
    "| Metrics | Conversion rate | Sharpe, returns, drawdown |\n",
    "| Environment | Relatively stable | Non-stationary markets |\n",
    "| Cost of error | Lost revenue | Capital loss |\n",
    "| Time horizon | Days to weeks | Weeks to months |\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "1. Statistical foundations for strategy comparison\n",
    "2. Frequentist hypothesis testing (t-test, Mann-Whitney U)\n",
    "3. Effect size and power analysis\n",
    "4. Bootstrap confidence intervals\n",
    "5. Sharpe ratio comparison methods\n",
    "6. Sequential testing for early stopping\n",
    "7. Bayesian A/B testing approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf4e316",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import numpy, pandas, scipy.stats, matplotlib, and other necessary libraries for statistical analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335955d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, norm, t as t_dist\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Plotting configuration\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5913b8e1",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Trading Data\n",
    "\n",
    "Create synthetic price data and trading signals to simulate two different trading strategies for comparison. We'll generate realistic market data with trends, volatility clustering, and regime changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb3eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_price_data(\n",
    "    n_days: int = 504,  # ~2 years of trading days\n",
    "    initial_price: float = 100.0,\n",
    "    annual_return: float = 0.08,\n",
    "    annual_volatility: float = 0.20,\n",
    "    seed: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generate synthetic price data using Geometric Brownian Motion\n",
    "    with volatility clustering (GARCH-like behavior).\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Daily parameters\n",
    "    daily_return = annual_return / 252\n",
    "    daily_vol = annual_volatility / np.sqrt(252)\n",
    "    \n",
    "    # Generate returns with volatility clustering\n",
    "    returns = np.zeros(n_days)\n",
    "    vol = daily_vol\n",
    "    \n",
    "    for i in range(n_days):\n",
    "        # GARCH(1,1)-like volatility update\n",
    "        vol = 0.9 * vol + 0.1 * daily_vol * (1 + 0.5 * np.abs(returns[i-1] if i > 0 else 0) / daily_vol)\n",
    "        returns[i] = daily_return + vol * np.random.randn()\n",
    "    \n",
    "    # Generate prices\n",
    "    prices = initial_price * np.exp(np.cumsum(returns))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    dates = pd.date_range(start='2024-01-01', periods=n_days, freq='B')\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'price': prices,\n",
    "        'returns': returns\n",
    "    })\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Add technical indicators\n",
    "    df['sma_20'] = df['price'].rolling(20).mean()\n",
    "    df['sma_50'] = df['price'].rolling(50).mean()\n",
    "    df['volatility_20'] = df['returns'].rolling(20).std() * np.sqrt(252)\n",
    "    df['momentum_10'] = df['price'].pct_change(10)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate price data\n",
    "price_data = generate_price_data(n_days=504, seed=42)\n",
    "\n",
    "print(f\"Generated {len(price_data)} days of price data\")\n",
    "print(f\"\\nPrice Data Summary:\")\n",
    "print(price_data.describe())\n",
    "\n",
    "# Plot price and volatility\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(price_data.index, price_data['price'], 'b-', linewidth=1.5, label='Price')\n",
    "axes[0].plot(price_data.index, price_data['sma_20'], 'r--', alpha=0.7, label='SMA(20)')\n",
    "axes[0].plot(price_data.index, price_data['sma_50'], 'g--', alpha=0.7, label='SMA(50)')\n",
    "axes[0].set_title('Synthetic Price Data', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].fill_between(price_data.index, 0, price_data['volatility_20'], alpha=0.5, color='orange')\n",
    "axes[1].set_title('Rolling 20-Day Volatility (Annualized)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Volatility')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6332f5e",
   "metadata": {},
   "source": [
    "## 3. Define Strategy A and Strategy B\n",
    "\n",
    "Implement two distinct trading strategies for comparison:\n",
    "- **Strategy A (Control):** Simple Moving Average Crossover (SMA 20/50)\n",
    "- **Strategy B (Treatment):** Enhanced SMA with Momentum Filter\n",
    "\n",
    "The treatment strategy adds a momentum confirmation signal to potentially improve timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab9fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingStrategy:\n",
    "    \"\"\"Base class for trading strategies.\"\"\"\n",
    "    \n",
    "    def __init__(self, name: str):\n",
    "        self.name = name\n",
    "        \n",
    "    def generate_signals(self, data: pd.DataFrame) -> pd.Series:\n",
    "        \"\"\"Generate trading signals: 1 for long, 0 for no position, -1 for short.\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "\n",
    "class StrategyA_SMA_Crossover(TradingStrategy):\n",
    "    \"\"\"\n",
    "    Strategy A (Control): Simple SMA Crossover\n",
    "    - Long when SMA(20) > SMA(50)\n",
    "    - Flat when SMA(20) <= SMA(50)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, short_window: int = 20, long_window: int = 50):\n",
    "        super().__init__(\"Strategy A: SMA Crossover\")\n",
    "        self.short_window = short_window\n",
    "        self.long_window = long_window\n",
    "        \n",
    "    def generate_signals(self, data: pd.DataFrame) -> pd.Series:\n",
    "        sma_short = data['price'].rolling(self.short_window).mean()\n",
    "        sma_long = data['price'].rolling(self.long_window).mean()\n",
    "        \n",
    "        signals = pd.Series(0, index=data.index)\n",
    "        signals[sma_short > sma_long] = 1\n",
    "        signals[sma_short <= sma_long] = 0\n",
    "        \n",
    "        return signals\n",
    "\n",
    "\n",
    "class StrategyB_SMA_Momentum(TradingStrategy):\n",
    "    \"\"\"\n",
    "    Strategy B (Treatment): SMA Crossover with Momentum Filter\n",
    "    - Long when SMA(20) > SMA(50) AND momentum_10 > 0\n",
    "    - Flat otherwise\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, short_window: int = 20, long_window: int = 50, momentum_window: int = 10):\n",
    "        super().__init__(\"Strategy B: SMA + Momentum\")\n",
    "        self.short_window = short_window\n",
    "        self.long_window = long_window\n",
    "        self.momentum_window = momentum_window\n",
    "        \n",
    "    def generate_signals(self, data: pd.DataFrame) -> pd.Series:\n",
    "        sma_short = data['price'].rolling(self.short_window).mean()\n",
    "        sma_long = data['price'].rolling(self.long_window).mean()\n",
    "        momentum = data['price'].pct_change(self.momentum_window)\n",
    "        \n",
    "        signals = pd.Series(0, index=data.index)\n",
    "        \n",
    "        # Long only when both conditions are met\n",
    "        long_condition = (sma_short > sma_long) & (momentum > 0)\n",
    "        signals[long_condition] = 1\n",
    "        \n",
    "        return signals\n",
    "\n",
    "\n",
    "# Initialize strategies\n",
    "strategy_a = StrategyA_SMA_Crossover()\n",
    "strategy_b = StrategyB_SMA_Momentum()\n",
    "\n",
    "# Generate signals\n",
    "signals_a = strategy_a.generate_signals(price_data)\n",
    "signals_b = strategy_b.generate_signals(price_data)\n",
    "\n",
    "# Display signal statistics\n",
    "print(\"=\" * 60)\n",
    "print(\"STRATEGY SIGNALS COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n{strategy_a.name}:\")\n",
    "print(f\"  Days in market: {(signals_a == 1).sum()} ({100*(signals_a == 1).mean():.1f}%)\")\n",
    "print(f\"  Days out of market: {(signals_a == 0).sum()} ({100*(signals_a == 0).mean():.1f}%)\")\n",
    "\n",
    "print(f\"\\n{strategy_b.name}:\")\n",
    "print(f\"  Days in market: {(signals_b == 1).sum()} ({100*(signals_b == 1).mean():.1f}%)\")\n",
    "print(f\"  Days out of market: {(signals_b == 0).sum()} ({100*(signals_b == 0).mean():.1f}%)\")\n",
    "\n",
    "# Visualize signals\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(price_data.index, price_data['price'], 'k-', linewidth=1, alpha=0.7, label='Price')\n",
    "\n",
    "# Highlight periods in market for each strategy\n",
    "in_market_a = signals_a == 1\n",
    "in_market_b = signals_b == 1\n",
    "\n",
    "ax.fill_between(price_data.index, price_data['price'].min(), price_data['price'].max(), \n",
    "                where=in_market_a, alpha=0.2, color='blue', label='Strategy A in market')\n",
    "ax.fill_between(price_data.index, price_data['price'].min(), price_data['price'].max(), \n",
    "                where=in_market_b, alpha=0.2, color='green', label='Strategy B in market')\n",
    "\n",
    "ax.set_title('Strategy Signals Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Price')\n",
    "ax.legend(loc='upper left')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611dc8f0",
   "metadata": {},
   "source": [
    "## 4. Calculate Strategy Returns\n",
    "\n",
    "Compute daily and cumulative returns for both strategies, including transaction costs consideration. We'll track:\n",
    "- Gross returns (before costs)\n",
    "- Net returns (after transaction costs)\n",
    "- Cumulative performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_strategy_returns(\n",
    "    data: pd.DataFrame,\n",
    "    signals: pd.Series,\n",
    "    transaction_cost_bps: float = 10.0,  # 10 basis points per trade\n",
    "    strategy_name: str = \"Strategy\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate strategy returns including transaction costs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : pd.DataFrame with 'returns' column\n",
    "    signals : pd.Series with position signals (0 or 1)\n",
    "    transaction_cost_bps : float, cost per trade in basis points\n",
    "    strategy_name : str, name for the strategy\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame with return calculations\n",
    "    \"\"\"\n",
    "    results = pd.DataFrame(index=data.index)\n",
    "    \n",
    "    # Shift signals to avoid look-ahead bias (trade next day)\n",
    "    positions = signals.shift(1).fillna(0)\n",
    "    \n",
    "    # Calculate position changes (trades)\n",
    "    position_changes = positions.diff().abs().fillna(0)\n",
    "    \n",
    "    # Gross returns (position * market returns)\n",
    "    results['gross_returns'] = positions * data['returns']\n",
    "    \n",
    "    # Transaction costs\n",
    "    cost_per_trade = transaction_cost_bps / 10000\n",
    "    results['transaction_costs'] = position_changes * cost_per_trade\n",
    "    \n",
    "    # Net returns\n",
    "    results['net_returns'] = results['gross_returns'] - results['transaction_costs']\n",
    "    \n",
    "    # Cumulative returns\n",
    "    results['cumulative_gross'] = (1 + results['gross_returns']).cumprod()\n",
    "    results['cumulative_net'] = (1 + results['net_returns']).cumprod()\n",
    "    \n",
    "    # Position tracking\n",
    "    results['position'] = positions\n",
    "    results['trades'] = position_changes\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Calculate returns for both strategies\n",
    "returns_a = calculate_strategy_returns(price_data, signals_a, strategy_name=\"Strategy A\")\n",
    "returns_b = calculate_strategy_returns(price_data, signals_b, strategy_name=\"Strategy B\")\n",
    "\n",
    "# Calculate buy-and-hold benchmark\n",
    "returns_benchmark = pd.DataFrame(index=price_data.index)\n",
    "returns_benchmark['net_returns'] = price_data['returns']\n",
    "returns_benchmark['cumulative_net'] = (1 + returns_benchmark['net_returns']).cumprod()\n",
    "\n",
    "# Summary statistics\n",
    "def calculate_performance_metrics(returns: pd.Series, name: str = \"Strategy\") -> Dict:\n",
    "    \"\"\"Calculate comprehensive performance metrics.\"\"\"\n",
    "    annual_factor = 252\n",
    "    \n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    annual_return = (1 + total_return) ** (annual_factor / len(returns)) - 1\n",
    "    annual_vol = returns.std() * np.sqrt(annual_factor)\n",
    "    sharpe = annual_return / annual_vol if annual_vol > 0 else 0\n",
    "    \n",
    "    # Drawdown calculation\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_drawdown = drawdown.min()\n",
    "    \n",
    "    # Win rate\n",
    "    winning_days = (returns > 0).sum()\n",
    "    trading_days = (returns != 0).sum()\n",
    "    win_rate = winning_days / trading_days if trading_days > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'name': name,\n",
    "        'total_return': total_return,\n",
    "        'annual_return': annual_return,\n",
    "        'annual_volatility': annual_vol,\n",
    "        'sharpe_ratio': sharpe,\n",
    "        'max_drawdown': max_drawdown,\n",
    "        'win_rate': win_rate,\n",
    "        'num_trades': 0  # Will be set separately\n",
    "    }\n",
    "\n",
    "\n",
    "# Calculate metrics\n",
    "metrics_a = calculate_performance_metrics(returns_a['net_returns'].dropna(), \"Strategy A\")\n",
    "metrics_a['num_trades'] = returns_a['trades'].sum()\n",
    "\n",
    "metrics_b = calculate_performance_metrics(returns_b['net_returns'].dropna(), \"Strategy B\")\n",
    "metrics_b['num_trades'] = returns_b['trades'].sum()\n",
    "\n",
    "metrics_bh = calculate_performance_metrics(returns_benchmark['net_returns'].dropna(), \"Buy & Hold\")\n",
    "\n",
    "# Display performance comparison\n",
    "print(\"=\" * 80)\n",
    "print(\"STRATEGY PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "metrics_df = pd.DataFrame([metrics_a, metrics_b, metrics_bh]).set_index('name')\n",
    "metrics_display = metrics_df.copy()\n",
    "metrics_display['total_return'] = metrics_display['total_return'].apply(lambda x: f\"{100*x:.2f}%\")\n",
    "metrics_display['annual_return'] = metrics_display['annual_return'].apply(lambda x: f\"{100*x:.2f}%\")\n",
    "metrics_display['annual_volatility'] = metrics_display['annual_volatility'].apply(lambda x: f\"{100*x:.2f}%\")\n",
    "metrics_display['sharpe_ratio'] = metrics_display['sharpe_ratio'].apply(lambda x: f\"{x:.3f}\")\n",
    "metrics_display['max_drawdown'] = metrics_display['max_drawdown'].apply(lambda x: f\"{100*x:.2f}%\")\n",
    "metrics_display['win_rate'] = metrics_display['win_rate'].apply(lambda x: f\"{100*x:.1f}%\")\n",
    "metrics_display['num_trades'] = metrics_display['num_trades'].apply(lambda x: f\"{int(x)}\")\n",
    "\n",
    "print(metrics_display.T.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a4c89a",
   "metadata": {},
   "source": [
    "## 5. Perform Statistical Hypothesis Testing\n",
    "\n",
    "Apply classical frequentist tests to determine if the difference in strategy returns is statistically significant.\n",
    "\n",
    "### Hypothesis Setup\n",
    "- **Null Hypothesis (H‚ÇÄ):** Mean return of Strategy B = Mean return of Strategy A\n",
    "- **Alternative Hypothesis (H‚ÇÅ):** Mean return of Strategy B ‚â† Mean return of Strategy A\n",
    "\n",
    "### Tests Applied\n",
    "1. **Two-sample t-test:** Assumes normally distributed returns\n",
    "2. **Mann-Whitney U test:** Non-parametric alternative, robust to non-normality\n",
    "3. **Welch's t-test:** Does not assume equal variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ee0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABTestHypothesis:\n",
    "    \"\"\"\n",
    "    A/B Testing for Trading Strategies using Frequentist Methods.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns_control: pd.Series, returns_treatment: pd.Series,\n",
    "                 alpha: float = 0.05):\n",
    "        \"\"\"\n",
    "        Initialize with returns from control and treatment strategies.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        returns_control : daily returns from control strategy (Strategy A)\n",
    "        returns_treatment : daily returns from treatment strategy (Strategy B)\n",
    "        alpha : significance level (default 0.05)\n",
    "        \"\"\"\n",
    "        self.control = returns_control.dropna().values\n",
    "        self.treatment = returns_treatment.dropna().values\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def two_sample_ttest(self, equal_var: bool = True) -> Dict:\n",
    "        \"\"\"\n",
    "        Perform two-sample t-test.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        equal_var : if True, assumes equal variances (Student's t-test)\n",
    "                   if False, does not assume equal variances (Welch's t-test)\n",
    "        \"\"\"\n",
    "        t_stat, p_value = ttest_ind(self.treatment, self.control, equal_var=equal_var)\n",
    "        \n",
    "        test_name = \"Student's t-test\" if equal_var else \"Welch's t-test\"\n",
    "        \n",
    "        return {\n",
    "            'test': test_name,\n",
    "            't_statistic': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < self.alpha,\n",
    "            'mean_control': np.mean(self.control),\n",
    "            'mean_treatment': np.mean(self.treatment),\n",
    "            'mean_diff': np.mean(self.treatment) - np.mean(self.control)\n",
    "        }\n",
    "    \n",
    "    def mann_whitney_test(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Perform Mann-Whitney U test (non-parametric alternative).\n",
    "        \"\"\"\n",
    "        u_stat, p_value = mannwhitneyu(self.treatment, self.control, alternative='two-sided')\n",
    "        \n",
    "        return {\n",
    "            'test': 'Mann-Whitney U',\n",
    "            'u_statistic': u_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant': p_value < self.alpha,\n",
    "            'median_control': np.median(self.control),\n",
    "            'median_treatment': np.median(self.treatment)\n",
    "        }\n",
    "    \n",
    "    def check_normality(self) -> Dict:\n",
    "        \"\"\"Check if returns are normally distributed using Shapiro-Wilk test.\"\"\"\n",
    "        # Use a sample if data is too large (Shapiro-Wilk has size limits)\n",
    "        sample_size = min(len(self.control), len(self.treatment), 5000)\n",
    "        \n",
    "        _, p_control = stats.shapiro(np.random.choice(self.control, sample_size, replace=False))\n",
    "        _, p_treatment = stats.shapiro(np.random.choice(self.treatment, sample_size, replace=False))\n",
    "        \n",
    "        return {\n",
    "            'control_normal_pvalue': p_control,\n",
    "            'treatment_normal_pvalue': p_treatment,\n",
    "            'control_is_normal': p_control > self.alpha,\n",
    "            'treatment_is_normal': p_treatment > self.alpha\n",
    "        }\n",
    "    \n",
    "    def run_all_tests(self) -> pd.DataFrame:\n",
    "        \"\"\"Run all hypothesis tests and return summary.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Check normality first\n",
    "        normality = self.check_normality()\n",
    "        \n",
    "        # Student's t-test\n",
    "        t_result = self.two_sample_ttest(equal_var=True)\n",
    "        results.append({\n",
    "            'Test': t_result['test'],\n",
    "            'Statistic': f\"{t_result['t_statistic']:.4f}\",\n",
    "            'P-Value': f\"{t_result['p_value']:.6f}\",\n",
    "            'Significant': '‚úì' if t_result['significant'] else '‚úó'\n",
    "        })\n",
    "        \n",
    "        # Welch's t-test\n",
    "        welch_result = self.two_sample_ttest(equal_var=False)\n",
    "        results.append({\n",
    "            'Test': welch_result['test'],\n",
    "            'Statistic': f\"{welch_result['t_statistic']:.4f}\",\n",
    "            'P-Value': f\"{welch_result['p_value']:.6f}\",\n",
    "            'Significant': '‚úì' if welch_result['significant'] else '‚úó'\n",
    "        })\n",
    "        \n",
    "        # Mann-Whitney U\n",
    "        mw_result = self.mann_whitney_test()\n",
    "        results.append({\n",
    "            'Test': mw_result['test'],\n",
    "            'Statistic': f\"{mw_result['u_statistic']:.4f}\",\n",
    "            'P-Value': f\"{mw_result['p_value']:.6f}\",\n",
    "            'Significant': '‚úì' if mw_result['significant'] else '‚úó'\n",
    "        })\n",
    "        \n",
    "        return pd.DataFrame(results), normality, t_result\n",
    "\n",
    "\n",
    "# Run hypothesis tests\n",
    "ab_test = ABTestHypothesis(\n",
    "    returns_control=returns_a['net_returns'],\n",
    "    returns_treatment=returns_b['net_returns'],\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "test_results_df, normality_check, detailed_result = ab_test.run_all_tests()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"HYPOTHESIS TESTING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nSignificance Level (Œ±): 0.05\")\n",
    "print(f\"\\nSample Sizes:\")\n",
    "print(f\"  Strategy A (Control): {len(ab_test.control)} observations\")\n",
    "print(f\"  Strategy B (Treatment): {len(ab_test.treatment)} observations\")\n",
    "\n",
    "print(f\"\\nüìä Normality Check (Shapiro-Wilk Test):\")\n",
    "print(f\"  Control returns normally distributed: {normality_check['control_is_normal']} (p={normality_check['control_normal_pvalue']:.4f})\")\n",
    "print(f\"  Treatment returns normally distributed: {normality_check['treatment_is_normal']} (p={normality_check['treatment_normal_pvalue']:.4f})\")\n",
    "\n",
    "print(f\"\\nüìà Mean Daily Returns:\")\n",
    "print(f\"  Strategy A (Control): {100*detailed_result['mean_control']:.4f}%\")\n",
    "print(f\"  Strategy B (Treatment): {100*detailed_result['mean_treatment']:.4f}%\")\n",
    "print(f\"  Difference: {100*detailed_result['mean_diff']:.4f}%\")\n",
    "\n",
    "print(f\"\\nüß™ Statistical Tests:\")\n",
    "print(test_results_df.to_string(index=False))\n",
    "\n",
    "# Interpretation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"INTERPRETATION\")\n",
    "print(\"=\" * 70)\n",
    "if detailed_result['p_value'] < 0.05:\n",
    "    if detailed_result['mean_diff'] > 0:\n",
    "        print(\"‚úÖ The treatment strategy (B) shows STATISTICALLY SIGNIFICANT improvement\")\n",
    "        print(\"   over the control strategy (A) at the 5% significance level.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  The treatment strategy (B) is SIGNIFICANTLY WORSE than the control (A)\")\n",
    "        print(\"   at the 5% significance level.\")\n",
    "else:\n",
    "    print(\"‚ùå We CANNOT REJECT the null hypothesis that the strategies have equal means.\")\n",
    "    print(\"   The observed difference may be due to random chance.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ff04e7",
   "metadata": {},
   "source": [
    "## 6. Calculate Effect Size and Power Analysis\n",
    "\n",
    "Statistical significance alone isn't enough‚Äîwe need to know:\n",
    "1. **Effect Size (Cohen's d):** How large is the practical difference?\n",
    "2. **Statistical Power:** What's our probability of detecting a true effect?\n",
    "3. **Required Sample Size:** How many observations do we need?\n",
    "\n",
    "### Effect Size Interpretation (Cohen's d)\n",
    "- Small: |d| ‚âà 0.2\n",
    "- Medium: |d| ‚âà 0.5\n",
    "- Large: |d| ‚âà 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32cc896",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_d(group1: np.ndarray, group2: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Cohen's d effect size.\n",
    "    \n",
    "    Cohen's d = (mean1 - mean2) / pooled_std\n",
    "    \"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    \n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    \n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "\n",
    "\n",
    "def calculate_power(effect_size: float, n1: int, n2: int, alpha: float = 0.05) -> float:\n",
    "    \"\"\"\n",
    "    Calculate statistical power for a two-sample t-test.\n",
    "    \n",
    "    Power = P(reject H0 | H0 is false)\n",
    "    \"\"\"\n",
    "    # Degrees of freedom\n",
    "    df = n1 + n2 - 2\n",
    "    \n",
    "    # Non-centrality parameter\n",
    "    se = np.sqrt(1/n1 + 1/n2)\n",
    "    ncp = effect_size / se\n",
    "    \n",
    "    # Critical value\n",
    "    t_crit = t_dist.ppf(1 - alpha/2, df)\n",
    "    \n",
    "    # Power = P(|T| > t_crit) under alternative\n",
    "    power = 1 - t_dist.cdf(t_crit - ncp, df) + t_dist.cdf(-t_crit - ncp, df)\n",
    "    \n",
    "    return power\n",
    "\n",
    "\n",
    "def required_sample_size(effect_size: float, power: float = 0.80, alpha: float = 0.05) -> int:\n",
    "    \"\"\"\n",
    "    Calculate required sample size per group to achieve desired power.\n",
    "    Uses iterative approximation.\n",
    "    \"\"\"\n",
    "    if abs(effect_size) < 0.001:\n",
    "        return float('inf')\n",
    "    \n",
    "    # Initial approximation\n",
    "    z_alpha = norm.ppf(1 - alpha/2)\n",
    "    z_beta = norm.ppf(power)\n",
    "    \n",
    "    n_approx = 2 * ((z_alpha + z_beta) / effect_size) ** 2\n",
    "    \n",
    "    # Refine iteratively\n",
    "    for n in range(int(n_approx * 0.5), int(n_approx * 2)):\n",
    "        if calculate_power(effect_size, n, n, alpha) >= power:\n",
    "            return n\n",
    "    \n",
    "    return int(n_approx)\n",
    "\n",
    "\n",
    "# Calculate effect size\n",
    "control_returns = returns_a['net_returns'].dropna().values\n",
    "treatment_returns = returns_b['net_returns'].dropna().values\n",
    "\n",
    "effect_size = cohens_d(treatment_returns, control_returns)\n",
    "current_power = calculate_power(effect_size, len(treatment_returns), len(control_returns))\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EFFECT SIZE AND POWER ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìè Effect Size (Cohen's d): {effect_size:.4f}\")\n",
    "\n",
    "# Interpret effect size\n",
    "if abs(effect_size) < 0.2:\n",
    "    effect_interpretation = \"Negligible/Small\"\n",
    "elif abs(effect_size) < 0.5:\n",
    "    effect_interpretation = \"Small to Medium\"\n",
    "elif abs(effect_size) < 0.8:\n",
    "    effect_interpretation = \"Medium to Large\"\n",
    "else:\n",
    "    effect_interpretation = \"Large\"\n",
    "\n",
    "print(f\"   Interpretation: {effect_interpretation}\")\n",
    "\n",
    "print(f\"\\n‚ö° Current Statistical Power: {100*current_power:.2f}%\")\n",
    "print(f\"   (Probability of detecting the effect if it's real)\")\n",
    "\n",
    "# Sample size analysis for different effect sizes\n",
    "print(\"\\nüìä Required Sample Size Analysis (per group):\")\n",
    "print(\"   Target Power: 80%, Significance Level: 5%\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "effect_sizes_to_test = [0.1, 0.2, 0.3, 0.5, 0.8]\n",
    "for es in effect_sizes_to_test:\n",
    "    req_n = required_sample_size(es, power=0.80, alpha=0.05)\n",
    "    req_days = f\"{req_n} days\" if req_n < 5000 else f\"~{req_n} days\"\n",
    "    trading_years = req_n / 252\n",
    "    print(f\"   Effect Size d={es:.1f}: {req_days} ({trading_years:.1f} trading years)\")\n",
    "\n",
    "# Power curve visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Power vs Sample Size for our observed effect\n",
    "sample_sizes = np.arange(50, 1000, 10)\n",
    "powers = [calculate_power(effect_size, n, n) for n in sample_sizes]\n",
    "\n",
    "axes[0].plot(sample_sizes, powers, 'b-', linewidth=2)\n",
    "axes[0].axhline(y=0.80, color='r', linestyle='--', label='80% Power Target')\n",
    "axes[0].axvline(x=len(treatment_returns), color='g', linestyle='--', \n",
    "                label=f'Current n={len(treatment_returns)}')\n",
    "axes[0].fill_between(sample_sizes, 0, powers, alpha=0.2)\n",
    "axes[0].set_xlabel('Sample Size (per group)', fontsize=12)\n",
    "axes[0].set_ylabel('Statistical Power', fontsize=12)\n",
    "axes[0].set_title(f'Power Curve for Observed Effect Size (d={effect_size:.3f})', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].set_ylim(0, 1)\n",
    "\n",
    "# Plot 2: Required sample size vs Effect size\n",
    "effect_sizes_range = np.arange(0.05, 1.0, 0.01)\n",
    "required_n = [required_sample_size(es, power=0.80) for es in effect_sizes_range]\n",
    "\n",
    "axes[1].plot(effect_sizes_range, required_n, 'b-', linewidth=2)\n",
    "axes[1].axvline(x=abs(effect_size), color='g', linestyle='--', \n",
    "                label=f'Our Effect Size: d={effect_size:.3f}')\n",
    "axes[1].axhline(y=len(treatment_returns), color='orange', linestyle='--',\n",
    "                label=f'Our Sample Size: n={len(treatment_returns)}')\n",
    "axes[1].set_xlabel(\"Effect Size (Cohen's d)\", fontsize=12)\n",
    "axes[1].set_ylabel('Required Sample Size (per group)', fontsize=12)\n",
    "axes[1].set_title('Required Sample Size for 80% Power', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 3000)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c03682",
   "metadata": {},
   "source": [
    "## 7. Bootstrap Confidence Intervals\n",
    "\n",
    "Use bootstrap resampling to construct confidence intervals for the difference in mean returns between strategies. Bootstrap is particularly useful when:\n",
    "- Distribution assumptions may not hold\n",
    "- We want non-parametric confidence intervals\n",
    "- We need intervals for complex statistics (Sharpe ratio, max drawdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa02cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BootstrapAnalysis:\n",
    "    \"\"\"\n",
    "    Bootstrap analysis for comparing trading strategy performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns_a: np.ndarray, returns_b: np.ndarray, \n",
    "                 n_bootstrap: int = 10000, random_state: int = 42):\n",
    "        self.returns_a = returns_a\n",
    "        self.returns_b = returns_b\n",
    "        self.n_bootstrap = n_bootstrap\n",
    "        self.rng = np.random.RandomState(random_state)\n",
    "        \n",
    "    def bootstrap_statistic(self, statistic_func: callable) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Generate bootstrap distributions for a given statistic.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        (bootstrap_a, bootstrap_b): Arrays of bootstrapped statistics\n",
    "        \"\"\"\n",
    "        n_a, n_b = len(self.returns_a), len(self.returns_b)\n",
    "        \n",
    "        bootstrap_a = np.zeros(self.n_bootstrap)\n",
    "        bootstrap_b = np.zeros(self.n_bootstrap)\n",
    "        \n",
    "        for i in range(self.n_bootstrap):\n",
    "            # Resample with replacement\n",
    "            sample_a = self.rng.choice(self.returns_a, size=n_a, replace=True)\n",
    "            sample_b = self.rng.choice(self.returns_b, size=n_b, replace=True)\n",
    "            \n",
    "            bootstrap_a[i] = statistic_func(sample_a)\n",
    "            bootstrap_b[i] = statistic_func(sample_b)\n",
    "            \n",
    "        return bootstrap_a, bootstrap_b\n",
    "    \n",
    "    def confidence_interval_diff(self, statistic_func: callable, \n",
    "                                  confidence: float = 0.95) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate confidence interval for the difference in a statistic.\n",
    "        \"\"\"\n",
    "        bootstrap_a, bootstrap_b = self.bootstrap_statistic(statistic_func)\n",
    "        \n",
    "        # Difference distribution\n",
    "        diff = bootstrap_b - bootstrap_a\n",
    "        \n",
    "        alpha = 1 - confidence\n",
    "        ci_lower = np.percentile(diff, 100 * alpha / 2)\n",
    "        ci_upper = np.percentile(diff, 100 * (1 - alpha / 2))\n",
    "        \n",
    "        # Probability that B > A\n",
    "        prob_b_better = (diff > 0).mean()\n",
    "        \n",
    "        return {\n",
    "            'mean_diff': diff.mean(),\n",
    "            'std_diff': diff.std(),\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper,\n",
    "            'confidence': confidence,\n",
    "            'prob_b_better': prob_b_better,\n",
    "            'bootstrap_diff': diff,\n",
    "            'bootstrap_a': bootstrap_a,\n",
    "            'bootstrap_b': bootstrap_b\n",
    "        }\n",
    "\n",
    "\n",
    "# Define statistics functions\n",
    "def mean_return(returns):\n",
    "    return np.mean(returns)\n",
    "\n",
    "def sharpe_ratio(returns, risk_free=0.0):\n",
    "    excess = returns - risk_free/252\n",
    "    if np.std(excess) == 0:\n",
    "        return 0\n",
    "    return np.mean(excess) / np.std(excess) * np.sqrt(252)\n",
    "\n",
    "def max_drawdown(returns):\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = np.maximum.accumulate(cumulative)\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    return np.min(drawdown)\n",
    "\n",
    "\n",
    "# Run bootstrap analysis\n",
    "bootstrap = BootstrapAnalysis(\n",
    "    returns_a=control_returns,\n",
    "    returns_b=treatment_returns,\n",
    "    n_bootstrap=10000\n",
    ")\n",
    "\n",
    "# Mean return difference\n",
    "mean_ci = bootstrap.confidence_interval_diff(mean_return)\n",
    "\n",
    "# Sharpe ratio difference\n",
    "sharpe_ci = bootstrap.confidence_interval_diff(sharpe_ratio)\n",
    "\n",
    "# Print results\n",
    "print(\"=\" * 70)\n",
    "print(\"BOOTSTRAP CONFIDENCE INTERVALS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Mean Daily Return Difference (Strategy B - Strategy A):\")\n",
    "print(f\"   Mean Difference: {100*mean_ci['mean_diff']:.4f}%\")\n",
    "print(f\"   95% CI: [{100*mean_ci['ci_lower']:.4f}%, {100*mean_ci['ci_upper']:.4f}%]\")\n",
    "print(f\"   P(Strategy B > Strategy A): {100*mean_ci['prob_b_better']:.1f}%\")\n",
    "\n",
    "contains_zero_mean = mean_ci['ci_lower'] <= 0 <= mean_ci['ci_upper']\n",
    "print(f\"   CI Contains Zero: {'Yes ‚ö†Ô∏è' if contains_zero_mean else 'No ‚úì'}\")\n",
    "\n",
    "print(f\"\\nüìà Sharpe Ratio Difference (Strategy B - Strategy A):\")\n",
    "print(f\"   Mean Difference: {sharpe_ci['mean_diff']:.4f}\")\n",
    "print(f\"   95% CI: [{sharpe_ci['ci_lower']:.4f}, {sharpe_ci['ci_upper']:.4f}]\")\n",
    "print(f\"   P(Strategy B > Strategy A): {100*sharpe_ci['prob_b_better']:.1f}%\")\n",
    "\n",
    "contains_zero_sharpe = sharpe_ci['ci_lower'] <= 0 <= sharpe_ci['ci_upper']\n",
    "print(f\"   CI Contains Zero: {'Yes ‚ö†Ô∏è' if contains_zero_sharpe else 'No ‚úì'}\")\n",
    "\n",
    "# Visualize bootstrap distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Mean return difference histogram\n",
    "axes[0, 0].hist(mean_ci['bootstrap_diff'] * 100, bins=50, density=True, \n",
    "                alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0, 0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero (No Difference)')\n",
    "axes[0, 0].axvline(x=mean_ci['ci_lower']*100, color='green', linestyle='--', label='95% CI')\n",
    "axes[0, 0].axvline(x=mean_ci['ci_upper']*100, color='green', linestyle='--')\n",
    "axes[0, 0].axvline(x=mean_ci['mean_diff']*100, color='orange', linewidth=2, label='Mean Diff')\n",
    "axes[0, 0].set_xlabel('Mean Return Difference (%)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Density', fontsize=11)\n",
    "axes[0, 0].set_title('Bootstrap Distribution: Mean Return Difference', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Sharpe ratio difference histogram\n",
    "axes[0, 1].hist(sharpe_ci['bootstrap_diff'], bins=50, density=True, \n",
    "                alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero (No Difference)')\n",
    "axes[0, 1].axvline(x=sharpe_ci['ci_lower'], color='green', linestyle='--', label='95% CI')\n",
    "axes[0, 1].axvline(x=sharpe_ci['ci_upper'], color='green', linestyle='--')\n",
    "axes[0, 1].axvline(x=sharpe_ci['mean_diff'], color='orange', linewidth=2, label='Mean Diff')\n",
    "axes[0, 1].set_xlabel('Sharpe Ratio Difference', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Density', fontsize=11)\n",
    "axes[0, 1].set_title('Bootstrap Distribution: Sharpe Ratio Difference', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Strategy A vs B Sharpe distributions\n",
    "axes[1, 0].hist(sharpe_ci['bootstrap_a'], bins=50, alpha=0.6, label='Strategy A', color='blue')\n",
    "axes[1, 0].hist(sharpe_ci['bootstrap_b'], bins=50, alpha=0.6, label='Strategy B', color='green')\n",
    "axes[1, 0].set_xlabel('Sharpe Ratio', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Frequency', fontsize=11)\n",
    "axes[1, 0].set_title('Bootstrap Sharpe Ratio Distributions', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Probability B > A over bootstrap samples\n",
    "cumulative_prob = np.cumsum(sharpe_ci['bootstrap_diff'] > 0) / np.arange(1, len(sharpe_ci['bootstrap_diff']) + 1)\n",
    "axes[1, 1].plot(cumulative_prob, 'b-', linewidth=1)\n",
    "axes[1, 1].axhline(y=0.5, color='red', linestyle='--', label='50% (No Preference)')\n",
    "axes[1, 1].axhline(y=sharpe_ci['prob_b_better'], color='green', linestyle='--', \n",
    "                   label=f'Final: {100*sharpe_ci[\"prob_b_better\"]:.1f}%')\n",
    "axes[1, 1].set_xlabel('Bootstrap Iteration', fontsize=11)\n",
    "axes[1, 1].set_ylabel('P(Strategy B Sharpe > Strategy A Sharpe)', fontsize=11)\n",
    "axes[1, 1].set_title('Convergence of P(B > A)', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4385534",
   "metadata": {},
   "source": [
    "## 8. Visualize Strategy Performance Comparison\n",
    "\n",
    "Create comprehensive visualizations comparing:\n",
    "- Equity curves (cumulative returns)\n",
    "- Return distributions\n",
    "- Drawdown analysis\n",
    "- Risk-return scatter plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b287c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drawdown_series(returns: pd.Series) -> pd.Series:\n",
    "    \"\"\"Calculate drawdown series from returns.\"\"\"\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    return drawdown\n",
    "\n",
    "\n",
    "# Calculate drawdowns\n",
    "dd_a = calculate_drawdown_series(returns_a['net_returns'].fillna(0))\n",
    "dd_b = calculate_drawdown_series(returns_b['net_returns'].fillna(0))\n",
    "dd_bh = calculate_drawdown_series(returns_benchmark['net_returns'].fillna(0))\n",
    "\n",
    "# Create comprehensive comparison visualization\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# 1. Equity Curves\n",
    "ax1 = fig.add_subplot(2, 2, 1)\n",
    "ax1.plot(returns_a.index, returns_a['cumulative_net'], 'b-', linewidth=1.5, \n",
    "         label='Strategy A (Control)', alpha=0.9)\n",
    "ax1.plot(returns_b.index, returns_b['cumulative_net'], 'g-', linewidth=1.5, \n",
    "         label='Strategy B (Treatment)', alpha=0.9)\n",
    "ax1.plot(returns_benchmark.index, returns_benchmark['cumulative_net'], 'k--', \n",
    "         linewidth=1, label='Buy & Hold', alpha=0.7)\n",
    "ax1.fill_between(returns_a.index, 1, returns_a['cumulative_net'], \n",
    "                 where=returns_a['cumulative_net'] > 1, alpha=0.1, color='blue')\n",
    "ax1.fill_between(returns_b.index, 1, returns_b['cumulative_net'], \n",
    "                 where=returns_b['cumulative_net'] > 1, alpha=0.1, color='green')\n",
    "ax1.set_title('Equity Curves Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Portfolio Value (Starting at 1)')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Return Distributions\n",
    "ax2 = fig.add_subplot(2, 2, 2)\n",
    "bins = np.linspace(-0.05, 0.05, 50)\n",
    "ax2.hist(returns_a['net_returns'].dropna() * 100, bins=bins*100, alpha=0.6, \n",
    "         label='Strategy A', color='blue', density=True)\n",
    "ax2.hist(returns_b['net_returns'].dropna() * 100, bins=bins*100, alpha=0.6, \n",
    "         label='Strategy B', color='green', density=True)\n",
    "ax2.axvline(x=returns_a['net_returns'].mean()*100, color='blue', linestyle='--', linewidth=2)\n",
    "ax2.axvline(x=returns_b['net_returns'].mean()*100, color='green', linestyle='--', linewidth=2)\n",
    "ax2.set_title('Daily Return Distributions', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Daily Return (%)')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Drawdown Comparison\n",
    "ax3 = fig.add_subplot(2, 2, 3)\n",
    "ax3.fill_between(dd_a.index, 0, dd_a * 100, alpha=0.5, color='blue', label='Strategy A')\n",
    "ax3.fill_between(dd_b.index, 0, dd_b * 100, alpha=0.5, color='green', label='Strategy B')\n",
    "ax3.plot(dd_bh.index, dd_bh * 100, 'k--', alpha=0.7, label='Buy & Hold')\n",
    "ax3.set_title('Drawdown Comparison', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Drawdown (%)')\n",
    "ax3.legend(loc='lower left')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Rolling Sharpe Comparison\n",
    "rolling_window = 63  # ~3 months\n",
    "rolling_sharpe_a = returns_a['net_returns'].rolling(rolling_window).apply(\n",
    "    lambda x: np.mean(x) / np.std(x) * np.sqrt(252) if np.std(x) > 0 else 0\n",
    ")\n",
    "rolling_sharpe_b = returns_b['net_returns'].rolling(rolling_window).apply(\n",
    "    lambda x: np.mean(x) / np.std(x) * np.sqrt(252) if np.std(x) > 0 else 0\n",
    ")\n",
    "\n",
    "ax4 = fig.add_subplot(2, 2, 4)\n",
    "ax4.plot(rolling_sharpe_a.index, rolling_sharpe_a, 'b-', linewidth=1.5, \n",
    "         label='Strategy A', alpha=0.8)\n",
    "ax4.plot(rolling_sharpe_b.index, rolling_sharpe_b, 'g-', linewidth=1.5, \n",
    "         label='Strategy B', alpha=0.8)\n",
    "ax4.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax4.fill_between(rolling_sharpe_a.index, rolling_sharpe_a, rolling_sharpe_b, \n",
    "                 where=rolling_sharpe_b > rolling_sharpe_a, \n",
    "                 alpha=0.3, color='green', label='B > A')\n",
    "ax4.fill_between(rolling_sharpe_a.index, rolling_sharpe_a, rolling_sharpe_b, \n",
    "                 where=rolling_sharpe_a > rolling_sharpe_b, \n",
    "                 alpha=0.3, color='blue', label='A > B')\n",
    "ax4.set_title(f'Rolling {rolling_window}-Day Sharpe Ratio', fontsize=14, fontweight='bold')\n",
    "ax4.set_xlabel('Date')\n",
    "ax4.set_ylabel('Sharpe Ratio')\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PERFORMANCE SUMMARY TABLE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary_data = {\n",
    "    'Metric': ['Total Return', 'Annual Return', 'Annual Volatility', \n",
    "               'Sharpe Ratio', 'Max Drawdown', 'Win Rate', 'Num Trades'],\n",
    "    'Strategy A': [\n",
    "        f\"{100*metrics_a['total_return']:.2f}%\",\n",
    "        f\"{100*metrics_a['annual_return']:.2f}%\",\n",
    "        f\"{100*metrics_a['annual_volatility']:.2f}%\",\n",
    "        f\"{metrics_a['sharpe_ratio']:.3f}\",\n",
    "        f\"{100*metrics_a['max_drawdown']:.2f}%\",\n",
    "        f\"{100*metrics_a['win_rate']:.1f}%\",\n",
    "        f\"{int(metrics_a['num_trades'])}\"\n",
    "    ],\n",
    "    'Strategy B': [\n",
    "        f\"{100*metrics_b['total_return']:.2f}%\",\n",
    "        f\"{100*metrics_b['annual_return']:.2f}%\",\n",
    "        f\"{100*metrics_b['annual_volatility']:.2f}%\",\n",
    "        f\"{metrics_b['sharpe_ratio']:.3f}\",\n",
    "        f\"{100*metrics_b['max_drawdown']:.2f}%\",\n",
    "        f\"{100*metrics_b['win_rate']:.1f}%\",\n",
    "        f\"{int(metrics_b['num_trades'])}\"\n",
    "    ],\n",
    "    'Difference': [\n",
    "        f\"{100*(metrics_b['total_return'] - metrics_a['total_return']):.2f}%\",\n",
    "        f\"{100*(metrics_b['annual_return'] - metrics_a['annual_return']):.2f}%\",\n",
    "        f\"{100*(metrics_b['annual_volatility'] - metrics_a['annual_volatility']):.2f}%\",\n",
    "        f\"{metrics_b['sharpe_ratio'] - metrics_a['sharpe_ratio']:.3f}\",\n",
    "        f\"{100*(metrics_b['max_drawdown'] - metrics_a['max_drawdown']):.2f}%\",\n",
    "        f\"{100*(metrics_b['win_rate'] - metrics_a['win_rate']):.1f}%\",\n",
    "        f\"{int(metrics_b['num_trades'] - metrics_a['num_trades'])}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ef3f3",
   "metadata": {},
   "source": [
    "## 9. Calculate Sharpe Ratio Comparison\n",
    "\n",
    "Compare risk-adjusted returns using Sharpe ratios with proper statistical testing. The Ledoit-Wolf (2008) method provides a robust test for Sharpe ratio differences that accounts for:\n",
    "- Non-normality of returns\n",
    "- Serial correlation\n",
    "- Estimation uncertainty\n",
    "\n",
    "Reference: *Robust Sharpe Ratio Tests for an Arbitrage-Free Asset*, Ledoit & Wolf (2008)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27653c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharpeRatioTest:\n",
    "    \"\"\"\n",
    "    Statistical test for comparing Sharpe ratios between two strategies.\n",
    "    Implements the HAC (Heteroskedasticity and Autocorrelation Consistent) \n",
    "    standard error approach.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns_a: np.ndarray, returns_b: np.ndarray, \n",
    "                 risk_free_rate: float = 0.0):\n",
    "        self.returns_a = returns_a\n",
    "        self.returns_b = returns_b\n",
    "        self.rf = risk_free_rate / 252  # Daily risk-free rate\n",
    "        self.n = len(returns_a)\n",
    "        \n",
    "    def compute_sharpe(self, returns: np.ndarray) -> float:\n",
    "        \"\"\"Compute annualized Sharpe ratio.\"\"\"\n",
    "        excess = returns - self.rf\n",
    "        return np.mean(excess) / np.std(excess, ddof=1) * np.sqrt(252)\n",
    "    \n",
    "    def newey_west_variance(self, x: np.ndarray, max_lag: int = None) -> float:\n",
    "        \"\"\"\n",
    "        Compute Newey-West HAC variance estimator.\n",
    "        Accounts for heteroskedasticity and autocorrelation.\n",
    "        \"\"\"\n",
    "        n = len(x)\n",
    "        if max_lag is None:\n",
    "            max_lag = int(np.floor(4 * (n / 100) ** (2/9)))\n",
    "        \n",
    "        # Sample variance\n",
    "        x_demean = x - np.mean(x)\n",
    "        variance = np.mean(x_demean ** 2)\n",
    "        \n",
    "        # Add autocovariance terms\n",
    "        for j in range(1, max_lag + 1):\n",
    "            weight = 1 - j / (max_lag + 1)  # Bartlett kernel\n",
    "            autocov = np.mean(x_demean[j:] * x_demean[:-j])\n",
    "            variance += 2 * weight * autocov\n",
    "            \n",
    "        return variance\n",
    "    \n",
    "    def jobson_korkie_test(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Jobson-Korkie test for equality of Sharpe ratios.\n",
    "        H0: Sharpe_A = Sharpe_B\n",
    "        \"\"\"\n",
    "        excess_a = self.returns_a - self.rf\n",
    "        excess_b = self.returns_b - self.rf\n",
    "        \n",
    "        mu_a, mu_b = np.mean(excess_a), np.mean(excess_b)\n",
    "        sigma_a, sigma_b = np.std(excess_a, ddof=1), np.std(excess_b, ddof=1)\n",
    "        \n",
    "        sr_a = mu_a / sigma_a\n",
    "        sr_b = mu_b / sigma_b\n",
    "        \n",
    "        # Covariance between returns\n",
    "        cov_ab = np.cov(excess_a, excess_b)[0, 1]\n",
    "        \n",
    "        # Test statistic variance (asymptotic)\n",
    "        theta = (\n",
    "            1 / self.n * (\n",
    "                2 * (1 - cov_ab / (sigma_a * sigma_b)) \n",
    "                + 0.5 * (sr_a**2 + sr_b**2 - 2 * sr_a * sr_b * cov_ab / (sigma_a * sigma_b))\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Z statistic\n",
    "        z_stat = (sr_a - sr_b) / np.sqrt(theta) if theta > 0 else 0\n",
    "        p_value = 2 * (1 - norm.cdf(abs(z_stat)))\n",
    "        \n",
    "        return {\n",
    "            'test': 'Jobson-Korkie',\n",
    "            'sharpe_a': sr_a * np.sqrt(252),\n",
    "            'sharpe_b': sr_b * np.sqrt(252),\n",
    "            'sharpe_diff': (sr_a - sr_b) * np.sqrt(252),\n",
    "            'z_statistic': z_stat,\n",
    "            'p_value': p_value,\n",
    "            'significant_005': p_value < 0.05\n",
    "        }\n",
    "    \n",
    "    def bootstrap_sharpe_test(self, n_bootstrap: int = 10000) -> Dict:\n",
    "        \"\"\"\n",
    "        Bootstrap test for Sharpe ratio difference using circular block bootstrap.\n",
    "        \"\"\"\n",
    "        rng = np.random.RandomState(42)\n",
    "        block_length = int(np.ceil(self.n ** (1/3)))  # Block length\n",
    "        \n",
    "        sr_a_original = self.compute_sharpe(self.returns_a)\n",
    "        sr_b_original = self.compute_sharpe(self.returns_b)\n",
    "        diff_original = sr_b_original - sr_a_original\n",
    "        \n",
    "        bootstrap_diffs = np.zeros(n_bootstrap)\n",
    "        \n",
    "        for i in range(n_bootstrap):\n",
    "            # Circular block bootstrap\n",
    "            n_blocks = int(np.ceil(self.n / block_length))\n",
    "            start_indices = rng.randint(0, self.n, n_blocks)\n",
    "            \n",
    "            indices = []\n",
    "            for start in start_indices:\n",
    "                block_indices = [(start + j) % self.n for j in range(block_length)]\n",
    "                indices.extend(block_indices)\n",
    "            indices = indices[:self.n]\n",
    "            \n",
    "            boot_a = self.returns_a[indices]\n",
    "            boot_b = self.returns_b[indices]\n",
    "            \n",
    "            sr_a_boot = self.compute_sharpe(boot_a)\n",
    "            sr_b_boot = self.compute_sharpe(boot_b)\n",
    "            bootstrap_diffs[i] = sr_b_boot - sr_a_boot\n",
    "        \n",
    "        # Two-sided p-value\n",
    "        p_value = 2 * min(\n",
    "            np.mean(bootstrap_diffs >= diff_original),\n",
    "            np.mean(bootstrap_diffs <= diff_original)\n",
    "        )\n",
    "        \n",
    "        ci_lower = np.percentile(bootstrap_diffs, 2.5)\n",
    "        ci_upper = np.percentile(bootstrap_diffs, 97.5)\n",
    "        \n",
    "        return {\n",
    "            'test': 'Bootstrap (Block)',\n",
    "            'sharpe_diff': diff_original,\n",
    "            'p_value': p_value,\n",
    "            'ci_95_lower': ci_lower,\n",
    "            'ci_95_upper': ci_upper,\n",
    "            'prob_b_better': np.mean(bootstrap_diffs > 0),\n",
    "            'bootstrap_distribution': bootstrap_diffs\n",
    "        }\n",
    "\n",
    "\n",
    "# Run Sharpe ratio tests\n",
    "sharpe_test = SharpeRatioTest(control_returns, treatment_returns)\n",
    "\n",
    "jk_result = sharpe_test.jobson_korkie_test()\n",
    "boot_result = sharpe_test.bootstrap_sharpe_test()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SHARPE RATIO STATISTICAL TESTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nAnnualized Sharpe Ratios:\")\n",
    "print(f\"  Strategy A (Control): {jk_result['sharpe_a']:.4f}\")\n",
    "print(f\"  Strategy B (Treatment): {jk_result['sharpe_b']:.4f}\")\n",
    "print(f\"  Difference (B - A): {jk_result['sharpe_diff']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Jobson-Korkie Test (Asymptotic):\")\n",
    "print(f\"  Z-statistic: {jk_result['z_statistic']:.4f}\")\n",
    "print(f\"  P-value: {jk_result['p_value']:.6f}\")\n",
    "print(f\"  Significant at 5%: {'Yes ‚úì' if jk_result['significant_005'] else 'No ‚úó'}\")\n",
    "\n",
    "print(f\"\\nüìä Bootstrap Test (Block Bootstrap):\")\n",
    "print(f\"  P-value: {boot_result['p_value']:.6f}\")\n",
    "print(f\"  95% CI for difference: [{boot_result['ci_95_lower']:.4f}, {boot_result['ci_95_upper']:.4f}]\")\n",
    "print(f\"  P(Strategy B > Strategy A): {100*boot_result['prob_b_better']:.1f}%\")\n",
    "\n",
    "# Visualize bootstrap distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bootstrap distribution\n",
    "axes[0].hist(boot_result['bootstrap_distribution'], bins=50, density=True, \n",
    "             alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[0].axvline(x=0, color='red', linestyle='--', linewidth=2, label='No Difference')\n",
    "axes[0].axvline(x=boot_result['sharpe_diff'], color='orange', linewidth=2, \n",
    "                label=f'Observed: {boot_result[\"sharpe_diff\"]:.3f}')\n",
    "axes[0].axvline(x=boot_result['ci_95_lower'], color='green', linestyle='--', label='95% CI')\n",
    "axes[0].axvline(x=boot_result['ci_95_upper'], color='green', linestyle='--')\n",
    "axes[0].set_xlabel('Sharpe Ratio Difference (B - A)', fontsize=12)\n",
    "axes[0].set_ylabel('Density', fontsize=12)\n",
    "axes[0].set_title('Bootstrap Distribution of Sharpe Ratio Difference', \n",
    "                  fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparison bar chart\n",
    "sharpes = [jk_result['sharpe_a'], jk_result['sharpe_b']]\n",
    "names = ['Strategy A\\n(Control)', 'Strategy B\\n(Treatment)']\n",
    "colors = ['steelblue', 'seagreen']\n",
    "bars = axes[1].bar(names, sharpes, color=colors, edgecolor='black', alpha=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars, sharpes):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
    "                 f'{val:.3f}', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "axes[1].set_ylabel('Annualized Sharpe Ratio', fontsize=12)\n",
    "axes[1].set_title('Sharpe Ratio Comparison', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80ae8a4",
   "metadata": {},
   "source": [
    "## 10. Implement Sequential A/B Testing\n",
    "\n",
    "Traditional fixed-horizon tests require waiting until the predetermined sample size is reached. **Sequential testing** allows for early stopping when:\n",
    "- One strategy clearly outperforms the other\n",
    "- There's no detectable difference (futility)\n",
    "\n",
    "### Methods Covered\n",
    "1. **Sequential Probability Ratio Test (SPRT):** Wald's original sequential test\n",
    "2. **Group Sequential Design:** Periodic interim analyses with adjusted significance levels\n",
    "3. **Bayesian Stopping Rules:** Based on posterior probability thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bd35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialABTest:\n",
    "    \"\"\"\n",
    "    Sequential A/B Testing Framework for Trading Strategies.\n",
    "    Allows for early stopping while controlling Type I and Type II error rates.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.05, beta: float = 0.20,\n",
    "                 min_effect_size: float = 0.1):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        alpha : Type I error rate (false positive)\n",
    "        beta : Type II error rate (false negative)  \n",
    "        min_effect_size : Minimum detectable effect (in std units)\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.min_effect_size = min_effect_size\n",
    "        \n",
    "        # SPRT thresholds (log-likelihood ratio bounds)\n",
    "        self.upper_bound = np.log((1 - beta) / alpha)\n",
    "        self.lower_bound = np.log(beta / (1 - alpha))\n",
    "        \n",
    "    def sprt_log_likelihood(self, diff: float, std: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate log-likelihood ratio for a single observation.\n",
    "        H0: mean difference = 0\n",
    "        H1: mean difference = min_effect_size * std\n",
    "        \"\"\"\n",
    "        effect = self.min_effect_size * std\n",
    "        if std == 0:\n",
    "            return 0\n",
    "        # Log-likelihood ratio: log(P(data|H1) / P(data|H0))\n",
    "        return (diff * effect - 0.5 * effect**2) / (std**2)\n",
    "    \n",
    "    def run_sprt(self, returns_control: np.ndarray, \n",
    "                 returns_treatment: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Run Sequential Probability Ratio Test.\n",
    "        Returns test progress and stopping point if applicable.\n",
    "        \"\"\"\n",
    "        n = min(len(returns_control), len(returns_treatment))\n",
    "        \n",
    "        cumulative_llr = 0\n",
    "        llr_history = []\n",
    "        decisions = []\n",
    "        \n",
    "        for i in range(n):\n",
    "            # Paired difference\n",
    "            diff = returns_treatment[i] - returns_control[i]\n",
    "            \n",
    "            # Estimate std from data so far\n",
    "            if i > 10:\n",
    "                diffs_so_far = returns_treatment[:i+1] - returns_control[:i+1]\n",
    "                std = np.std(diffs_so_far)\n",
    "            else:\n",
    "                std = np.std(returns_treatment[:i+1] - returns_control[:i+1])\n",
    "                \n",
    "            if std > 0:\n",
    "                cumulative_llr += self.sprt_log_likelihood(diff, std)\n",
    "            \n",
    "            llr_history.append(cumulative_llr)\n",
    "            \n",
    "            # Decision\n",
    "            if cumulative_llr >= self.upper_bound:\n",
    "                decisions.append('Reject H0 (B > A)')\n",
    "            elif cumulative_llr <= self.lower_bound:\n",
    "                decisions.append('Accept H0 (No difference)')\n",
    "            else:\n",
    "                decisions.append('Continue')\n",
    "        \n",
    "        # Find first stopping point\n",
    "        stopping_point = None\n",
    "        final_decision = 'No conclusion (test continues)'\n",
    "        \n",
    "        for i, decision in enumerate(decisions):\n",
    "            if decision != 'Continue':\n",
    "                stopping_point = i + 1\n",
    "                final_decision = decision\n",
    "                break\n",
    "                \n",
    "        return {\n",
    "            'llr_history': np.array(llr_history),\n",
    "            'upper_bound': self.upper_bound,\n",
    "            'lower_bound': self.lower_bound,\n",
    "            'stopping_point': stopping_point,\n",
    "            'final_decision': final_decision,\n",
    "            'decisions': decisions\n",
    "        }\n",
    "    \n",
    "    def group_sequential_test(self, returns_control: np.ndarray,\n",
    "                              returns_treatment: np.ndarray,\n",
    "                              n_looks: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        Group Sequential Design with O'Brien-Fleming spending function.\n",
    "        Performs interim analyses at equally spaced intervals.\n",
    "        \"\"\"\n",
    "        n = min(len(returns_control), len(returns_treatment))\n",
    "        analysis_points = np.linspace(n // n_looks, n, n_looks, dtype=int)\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for i, look_n in enumerate(analysis_points):\n",
    "            # Get data up to this point\n",
    "            ctrl = returns_control[:look_n]\n",
    "            treat = returns_treatment[:look_n]\n",
    "            \n",
    "            # T-test\n",
    "            t_stat, p_value = ttest_ind(treat, ctrl)\n",
    "            \n",
    "            # O'Brien-Fleming boundary (alpha spending)\n",
    "            info_fraction = (i + 1) / n_looks\n",
    "            # Approximate O'Brien-Fleming boundary\n",
    "            z_boundary = norm.ppf(1 - self.alpha / 2) / np.sqrt(info_fraction)\n",
    "            alpha_spent = 2 * (1 - norm.cdf(z_boundary))\n",
    "            \n",
    "            # Decision\n",
    "            reject = p_value < alpha_spent\n",
    "            \n",
    "            results.append({\n",
    "                'look': i + 1,\n",
    "                'n_observations': look_n,\n",
    "                'info_fraction': info_fraction,\n",
    "                't_statistic': t_stat,\n",
    "                'p_value': p_value,\n",
    "                'alpha_boundary': alpha_spent,\n",
    "                'reject_h0': reject,\n",
    "                'mean_diff': np.mean(treat) - np.mean(ctrl)\n",
    "            })\n",
    "            \n",
    "            if reject:\n",
    "                break  # Early stopping\n",
    "                \n",
    "        return {\n",
    "            'interim_results': results,\n",
    "            'final_decision': results[-1],\n",
    "            'early_stopped': len(results) < n_looks\n",
    "        }\n",
    "\n",
    "\n",
    "# Run Sequential Tests\n",
    "seq_test = SequentialABTest(alpha=0.05, beta=0.20, min_effect_size=0.15)\n",
    "\n",
    "# SPRT\n",
    "sprt_result = seq_test.run_sprt(control_returns, treatment_returns)\n",
    "\n",
    "# Group Sequential\n",
    "gs_result = seq_test.group_sequential_test(control_returns, treatment_returns, n_looks=5)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"SEQUENTIAL A/B TESTING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nüìà Sequential Probability Ratio Test (SPRT):\")\n",
    "print(f\"  Upper Boundary (Reject H0): {sprt_result['upper_bound']:.4f}\")\n",
    "print(f\"  Lower Boundary (Accept H0): {sprt_result['lower_bound']:.4f}\")\n",
    "if sprt_result['stopping_point']:\n",
    "    print(f\"  Stopping Point: Day {sprt_result['stopping_point']}\")\n",
    "    print(f\"  Decision: {sprt_result['final_decision']}\")\n",
    "else:\n",
    "    print(f\"  Status: Test did not reach a conclusion\")\n",
    "    print(f\"  Final LLR: {sprt_result['llr_history'][-1]:.4f}\")\n",
    "\n",
    "print(\"\\nüìä Group Sequential Design (O'Brien-Fleming):\")\n",
    "print(f\"  Number of Interim Analyses: {len(gs_result['interim_results'])}\")\n",
    "print(f\"  Early Stopped: {'Yes' if gs_result['early_stopped'] else 'No'}\")\n",
    "print(\"\\n  Interim Analysis Results:\")\n",
    "print(\"  \" + \"-\" * 60)\n",
    "\n",
    "interim_df = pd.DataFrame(gs_result['interim_results'])\n",
    "interim_df['mean_diff_pct'] = interim_df['mean_diff'] * 100\n",
    "interim_df_display = interim_df[['look', 'n_observations', 'p_value', 'alpha_boundary', 'reject_h0']].copy()\n",
    "interim_df_display['p_value'] = interim_df_display['p_value'].apply(lambda x: f\"{x:.6f}\")\n",
    "interim_df_display['alpha_boundary'] = interim_df_display['alpha_boundary'].apply(lambda x: f\"{x:.6f}\")\n",
    "print(interim_df_display.to_string(index=False))\n",
    "\n",
    "# Visualize SPRT\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# SPRT trajectory\n",
    "x = np.arange(1, len(sprt_result['llr_history']) + 1)\n",
    "axes[0].plot(x, sprt_result['llr_history'], 'b-', linewidth=1.5, label='Log-Likelihood Ratio')\n",
    "axes[0].axhline(y=sprt_result['upper_bound'], color='green', linestyle='--', \n",
    "                linewidth=2, label=f'Reject H0 boundary ({sprt_result[\"upper_bound\"]:.2f})')\n",
    "axes[0].axhline(y=sprt_result['lower_bound'], color='red', linestyle='--', \n",
    "                linewidth=2, label=f'Accept H0 boundary ({sprt_result[\"lower_bound\"]:.2f})')\n",
    "axes[0].axhline(y=0, color='gray', linestyle='-', alpha=0.5)\n",
    "\n",
    "if sprt_result['stopping_point']:\n",
    "    axes[0].axvline(x=sprt_result['stopping_point'], color='orange', linestyle=':', \n",
    "                    linewidth=2, label=f'Stop at day {sprt_result[\"stopping_point\"]}')\n",
    "\n",
    "axes[0].fill_between(x, sprt_result['lower_bound'], sprt_result['upper_bound'], \n",
    "                     alpha=0.1, color='yellow', label='Continue testing region')\n",
    "axes[0].set_xlabel('Trading Day', fontsize=12)\n",
    "axes[0].set_ylabel('Cumulative Log-Likelihood Ratio', fontsize=12)\n",
    "axes[0].set_title('SPRT: Sequential Probability Ratio Test', fontsize=13, fontweight='bold')\n",
    "axes[0].legend(loc='best', fontsize=9)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Group Sequential boundaries\n",
    "looks = interim_df['look'].values\n",
    "p_values = interim_df['p_value'].apply(lambda x: float(x)).values\n",
    "alpha_boundaries = interim_df['alpha_boundary'].apply(lambda x: float(x)).values\n",
    "\n",
    "axes[1].plot(looks, p_values, 'bo-', markersize=10, linewidth=2, label='P-value')\n",
    "axes[1].plot(looks, alpha_boundaries, 'r--', linewidth=2, label='O\\'Brien-Fleming Boundary')\n",
    "axes[1].fill_between(looks, 0, alpha_boundaries, alpha=0.2, color='red', label='Rejection region')\n",
    "\n",
    "# Mark stopping point if applicable\n",
    "reject_indices = np.where(p_values < alpha_boundaries)[0]\n",
    "if len(reject_indices) > 0:\n",
    "    stop_idx = reject_indices[0]\n",
    "    axes[1].plot(looks[stop_idx], p_values[stop_idx], 'go', markersize=15, \n",
    "                 markeredgecolor='black', markeredgewidth=2, label='Early stop')\n",
    "\n",
    "axes[1].set_xlabel('Interim Analysis (Look)', fontsize=12)\n",
    "axes[1].set_ylabel('P-value / Alpha Boundary', fontsize=12)\n",
    "axes[1].set_title('Group Sequential Design: O\\'Brien-Fleming', fontsize=13, fontweight='bold')\n",
    "axes[1].legend(loc='best')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].set_xticks(looks)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8b6dd",
   "metadata": {},
   "source": [
    "## 11. Bayesian A/B Testing\n",
    "\n",
    "The Bayesian approach offers several advantages for trading strategy comparison:\n",
    "- Provides probability statements (\"95% probability B is better\")\n",
    "- Naturally handles sequential updates\n",
    "- Incorporates prior knowledge\n",
    "- Calculates expected loss from wrong decisions\n",
    "\n",
    "### Key Concepts\n",
    "- **Prior:** Initial belief about strategy performance\n",
    "- **Likelihood:** Evidence from observed returns\n",
    "- **Posterior:** Updated belief after seeing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672bdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianABTest:\n",
    "    \"\"\"\n",
    "    Bayesian A/B Testing for Trading Strategies.\n",
    "    Uses Normal-Inverse-Gamma conjugate prior for unknown mean and variance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prior_mean: float = 0.0, prior_std: float = 0.001,\n",
    "                 prior_df: float = 1.0):\n",
    "        \"\"\"\n",
    "        Initialize with prior parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        prior_mean : Prior mean for daily returns (usually 0 for no prior belief)\n",
    "        prior_std : Prior standard deviation for returns\n",
    "        prior_df : Prior degrees of freedom (strength of prior)\n",
    "        \"\"\"\n",
    "        self.prior_mean = prior_mean\n",
    "        self.prior_std = prior_std\n",
    "        self.prior_df = prior_df\n",
    "        \n",
    "    def update_posterior(self, returns: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Update posterior parameters given observed returns.\n",
    "        Using Normal-Gamma conjugate update.\n",
    "        \"\"\"\n",
    "        n = len(returns)\n",
    "        sample_mean = np.mean(returns)\n",
    "        sample_var = np.var(returns, ddof=1) if n > 1 else self.prior_std**2\n",
    "        \n",
    "        # Posterior parameters\n",
    "        posterior_df = self.prior_df + n\n",
    "        \n",
    "        # Posterior mean (weighted average of prior and sample)\n",
    "        weight_prior = self.prior_df / (self.prior_df + n)\n",
    "        weight_data = n / (self.prior_df + n)\n",
    "        posterior_mean = weight_prior * self.prior_mean + weight_data * sample_mean\n",
    "        \n",
    "        # Posterior variance\n",
    "        prior_ss = self.prior_df * self.prior_std**2\n",
    "        data_ss = (n - 1) * sample_var if n > 1 else 0\n",
    "        mean_adjustment = (self.prior_df * n) / (self.prior_df + n) * (sample_mean - self.prior_mean)**2\n",
    "        \n",
    "        posterior_var = (prior_ss + data_ss + mean_adjustment) / posterior_df\n",
    "        posterior_std = np.sqrt(posterior_var)\n",
    "        \n",
    "        return {\n",
    "            'mean': posterior_mean,\n",
    "            'std': posterior_std,\n",
    "            'df': posterior_df,\n",
    "            'n': n\n",
    "        }\n",
    "    \n",
    "    def probability_b_better(self, returns_a: np.ndarray, returns_b: np.ndarray,\n",
    "                             n_samples: int = 100000) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate P(Strategy B > Strategy A) using Monte Carlo sampling.\n",
    "        \"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        # Get posteriors\n",
    "        post_a = self.update_posterior(returns_a)\n",
    "        post_b = self.update_posterior(returns_b)\n",
    "        \n",
    "        # Sample from posterior t-distributions\n",
    "        samples_a = post_a['mean'] + post_a['std'] * np.random.standard_t(post_a['df'], n_samples)\n",
    "        samples_b = post_b['mean'] + post_b['std'] * np.random.standard_t(post_b['df'], n_samples)\n",
    "        \n",
    "        # Probability B > A\n",
    "        prob_b_better = (samples_b > samples_a).mean()\n",
    "        \n",
    "        # Expected loss (if we wrongly choose B when A is better)\n",
    "        loss_choosing_b = np.maximum(samples_a - samples_b, 0).mean()\n",
    "        loss_choosing_a = np.maximum(samples_b - samples_a, 0).mean()\n",
    "        \n",
    "        # 95% credible interval for difference\n",
    "        diff_samples = samples_b - samples_a\n",
    "        ci_lower = np.percentile(diff_samples, 2.5)\n",
    "        ci_upper = np.percentile(diff_samples, 97.5)\n",
    "        \n",
    "        return {\n",
    "            'prob_b_better': prob_b_better,\n",
    "            'prob_a_better': 1 - prob_b_better,\n",
    "            'expected_loss_choose_b': loss_choosing_b,\n",
    "            'expected_loss_choose_a': loss_choosing_a,\n",
    "            'mean_diff': np.mean(diff_samples),\n",
    "            'ci_95_lower': ci_lower,\n",
    "            'ci_95_upper': ci_upper,\n",
    "            'samples_a': samples_a,\n",
    "            'samples_b': samples_b,\n",
    "            'posterior_a': post_a,\n",
    "            'posterior_b': post_b\n",
    "        }\n",
    "    \n",
    "    def sequential_bayesian(self, returns_a: np.ndarray, returns_b: np.ndarray,\n",
    "                            prob_threshold: float = 0.95) -> Dict:\n",
    "        \"\"\"\n",
    "        Sequential Bayesian analysis with probability threshold stopping.\n",
    "        \"\"\"\n",
    "        n = min(len(returns_a), len(returns_b))\n",
    "        \n",
    "        history = []\n",
    "        stopped_at = None\n",
    "        \n",
    "        for i in range(20, n, 5):  # Start after 20 days, check every 5 days\n",
    "            result = self.probability_b_better(returns_a[:i], returns_b[:i], n_samples=10000)\n",
    "            \n",
    "            history.append({\n",
    "                'day': i,\n",
    "                'prob_b_better': result['prob_b_better'],\n",
    "                'mean_diff': result['mean_diff'] * 252,  # Annualized\n",
    "                'expected_loss_b': result['expected_loss_choose_b'] * 252\n",
    "            })\n",
    "            \n",
    "            # Stopping criterion\n",
    "            if result['prob_b_better'] >= prob_threshold or result['prob_a_better'] >= prob_threshold:\n",
    "                stopped_at = i\n",
    "                break\n",
    "                \n",
    "        return {\n",
    "            'history': history,\n",
    "            'stopped_at': stopped_at,\n",
    "            'final_prob_b_better': history[-1]['prob_b_better']\n",
    "        }\n",
    "\n",
    "\n",
    "# Run Bayesian A/B Test\n",
    "bayes_test = BayesianABTest(prior_mean=0.0, prior_std=0.01, prior_df=1.0)\n",
    "\n",
    "# Full analysis\n",
    "bayes_result = bayes_test.probability_b_better(control_returns, treatment_returns)\n",
    "\n",
    "# Sequential analysis\n",
    "seq_bayes = bayes_test.sequential_bayesian(control_returns, treatment_returns, prob_threshold=0.95)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"BAYESIAN A/B TESTING RESULTS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Posterior Summary:\")\n",
    "print(f\"\\n  Strategy A (Control):\")\n",
    "print(f\"    Posterior Mean (Daily): {100*bayes_result['posterior_a']['mean']:.4f}%\")\n",
    "print(f\"    Posterior Std: {100*bayes_result['posterior_a']['std']:.4f}%\")\n",
    "\n",
    "print(f\"\\n  Strategy B (Treatment):\")\n",
    "print(f\"    Posterior Mean (Daily): {100*bayes_result['posterior_b']['mean']:.4f}%\")\n",
    "print(f\"    Posterior Std: {100*bayes_result['posterior_b']['std']:.4f}%\")\n",
    "\n",
    "print(f\"\\nüéØ Key Results:\")\n",
    "print(f\"  P(Strategy B > Strategy A): {100*bayes_result['prob_b_better']:.2f}%\")\n",
    "print(f\"  P(Strategy A > Strategy B): {100*bayes_result['prob_a_better']:.2f}%\")\n",
    "print(f\"\\n  95% Credible Interval for Difference (Daily):\")\n",
    "print(f\"    [{100*bayes_result['ci_95_lower']:.4f}%, {100*bayes_result['ci_95_upper']:.4f}%]\")\n",
    "\n",
    "print(f\"\\nüí∞ Expected Loss Analysis (Annualized):\")\n",
    "print(f\"  If we choose Strategy B (and A is actually better): {100*bayes_result['expected_loss_choose_b']*252:.2f}%\")\n",
    "print(f\"  If we choose Strategy A (and B is actually better): {100*bayes_result['expected_loss_choose_a']*252:.2f}%\")\n",
    "\n",
    "# Recommendation\n",
    "print(f\"\\nüìã RECOMMENDATION:\")\n",
    "if bayes_result['prob_b_better'] >= 0.95:\n",
    "    print(\"  ‚úÖ Strong evidence that Strategy B is better (>95% probability)\")\n",
    "    print(\"  ‚û°Ô∏è  Consider deploying Strategy B\")\n",
    "elif bayes_result['prob_b_better'] >= 0.80:\n",
    "    print(\"  üî∂ Moderate evidence that Strategy B is better (80-95% probability)\")\n",
    "    print(\"  ‚û°Ô∏è  Continue testing or deploy with caution\")\n",
    "elif bayes_result['prob_b_better'] >= 0.50:\n",
    "    print(\"  ‚öñÔ∏è  Inconclusive: No clear winner\")\n",
    "    print(\"  ‚û°Ô∏è  Continue testing to gather more evidence\")\n",
    "else:\n",
    "    print(\"  üî¥ Evidence suggests Strategy A is better\")\n",
    "    print(\"  ‚û°Ô∏è  Keep Strategy A, abandon Strategy B\")\n",
    "\n",
    "# Visualize Bayesian results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Posterior distributions\n",
    "x_range = np.linspace(\n",
    "    min(bayes_result['samples_a'].min(), bayes_result['samples_b'].min()),\n",
    "    max(bayes_result['samples_a'].max(), bayes_result['samples_b'].max()),\n",
    "    100\n",
    ")\n",
    "\n",
    "axes[0, 0].hist(bayes_result['samples_a'] * 100, bins=50, density=True, \n",
    "                alpha=0.6, label='Strategy A', color='blue')\n",
    "axes[0, 0].hist(bayes_result['samples_b'] * 100, bins=50, density=True, \n",
    "                alpha=0.6, label='Strategy B', color='green')\n",
    "axes[0, 0].axvline(x=0, color='red', linestyle='--', label='Zero')\n",
    "axes[0, 0].set_xlabel('Daily Return (%)', fontsize=11)\n",
    "axes[0, 0].set_ylabel('Density', fontsize=11)\n",
    "axes[0, 0].set_title('Posterior Distributions of Mean Return', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Difference distribution\n",
    "diff = bayes_result['samples_b'] - bayes_result['samples_a']\n",
    "axes[0, 1].hist(diff * 100, bins=50, density=True, alpha=0.7, \n",
    "                color='purple', edgecolor='black')\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='No Difference')\n",
    "axes[0, 1].axvline(x=bayes_result['ci_95_lower']*100, color='green', linestyle='--', label='95% CI')\n",
    "axes[0, 1].axvline(x=bayes_result['ci_95_upper']*100, color='green', linestyle='--')\n",
    "axes[0, 1].fill_between(\n",
    "    np.linspace(diff.min()*100, 0, 50),\n",
    "    0, 5,\n",
    "    alpha=0.2, color='red', label=f'P(A>B)={100*bayes_result[\"prob_a_better\"]:.1f}%'\n",
    ")\n",
    "axes[0, 1].set_xlabel('Difference in Daily Return (B - A) (%)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Density', fontsize=11)\n",
    "axes[0, 1].set_title('Posterior Distribution of Difference', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Sequential probability evolution\n",
    "if seq_bayes['history']:\n",
    "    days = [h['day'] for h in seq_bayes['history']]\n",
    "    probs = [h['prob_b_better'] for h in seq_bayes['history']]\n",
    "    \n",
    "    axes[1, 0].plot(days, probs, 'b-o', linewidth=2, markersize=6)\n",
    "    axes[1, 0].axhline(y=0.95, color='green', linestyle='--', label='95% threshold')\n",
    "    axes[1, 0].axhline(y=0.50, color='gray', linestyle='--', alpha=0.5, label='50% (no preference)')\n",
    "    axes[1, 0].axhline(y=0.05, color='red', linestyle='--', label='5% threshold')\n",
    "    axes[1, 0].fill_between(days, 0.95, 1.0, alpha=0.2, color='green', label='Conclude B better')\n",
    "    axes[1, 0].fill_between(days, 0.0, 0.05, alpha=0.2, color='red', label='Conclude A better')\n",
    "    \n",
    "    if seq_bayes['stopped_at']:\n",
    "        axes[1, 0].axvline(x=seq_bayes['stopped_at'], color='orange', linestyle=':', \n",
    "                           linewidth=2, label=f'Early stop (day {seq_bayes[\"stopped_at\"]})')\n",
    "    \n",
    "    axes[1, 0].set_xlabel('Trading Day', fontsize=11)\n",
    "    axes[1, 0].set_ylabel('P(Strategy B > Strategy A)', fontsize=11)\n",
    "    axes[1, 0].set_title('Sequential Bayesian: Probability Evolution', fontsize=12, fontweight='bold')\n",
    "    axes[1, 0].legend(loc='center right', fontsize=9)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    axes[1, 0].set_ylim(0, 1)\n",
    "\n",
    "# 4. Expected loss over time\n",
    "if seq_bayes['history']:\n",
    "    losses = [h['expected_loss_b'] * 100 for h in seq_bayes['history']]\n",
    "    \n",
    "    axes[1, 1].plot(days, losses, 'r-o', linewidth=2, markersize=6)\n",
    "    axes[1, 1].fill_between(days, 0, losses, alpha=0.3, color='red')\n",
    "    axes[1, 1].set_xlabel('Trading Day', fontsize=11)\n",
    "    axes[1, 1].set_ylabel('Expected Loss if B is Wrong (%)', fontsize=11)\n",
    "    axes[1, 1].set_title('Expected Loss from Choosing B (Annualized)', fontsize=12, fontweight='bold')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
