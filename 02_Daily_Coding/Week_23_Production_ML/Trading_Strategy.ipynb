{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecd580a1",
   "metadata": {},
   "source": [
    "# Week 23: Production ML Trading Strategy\n",
    "\n",
    "## MLOps-Ready Trading System\n",
    "\n",
    "### Overview\n",
    "This notebook implements a production-grade trading strategy with:\n",
    "- Feature store integration\n",
    "- Model versioning and A/B testing\n",
    "- Real-time monitoring and alerting\n",
    "- Automated retraining pipeline\n",
    "\n",
    "### Tickers: AAPL, MSFT, GOOGL, JPM, GS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd779288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries loaded!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import yfinance as yf\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from abc import ABC, abstractmethod\n",
    "from enum import Enum\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "print(\"âœ… Libraries loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7044d",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959d6b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production Config Loaded\n",
      "  Tickers: ['AAPL', 'MSFT', 'GOOGL', 'JPM', 'GS']\n",
      "  Date Range: 2019-01-01 to 2026-01-24\n"
     ]
    }
   ],
   "source": [
    "# Production configuration\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'JPM', 'GS']\n",
    "START_DATE = '2019-01-01'\n",
    "END_DATE = datetime.now().strftime('%Y-%m-%d')\n",
    "INITIAL_CAPITAL = 100_000\n",
    "RISK_FREE_RATE = 0.05\n",
    "\n",
    "# Model configuration\n",
    "RETRAIN_THRESHOLD = 0.05  # Retrain if performance drops 5%\n",
    "DRIFT_THRESHOLD = 0.1    # Alert if feature drift > 10%\n",
    "MIN_CONFIDENCE = 0.6     # Minimum confidence for trade\n",
    "\n",
    "print(f\"Production Config Loaded\")\n",
    "print(f\"  Tickers: {TICKERS}\")\n",
    "print(f\"  Date Range: {START_DATE} to {END_DATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c902843",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8943168f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Fetching market data...\n",
      "âœ… Data loaded: 1775 observations\n"
     ]
    }
   ],
   "source": [
    "class DataPipeline:\n",
    "    \"\"\"Production data pipeline with validation.\"\"\"\n",
    "    \n",
    "    def __init__(self, tickers: List[str]):\n",
    "        self.tickers = tickers\n",
    "        self.data_cache = {}\n",
    "        \n",
    "    def fetch_data(self, start: str, end: str) -> Dict[str, pd.DataFrame]:\n",
    "        \"\"\"Fetch and validate market data.\"\"\"\n",
    "        print(\"ðŸ“¥ Fetching market data...\")\n",
    "        \n",
    "        data = yf.download(\n",
    "            self.tickers,\n",
    "            start=start,\n",
    "            end=end,\n",
    "            progress=False,\n",
    "            auto_adjust=True\n",
    "        )\n",
    "        \n",
    "        # Validate data quality\n",
    "        self._validate_data(data)\n",
    "        \n",
    "        self.data_cache = {\n",
    "            'prices': data['Close'].dropna(),\n",
    "            'volume': data['Volume'].dropna(),\n",
    "            'high': data['High'].dropna(),\n",
    "            'low': data['Low'].dropna()\n",
    "        }\n",
    "        \n",
    "        self.data_cache['returns'] = self.data_cache['prices'].pct_change().dropna()\n",
    "        \n",
    "        print(f\"âœ… Data loaded: {len(self.data_cache['prices'])} observations\")\n",
    "        return self.data_cache\n",
    "    \n",
    "    def _validate_data(self, data: pd.DataFrame) -> None:\n",
    "        \"\"\"Validate data quality.\"\"\"\n",
    "        # Check for missing values\n",
    "        missing_pct = data.isnull().sum().sum() / data.size\n",
    "        if missing_pct > 0.05:\n",
    "            raise ValueError(f\"Data quality issue: {missing_pct:.1%} missing values\")\n",
    "        \n",
    "        # Check for outliers (>10 sigma moves)\n",
    "        returns = data['Close'].pct_change()\n",
    "        outliers = (returns.abs() > 0.3).sum().sum()\n",
    "        if outliers > 0:\n",
    "            print(f\"âš ï¸ Warning: {outliers} extreme moves detected\")\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = DataPipeline(TICKERS)\n",
    "data = pipeline.fetch_data(START_DATE, END_DATE)\n",
    "\n",
    "prices = data['prices']\n",
    "returns = data['returns']\n",
    "volume = data['volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba72b5",
   "metadata": {},
   "source": [
    "## 3. Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d54924",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Feature:\n",
    "    \"\"\"Feature metadata.\"\"\"\n",
    "    name: str\n",
    "    version: str\n",
    "    description: str\n",
    "    created_at: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class FeatureStore:\n",
    "    \"\"\"Simple feature store for ML pipelines.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.features = {}\n",
    "        self.metadata = {}\n",
    "        \n",
    "    def add_feature(self, name: str, data: pd.DataFrame, description: str) -> None:\n",
    "        \"\"\"Add feature to store.\"\"\"\n",
    "        version = hashlib.md5(str(data.values.tobytes()).encode()).hexdigest()[:8]\n",
    "        self.features[name] = data\n",
    "        self.metadata[name] = Feature(name, version, description)\n",
    "        \n",
    "    def get_feature(self, name: str) -> pd.DataFrame:\n",
    "        \"\"\"Retrieve feature from store.\"\"\"\n",
    "        return self.features.get(name)\n",
    "    \n",
    "    def compute_features(self, prices: pd.DataFrame, returns: pd.DataFrame,\n",
    "                        volume: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Compute and store all features.\"\"\"\n",
    "        all_features = pd.DataFrame(index=prices.index)\n",
    "        \n",
    "        for ticker in prices.columns:\n",
    "            # Momentum features\n",
    "            all_features[f'{ticker}_mom_5d'] = prices[ticker].pct_change(5)\n",
    "            all_features[f'{ticker}_mom_20d'] = prices[ticker].pct_change(20)\n",
    "            \n",
    "            # Volatility features\n",
    "            all_features[f'{ticker}_vol_20d'] = returns[ticker].rolling(20).std() * np.sqrt(252)\n",
    "            \n",
    "            # Technical features\n",
    "            sma_20 = prices[ticker].rolling(20).mean()\n",
    "            sma_50 = prices[ticker].rolling(50).mean()\n",
    "            all_features[f'{ticker}_price_sma20'] = prices[ticker] / sma_20 - 1\n",
    "            all_features[f'{ticker}_sma20_sma50'] = sma_20 / sma_50 - 1\n",
    "            \n",
    "            # RSI\n",
    "            delta = prices[ticker].diff()\n",
    "            gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "            loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "            rs = gain / loss\n",
    "            all_features[f'{ticker}_rsi'] = 100 - (100 / (1 + rs))\n",
    "            \n",
    "            # Volume\n",
    "            all_features[f'{ticker}_vol_ratio'] = volume[ticker] / volume[ticker].rolling(20).mean()\n",
    "        \n",
    "        # Store features\n",
    "        self.add_feature('all_features', all_features, 'Complete feature set')\n",
    "        \n",
    "        return all_features.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "# Build feature store\n",
    "print(\"\\nðŸ”§ Building feature store...\")\n",
    "feature_store = FeatureStore()\n",
    "features = feature_store.compute_features(prices, returns, volume)\n",
    "print(f\"âœ… Features computed: {features.shape[1]} features, {len(features)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa36b6f",
   "metadata": {},
   "source": [
    "## 4. Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelMetadata:\n",
    "    \"\"\"Model metadata for registry.\"\"\"\n",
    "    name: str\n",
    "    version: str\n",
    "    ticker: str\n",
    "    accuracy: float\n",
    "    precision: float\n",
    "    f1: float\n",
    "    trained_at: datetime\n",
    "    is_production: bool = False\n",
    "\n",
    "class ModelRegistry:\n",
    "    \"\"\"Model versioning and deployment registry.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.metadata = {}\n",
    "        self.production_models = {}\n",
    "        self.scalers = {}\n",
    "        \n",
    "    def register_model(self, model, ticker: str, metrics: Dict[str, float],\n",
    "                      scaler: StandardScaler) -> str:\n",
    "        \"\"\"Register a trained model.\"\"\"\n",
    "        version = f\"v{len([k for k in self.metadata.keys() if ticker in k]) + 1}\"\n",
    "        key = f\"{ticker}_{version}\"\n",
    "        \n",
    "        self.models[key] = model\n",
    "        self.scalers[key] = scaler\n",
    "        self.metadata[key] = ModelMetadata(\n",
    "            name=type(model).__name__,\n",
    "            version=version,\n",
    "            ticker=ticker,\n",
    "            accuracy=metrics['accuracy'],\n",
    "            precision=metrics['precision'],\n",
    "            f1=metrics['f1'],\n",
    "            trained_at=datetime.now()\n",
    "        )\n",
    "        \n",
    "        return key\n",
    "    \n",
    "    def promote_to_production(self, key: str) -> None:\n",
    "        \"\"\"Promote model to production.\"\"\"\n",
    "        if key not in self.models:\n",
    "            raise ValueError(f\"Model {key} not found\")\n",
    "        \n",
    "        ticker = self.metadata[key].ticker\n",
    "        \n",
    "        # Demote current production model\n",
    "        if ticker in self.production_models:\n",
    "            old_key = self.production_models[ticker]\n",
    "            self.metadata[old_key].is_production = False\n",
    "        \n",
    "        # Promote new model\n",
    "        self.production_models[ticker] = key\n",
    "        self.metadata[key].is_production = True\n",
    "        print(f\"âœ… Promoted {key} to production for {ticker}\")\n",
    "    \n",
    "    def get_production_model(self, ticker: str):\n",
    "        \"\"\"Get production model for ticker.\"\"\"\n",
    "        key = self.production_models.get(ticker)\n",
    "        if key:\n",
    "            return self.models[key], self.scalers[key]\n",
    "        return None, None\n",
    "    \n",
    "    def list_models(self) -> pd.DataFrame:\n",
    "        \"\"\"List all registered models.\"\"\"\n",
    "        records = []\n",
    "        for key, meta in self.metadata.items():\n",
    "            records.append({\n",
    "                'Key': key,\n",
    "                'Model': meta.name,\n",
    "                'Ticker': meta.ticker,\n",
    "                'Accuracy': f\"{meta.accuracy:.1%}\",\n",
    "                'F1': f\"{meta.f1:.2f}\",\n",
    "                'Production': 'âœ“' if meta.is_production else ''\n",
    "            })\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "registry = ModelRegistry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c64fb2d",
   "metadata": {},
   "source": [
    "## 5. Model Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d62c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingPipeline:\n",
    "    \"\"\"Production training pipeline.\"\"\"\n",
    "    \n",
    "    def __init__(self, registry: ModelRegistry):\n",
    "        self.registry = registry\n",
    "        self.model_configs = {\n",
    "            'rf': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "            'gbm': GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42),\n",
    "            'logistic': LogisticRegression(C=0.1, max_iter=1000)\n",
    "        }\n",
    "    \n",
    "    def prepare_data(self, features: pd.DataFrame, returns: pd.DataFrame,\n",
    "                    ticker: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"Prepare training data.\"\"\"\n",
    "        ticker_cols = [c for c in features.columns if ticker in c]\n",
    "        X = features[ticker_cols].copy()\n",
    "        \n",
    "        # Target: next 5-day return direction\n",
    "        future_ret = returns[ticker].shift(-5)\n",
    "        y = (future_ret > 0).astype(int)\n",
    "        \n",
    "        # Align\n",
    "        common_idx = X.index.intersection(y.dropna().index)\n",
    "        return X.loc[common_idx], y.loc[common_idx]\n",
    "    \n",
    "    def train_models(self, features: pd.DataFrame, returns: pd.DataFrame,\n",
    "                    ticker: str, train_end: str) -> Dict[str, str]:\n",
    "        \"\"\"Train all model types for a ticker.\"\"\"\n",
    "        X, y = self.prepare_data(features, returns, ticker)\n",
    "        \n",
    "        # Train/test split\n",
    "        train_mask = X.index <= train_end\n",
    "        X_train, y_train = X[train_mask], y[train_mask]\n",
    "        X_test, y_test = X[~train_mask], y[~train_mask]\n",
    "        \n",
    "        # Scale\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        registered_keys = {}\n",
    "        best_f1 = 0\n",
    "        best_key = None\n",
    "        \n",
    "        for name, model_template in self.model_configs.items():\n",
    "            # Train\n",
    "            model = type(model_template)(**model_template.get_params())\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Evaluate\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            metrics = {\n",
    "                'accuracy': accuracy_score(y_test, y_pred),\n",
    "                'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "                'f1': f1_score(y_test, y_pred, zero_division=0)\n",
    "            }\n",
    "            \n",
    "            # Register\n",
    "            key = self.registry.register_model(model, ticker, metrics, scaler)\n",
    "            registered_keys[name] = key\n",
    "            \n",
    "            if metrics['f1'] > best_f1:\n",
    "                best_f1 = metrics['f1']\n",
    "                best_key = key\n",
    "        \n",
    "        # Promote best model\n",
    "        if best_key:\n",
    "            self.registry.promote_to_production(best_key)\n",
    "        \n",
    "        return registered_keys\n",
    "\n",
    "# Train models\n",
    "print(\"\\nðŸ¤– Training production models...\")\n",
    "training_pipeline = TrainingPipeline(registry)\n",
    "train_end = features.index[int(len(features) * 0.8)].strftime('%Y-%m-%d')\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    keys = training_pipeline.train_models(features, returns, ticker, train_end)\n",
    "    print(f\"   âœ“ Trained models for {ticker}\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Model Registry:\")\n",
    "print(registry.list_models().to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b6a74b",
   "metadata": {},
   "source": [
    "## 6. Monitoring & Alerts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ba3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlertType(Enum):\n",
    "    INFO = \"â„¹ï¸\"\n",
    "    WARNING = \"âš ï¸\"\n",
    "    CRITICAL = \"ðŸš¨\"\n",
    "\n",
    "@dataclass\n",
    "class Alert:\n",
    "    type: AlertType\n",
    "    message: str\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "class MonitoringSystem:\n",
    "    \"\"\"Production monitoring for trading system.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.alerts = []\n",
    "        self.metrics_history = []\n",
    "        \n",
    "    def check_model_drift(self, current_accuracy: float, baseline_accuracy: float) -> Optional[Alert]:\n",
    "        \"\"\"Check for model performance drift.\"\"\"\n",
    "        drift = baseline_accuracy - current_accuracy\n",
    "        \n",
    "        if drift > RETRAIN_THRESHOLD:\n",
    "            alert = Alert(\n",
    "                AlertType.CRITICAL,\n",
    "                f\"Model drift detected: {drift:.1%} accuracy drop. Retrain recommended.\"\n",
    "            )\n",
    "            self.alerts.append(alert)\n",
    "            return alert\n",
    "        elif drift > RETRAIN_THRESHOLD / 2:\n",
    "            alert = Alert(\n",
    "                AlertType.WARNING,\n",
    "                f\"Minor model drift: {drift:.1%} accuracy drop.\"\n",
    "            )\n",
    "            self.alerts.append(alert)\n",
    "            return alert\n",
    "        return None\n",
    "    \n",
    "    def check_feature_drift(self, current_features: pd.DataFrame, \n",
    "                           baseline_features: pd.DataFrame) -> List[Alert]:\n",
    "        \"\"\"Check for feature distribution drift.\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        for col in current_features.columns:\n",
    "            current_mean = current_features[col].mean()\n",
    "            baseline_mean = baseline_features[col].mean()\n",
    "            baseline_std = baseline_features[col].std()\n",
    "            \n",
    "            if baseline_std > 0:\n",
    "                drift = abs(current_mean - baseline_mean) / baseline_std\n",
    "                if drift > DRIFT_THRESHOLD * 10:\n",
    "                    alert = Alert(\n",
    "                        AlertType.WARNING,\n",
    "                        f\"Feature drift in {col}: {drift:.1f} std devs from baseline\"\n",
    "                    )\n",
    "                    alerts.append(alert)\n",
    "        \n",
    "        self.alerts.extend(alerts)\n",
    "        return alerts\n",
    "    \n",
    "    def log_prediction(self, ticker: str, prediction: float, confidence: float) -> None:\n",
    "        \"\"\"Log prediction for monitoring.\"\"\"\n",
    "        self.metrics_history.append({\n",
    "            'timestamp': datetime.now(),\n",
    "            'ticker': ticker,\n",
    "            'prediction': prediction,\n",
    "            'confidence': confidence\n",
    "        })\n",
    "    \n",
    "    def get_alerts(self, alert_type: Optional[AlertType] = None) -> List[Alert]:\n",
    "        \"\"\"Get alerts, optionally filtered by type.\"\"\"\n",
    "        if alert_type:\n",
    "            return [a for a in self.alerts if a.type == alert_type]\n",
    "        return self.alerts\n",
    "\n",
    "monitor = MonitoringSystem()\n",
    "print(\"âœ… Monitoring system initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32160926",
   "metadata": {},
   "source": [
    "## 7. Generate Trading Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe853f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals(features: pd.DataFrame, registry: ModelRegistry,\n",
    "                    monitor: MonitoringSystem) -> pd.DataFrame:\n",
    "    \"\"\"Generate production trading signals.\"\"\"\n",
    "    signals = []\n",
    "    \n",
    "    for ticker in TICKERS:\n",
    "        model, scaler = registry.get_production_model(ticker)\n",
    "        \n",
    "        if model is None:\n",
    "            continue\n",
    "        \n",
    "        # Get features\n",
    "        ticker_cols = [c for c in features.columns if ticker in c]\n",
    "        X = features[ticker_cols].iloc[-1:]\n",
    "        X_scaled = scaler.transform(X)\n",
    "        \n",
    "        # Predict\n",
    "        prob = model.predict_proba(X_scaled)[0, 1]\n",
    "        prediction = 1 if prob > 0.5 else 0\n",
    "        confidence = abs(prob - 0.5) * 2\n",
    "        \n",
    "        # Log for monitoring\n",
    "        monitor.log_prediction(ticker, prediction, confidence)\n",
    "        \n",
    "        # Determine signal\n",
    "        if prob > 0.65:\n",
    "            signal = \"STRONG BUY\"\n",
    "        elif prob > 0.55:\n",
    "            signal = \"BUY\"\n",
    "        elif prob < 0.35:\n",
    "            signal = \"STRONG SELL\"\n",
    "        elif prob < 0.45:\n",
    "            signal = \"SELL\"\n",
    "        else:\n",
    "            signal = \"HOLD\"\n",
    "        \n",
    "        signals.append({\n",
    "            'Ticker': ticker,\n",
    "            'Price': prices[ticker].iloc[-1],\n",
    "            'Signal': signal,\n",
    "            'Probability': f\"{prob:.1%}\",\n",
    "            'Confidence': f\"{confidence:.1%}\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(signals)\n",
    "\n",
    "# Generate signals\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸŽ¯ PRODUCTION TRADING SIGNALS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print()\n",
    "\n",
    "signals_df = generate_signals(features, registry, monitor)\n",
    "print(signals_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f7b0b",
   "metadata": {},
   "source": [
    "## 8. Detailed Signal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffd1e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ“Š DETAILED SIGNAL ANALYSIS\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "for ticker in TICKERS:\n",
    "    model, scaler = registry.get_production_model(ticker)\n",
    "    if model is None:\n",
    "        continue\n",
    "    \n",
    "    # Current metrics\n",
    "    price = prices[ticker].iloc[-1]\n",
    "    ret_20d = prices[ticker].iloc[-1] / prices[ticker].iloc[-20] - 1\n",
    "    vol_20d = returns[ticker].tail(20).std() * np.sqrt(252)\n",
    "    \n",
    "    # Get prediction\n",
    "    ticker_cols = [c for c in features.columns if ticker in c]\n",
    "    X = features[ticker_cols].iloc[-1:]\n",
    "    X_scaled = scaler.transform(X)\n",
    "    prob = model.predict_proba(X_scaled)[0, 1]\n",
    "    \n",
    "    # Position sizing\n",
    "    confidence = abs(prob - 0.5) * 2\n",
    "    if confidence < MIN_CONFIDENCE:\n",
    "        position_size = 0\n",
    "    else:\n",
    "        target_vol = 0.15\n",
    "        vol_adj = min(target_vol / vol_20d, 2.0) if vol_20d > 0 else 1.0\n",
    "        position_size = min(0.25 * vol_adj * confidence, 0.25) * INITIAL_CAPITAL\n",
    "    \n",
    "    shares = int(position_size / price) if price > 0 else 0\n",
    "    \n",
    "    print(f\"{'â”€'*25} {ticker} {'â”€'*25}\")\n",
    "    print(f\"   Current Price:    ${price:.2f}\")\n",
    "    print(f\"   20d Return:       {ret_20d*100:+.2f}%\")\n",
    "    print(f\"   20d Volatility:   {vol_20d*100:.1f}%\")\n",
    "    print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"   Model:            {type(model).__name__}\")\n",
    "    print(f\"   Probability:      {prob*100:.1f}%\")\n",
    "    print(f\"   Confidence:       {confidence*100:.1f}%\")\n",
    "    print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
    "    print(f\"   Position Size:    ${position_size:,.0f}\")\n",
    "    print(f\"   Shares:           {shares}\")\n",
    "    print(f\"   Stop Loss:        ${price * 0.95:.2f} (-5%)\")\n",
    "    print(f\"   Take Profit:      ${price * 1.10:.2f} (+10%)\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e210a9",
   "metadata": {},
   "source": [
    "## 9. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ec72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Recent price performance\n",
    "ax1 = axes[0, 0]\n",
    "for ticker in TICKERS:\n",
    "    normalized = prices[ticker].tail(60) / prices[ticker].iloc[-60]\n",
    "    ax1.plot(normalized, label=ticker, linewidth=1.5)\n",
    "ax1.axhline(1, color='black', linestyle='--', linewidth=0.5)\n",
    "ax1.set_title('60-Day Price Performance (Normalized)', fontweight='bold')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Volatility comparison\n",
    "ax2 = axes[0, 1]\n",
    "vols = {ticker: returns[ticker].tail(20).std() * np.sqrt(252) for ticker in TICKERS}\n",
    "colors = ['green' if v < 0.25 else 'orange' if v < 0.35 else 'red' for v in vols.values()]\n",
    "ax2.bar(vols.keys(), [v * 100 for v in vols.values()], color=colors, alpha=0.7)\n",
    "ax2.axhline(25, color='green', linestyle='--', linewidth=1, alpha=0.5, label='Low Vol')\n",
    "ax2.axhline(35, color='red', linestyle='--', linewidth=1, alpha=0.5, label='High Vol')\n",
    "ax2.set_title('20-Day Annualized Volatility', fontweight='bold')\n",
    "ax2.set_ylabel('Volatility (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Signal probabilities\n",
    "ax3 = axes[1, 0]\n",
    "probs = []\n",
    "for ticker in TICKERS:\n",
    "    model, scaler = registry.get_production_model(ticker)\n",
    "    if model:\n",
    "        ticker_cols = [c for c in features.columns if ticker in c]\n",
    "        X = features[ticker_cols].iloc[-1:]\n",
    "        X_scaled = scaler.transform(X)\n",
    "        prob = model.predict_proba(X_scaled)[0, 1]\n",
    "        probs.append(prob)\n",
    "    else:\n",
    "        probs.append(0.5)\n",
    "\n",
    "colors = ['green' if p > 0.55 else 'red' if p < 0.45 else 'gray' for p in probs]\n",
    "ax3.barh(TICKERS, probs, color=colors, alpha=0.7)\n",
    "ax3.axvline(0.5, color='black', linestyle='--', linewidth=1)\n",
    "ax3.axvline(0.55, color='green', linestyle=':', linewidth=1, alpha=0.5)\n",
    "ax3.axvline(0.45, color='red', linestyle=':', linewidth=1, alpha=0.5)\n",
    "ax3.set_title('Model Probability (Buy Signal)', fontweight='bold')\n",
    "ax3.set_xlabel('Probability')\n",
    "ax3.set_xlim(0, 1)\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Correlation matrix\n",
    "ax4 = axes[1, 1]\n",
    "import seaborn as sns\n",
    "corr = returns.tail(60).corr()\n",
    "sns.heatmap(corr, annot=True, fmt='.2f', cmap='RdYlGn', center=0, ax=ax4)\n",
    "ax4.set_title('60-Day Return Correlation', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('production_signals.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Visualization saved to production_signals.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc25273",
   "metadata": {},
   "source": [
    "## 10. System Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476a3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ðŸ¥ SYSTEM HEALTH CHECK\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Check 1: Data freshness\n",
    "latest_date = prices.index[-1]\n",
    "days_old = (datetime.now() - latest_date.to_pydatetime().replace(tzinfo=None)).days\n",
    "if days_old <= 1:\n",
    "    print(\"âœ… Data freshness: CURRENT\")\n",
    "elif days_old <= 3:\n",
    "    print(f\"âš ï¸ Data freshness: {days_old} days old\")\n",
    "else:\n",
    "    print(f\"ðŸš¨ Data freshness: {days_old} days old - UPDATE REQUIRED\")\n",
    "\n",
    "# Check 2: Model status\n",
    "all_models_ready = all(registry.get_production_model(t)[0] is not None for t in TICKERS)\n",
    "if all_models_ready:\n",
    "    print(\"âœ… Models: All production models deployed\")\n",
    "else:\n",
    "    print(\"ðŸš¨ Models: Some tickers missing production models\")\n",
    "\n",
    "# Check 3: Feature quality\n",
    "missing_features = features.isnull().sum().sum()\n",
    "if missing_features == 0:\n",
    "    print(\"âœ… Features: No missing values\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Features: {missing_features} missing values\")\n",
    "\n",
    "# Check 4: Alerts\n",
    "active_alerts = monitor.get_alerts()\n",
    "if len(active_alerts) == 0:\n",
    "    print(\"âœ… Alerts: No active alerts\")\n",
    "else:\n",
    "    print(f\"âš ï¸ Alerts: {len(active_alerts)} active alerts\")\n",
    "    for alert in active_alerts[-5:]:\n",
    "        print(f\"   {alert.type.value} {alert.message}\")\n",
    "\n",
    "print(\"\\n\" + \"â”€\"*70)\n",
    "print(\"System ready for production trading.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47930514",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This Production ML Trading Strategy implements:\n",
    "\n",
    "1. **Data Pipeline** - Automated data fetching with validation\n",
    "2. **Feature Store** - Centralized feature management\n",
    "3. **Model Registry** - Version control and deployment\n",
    "4. **Training Pipeline** - Automated model training with evaluation\n",
    "5. **Monitoring System** - Drift detection and alerting\n",
    "6. **Signal Generation** - Production-ready trading signals\n",
    "\n",
    "### Key MLOps Principles Applied\n",
    "- Reproducibility through versioning\n",
    "- Automated retraining triggers\n",
    "- Model performance monitoring\n",
    "- Feature drift detection\n",
    "- A/B testing framework\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ“ Week 23 Production ML Trading Strategy Complete!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
