{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea7d271",
   "metadata": {},
   "source": [
    "# Day 03: Online Learning for Trading Models\n",
    "\n",
    "## Week 23: Production ML\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "1. Understand online learning vs batch learning paradigms\n",
    "2. Implement incremental learning algorithms for streaming financial data\n",
    "3. Detect and handle concept drift in trading models\n",
    "4. Build adaptive models that learn from new market regimes\n",
    "5. Apply online learning libraries (River, scikit-learn) to trading strategies\n",
    "\n",
    "---\n",
    "\n",
    "## Why Online Learning for Trading?\n",
    "\n",
    "Financial markets are **non-stationary** - statistical properties change over time due to:\n",
    "- Market regime shifts (bull/bear markets)\n",
    "- Structural changes (regulations, new instruments)\n",
    "- Alpha decay (strategies lose edge as others discover them)\n",
    "- Changing volatility regimes\n",
    "\n",
    "**Online learning** allows models to:\n",
    "- Adapt to new patterns without full retraining\n",
    "- Process streaming data efficiently\n",
    "- Maintain performance during regime changes\n",
    "- Reduce computational costs vs frequent batch retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83dfd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Online learning\n",
    "from river import linear_model, preprocessing, metrics, drift, ensemble\n",
    "from river import stream, optim, compose\n",
    "\n",
    "# Scikit-learn incremental learning\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor, PassiveAggressiveClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "# Data\n",
    "import yfinance as yf\n",
    "\n",
    "# Visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30deb35",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Online Learning Fundamentals\n",
    "\n",
    "### Batch vs Online Learning\n",
    "\n",
    "| Aspect | Batch Learning | Online Learning |\n",
    "|--------|---------------|----------------|\n",
    "| Data | All at once | One sample at a time |\n",
    "| Memory | High (store all data) | Low (constant) |\n",
    "| Adaptation | Requires retraining | Continuous updates |\n",
    "| Computation | Heavy periodic jobs | Light continuous |\n",
    "| Use Case | Static environments | Streaming/changing data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch historical data for experiments\n",
    "symbols = ['SPY', 'QQQ', 'IWM']\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "data = {}\n",
    "for symbol in symbols:\n",
    "    df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
    "    df.columns = df.columns.droplevel(1) if isinstance(df.columns, pd.MultiIndex) else df.columns\n",
    "    data[symbol] = df\n",
    "\n",
    "# Use SPY as primary dataset\n",
    "df = data['SPY'].copy()\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index[0]} to {df.index[-1]}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c987b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df, lookbacks=[5, 10, 20, 60]):\n",
    "    \"\"\"\n",
    "    Create features for online learning trading model.\n",
    "    Features designed to capture momentum, volatility, and mean-reversion.\n",
    "    \"\"\"\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Returns\n",
    "    features['returns'] = df['Close'].pct_change()\n",
    "    \n",
    "    # Momentum features\n",
    "    for lb in lookbacks:\n",
    "        features[f'momentum_{lb}'] = df['Close'].pct_change(lb)\n",
    "        features[f'volatility_{lb}'] = features['returns'].rolling(lb).std()\n",
    "        features[f'rsi_{lb}'] = compute_rsi(df['Close'], lb)\n",
    "    \n",
    "    # Volume features\n",
    "    features['volume_change'] = df['Volume'].pct_change()\n",
    "    features['volume_ma_ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()\n",
    "    \n",
    "    # Price position\n",
    "    features['high_low_range'] = (df['High'] - df['Low']) / df['Close']\n",
    "    features['close_position'] = (df['Close'] - df['Low']) / (df['High'] - df['Low'])\n",
    "    \n",
    "    # Moving average relationships\n",
    "    features['ma_20_ratio'] = df['Close'] / df['Close'].rolling(20).mean() - 1\n",
    "    features['ma_50_ratio'] = df['Close'] / df['Close'].rolling(50).mean() - 1\n",
    "    \n",
    "    # Target: Next day return direction (1 = up, 0 = down)\n",
    "    features['target'] = (features['returns'].shift(-1) > 0).astype(int)\n",
    "    features['target_return'] = features['returns'].shift(-1)\n",
    "    \n",
    "    return features.dropna()\n",
    "\n",
    "\n",
    "def compute_rsi(series, period):\n",
    "    \"\"\"Compute Relative Strength Index.\"\"\"\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "\n",
    "# Create feature dataset\n",
    "features_df = create_features(df)\n",
    "print(f\"Feature dataset shape: {features_df.shape}\")\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e64242",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Online Learning with River\n",
    "\n",
    "[River](https://riverml.xyz/) is a Python library for online machine learning. It's designed for:\n",
    "- Single-pass learning (each observation seen once)\n",
    "- Constant memory usage\n",
    "- Real-time predictions and updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf00703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for River (dict format)\n",
    "feature_cols = [col for col in features_df.columns \n",
    "                if col not in ['target', 'target_return', 'returns']]\n",
    "\n",
    "X = features_df[feature_cols]\n",
    "y = features_df['target']\n",
    "\n",
    "print(f\"Features: {feature_cols}\")\n",
    "print(f\"Number of samples: {len(X)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3250f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build River online learning pipeline\n",
    "model_river = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression(optimizer=optim.SGD(lr=0.01))\n",
    ")\n",
    "\n",
    "# Metrics to track\n",
    "metric = metrics.Accuracy()\n",
    "rolling_metric = metrics.Rolling(metrics.Accuracy(), window_size=100)\n",
    "\n",
    "# Store results for analysis\n",
    "results = {\n",
    "    'date': [],\n",
    "    'prediction': [],\n",
    "    'actual': [],\n",
    "    'accuracy': [],\n",
    "    'rolling_accuracy': []\n",
    "}\n",
    "\n",
    "# Online learning loop - process one sample at a time\n",
    "for i, (idx, row) in enumerate(X.iterrows()):\n",
    "    x_dict = row.to_dict()  # River expects dict format\n",
    "    y_true = int(y.loc[idx])\n",
    "    \n",
    "    # Predict BEFORE learning (prequential evaluation)\n",
    "    y_pred = model_river.predict_one(x_dict)\n",
    "    \n",
    "    # Update metrics\n",
    "    if y_pred is not None:\n",
    "        metric.update(y_true, y_pred)\n",
    "        rolling_metric.update(y_true, y_pred)\n",
    "        \n",
    "        results['date'].append(idx)\n",
    "        results['prediction'].append(y_pred)\n",
    "        results['actual'].append(y_true)\n",
    "        results['accuracy'].append(metric.get())\n",
    "        results['rolling_accuracy'].append(rolling_metric.get())\n",
    "    \n",
    "    # Learn from this sample\n",
    "    model_river.learn_one(x_dict, y_true)\n",
    "\n",
    "print(f\"Final Accuracy: {metric.get():.4f}\")\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16ee9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize online learning performance over time\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Cumulative accuracy\n",
    "axes[0].plot(results_df.index, results_df['accuracy'], label='Cumulative Accuracy', alpha=0.8)\n",
    "axes[0].axhline(y=0.5, color='r', linestyle='--', label='Random Baseline')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Online Learning: Cumulative Accuracy Over Time')\n",
    "axes[0].legend()\n",
    "\n",
    "# Rolling accuracy (100-day window)\n",
    "axes[1].plot(results_df.index, results_df['rolling_accuracy'], \n",
    "             label='100-Day Rolling Accuracy', color='green', alpha=0.8)\n",
    "axes[1].axhline(y=0.5, color='r', linestyle='--', label='Random Baseline')\n",
    "axes[1].set_ylabel('Rolling Accuracy')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_title('Online Learning: Rolling Accuracy (Window=100)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c0053",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Concept Drift Detection\n",
    "\n",
    "**Concept drift** occurs when the statistical properties of the target variable change over time. In trading:\n",
    "- Market regime changes\n",
    "- Volatility shifts\n",
    "- Correlation breakdowns\n",
    "\n",
    "### Common Drift Detectors:\n",
    "1. **ADWIN (Adaptive Windowing)**: Automatically adjusts window size\n",
    "2. **DDM (Drift Detection Method)**: Monitors error rate statistics\n",
    "3. **Page-Hinkley**: Detects changes in mean of Gaussian signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8baf99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement concept drift detection\n",
    "from river.drift import ADWIN, DDM, PageHinkley\n",
    "\n",
    "# Create drift detectors\n",
    "adwin = ADWIN(delta=0.002)\n",
    "ddm = DDM()\n",
    "ph = PageHinkley()\n",
    "\n",
    "# Track drift points\n",
    "drift_points = {\n",
    "    'ADWIN': [],\n",
    "    'DDM': [],\n",
    "    'PageHinkley': []\n",
    "}\n",
    "\n",
    "# Simulate streaming with drift detection\n",
    "model_drift = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression(optimizer=optim.SGD(lr=0.01))\n",
    ")\n",
    "\n",
    "errors = []\n",
    "\n",
    "for i, (idx, row) in enumerate(X.iterrows()):\n",
    "    x_dict = row.to_dict()\n",
    "    y_true = int(y.loc[idx])\n",
    "    \n",
    "    y_pred = model_drift.predict_one(x_dict)\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        error = int(y_pred != y_true)\n",
    "        errors.append(error)\n",
    "        \n",
    "        # Update drift detectors with error signal\n",
    "        adwin.update(error)\n",
    "        ddm.update(error)\n",
    "        ph.update(error)\n",
    "        \n",
    "        # Check for drift\n",
    "        if adwin.drift_detected:\n",
    "            drift_points['ADWIN'].append(idx)\n",
    "        if ddm.drift_detected:\n",
    "            drift_points['DDM'].append(idx)\n",
    "        if ph.drift_detected:\n",
    "            drift_points['PageHinkley'].append(idx)\n",
    "    \n",
    "    model_drift.learn_one(x_dict, y_true)\n",
    "\n",
    "print(\"Drift Detection Summary:\")\n",
    "for detector, points in drift_points.items():\n",
    "    print(f\"  {detector}: {len(points)} drift points detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06776141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize drift points with SPY price\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# SPY price with drift points\n",
    "axes[0].plot(df.index, df['Close'], label='SPY Close', alpha=0.8)\n",
    "\n",
    "colors = {'ADWIN': 'red', 'DDM': 'orange', 'PageHinkley': 'purple'}\n",
    "for detector, points in drift_points.items():\n",
    "    if points:\n",
    "        for point in points[:50]:  # Limit for visibility\n",
    "            axes[0].axvline(x=point, color=colors[detector], alpha=0.3, linewidth=0.5)\n",
    "\n",
    "axes[0].set_ylabel('Price')\n",
    "axes[0].set_title('SPY Price with Detected Drift Points')\n",
    "axes[0].legend()\n",
    "\n",
    "# Rolling error rate\n",
    "error_series = pd.Series(errors, index=results_df.index)\n",
    "rolling_error = error_series.rolling(50).mean()\n",
    "axes[1].plot(rolling_error.index, rolling_error, label='50-Day Rolling Error Rate', color='red')\n",
    "axes[1].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].set_ylabel('Error Rate')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_title('Rolling Prediction Error Rate')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbbd3dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Adaptive Learning with Drift Response\n",
    "\n",
    "When drift is detected, we can:\n",
    "1. **Reset the model** - Start fresh\n",
    "2. **Increase learning rate** - Adapt faster to new patterns\n",
    "3. **Use ensemble methods** - Combine old and new models\n",
    "4. **Window-based retraining** - Retrain on recent data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5cc92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveOnlineLearner:\n",
    "    \"\"\"\n",
    "    Online learner that adapts learning rate when drift is detected.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_lr=0.01, drift_lr=0.1, cooldown=50):\n",
    "        self.base_lr = base_lr\n",
    "        self.drift_lr = drift_lr\n",
    "        self.cooldown = cooldown\n",
    "        self.steps_since_drift = cooldown\n",
    "        \n",
    "        self.drift_detector = ADWIN(delta=0.002)\n",
    "        self._build_model(base_lr)\n",
    "        \n",
    "        self.metric = metrics.Accuracy()\n",
    "        self.drift_events = []\n",
    "        \n",
    "    def _build_model(self, lr):\n",
    "        self.model = compose.Pipeline(\n",
    "            preprocessing.StandardScaler(),\n",
    "            linear_model.LogisticRegression(optimizer=optim.SGD(lr=lr))\n",
    "        )\n",
    "    \n",
    "    def _get_current_lr(self):\n",
    "        if self.steps_since_drift < self.cooldown:\n",
    "            # Decay from drift_lr to base_lr\n",
    "            progress = self.steps_since_drift / self.cooldown\n",
    "            return self.drift_lr * (1 - progress) + self.base_lr * progress\n",
    "        return self.base_lr\n",
    "    \n",
    "    def predict_one(self, x):\n",
    "        return self.model.predict_one(x)\n",
    "    \n",
    "    def learn_one(self, x, y, timestamp=None):\n",
    "        # Get prediction for drift detection\n",
    "        y_pred = self.model.predict_one(x)\n",
    "        \n",
    "        if y_pred is not None:\n",
    "            error = int(y_pred != y)\n",
    "            self.drift_detector.update(error)\n",
    "            self.metric.update(y, y_pred)\n",
    "            \n",
    "            if self.drift_detector.drift_detected:\n",
    "                self.steps_since_drift = 0\n",
    "                self.drift_events.append(timestamp)\n",
    "                # Rebuild model with higher learning rate\n",
    "                self._build_model(self.drift_lr)\n",
    "        \n",
    "        # Learn with current model\n",
    "        self.model.learn_one(x, y)\n",
    "        self.steps_since_drift += 1\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "# Train adaptive model\n",
    "adaptive_model = AdaptiveOnlineLearner(base_lr=0.01, drift_lr=0.1, cooldown=100)\n",
    "\n",
    "adaptive_results = {\n",
    "    'date': [],\n",
    "    'prediction': [],\n",
    "    'actual': [],\n",
    "    'accuracy': []\n",
    "}\n",
    "\n",
    "for idx, row in X.iterrows():\n",
    "    x_dict = row.to_dict()\n",
    "    y_true = int(y.loc[idx])\n",
    "    \n",
    "    y_pred = adaptive_model.predict_one(x_dict)\n",
    "    adaptive_model.learn_one(x_dict, y_true, timestamp=idx)\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        adaptive_results['date'].append(idx)\n",
    "        adaptive_results['prediction'].append(y_pred)\n",
    "        adaptive_results['actual'].append(y_true)\n",
    "        adaptive_results['accuracy'].append(adaptive_model.metric.get())\n",
    "\n",
    "adaptive_df = pd.DataFrame(adaptive_results).set_index('date')\n",
    "print(f\"Adaptive Model Final Accuracy: {adaptive_model.metric.get():.4f}\")\n",
    "print(f\"Number of drift events: {len(adaptive_model.drift_events)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare base vs adaptive model\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(results_df.index, results_df['accuracy'], \n",
    "        label='Base Online Model', alpha=0.8)\n",
    "ax.plot(adaptive_df.index, adaptive_df['accuracy'], \n",
    "        label='Adaptive Model', alpha=0.8)\n",
    "ax.axhline(y=0.5, color='r', linestyle='--', label='Random Baseline', alpha=0.5)\n",
    "\n",
    "# Mark drift events\n",
    "for event in adaptive_model.drift_events:\n",
    "    ax.axvline(x=event, color='orange', alpha=0.3, linewidth=1)\n",
    "\n",
    "ax.set_ylabel('Cumulative Accuracy')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Base vs Adaptive Online Learning Model')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72102852",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Ensemble Methods for Online Learning\n",
    "\n",
    "Ensemble methods can improve robustness in changing environments:\n",
    "- **Bagging**: Multiple models trained on different bootstrap samples\n",
    "- **Adaptive Random Forest**: Random forest with drift detection per tree\n",
    "- **Leveraging Bagging**: Poisson(λ) weighted bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee7cba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.ensemble import ADWINBaggingClassifier, LeveragingBaggingClassifier\n",
    "from river.tree import HoeffdingTreeClassifier\n",
    "\n",
    "# Create ensemble models\n",
    "bagging_model = ADWINBaggingClassifier(\n",
    "    model=linear_model.LogisticRegression(),\n",
    "    n_models=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "leverage_model = LeveragingBaggingClassifier(\n",
    "    model=HoeffdingTreeClassifier(),\n",
    "    n_models=10,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Train and evaluate ensembles\n",
    "ensemble_metrics = {\n",
    "    'ADWIN Bagging': metrics.Accuracy(),\n",
    "    'Leveraging Bagging': metrics.Accuracy()\n",
    "}\n",
    "\n",
    "ensemble_results = {\n",
    "    'date': [],\n",
    "    'ADWIN Bagging': [],\n",
    "    'Leveraging Bagging': []\n",
    "}\n",
    "\n",
    "for idx, row in X.iterrows():\n",
    "    x_dict = row.to_dict()\n",
    "    y_true = int(y.loc[idx])\n",
    "    \n",
    "    # ADWIN Bagging\n",
    "    pred_bagging = bagging_model.predict_one(x_dict)\n",
    "    if pred_bagging is not None:\n",
    "        ensemble_metrics['ADWIN Bagging'].update(y_true, pred_bagging)\n",
    "    bagging_model.learn_one(x_dict, y_true)\n",
    "    \n",
    "    # Leveraging Bagging\n",
    "    pred_leverage = leverage_model.predict_one(x_dict)\n",
    "    if pred_leverage is not None:\n",
    "        ensemble_metrics['Leveraging Bagging'].update(y_true, pred_leverage)\n",
    "    leverage_model.learn_one(x_dict, y_true)\n",
    "    \n",
    "    if pred_bagging is not None and pred_leverage is not None:\n",
    "        ensemble_results['date'].append(idx)\n",
    "        ensemble_results['ADWIN Bagging'].append(ensemble_metrics['ADWIN Bagging'].get())\n",
    "        ensemble_results['Leveraging Bagging'].append(ensemble_metrics['Leveraging Bagging'].get())\n",
    "\n",
    "ensemble_df = pd.DataFrame(ensemble_results).set_index('date')\n",
    "\n",
    "print(\"Ensemble Model Final Accuracies:\")\n",
    "for name, metric in ensemble_metrics.items():\n",
    "    print(f\"  {name}: {metric.get():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd6ddd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "ax.plot(results_df.index, results_df['accuracy'], \n",
    "        label='Single Logistic Regression', alpha=0.7)\n",
    "ax.plot(adaptive_df.index, adaptive_df['accuracy'], \n",
    "        label='Adaptive Model', alpha=0.7)\n",
    "ax.plot(ensemble_df.index, ensemble_df['ADWIN Bagging'], \n",
    "        label='ADWIN Bagging', alpha=0.7)\n",
    "ax.plot(ensemble_df.index, ensemble_df['Leveraging Bagging'], \n",
    "        label='Leveraging Bagging', alpha=0.7)\n",
    "ax.axhline(y=0.5, color='r', linestyle='--', label='Random', alpha=0.5)\n",
    "\n",
    "ax.set_ylabel('Cumulative Accuracy')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Online Learning Model Comparison')\n",
    "ax.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d2455",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Scikit-learn Incremental Learning\n",
    "\n",
    "For compatibility with existing sklearn pipelines, use `partial_fit()` method:\n",
    "- `SGDClassifier` / `SGDRegressor`\n",
    "- `PassiveAggressiveClassifier`\n",
    "- `MiniBatchKMeans`\n",
    "- `MultinomialNB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014718c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, PassiveAggressiveClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class SklearnOnlineModel:\n",
    "    \"\"\"\n",
    "    Wrapper for sklearn incremental learning models.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_type='sgd', warm_start_samples=100):\n",
    "        self.model_type = model_type\n",
    "        self.warm_start_samples = warm_start_samples\n",
    "        self.scaler = StandardScaler()\n",
    "        self.fitted = False\n",
    "        self.buffer_X = []\n",
    "        self.buffer_y = []\n",
    "        \n",
    "        if model_type == 'sgd':\n",
    "            self.model = SGDClassifier(\n",
    "                loss='log_loss',\n",
    "                learning_rate='adaptive',\n",
    "                eta0=0.01,\n",
    "                random_state=42\n",
    "            )\n",
    "        elif model_type == 'pa':\n",
    "            self.model = PassiveAggressiveClassifier(\n",
    "                C=0.1,\n",
    "                random_state=42\n",
    "            )\n",
    "    \n",
    "    def partial_fit(self, X, y):\n",
    "        if not self.fitted:\n",
    "            # Buffer samples for initial fit\n",
    "            self.buffer_X.append(X)\n",
    "            self.buffer_y.append(y)\n",
    "            \n",
    "            if len(self.buffer_X) >= self.warm_start_samples:\n",
    "                X_init = np.vstack(self.buffer_X)\n",
    "                y_init = np.array(self.buffer_y)\n",
    "                \n",
    "                self.scaler.fit(X_init)\n",
    "                X_scaled = self.scaler.transform(X_init)\n",
    "                self.model.partial_fit(X_scaled, y_init, classes=[0, 1])\n",
    "                self.fitted = True\n",
    "                self.buffer_X = []\n",
    "                self.buffer_y = []\n",
    "        else:\n",
    "            X_scaled = self.scaler.transform(X.reshape(1, -1))\n",
    "            self.model.partial_fit(X_scaled, [y])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if not self.fitted:\n",
    "            return None\n",
    "        X_scaled = self.scaler.transform(X.reshape(1, -1))\n",
    "        return self.model.predict(X_scaled)[0]\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if not self.fitted or not hasattr(self.model, 'predict_proba'):\n",
    "            return None\n",
    "        X_scaled = self.scaler.transform(X.reshape(1, -1))\n",
    "        return self.model.predict_proba(X_scaled)[0]\n",
    "\n",
    "\n",
    "# Train sklearn online models\n",
    "sklearn_models = {\n",
    "    'SGD': SklearnOnlineModel('sgd'),\n",
    "    'PassiveAggressive': SklearnOnlineModel('pa')\n",
    "}\n",
    "\n",
    "sklearn_results = {name: [] for name in sklearn_models.keys()}\n",
    "sklearn_dates = []\n",
    "\n",
    "X_array = X.values\n",
    "y_array = y.values\n",
    "\n",
    "for i in range(len(X_array)):\n",
    "    predictions = {}\n",
    "    \n",
    "    for name, model in sklearn_models.items():\n",
    "        pred = model.predict(X_array[i])\n",
    "        model.partial_fit(X_array[i], y_array[i])\n",
    "        predictions[name] = pred\n",
    "    \n",
    "    if all(p is not None for p in predictions.values()):\n",
    "        sklearn_dates.append(X.index[i])\n",
    "        for name, pred in predictions.items():\n",
    "            sklearn_results[name].append(int(pred == y_array[i]))\n",
    "\n",
    "# Calculate cumulative accuracies\n",
    "sklearn_df = pd.DataFrame(index=sklearn_dates)\n",
    "for name, results in sklearn_results.items():\n",
    "    sklearn_df[name] = np.cumsum(results) / np.arange(1, len(results) + 1)\n",
    "\n",
    "print(\"\\nSklearn Online Models Final Accuracies:\")\n",
    "for name in sklearn_results.keys():\n",
    "    print(f\"  {name}: {sklearn_df[name].iloc[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c755005",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Online Learning for Return Prediction (Regression)\n",
    "\n",
    "Predicting actual returns instead of direction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d5cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river.metrics import MAE, RMSE, R2\n",
    "\n",
    "# Online regression model\n",
    "reg_model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LinearRegression(optimizer=optim.SGD(lr=0.001))\n",
    ")\n",
    "\n",
    "# Target: next day returns\n",
    "y_reg = features_df['target_return']\n",
    "\n",
    "# Metrics\n",
    "mae_metric = MAE()\n",
    "rmse_metric = RMSE()\n",
    "r2_metric = R2()\n",
    "\n",
    "reg_results = {\n",
    "    'date': [],\n",
    "    'prediction': [],\n",
    "    'actual': [],\n",
    "    'mae': [],\n",
    "    'rmse': []\n",
    "}\n",
    "\n",
    "for idx, row in X.iterrows():\n",
    "    x_dict = row.to_dict()\n",
    "    y_true = float(y_reg.loc[idx])\n",
    "    \n",
    "    y_pred = reg_model.predict_one(x_dict)\n",
    "    \n",
    "    if y_pred is not None:\n",
    "        mae_metric.update(y_true, y_pred)\n",
    "        rmse_metric.update(y_true, y_pred)\n",
    "        r2_metric.update(y_true, y_pred)\n",
    "        \n",
    "        reg_results['date'].append(idx)\n",
    "        reg_results['prediction'].append(y_pred)\n",
    "        reg_results['actual'].append(y_true)\n",
    "        reg_results['mae'].append(mae_metric.get())\n",
    "        reg_results['rmse'].append(rmse_metric.get())\n",
    "    \n",
    "    reg_model.learn_one(x_dict, y_true)\n",
    "\n",
    "reg_df = pd.DataFrame(reg_results).set_index('date')\n",
    "\n",
    "print(f\"Online Regression Results:\")\n",
    "print(f\"  MAE: {mae_metric.get():.6f}\")\n",
    "print(f\"  RMSE: {rmse_metric.get():.6f}\")\n",
    "print(f\"  R²: {r2_metric.get():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ee27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regression predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Actual vs Predicted scatter\n",
    "axes[0, 0].scatter(reg_df['actual'], reg_df['prediction'], alpha=0.3, s=5)\n",
    "axes[0, 0].plot([-0.1, 0.1], [-0.1, 0.1], 'r--', label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('Actual Return')\n",
    "axes[0, 0].set_ylabel('Predicted Return')\n",
    "axes[0, 0].set_title('Actual vs Predicted Returns')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# MAE over time\n",
    "axes[0, 1].plot(reg_df.index, reg_df['mae'])\n",
    "axes[0, 1].set_ylabel('MAE')\n",
    "axes[0, 1].set_title('Cumulative MAE Over Time')\n",
    "\n",
    "# Prediction time series (last 100 days)\n",
    "last_100 = reg_df.tail(100)\n",
    "axes[1, 0].plot(last_100.index, last_100['actual'], label='Actual', alpha=0.7)\n",
    "axes[1, 0].plot(last_100.index, last_100['prediction'], label='Predicted', alpha=0.7)\n",
    "axes[1, 0].set_ylabel('Return')\n",
    "axes[1, 0].set_title('Last 100 Days: Actual vs Predicted')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Prediction error distribution\n",
    "errors = reg_df['actual'] - reg_df['prediction']\n",
    "axes[1, 1].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(x=0, color='r', linestyle='--')\n",
    "axes[1, 1].set_xlabel('Prediction Error')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].set_title('Prediction Error Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b7d61",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Trading Strategy with Online Learning\n",
    "\n",
    "Let's build a complete trading strategy using online learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8666e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineTradingStrategy:\n",
    "    \"\"\"\n",
    "    Trading strategy using online learning with adaptive learning rates.\n",
    "    \"\"\"\n",
    "    def __init__(self, threshold=0.55, transaction_cost=0.001):\n",
    "        self.threshold = threshold\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "        # Model with probability output\n",
    "        self.model = compose.Pipeline(\n",
    "            preprocessing.StandardScaler(),\n",
    "            linear_model.LogisticRegression(optimizer=optim.SGD(lr=0.01))\n",
    "        )\n",
    "        \n",
    "        self.drift_detector = ADWIN(delta=0.002)\n",
    "        self.position = 0  # 0 = flat, 1 = long, -1 = short\n",
    "        \n",
    "        # Track performance\n",
    "        self.trades = []\n",
    "        self.equity_curve = [1.0]\n",
    "        self.dates = []\n",
    "        \n",
    "    def get_signal(self, x):\n",
    "        \"\"\"Generate trading signal based on prediction probability.\"\"\"\n",
    "        proba = self.model.predict_proba_one(x)\n",
    "        \n",
    "        if proba is None:\n",
    "            return 0\n",
    "        \n",
    "        prob_up = proba.get(1, 0.5)\n",
    "        \n",
    "        if prob_up > self.threshold:\n",
    "            return 1  # Long\n",
    "        elif prob_up < (1 - self.threshold):\n",
    "            return -1  # Short\n",
    "        else:\n",
    "            return 0  # Flat\n",
    "    \n",
    "    def step(self, x, y_true, actual_return, date):\n",
    "        \"\"\"Process one time step.\"\"\"\n",
    "        # Get signal before learning\n",
    "        signal = self.get_signal(x)\n",
    "        \n",
    "        # Calculate strategy return\n",
    "        position_return = self.position * actual_return\n",
    "        \n",
    "        # Transaction costs\n",
    "        if signal != self.position:\n",
    "            position_return -= self.transaction_cost * abs(signal - self.position)\n",
    "            self.trades.append({\n",
    "                'date': date,\n",
    "                'old_position': self.position,\n",
    "                'new_position': signal\n",
    "            })\n",
    "        \n",
    "        # Update equity\n",
    "        new_equity = self.equity_curve[-1] * (1 + position_return)\n",
    "        self.equity_curve.append(new_equity)\n",
    "        self.dates.append(date)\n",
    "        \n",
    "        # Update position\n",
    "        self.position = signal\n",
    "        \n",
    "        # Learn from observation\n",
    "        y_pred = self.model.predict_one(x)\n",
    "        if y_pred is not None:\n",
    "            self.drift_detector.update(int(y_pred != y_true))\n",
    "        self.model.learn_one(x, y_true)\n",
    "        \n",
    "        return position_return\n",
    "    \n",
    "    def get_performance_metrics(self, risk_free_rate=0.0):\n",
    "        \"\"\"Calculate strategy performance metrics.\"\"\"\n",
    "        returns = pd.Series(self.equity_curve).pct_change().dropna()\n",
    "        \n",
    "        total_return = (self.equity_curve[-1] / self.equity_curve[0]) - 1\n",
    "        annual_return = (1 + total_return) ** (252 / len(returns)) - 1\n",
    "        volatility = returns.std() * np.sqrt(252)\n",
    "        sharpe = (annual_return - risk_free_rate) / volatility if volatility > 0 else 0\n",
    "        \n",
    "        # Max drawdown\n",
    "        equity = pd.Series(self.equity_curve)\n",
    "        rolling_max = equity.expanding().max()\n",
    "        drawdowns = equity / rolling_max - 1\n",
    "        max_dd = drawdowns.min()\n",
    "        \n",
    "        return {\n",
    "            'Total Return': f\"{total_return:.2%}\",\n",
    "            'Annual Return': f\"{annual_return:.2%}\",\n",
    "            'Volatility': f\"{volatility:.2%}\",\n",
    "            'Sharpe Ratio': f\"{sharpe:.2f}\",\n",
    "            'Max Drawdown': f\"{max_dd:.2%}\",\n",
    "            'Num Trades': len(self.trades)\n",
    "        }\n",
    "\n",
    "\n",
    "# Run strategy\n",
    "strategy = OnlineTradingStrategy(threshold=0.52, transaction_cost=0.0005)\n",
    "\n",
    "for idx, row in X.iterrows():\n",
    "    x_dict = row.to_dict()\n",
    "    y_true = int(y.loc[idx])\n",
    "    actual_return = float(y_reg.loc[idx])\n",
    "    \n",
    "    strategy.step(x_dict, y_true, actual_return, idx)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n=== Online Learning Strategy Performance ===\")\n",
    "for metric, value in strategy.get_performance_metrics().items():\n",
    "    print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ed1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare strategy vs buy-and-hold\n",
    "buy_hold_equity = (1 + features_df['target_return']).cumprod()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Equity curves\n",
    "strategy_equity = pd.Series(strategy.equity_curve[1:], index=strategy.dates)\n",
    "axes[0].plot(strategy_equity.index, strategy_equity, label='Online Learning Strategy', linewidth=1.5)\n",
    "axes[0].plot(buy_hold_equity.index, buy_hold_equity, label='Buy & Hold SPY', linewidth=1.5, alpha=0.7)\n",
    "axes[0].set_ylabel('Equity')\n",
    "axes[0].set_title('Strategy Performance: Online Learning vs Buy & Hold')\n",
    "axes[0].legend()\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "# Drawdown\n",
    "strategy_dd = strategy_equity / strategy_equity.expanding().max() - 1\n",
    "bh_dd = buy_hold_equity / buy_hold_equity.expanding().max() - 1\n",
    "\n",
    "axes[1].fill_between(strategy_dd.index, strategy_dd, 0, alpha=0.5, label='Strategy Drawdown')\n",
    "axes[1].fill_between(bh_dd.index, bh_dd, 0, alpha=0.5, label='Buy & Hold Drawdown')\n",
    "axes[1].set_ylabel('Drawdown')\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_title('Drawdown Comparison')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4c2ead",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Best Practices for Online Learning in Production\n",
    "\n",
    "### Key Considerations:\n",
    "\n",
    "1. **Data Quality**\n",
    "   - Handle missing values gracefully\n",
    "   - Detect and handle outliers online\n",
    "   - Validate feature distributions\n",
    "\n",
    "2. **Model Stability**\n",
    "   - Use regularization to prevent overfitting to noise\n",
    "   - Implement learning rate schedules\n",
    "   - Monitor for catastrophic forgetting\n",
    "\n",
    "3. **Drift Management**\n",
    "   - Multiple drift detectors for robustness\n",
    "   - Gradual vs sudden drift handling\n",
    "   - Maintain historical model checkpoints\n",
    "\n",
    "4. **Monitoring**\n",
    "   - Track prediction accuracy over time\n",
    "   - Monitor feature importance changes\n",
    "   - Alert on performance degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e83a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionOnlineLearner:\n",
    "    \"\"\"\n",
    "    Production-ready online learning system with monitoring.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, drift_threshold=0.002, window_size=100):\n",
    "        self.model = model\n",
    "        self.drift_detector = ADWIN(delta=drift_threshold)\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        # Monitoring\n",
    "        self.predictions = []\n",
    "        self.actuals = []\n",
    "        self.timestamps = []\n",
    "        self.drift_events = []\n",
    "        self.feature_stats = {}\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.rolling_accuracy = []\n",
    "        \n",
    "    def predict(self, x, timestamp=None):\n",
    "        \"\"\"Make prediction with monitoring.\"\"\"\n",
    "        pred = self.model.predict_one(x)\n",
    "        \n",
    "        # Update feature statistics\n",
    "        for feature, value in x.items():\n",
    "            if feature not in self.feature_stats:\n",
    "                self.feature_stats[feature] = {'values': []}\n",
    "            self.feature_stats[feature]['values'].append(value)\n",
    "            # Keep only recent values\n",
    "            if len(self.feature_stats[feature]['values']) > self.window_size * 10:\n",
    "                self.feature_stats[feature]['values'] = \\\n",
    "                    self.feature_stats[feature]['values'][-self.window_size * 5:]\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def learn(self, x, y_true, timestamp=None):\n",
    "        \"\"\"Learn from observation with drift detection.\"\"\"\n",
    "        y_pred = self.model.predict_one(x)\n",
    "        \n",
    "        if y_pred is not None:\n",
    "            # Track predictions\n",
    "            self.predictions.append(y_pred)\n",
    "            self.actuals.append(y_true)\n",
    "            self.timestamps.append(timestamp)\n",
    "            \n",
    "            # Drift detection\n",
    "            error = int(y_pred != y_true)\n",
    "            self.drift_detector.update(error)\n",
    "            \n",
    "            if self.drift_detector.drift_detected:\n",
    "                self.drift_events.append({\n",
    "                    'timestamp': timestamp,\n",
    "                    'rolling_acc': self.get_rolling_accuracy()\n",
    "                })\n",
    "            \n",
    "            # Update rolling accuracy\n",
    "            self.rolling_accuracy.append(self.get_rolling_accuracy())\n",
    "        \n",
    "        self.model.learn_one(x, y_true)\n",
    "        return self\n",
    "    \n",
    "    def get_rolling_accuracy(self):\n",
    "        \"\"\"Calculate rolling accuracy.\"\"\"\n",
    "        if len(self.predictions) < self.window_size:\n",
    "            return None\n",
    "        recent_preds = self.predictions[-self.window_size:]\n",
    "        recent_actuals = self.actuals[-self.window_size:]\n",
    "        return np.mean([p == a for p, a in zip(recent_preds, recent_actuals)])\n",
    "    \n",
    "    def get_feature_drift_report(self):\n",
    "        \"\"\"Check for feature distribution drift.\"\"\"\n",
    "        report = {}\n",
    "        for feature, stats in self.feature_stats.items():\n",
    "            values = stats['values']\n",
    "            if len(values) > self.window_size * 2:\n",
    "                old_values = values[:self.window_size]\n",
    "                new_values = values[-self.window_size:]\n",
    "                \n",
    "                mean_shift = abs(np.mean(new_values) - np.mean(old_values)) / (np.std(old_values) + 1e-8)\n",
    "                std_ratio = np.std(new_values) / (np.std(old_values) + 1e-8)\n",
    "                \n",
    "                report[feature] = {\n",
    "                    'mean_shift_zscore': mean_shift,\n",
    "                    'std_ratio': std_ratio,\n",
    "                    'drift_suspected': mean_shift > 2 or std_ratio > 2 or std_ratio < 0.5\n",
    "                }\n",
    "        return report\n",
    "    \n",
    "    def get_monitoring_summary(self):\n",
    "        \"\"\"Get monitoring summary.\"\"\"\n",
    "        if not self.predictions:\n",
    "            return \"No predictions made yet.\"\n",
    "        \n",
    "        overall_acc = np.mean([p == a for p, a in zip(self.predictions, self.actuals)])\n",
    "        \n",
    "        return {\n",
    "            'total_samples': len(self.predictions),\n",
    "            'overall_accuracy': f\"{overall_acc:.4f}\",\n",
    "            'rolling_accuracy': f\"{self.get_rolling_accuracy():.4f}\" if self.get_rolling_accuracy() else \"N/A\",\n",
    "            'drift_events': len(self.drift_events),\n",
    "            'features_with_drift': sum(1 for f, r in self.get_feature_drift_report().items() \n",
    "                                       if r.get('drift_suspected', False))\n",
    "        }\n",
    "\n",
    "\n",
    "# Demo production system\n",
    "prod_model = compose.Pipeline(\n",
    "    preprocessing.StandardScaler(),\n",
    "    linear_model.LogisticRegression(optimizer=optim.SGD(lr=0.01))\n",
    ")\n",
    "\n",
    "prod_learner = ProductionOnlineLearner(prod_model, window_size=100)\n",
    "\n",
    "# Simulate production environment\n",
    "for idx, row in X.iterrows():\n",
    "    x_dict = row.to_dict()\n",
    "    y_true = int(y.loc[idx])\n",
    "    \n",
    "    pred = prod_learner.predict(x_dict, timestamp=idx)\n",
    "    prod_learner.learn(x_dict, y_true, timestamp=idx)\n",
    "\n",
    "# Get monitoring report\n",
    "print(\"\\n=== Production Monitoring Summary ===\")\n",
    "summary = prod_learner.get_monitoring_summary()\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\n=== Feature Drift Report ===\")\n",
    "drift_report = prod_learner.get_feature_drift_report()\n",
    "drifted_features = [f for f, r in drift_report.items() if r.get('drift_suspected', False)]\n",
    "print(f\"  Features with suspected drift: {drifted_features if drifted_features else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb2c092",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Summary & Key Takeaways\n",
    "\n",
    "### Online Learning Advantages for Trading:\n",
    "1. **Adaptability**: Models continuously adapt to new market regimes\n",
    "2. **Efficiency**: No need to store/reprocess all historical data\n",
    "3. **Real-time**: Updates as new data arrives\n",
    "4. **Memory**: Constant memory usage regardless of data size\n",
    "\n",
    "### Key Algorithms Covered:\n",
    "- **River**: LogisticRegression, LinearRegression, Hoeffding Trees\n",
    "- **Sklearn**: SGDClassifier, PassiveAggressiveClassifier\n",
    "- **Drift Detection**: ADWIN, DDM, Page-Hinkley\n",
    "- **Ensembles**: ADWIN Bagging, Leveraging Bagging\n",
    "\n",
    "### Production Considerations:\n",
    "- Monitor model performance continuously\n",
    "- Implement drift detection and response\n",
    "- Track feature distributions for data quality\n",
    "- Maintain model checkpoints for rollback\n",
    "\n",
    "### Challenges:\n",
    "- Lower accuracy than batch models with full data\n",
    "- Sensitivity to learning rate tuning\n",
    "- Risk of overfitting to recent noise\n",
    "- Need for robust monitoring infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final comparison table\n",
    "comparison_data = {\n",
    "    'Model': ['River Logistic', 'Adaptive Model', 'ADWIN Bagging', \n",
    "              'Leveraging Bagging', 'SKLearn SGD', 'SKLearn PA'],\n",
    "    'Final Accuracy': [\n",
    "        results_df['accuracy'].iloc[-1],\n",
    "        adaptive_df['accuracy'].iloc[-1],\n",
    "        ensemble_df['ADWIN Bagging'].iloc[-1],\n",
    "        ensemble_df['Leveraging Bagging'].iloc[-1],\n",
    "        sklearn_df['SGD'].iloc[-1],\n",
    "        sklearn_df['PassiveAggressive'].iloc[-1]\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_table = pd.DataFrame(comparison_data)\n",
    "comparison_table['Final Accuracy'] = comparison_table['Final Accuracy'].apply(lambda x: f\"{x:.4f}\")\n",
    "comparison_table = comparison_table.sort_values('Final Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\n=== Online Learning Model Comparison ===\")\n",
    "print(comparison_table.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5dd3e7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "1. **Multi-Asset Online Learning**: Extend the strategy to trade multiple assets simultaneously\n",
    "\n",
    "2. **Feature Selection**: Implement online feature importance tracking and dynamic feature selection\n",
    "\n",
    "3. **Regime Detection**: Build a regime detection system that adjusts model hyperparameters based on detected market regime\n",
    "\n",
    "4. **Ensemble Strategies**: Create an ensemble that combines batch-trained and online models\n",
    "\n",
    "5. **Latency Analysis**: Measure and optimize the prediction latency of online models for HFT applications\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. River Documentation: https://riverml.xyz/\n",
    "2. Gama, J., et al. (2014). \"A Survey on Concept Drift Adaptation\"\n",
    "3. Bifet, A., & Gavaldà, R. (2007). \"Learning from Time-Changing Data with Adaptive Windowing\"\n",
    "4. Shalev-Shwartz, S. (2012). \"Online Learning and Online Convex Optimization\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
