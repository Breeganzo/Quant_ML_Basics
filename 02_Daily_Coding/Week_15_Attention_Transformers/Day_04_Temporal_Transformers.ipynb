{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ff9e69",
   "metadata": {},
   "source": [
    "# Week 15 - Day 4: Temporal Transformers for Financial Time Series\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand time series specific transformer modifications\n",
    "- Implement Temporal Fusion Transformer (TFT) concepts\n",
    "- Explore interpretability mechanisms in transformers\n",
    "- Build a practical trading prediction system\n",
    "\n",
    "---\n",
    "\n",
    "## Why Temporal Transformers?\n",
    "\n",
    "Standard transformers were designed for NLP tasks where positional encoding is sufficient. However, financial time series have:\n",
    "- **Irregular temporal patterns** (weekends, holidays, varying volatility regimes)\n",
    "- **Multi-horizon forecasting needs** (predict 1-day, 5-day, 20-day ahead)\n",
    "- **Multiple input types** (static features, known future inputs, observed values)\n",
    "- **Need for interpretability** (understanding why models make predictions)\n",
    "\n",
    "The **Temporal Fusion Transformer (TFT)** addresses these challenges with specialized components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acbae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# Sklearn for preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f9fd0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Time Series Specific Transformer Modifications\n",
    "\n",
    "### 1.1 Temporal Positional Encoding\n",
    "\n",
    "Unlike standard positional encoding, temporal encoding captures:\n",
    "- **Time-of-day patterns** (market open/close effects)\n",
    "- **Day-of-week patterns** (Monday effect, Friday positioning)\n",
    "- **Seasonal patterns** (earnings seasons, year-end rebalancing)\n",
    "- **Distance-aware encoding** (how far apart observations are in time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a89ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalPositionalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced positional encoding for time series.\n",
    "    Combines standard sinusoidal encoding with temporal features.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Standard sinusoidal positional encoding\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # (1, max_len, d_model)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor of shape (batch_size, seq_len, d_model)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class LearnedTemporalEncoding(nn.Module):\n",
    "    \"\"\"\n",
    "    Learned positional encoding that can capture complex temporal patterns.\n",
    "    Better for financial time series with irregular patterns.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Learnable position embeddings\n",
    "        self.position_embedding = nn.Embedding(max_len, d_model)\n",
    "        \n",
    "        # Temporal feature embeddings (day of week, month, etc.)\n",
    "        self.day_of_week_embedding = nn.Embedding(7, d_model // 4)\n",
    "        self.month_embedding = nn.Embedding(12, d_model // 4)\n",
    "        \n",
    "        # Projection to combine temporal features\n",
    "        self.temporal_projection = nn.Linear(d_model // 2, d_model)\n",
    "        \n",
    "    def forward(self, x, day_of_week=None, month=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch_size, seq_len, d_model)\n",
    "            day_of_week: Day indices (batch_size, seq_len)\n",
    "            month: Month indices (batch_size, seq_len)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len = x.size(0), x.size(1)\n",
    "        \n",
    "        # Position encoding\n",
    "        positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1)\n",
    "        pos_encoding = self.position_embedding(positions)\n",
    "        \n",
    "        # Add temporal features if provided\n",
    "        if day_of_week is not None and month is not None:\n",
    "            dow_emb = self.day_of_week_embedding(day_of_week)\n",
    "            month_emb = self.month_embedding(month)\n",
    "            temporal_features = torch.cat([dow_emb, month_emb], dim=-1)\n",
    "            temporal_encoding = self.temporal_projection(temporal_features)\n",
    "            pos_encoding = pos_encoding + temporal_encoding\n",
    "        \n",
    "        return self.dropout(x + pos_encoding)\n",
    "\n",
    "\n",
    "# Demonstrate positional encodings\n",
    "d_model = 64\n",
    "seq_len = 100\n",
    "\n",
    "# Create sample input\n",
    "x = torch.randn(2, seq_len, d_model)\n",
    "\n",
    "# Test standard encoding\n",
    "standard_pe = TemporalPositionalEncoding(d_model)\n",
    "x_encoded = standard_pe(x)\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Encoded shape: {x_encoded.shape}\")\n",
    "\n",
    "# Visualize positional encoding patterns\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot sinusoidal patterns\n",
    "pe_values = standard_pe.pe[0, :50, :16].numpy()\n",
    "im = axes[0].imshow(pe_values.T, aspect='auto', cmap='RdBu')\n",
    "axes[0].set_xlabel('Position')\n",
    "axes[0].set_ylabel('Encoding Dimension')\n",
    "axes[0].set_title('Sinusoidal Positional Encoding')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "# Plot encoding values at different positions\n",
    "positions = [0, 10, 25, 49]\n",
    "for pos in positions:\n",
    "    axes[1].plot(pe_values[pos, :], label=f'Position {pos}', alpha=0.8)\n",
    "axes[1].set_xlabel('Encoding Dimension')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].set_title('Encoding Values at Different Positions')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad76ed41",
   "metadata": {},
   "source": [
    "### 1.2 Causal (Autoregressive) Attention Mask\n",
    "\n",
    "For time series prediction, we must ensure the model cannot \"look into the future\".\n",
    "This is achieved through **causal masking** in the attention mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d136b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalSelfAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Causal (masked) self-attention for autoregressive time series modeling.\n",
    "    Each position can only attend to previous positions.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        \n",
    "        # Q, K, V projections\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Output projection\n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "    def generate_causal_mask(self, seq_len, device):\n",
    "        \"\"\"Generate lower triangular mask to prevent attending to future positions.\"\"\"\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, x, return_attention=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch_size, seq_len, d_model)\n",
    "            return_attention: Whether to return attention weights\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Linear projections\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        \n",
    "        # Reshape for multi-head attention\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        V = V.view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Scaled dot-product attention with causal mask\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        # Apply causal mask\n",
    "        causal_mask = self.generate_causal_mask(seq_len, x.device)\n",
    "        attention_scores = attention_scores + causal_mask\n",
    "        \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        # Apply attention to values\n",
    "        attention_output = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        # Reshape and project\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous()\n",
    "        attention_output = attention_output.view(batch_size, seq_len, self.d_model)\n",
    "        output = self.out_proj(attention_output)\n",
    "        \n",
    "        if return_attention:\n",
    "            return output, attention_weights\n",
    "        return output\n",
    "\n",
    "\n",
    "# Visualize causal mask\n",
    "seq_len = 10\n",
    "causal_attn = CausalSelfAttention(d_model=64, n_heads=4)\n",
    "mask = causal_attn.generate_causal_mask(seq_len, device='cpu')\n",
    "\n",
    "# Convert for visualization (replace -inf with 0 for display)\n",
    "mask_viz = mask.clone()\n",
    "mask_viz[mask_viz == float('-inf')] = -10\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(mask_viz.numpy(), annot=True, fmt='.0f', cmap='RdYlGn_r',\n",
    "            xticklabels=[f't-{seq_len-1-i}' for i in range(seq_len)],\n",
    "            yticklabels=[f't-{seq_len-1-i}' for i in range(seq_len)])\n",
    "plt.title('Causal Attention Mask\\n(0 = can attend, -inf = blocked)')\n",
    "plt.xlabel('Key Positions')\n",
    "plt.ylabel('Query Positions')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCausal mask ensures each position only attends to current and past positions.\")\n",
    "print(\"This is critical for time series to prevent information leakage.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5653be7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Temporal Fusion Transformer (TFT) Concepts\n",
    "\n",
    "The TFT architecture (Lim et al., 2019) introduces several key innovations:\n",
    "\n",
    "1. **Variable Selection Networks** - Learn which inputs are important\n",
    "2. **Gated Residual Networks (GRN)** - Flexible nonlinear processing\n",
    "3. **Interpretable Multi-Head Attention** - Understand temporal patterns\n",
    "4. **Quantile Outputs** - Probabilistic predictions\n",
    "\n",
    "### 2.1 Gated Residual Network (GRN)\n",
    "\n",
    "The GRN is a fundamental building block that provides:\n",
    "- Skip connections for gradient flow\n",
    "- Gating mechanism to control information flow\n",
    "- Flexibility to learn complex patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedLinearUnit(nn.Module):\n",
    "    \"\"\"Gated Linear Unit (GLU) for controlled information flow.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim * 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x, gate = x.chunk(2, dim=-1)\n",
    "        return x * torch.sigmoid(gate)\n",
    "\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Gated Residual Network from TFT paper.\n",
    "    Provides flexible nonlinear processing with skip connections.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.1, context_dim=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        # Primary transformation\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Context integration (optional)\n",
    "        self.context_projection = None\n",
    "        if context_dim is not None:\n",
    "            self.context_projection = nn.Linear(context_dim, hidden_dim, bias=False)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Gating mechanism\n",
    "        self.gate = GatedLinearUnit(output_dim, output_dim)\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(output_dim)\n",
    "        \n",
    "        # Skip connection projection (if dimensions differ)\n",
    "        self.skip_projection = None\n",
    "        if input_dim != output_dim:\n",
    "            self.skip_projection = nn.Linear(input_dim, output_dim)\n",
    "            \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.elu = nn.ELU()\n",
    "        \n",
    "    def forward(self, x, context=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor\n",
    "            context: Optional context tensor for conditioning\n",
    "        \"\"\"\n",
    "        # Skip connection\n",
    "        residual = x if self.skip_projection is None else self.skip_projection(x)\n",
    "        \n",
    "        # Primary transformation\n",
    "        hidden = self.fc1(x)\n",
    "        \n",
    "        # Add context if provided\n",
    "        if context is not None and self.context_projection is not None:\n",
    "            hidden = hidden + self.context_projection(context)\n",
    "            \n",
    "        hidden = self.elu(hidden)\n",
    "        hidden = self.fc2(hidden)\n",
    "        hidden = self.dropout(hidden)\n",
    "        \n",
    "        # Gated skip connection\n",
    "        gated = self.gate(hidden)\n",
    "        output = self.layer_norm(residual + gated)\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "# Test GRN\n",
    "grn = GatedResidualNetwork(input_dim=32, hidden_dim=64, output_dim=32)\n",
    "x = torch.randn(4, 10, 32)  # (batch, seq_len, features)\n",
    "output = grn(x)\n",
    "print(f\"GRN Input: {x.shape} -> Output: {output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690c4e37",
   "metadata": {},
   "source": [
    "### 2.2 Variable Selection Network (VSN)\n",
    "\n",
    "The VSN learns to weight different input features based on their importance.\n",
    "This provides **interpretability** by showing which features the model relies on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb023e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableSelectionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Variable Selection Network from TFT.\n",
    "    Learns to weight different input variables based on their relevance.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim, num_vars, hidden_dim, dropout=0.1, context_dim=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_vars = num_vars\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Individual variable processing\n",
    "        self.var_grns = nn.ModuleList([\n",
    "            GatedResidualNetwork(\n",
    "                input_dim=input_dim // num_vars,\n",
    "                hidden_dim=hidden_dim,\n",
    "                output_dim=hidden_dim,\n",
    "                dropout=dropout\n",
    "            )\n",
    "            for _ in range(num_vars)\n",
    "        ])\n",
    "        \n",
    "        # Softmax variable weights GRN\n",
    "        self.flattened_grn = GatedResidualNetwork(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=num_vars,\n",
    "            dropout=dropout,\n",
    "            context_dim=context_dim\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, context=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch, seq_len, num_vars * var_dim)\n",
    "            context: Optional context for conditioning\n",
    "            \n",
    "        Returns:\n",
    "            output: Weighted combination of processed variables\n",
    "            weights: Variable importance weights (for interpretability)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        var_dim = x.size(-1) // self.num_vars\n",
    "        \n",
    "        # Split input into individual variables\n",
    "        var_inputs = x.view(batch_size, seq_len, self.num_vars, var_dim)\n",
    "        \n",
    "        # Process each variable through its GRN\n",
    "        var_outputs = []\n",
    "        for i in range(self.num_vars):\n",
    "            var_out = self.var_grns[i](var_inputs[:, :, i, :])\n",
    "            var_outputs.append(var_out)\n",
    "        \n",
    "        # Stack processed variables: (batch, seq_len, num_vars, hidden_dim)\n",
    "        var_outputs = torch.stack(var_outputs, dim=2)\n",
    "        \n",
    "        # Compute variable selection weights\n",
    "        weights = self.flattened_grn(x, context)  # (batch, seq_len, num_vars)\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        \n",
    "        # Weighted combination\n",
    "        weights_expanded = weights.unsqueeze(-1)  # (batch, seq_len, num_vars, 1)\n",
    "        output = (var_outputs * weights_expanded).sum(dim=2)  # (batch, seq_len, hidden_dim)\n",
    "        \n",
    "        return output, weights\n",
    "\n",
    "\n",
    "# Test Variable Selection Network\n",
    "num_vars = 5\n",
    "var_dim = 8\n",
    "hidden_dim = 32\n",
    "\n",
    "vsn = VariableSelectionNetwork(\n",
    "    input_dim=num_vars * var_dim,\n",
    "    num_vars=num_vars,\n",
    "    hidden_dim=hidden_dim\n",
    ")\n",
    "\n",
    "x = torch.randn(4, 10, num_vars * var_dim)\n",
    "output, weights = vsn(x)\n",
    "\n",
    "print(f\"VSN Input: {x.shape}\")\n",
    "print(f\"VSN Output: {output.shape}\")\n",
    "print(f\"Variable Weights: {weights.shape}\")\n",
    "print(f\"\\nSample weights (first timestep): {weights[0, 0, :].detach().numpy().round(3)}\")\n",
    "print(f\"Weights sum to: {weights[0, 0, :].sum().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e61c65",
   "metadata": {},
   "source": [
    "### 2.3 Interpretable Multi-Head Attention\n",
    "\n",
    "TFT uses a modified attention mechanism that enables interpretation of:\n",
    "- Which past time steps are most important for prediction\n",
    "- How attention patterns change across different forecasting horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterpretableMultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Interpretable Multi-Head Attention from TFT.\n",
    "    Shares values across heads for interpretability while keeping\n",
    "    separate queries and keys for different attention patterns.\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, n_heads, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % n_heads == 0\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.head_dim = d_model // n_heads\n",
    "        \n",
    "        # Separate Q, K projections per head\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Shared value projection (interpretability)\n",
    "        self.value = nn.Linear(d_model, self.head_dim)  # Single head for values\n",
    "        \n",
    "        # Output projection\n",
    "        self.out_proj = nn.Linear(self.head_dim, d_model)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.scale = self.head_dim ** -0.5\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch, seq_len, d_model)\n",
    "            mask: Optional attention mask\n",
    "            \n",
    "        Returns:\n",
    "            output: Attention output\n",
    "            attention_weights: Average attention across heads (interpretable)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        \n",
    "        # Compute Q, K, V\n",
    "        Q = self.query(x)  # (batch, seq_len, d_model)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)  # (batch, seq_len, head_dim) - shared across heads\n",
    "        \n",
    "        # Reshape Q, K for multi-head\n",
    "        Q = Q.view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        K = K.view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) * self.scale\n",
    "        \n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            attention_scores = attention_scores + mask\n",
    "            \n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "        \n",
    "        # Average attention across heads (for interpretability)\n",
    "        avg_attention = attention_weights.mean(dim=1)  # (batch, seq_len, seq_len)\n",
    "        \n",
    "        # Apply attention to shared values\n",
    "        # Sum weighted values across heads\n",
    "        attention_output = torch.matmul(avg_attention, V)  # (batch, seq_len, head_dim)\n",
    "        \n",
    "        # Output projection\n",
    "        output = self.out_proj(attention_output)\n",
    "        \n",
    "        return output, avg_attention\n",
    "\n",
    "\n",
    "# Test interpretable attention\n",
    "int_attn = InterpretableMultiHeadAttention(d_model=64, n_heads=4)\n",
    "x = torch.randn(2, 20, 64)\n",
    "output, attn_weights = int_attn(x)\n",
    "\n",
    "print(f\"Input: {x.shape}\")\n",
    "print(f\"Output: {output.shape}\")\n",
    "print(f\"Attention Weights: {attn_weights.shape}\")\n",
    "\n",
    "# Visualize attention pattern\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(attn_weights[0].detach().numpy(), cmap='viridis')\n",
    "plt.title('Interpretable Attention Weights\\n(Averaged across heads)')\n",
    "plt.xlabel('Key Positions (Past)')\n",
    "plt.ylabel('Query Positions (Current)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092ba45",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Building a Temporal Transformer for Trading\n",
    "\n",
    "Now let's combine these components into a complete Temporal Transformer for stock price prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2deb8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalTransformerBlock(nn.Module):\n",
    "    \"\"\"Single Temporal Transformer block with GRN and attention.\"\"\"\n",
    "    \n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Interpretable multi-head attention\n",
    "        self.attention = InterpretableMultiHeadAttention(d_model, n_heads, dropout)\n",
    "        \n",
    "        # Post-attention GRN\n",
    "        self.grn1 = GatedResidualNetwork(d_model, d_ff, d_model, dropout)\n",
    "        \n",
    "        # Feed-forward GRN\n",
    "        self.grn2 = GatedResidualNetwork(d_model, d_ff, d_model, dropout)\n",
    "        \n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        # Self-attention with residual\n",
    "        attn_out, attn_weights = self.attention(x, mask)\n",
    "        x = self.layer_norm1(x + self.dropout(attn_out))\n",
    "        x = self.grn1(x)\n",
    "        \n",
    "        # Feed-forward with residual\n",
    "        x = self.grn2(x)\n",
    "        \n",
    "        return x, attn_weights\n",
    "\n",
    "\n",
    "class TemporalFusionTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    Simplified Temporal Fusion Transformer for stock prediction.\n",
    "    Combines variable selection, temporal encoding, and interpretable attention.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 num_features,\n",
    "                 d_model=64,\n",
    "                 n_heads=4,\n",
    "                 n_layers=2,\n",
    "                 d_ff=128,\n",
    "                 dropout=0.1,\n",
    "                 max_seq_len=256,\n",
    "                 num_quantiles=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_features = num_features\n",
    "        self.d_model = d_model\n",
    "        self.num_quantiles = num_quantiles\n",
    "        \n",
    "        # Input embedding\n",
    "        self.input_projection = nn.Linear(num_features, d_model)\n",
    "        \n",
    "        # Variable Selection (for interpretability)\n",
    "        self.variable_selection = VariableSelectionNetwork(\n",
    "            input_dim=d_model,\n",
    "            num_vars=num_features,\n",
    "            hidden_dim=d_model,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.pos_encoding = LearnedTemporalEncoding(d_model, max_seq_len, dropout)\n",
    "        \n",
    "        # LSTM for local patterns (TFT uses this before attention)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=d_model,\n",
    "            hidden_size=d_model,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if n_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Temporal transformer blocks\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TemporalTransformerBlock(d_model, n_heads, d_ff, dropout)\n",
    "            for _ in range(n_layers)\n",
    "        ])\n",
    "        \n",
    "        # Output layers\n",
    "        self.output_grn = GatedResidualNetwork(d_model, d_ff, d_model, dropout)\n",
    "        \n",
    "        # Quantile outputs (for probabilistic predictions)\n",
    "        self.quantile_outputs = nn.Linear(d_model, num_quantiles)\n",
    "        \n",
    "        # Point prediction output\n",
    "        self.point_output = nn.Linear(d_model, 1)\n",
    "        \n",
    "    def generate_causal_mask(self, seq_len, device):\n",
    "        \"\"\"Generate causal mask for attention.\"\"\"\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len, device=device), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, x, return_attention=False, return_var_weights=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor (batch, seq_len, num_features)\n",
    "            return_attention: Return attention weights for interpretation\n",
    "            return_var_weights: Return variable importance weights\n",
    "            \n",
    "        Returns:\n",
    "            predictions: Point predictions (batch, seq_len, 1)\n",
    "            quantiles: Quantile predictions (batch, seq_len, num_quantiles)\n",
    "            attention_weights: List of attention weights per layer (optional)\n",
    "            var_weights: Variable importance weights (optional)\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        device = x.device\n",
    "        \n",
    "        # Input projection\n",
    "        x_proj = self.input_projection(x)\n",
    "        \n",
    "        # Variable selection (with interpretability)\n",
    "        # Reshape for VSN: treat each feature dimension separately\n",
    "        x_expanded = x.unsqueeze(-1).expand(-1, -1, -1, self.d_model // self.num_features)\n",
    "        x_flat = x_expanded.reshape(batch_size, seq_len, -1)\n",
    "        x_selected, var_weights = self.variable_selection(x_flat)\n",
    "        \n",
    "        # Combine projected input with selected features\n",
    "        x = x_proj + x_selected\n",
    "        \n",
    "        # Add positional encoding\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        # LSTM for local temporal patterns\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        x = x + lstm_out  # Residual connection\n",
    "        \n",
    "        # Causal mask\n",
    "        causal_mask = self.generate_causal_mask(seq_len, device)\n",
    "        \n",
    "        # Transformer blocks\n",
    "        attention_weights_list = []\n",
    "        for block in self.transformer_blocks:\n",
    "            x, attn_weights = block(x, causal_mask)\n",
    "            if return_attention:\n",
    "                attention_weights_list.append(attn_weights)\n",
    "        \n",
    "        # Output processing\n",
    "        output = self.output_grn(x)\n",
    "        \n",
    "        # Generate predictions\n",
    "        point_pred = self.point_output(output)\n",
    "        quantile_pred = self.quantile_outputs(output)\n",
    "        \n",
    "        results = [point_pred, quantile_pred]\n",
    "        \n",
    "        if return_attention:\n",
    "            results.append(attention_weights_list)\n",
    "        if return_var_weights:\n",
    "            results.append(var_weights)\n",
    "            \n",
    "        return tuple(results) if len(results) > 2 else (point_pred, quantile_pred)\n",
    "\n",
    "\n",
    "# Test the model\n",
    "model = TemporalFusionTransformer(\n",
    "    num_features=5,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2\n",
    ")\n",
    "\n",
    "x = torch.randn(4, 30, 5)  # (batch, seq_len, features)\n",
    "point_pred, quantile_pred, attn_weights, var_weights = model(x, return_attention=True, return_var_weights=True)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Point predictions: {point_pred.shape}\")\n",
    "print(f\"Quantile predictions: {quantile_pred.shape}\")\n",
    "print(f\"Number of attention weight tensors: {len(attn_weights)}\")\n",
    "print(f\"Variable weights shape: {var_weights.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c32e39c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Trading Prediction Practical\n",
    "\n",
    "### 4.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download stock data\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'SPY']  # Multiple stocks + market index\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "# Download data\n",
    "data = {}\n",
    "for symbol in symbols:\n",
    "    df = yf.download(symbol, start=start_date, end=end_date, progress=False)\n",
    "    data[symbol] = df['Close']\n",
    "    print(f\"Downloaded {symbol}: {len(df)} days\")\n",
    "\n",
    "# Combine into DataFrame\n",
    "prices_df = pd.DataFrame(data)\n",
    "prices_df = prices_df.dropna()\n",
    "\n",
    "print(f\"\\nCombined dataset: {prices_df.shape}\")\n",
    "print(f\"Date range: {prices_df.index[0]} to {prices_df.index[-1]}\")\n",
    "prices_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdefd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(prices_df, target_col='AAPL'):\n",
    "    \"\"\"\n",
    "    Create features for the Temporal Transformer.\n",
    "    \n",
    "    Features include:\n",
    "    - Returns (1-day, 5-day, 20-day)\n",
    "    - Volatility (rolling std)\n",
    "    - Momentum indicators\n",
    "    - Cross-asset features\n",
    "    \"\"\"\n",
    "    df = prices_df.copy()\n",
    "    \n",
    "    # Returns for all assets\n",
    "    for col in df.columns:\n",
    "        df[f'{col}_ret_1d'] = df[col].pct_change(1)\n",
    "        df[f'{col}_ret_5d'] = df[col].pct_change(5)\n",
    "        df[f'{col}_ret_20d'] = df[col].pct_change(20)\n",
    "    \n",
    "    # Target-specific features\n",
    "    target = df[target_col]\n",
    "    \n",
    "    # Moving averages\n",
    "    df['ma_ratio_5_20'] = target.rolling(5).mean() / target.rolling(20).mean()\n",
    "    df['ma_ratio_20_50'] = target.rolling(20).mean() / target.rolling(50).mean()\n",
    "    \n",
    "    # Volatility\n",
    "    df['volatility_20d'] = df[f'{target_col}_ret_1d'].rolling(20).std()\n",
    "    df['volatility_60d'] = df[f'{target_col}_ret_1d'].rolling(60).std()\n",
    "    df['vol_ratio'] = df['volatility_20d'] / df['volatility_60d']\n",
    "    \n",
    "    # Momentum\n",
    "    df['momentum_10d'] = target.pct_change(10)\n",
    "    df['momentum_30d'] = target.pct_change(30)\n",
    "    \n",
    "    # RSI-like feature\n",
    "    delta = target.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    df['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Beta to market (SPY)\n",
    "    if 'SPY' in df.columns:\n",
    "        rolling_cov = df[f'{target_col}_ret_1d'].rolling(60).cov(df['SPY_ret_1d'])\n",
    "        rolling_var = df['SPY_ret_1d'].rolling(60).var()\n",
    "        df['beta_60d'] = rolling_cov / rolling_var\n",
    "    \n",
    "    # Target: Next day return\n",
    "    df['target'] = df[f'{target_col}_ret_1d'].shift(-1)\n",
    "    \n",
    "    # Drop original price columns and NaN\n",
    "    feature_cols = [c for c in df.columns if c not in symbols]\n",
    "    df = df[feature_cols].dropna()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Create features\n",
    "features_df = create_features(prices_df, target_col='AAPL')\n",
    "print(f\"Feature DataFrame shape: {features_df.shape}\")\n",
    "print(f\"\\nFeatures:\")\n",
    "print(features_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21c3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    \"\"\"Dataset for sequence-to-sequence time series prediction.\"\"\"\n",
    "    \n",
    "    def __init__(self, features, targets, seq_len=60, pred_len=1):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.features) - self.seq_len - self.pred_len + 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx:idx + self.seq_len]\n",
    "        y = self.targets[idx + self.seq_len:idx + self.seq_len + self.pred_len]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def prepare_data(df, seq_len=60, train_ratio=0.7, val_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Prepare train/val/test datasets with proper scaling.\n",
    "    Uses time-based split (no shuffling for time series).\n",
    "    \"\"\"\n",
    "    # Separate features and target\n",
    "    feature_cols = [c for c in df.columns if c != 'target']\n",
    "    X = df[feature_cols].values\n",
    "    y = df['target'].values.reshape(-1, 1)\n",
    "    \n",
    "    # Time-based split\n",
    "    n = len(df)\n",
    "    train_end = int(n * train_ratio)\n",
    "    val_end = int(n * (train_ratio + val_ratio))\n",
    "    \n",
    "    X_train, y_train = X[:train_end], y[:train_end]\n",
    "    X_val, y_val = X[train_end:val_end], y[train_end:val_end]\n",
    "    X_test, y_test = X[val_end:], y[val_end:]\n",
    "    \n",
    "    # Scale features (fit on train only)\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    \n",
    "    X_train = scaler_X.fit_transform(X_train)\n",
    "    X_val = scaler_X.transform(X_val)\n",
    "    X_test = scaler_X.transform(X_test)\n",
    "    \n",
    "    y_train = scaler_y.fit_transform(y_train)\n",
    "    y_val = scaler_y.transform(y_val)\n",
    "    y_test = scaler_y.transform(y_test)\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = TimeSeriesDataset(X_train, y_train, seq_len)\n",
    "    val_dataset = TimeSeriesDataset(X_val, y_val, seq_len)\n",
    "    test_dataset = TimeSeriesDataset(X_test, y_test, seq_len)\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset, scaler_X, scaler_y, feature_cols\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "SEQ_LEN = 60  # Use 60 days of history\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset, val_dataset, test_dataset, scaler_X, scaler_y, feature_cols = prepare_data(\n",
    "    features_df, seq_len=SEQ_LEN\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Check a batch\n",
    "x_batch, y_batch = next(iter(train_loader))\n",
    "print(f\"\\nBatch shapes: X={x_batch.shape}, y={y_batch.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed29880",
   "metadata": {},
   "source": [
    "### 4.2 Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLoss(nn.Module):\n",
    "    \"\"\"Quantile loss for probabilistic predictions.\"\"\"\n",
    "    \n",
    "    def __init__(self, quantiles=[0.1, 0.5, 0.9]):\n",
    "        super().__init__()\n",
    "        self.quantiles = quantiles\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            predictions: (batch, seq_len, num_quantiles)\n",
    "            targets: (batch, seq_len, 1)\n",
    "        \"\"\"\n",
    "        losses = []\n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            pred_q = predictions[:, :, i:i+1]\n",
    "            error = targets - pred_q\n",
    "            loss = torch.max(q * error, (q - 1) * error)\n",
    "            losses.append(loss.mean())\n",
    "        return sum(losses) / len(losses)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.001, device='cpu'):\n",
    "    \"\"\"\n",
    "    Train the Temporal Transformer model.\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Loss functions\n",
    "    mse_loss = nn.MSELoss()\n",
    "    quantile_loss = QuantileLoss(quantiles=[0.1, 0.5, 0.9])\n",
    "    \n",
    "    # Optimizer with gradient clipping\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "    \n",
    "    # Training history\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_mse': [], 'val_mse': []}\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        train_mses = []\n",
    "        \n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass (use last timestep for prediction)\n",
    "            point_pred, quantile_pred = model(x_batch)\n",
    "            \n",
    "            # Use only the last timestep predictions\n",
    "            point_pred_last = point_pred[:, -1:, :]  # (batch, 1, 1)\n",
    "            quantile_pred_last = quantile_pred[:, -1:, :]  # (batch, 1, 3)\n",
    "            \n",
    "            # Compute losses\n",
    "            mse = mse_loss(point_pred_last.squeeze(-1), y_batch.squeeze(-1))\n",
    "            q_loss = quantile_loss(quantile_pred_last, y_batch)\n",
    "            loss = mse + 0.5 * q_loss\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_mses.append(mse.item())\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_losses = []\n",
    "        val_mses = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in val_loader:\n",
    "                x_batch = x_batch.to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                \n",
    "                point_pred, quantile_pred = model(x_batch)\n",
    "                point_pred_last = point_pred[:, -1:, :]\n",
    "                quantile_pred_last = quantile_pred[:, -1:, :]\n",
    "                \n",
    "                mse = mse_loss(point_pred_last.squeeze(-1), y_batch.squeeze(-1))\n",
    "                q_loss = quantile_loss(quantile_pred_last, y_batch)\n",
    "                loss = mse + 0.5 * q_loss\n",
    "                \n",
    "                val_losses.append(loss.item())\n",
    "                val_mses.append(mse.item())\n",
    "        \n",
    "        # Record metrics\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        train_mse = np.mean(train_mses)\n",
    "        val_mse = np.mean(val_mses)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_mse'].append(train_mse)\n",
    "        history['val_mse'].append(val_mse)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Save best model\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | \"\n",
    "                  f\"Train MSE: {train_mse:.6f} | Val MSE: {val_mse:.6f}\")\n",
    "    \n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "num_features = len(feature_cols)\n",
    "\n",
    "model = TemporalFusionTransformer(\n",
    "    num_features=num_features,\n",
    "    d_model=64,\n",
    "    n_heads=4,\n",
    "    n_layers=2,\n",
    "    d_ff=128,\n",
    "    dropout=0.1,\n",
    "    max_seq_len=SEQ_LEN + 10,\n",
    "    num_quantiles=3\n",
    ")\n",
    "\n",
    "print(f\"Model initialized with {sum(p.numel() for p in model.parameters()):,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd303c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model, history = train_model(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    epochs=50, \n",
    "    lr=0.001,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(history['train_loss'], label='Train Loss', alpha=0.8)\n",
    "axes[0].plot(history['val_loss'], label='Val Loss', alpha=0.8)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training & Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].plot(history['train_mse'], label='Train MSE', alpha=0.8)\n",
    "axes[1].plot(history['val_mse'], label='Val MSE', alpha=0.8)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('MSE')\n",
    "axes[1].set_title('Training & Validation MSE')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef781b3",
   "metadata": {},
   "source": [
    "### 4.3 Model Evaluation and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6bcb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, scaler_y, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate the model and collect predictions with attention weights.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_quantiles = []\n",
    "    all_attention = []\n",
    "    all_var_weights = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            # Get predictions with interpretability outputs\n",
    "            point_pred, quantile_pred, attn_weights, var_weights = model(\n",
    "                x_batch, return_attention=True, return_var_weights=True\n",
    "            )\n",
    "            \n",
    "            # Extract last timestep predictions\n",
    "            point_pred_last = point_pred[:, -1, 0].cpu().numpy()\n",
    "            quantile_pred_last = quantile_pred[:, -1, :].cpu().numpy()\n",
    "            targets = y_batch[:, 0, 0].cpu().numpy()\n",
    "            \n",
    "            all_predictions.extend(point_pred_last)\n",
    "            all_targets.extend(targets)\n",
    "            all_quantiles.extend(quantile_pred_last)\n",
    "            all_attention.append([a.cpu().numpy() for a in attn_weights])\n",
    "            all_var_weights.append(var_weights.cpu().numpy())\n",
    "    \n",
    "    # Convert to arrays\n",
    "    predictions = np.array(all_predictions)\n",
    "    targets = np.array(all_targets)\n",
    "    quantiles = np.array(all_quantiles)\n",
    "    \n",
    "    # Inverse transform to get actual returns\n",
    "    predictions_orig = scaler_y.inverse_transform(predictions.reshape(-1, 1)).flatten()\n",
    "    targets_orig = scaler_y.inverse_transform(targets.reshape(-1, 1)).flatten()\n",
    "    quantiles_orig = scaler_y.inverse_transform(quantiles)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(targets_orig, predictions_orig)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(targets_orig, predictions_orig)\n",
    "    \n",
    "    # Direction accuracy\n",
    "    direction_correct = (np.sign(predictions_orig) == np.sign(targets_orig)).mean()\n",
    "    \n",
    "    # Quantile coverage\n",
    "    lower_coverage = (targets_orig >= quantiles_orig[:, 0]).mean()\n",
    "    upper_coverage = (targets_orig <= quantiles_orig[:, 2]).mean()\n",
    "    interval_coverage = ((targets_orig >= quantiles_orig[:, 0]) & \n",
    "                         (targets_orig <= quantiles_orig[:, 2])).mean()\n",
    "    \n",
    "    results = {\n",
    "        'predictions': predictions_orig,\n",
    "        'targets': targets_orig,\n",
    "        'quantiles': quantiles_orig,\n",
    "        'attention': all_attention,\n",
    "        'var_weights': np.concatenate(all_var_weights, axis=0),\n",
    "        'metrics': {\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'Direction Accuracy': direction_correct,\n",
    "            'Lower Quantile Coverage (10%)': lower_coverage,\n",
    "            'Upper Quantile Coverage (90%)': upper_coverage,\n",
    "            '80% Interval Coverage': interval_coverage\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "results = evaluate_model(model, test_loader, scaler_y, device)\n",
    "\n",
    "# Print metrics\n",
    "print(\"=\"*50)\n",
    "print(\"TEST SET EVALUATION METRICS\")\n",
    "print(\"=\"*50)\n",
    "for metric, value in results['metrics'].items():\n",
    "    if 'Coverage' in metric or 'Accuracy' in metric:\n",
    "        print(f\"{metric}: {value:.2%}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eeb50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Predictions vs Actual (time series)\n",
    "n_show = 200\n",
    "ax = axes[0, 0]\n",
    "ax.plot(results['targets'][:n_show], label='Actual', alpha=0.7, linewidth=1)\n",
    "ax.plot(results['predictions'][:n_show], label='Predicted', alpha=0.7, linewidth=1)\n",
    "ax.fill_between(range(n_show), \n",
    "                results['quantiles'][:n_show, 0], \n",
    "                results['quantiles'][:n_show, 2], \n",
    "                alpha=0.2, label='80% Interval')\n",
    "ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Return')\n",
    "ax.set_title('Predictions vs Actual Returns (Test Set)')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Scatter plot\n",
    "ax = axes[0, 1]\n",
    "ax.scatter(results['targets'], results['predictions'], alpha=0.3, s=10)\n",
    "ax.plot([-0.1, 0.1], [-0.1, 0.1], 'r--', label='Perfect Prediction')\n",
    "ax.set_xlabel('Actual Return')\n",
    "ax.set_ylabel('Predicted Return')\n",
    "ax.set_title('Prediction Scatter Plot')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Cumulative returns (trading strategy)\n",
    "ax = axes[1, 0]\n",
    "signal = np.sign(results['predictions'])\n",
    "strategy_returns = signal * results['targets']\n",
    "cumulative_strategy = (1 + strategy_returns).cumprod()\n",
    "cumulative_buy_hold = (1 + results['targets']).cumprod()\n",
    "\n",
    "ax.plot(cumulative_strategy, label='Transformer Strategy', linewidth=2)\n",
    "ax.plot(cumulative_buy_hold, label='Buy & Hold', linewidth=2)\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Cumulative Return')\n",
    "ax.set_title('Strategy Performance vs Buy & Hold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Error distribution\n",
    "ax = axes[1, 1]\n",
    "errors = results['predictions'] - results['targets']\n",
    "ax.hist(errors, bins=50, density=True, alpha=0.7, edgecolor='black')\n",
    "ax.axvline(x=0, color='red', linestyle='--', label='Zero Error')\n",
    "ax.set_xlabel('Prediction Error')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title(f'Prediction Error Distribution\\nMean: {errors.mean():.4f}, Std: {errors.std():.4f}')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate Sharpe Ratio\n",
    "sharpe_strategy = np.sqrt(252) * strategy_returns.mean() / strategy_returns.std()\n",
    "sharpe_buyhold = np.sqrt(252) * results['targets'].mean() / results['targets'].std()\n",
    "print(f\"\\nSharpe Ratio (Strategy): {sharpe_strategy:.2f}\")\n",
    "print(f\"Sharpe Ratio (Buy & Hold): {sharpe_buyhold:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5ec43",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Interpretability Analysis\n",
    "\n",
    "One of the key advantages of the Temporal Fusion Transformer is its interpretability.\n",
    "Let's analyze:\n",
    "1. Variable importance weights\n",
    "2. Temporal attention patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3561e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Variable Importance\n",
    "var_weights = results['var_weights']  # (samples, seq_len, num_vars)\n",
    "\n",
    "# Average importance across samples and time\n",
    "avg_importance = var_weights.mean(axis=(0, 1))  # (num_vars,)\n",
    "\n",
    "# Since we expanded features for VSN, map back to original features\n",
    "# This is an approximation since VSN treats each feature separately\n",
    "num_vars_actual = min(len(feature_cols), len(avg_importance))\n",
    "\n",
    "# Plot variable importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Top variable importance\n",
    "ax = axes[0]\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_cols[:num_vars_actual],\n",
    "    'Importance': avg_importance[:num_vars_actual]\n",
    "}).sort_values('Importance', ascending=True)\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0.2, 0.8, len(importance_df)))\n",
    "ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "ax.set_xlabel('Average Importance Weight')\n",
    "ax.set_title('Variable Selection Network: Feature Importance')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Variable importance over time (for a sample)\n",
    "ax = axes[1]\n",
    "sample_idx = 0\n",
    "time_importance = var_weights[sample_idx, :, :num_vars_actual]  # (seq_len, num_vars)\n",
    "\n",
    "# Show only top 5 most important variables\n",
    "top_indices = np.argsort(avg_importance[:num_vars_actual])[-5:]\n",
    "for idx in top_indices:\n",
    "    ax.plot(time_importance[:, idx], label=feature_cols[idx], alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Time Step')\n",
    "ax.set_ylabel('Importance Weight')\n",
    "ax.set_title('Top 5 Variable Importance Over Time (Sample)')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e823d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Temporal Attention Patterns\n",
    "# Get attention from a batch\n",
    "model.eval()\n",
    "x_sample, _ = next(iter(test_loader))\n",
    "x_sample = x_sample.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    _, _, attn_weights, _ = model(x_sample[:1], return_attention=True, return_var_weights=True)\n",
    "\n",
    "# Plot attention for each layer\n",
    "fig, axes = plt.subplots(1, len(attn_weights), figsize=(7*len(attn_weights), 6))\n",
    "\n",
    "if len(attn_weights) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, attn in enumerate(attn_weights):\n",
    "    attn_matrix = attn[0].cpu().numpy()  # First sample\n",
    "    \n",
    "    im = axes[i].imshow(attn_matrix, cmap='viridis', aspect='auto')\n",
    "    axes[i].set_xlabel('Key Position (History)')\n",
    "    axes[i].set_ylabel('Query Position (Current)')\n",
    "    axes[i].set_title(f'Layer {i+1} Attention Pattern')\n",
    "    plt.colorbar(im, ax=axes[i])\n",
    "\n",
    "plt.suptitle('Temporal Attention Patterns\\n(How model attends to historical data)', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyze attention at the last (prediction) position\n",
    "last_position_attention = attn_weights[-1][0, -1, :].cpu().numpy()  # Last layer, last position\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(last_position_attention)), last_position_attention, alpha=0.7)\n",
    "plt.xlabel('Historical Time Step')\n",
    "plt.ylabel('Attention Weight')\n",
    "plt.title('Attention Distribution at Prediction Time\\n(Which historical steps matter most for the prediction)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark most attended positions\n",
    "top_5_positions = np.argsort(last_position_attention)[-5:]\n",
    "for pos in top_5_positions:\n",
    "    plt.axvline(x=pos, color='red', linestyle='--', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMost attended time steps (from recent to oldest):\")\n",
    "for pos in sorted(top_5_positions, reverse=True):\n",
    "    days_ago = SEQ_LEN - 1 - pos\n",
    "    print(f\"  - Position {pos} ({days_ago} days ago): attention weight = {last_position_attention[pos]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c5b678",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Takeaways\n",
    "\n",
    "### Time Series Transformer Modifications\n",
    "1. **Temporal Positional Encoding**: Captures day-of-week, seasonal, and learned patterns\n",
    "2. **Causal Masking**: Prevents information leakage from future to past\n",
    "3. **LSTM Integration**: Captures local temporal patterns before global attention\n",
    "\n",
    "### TFT Key Components\n",
    "1. **Variable Selection Network**: Learns feature importance dynamically\n",
    "2. **Gated Residual Networks**: Flexible nonlinear processing with skip connections\n",
    "3. **Interpretable Multi-Head Attention**: Shared values enable attention interpretation\n",
    "4. **Quantile Outputs**: Probabilistic predictions with uncertainty estimation\n",
    "\n",
    "### Trading Applications\n",
    "- **Direction Prediction**: Achieved through sign of predicted returns\n",
    "- **Risk Management**: Quantile outputs provide prediction intervals\n",
    "- **Feature Analysis**: VSN shows which factors drive predictions\n",
    "- **Temporal Patterns**: Attention weights reveal important historical periods\n",
    "\n",
    "### Practical Considerations\n",
    "- Start with simpler models (LSTM, GRU) before using transformers\n",
    "- Transformers shine with longer sequences and more features\n",
    "- Interpretability is valuable for trading strategy validation\n",
    "- Quantile predictions are essential for risk-adjusted position sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0212a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary comparison\n",
    "print(\"=\"*60)\n",
    "print(\"TEMPORAL TRANSFORMER MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel Architecture:\")\n",
    "print(f\"  - Embedding Dimension: 64\")\n",
    "print(f\"  - Number of Attention Heads: 4\")\n",
    "print(f\"  - Number of Transformer Layers: 2\")\n",
    "print(f\"  - Sequence Length: {SEQ_LEN} days\")\n",
    "print(f\"  - Total Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "print(f\"\\nKey Innovations:\")\n",
    "print(f\"   Variable Selection Network for feature importance\")\n",
    "print(f\"   Learned temporal positional encoding\")\n",
    "print(f\"   Causal attention masking\")\n",
    "print(f\"   LSTM integration for local patterns\")\n",
    "print(f\"   Quantile outputs for uncertainty\")\n",
    "print(f\"   Interpretable attention weights\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "for metric, value in results['metrics'].items():\n",
    "    if 'Coverage' in metric or 'Accuracy' in metric:\n",
    "        print(f\"  - {metric}: {value:.2%}\")\n",
    "    else:\n",
    "        print(f\"  - {metric}: {value:.6f}\")\n",
    "\n",
    "print(f\"\\nStrategy Metrics:\")\n",
    "print(f\"  - Strategy Sharpe Ratio: {sharpe_strategy:.2f}\")\n",
    "print(f\"  - Buy & Hold Sharpe Ratio: {sharpe_buyhold:.2f}\")\n",
    "print(f\"  - Strategy Final Value: ${cumulative_strategy[-1]:.2f}\")\n",
    "print(f\"  - Buy & Hold Final Value: ${cumulative_buy_hold[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e8440",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Practice Exercises\n",
    "\n",
    "1. **Multi-Horizon Forecasting**: Modify the model to predict 1, 5, and 20-day returns simultaneously\n",
    "\n",
    "2. **Attention Variants**: Implement different attention mechanisms:\n",
    "   - Sparse attention (attend to only top-k positions)\n",
    "   - Relative positional attention\n",
    "   - Local + global attention hybrid\n",
    "\n",
    "3. **Alternative Data Integration**: Add sentiment features from news or social media\n",
    "\n",
    "4. **Portfolio Application**: Extend to multiple stocks and predict portfolio weights\n",
    "\n",
    "5. **Regime Detection**: Use attention patterns to identify market regime changes\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. Lim, B., et al. (2021). \"Temporal Fusion Transformers for Interpretable Multi-horizon Time Series Forecasting\"\n",
    "2. Vaswani, A., et al. (2017). \"Attention Is All You Need\"\n",
    "3. Li, S., et al. (2019). \"Enhancing the Locality and Breaking the Memory Bottleneck of Transformer on Time Series Forecasting\"\n",
    "4. Zhou, H., et al. (2021). \"Informer: Beyond Efficient Transformer for Long Sequence Time-Series Forecasting\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
