{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef63e3f8",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Week 15 Trading Strategy: Transformer-Based Prediction\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Strategy Overview\n",
    "\n",
    "**Building on Weeks 1-14 + Adding Week 15 Concepts:**\n",
    "- All previous ML methods\n",
    "- **NEW:** Self-attention for feature importance\n",
    "- **NEW:** Transformer encoder for sequence modeling\n",
    "- **NEW:** Attention-weighted trading signals\n",
    "- **NEW:** Interpretable attention patterns\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9604f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
    "BENCHMARK = 'SPY'\n",
    "LOOKBACK_DAYS = 252 * 2\n",
    "SEQUENCE_LENGTH = 30\n",
    "PREDICTION_HORIZON = 5\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š WEEK 15 TRADING STRATEGY: TRANSFORMERS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nðŸŽ¯ Analyzing: {TICKERS}\")\n",
    "print(f\"ðŸ“… Sequence length: {SEQUENCE_LENGTH} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb34d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# IMPORTS & DATA\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# Fetch data\n",
    "all_tickers = TICKERS + [BENCHMARK]\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=int(LOOKBACK_DAYS * 1.5))\n",
    "\n",
    "print(\"\\nðŸ“¥ Downloading market data...\")\n",
    "data = yf.download(all_tickers, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna().tail(LOOKBACK_DAYS)\n",
    "volumes = data['Volume'].dropna().tail(LOOKBACK_DAYS)\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(f\"âœ… Loaded {len(prices)} trading days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f1879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRANSFORMER MODEL\n",
    "# ============================================================\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        \n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        Q = self.W_q(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = self.W_k(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = self.W_v(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn_weights, V)\n",
    "        \n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.d_model)\n",
    "        return self.W_o(context), attn_weights\n",
    "\n",
    "class TradingTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=32, num_heads=4, num_layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        \n",
    "        # Positional encoding\n",
    "        pe = torch.zeros(500, d_model)\n",
    "        position = torch.arange(0, 500).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "        # Transformer layers\n",
    "        self.attention_layers = nn.ModuleList()\n",
    "        self.ff_layers = nn.ModuleList()\n",
    "        self.norms1 = nn.ModuleList()\n",
    "        self.norms2 = nn.ModuleList()\n",
    "        \n",
    "        for _ in range(num_layers):\n",
    "            self.attention_layers.append(MultiHeadAttention(d_model, num_heads))\n",
    "            self.ff_layers.append(nn.Sequential(\n",
    "                nn.Linear(d_model, d_model * 4),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.Linear(d_model * 4, d_model)\n",
    "            ))\n",
    "            self.norms1.append(nn.LayerNorm(d_model))\n",
    "            self.norms2.append(nn.LayerNorm(d_model))\n",
    "        \n",
    "        self.output = nn.Linear(d_model, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.last_attn_weights = None\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        x = self.input_proj(x)\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for attn, ff, norm1, norm2 in zip(self.attention_layers, self.ff_layers, \n",
    "                                           self.norms1, self.norms2):\n",
    "            attn_out, weights = attn(x, mask)\n",
    "            x = norm1(x + self.dropout(attn_out))\n",
    "            x = norm2(x + self.dropout(ff(x)))\n",
    "            self.last_attn_weights = weights\n",
    "        \n",
    "        return torch.sigmoid(self.output(x[:, -1, :]))\n",
    "\n",
    "print(\"âœ… TradingTransformer model defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# DATA PREPARATION\n",
    "# ============================================================\n",
    "\n",
    "def create_features(prices, returns, volumes, ticker):\n",
    "    df = pd.DataFrame(index=prices.index)\n",
    "    df['returns'] = returns[ticker]\n",
    "    df['vol_5'] = returns[ticker].rolling(5).std()\n",
    "    df['vol_20'] = returns[ticker].rolling(20).std()\n",
    "    df['mom_5'] = prices[ticker].pct_change(5)\n",
    "    df['mom_20'] = prices[ticker].pct_change(20)\n",
    "    \n",
    "    # RSI\n",
    "    delta = prices[ticker].diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    df['rsi'] = 100 - (100 / (1 + gain / loss))\n",
    "    \n",
    "    if ticker in volumes.columns:\n",
    "        df['vol_ratio'] = volumes[ticker] / volumes[ticker].rolling(20).mean()\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "def create_sequences(features, labels, seq_len=30, horizon=5):\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - seq_len - horizon + 1):\n",
    "        X.append(features[i:i+seq_len])\n",
    "        future_ret = labels[i+seq_len:i+seq_len+horizon].mean()\n",
    "        y.append(1 if future_ret > 0 else 0)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare data\n",
    "all_data = {}\n",
    "for ticker in TICKERS:\n",
    "    features = create_features(prices, returns, volumes, ticker)\n",
    "    feature_cols = [c for c in features.columns if c != 'returns']\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(features[feature_cols])\n",
    "    \n",
    "    X, y = create_sequences(scaled, features['returns'].values)\n",
    "    \n",
    "    if len(X) > 100:\n",
    "        all_data[ticker] = {'X': X, 'y': y, 'scaler': scaler, 'features': features}\n",
    "        print(f\"{ticker}: {len(X)} sequences\")\n",
    "\n",
    "print(f\"\\nâœ… Prepared data for {len(all_data)} tickers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee46afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TRAINING\n",
    "# ============================================================\n",
    "\n",
    "def train_transformer(ticker_data, epochs=80):\n",
    "    X, y = ticker_data['X'], ticker_data['y']\n",
    "    \n",
    "    train_end = int(len(X) * 0.7)\n",
    "    X_train = torch.FloatTensor(X[:train_end])\n",
    "    y_train = torch.FloatTensor(y[:train_end]).unsqueeze(1)\n",
    "    X_test = torch.FloatTensor(X[train_end:])\n",
    "    y_test = torch.FloatTensor(y[train_end:]).unsqueeze(1)\n",
    "    \n",
    "    model = TradingTransformer(input_dim=X.shape[2], d_model=32, num_heads=4, num_layers=2)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    best_state = None\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_train)\n",
    "        loss = criterion(output, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_out = model(X_test)\n",
    "            test_loss = criterion(test_out, y_test)\n",
    "        \n",
    "        if test_loss < best_loss:\n",
    "            best_loss = test_loss\n",
    "            best_state = model.state_dict().copy()\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = (model(X_test) > 0.5).float()\n",
    "        acc = (pred == y_test).float().mean().item()\n",
    "    \n",
    "    return model, acc\n",
    "\n",
    "# Train for all tickers\n",
    "print(\"ðŸ“Š TRAINING TRANSFORMERS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = {}\n",
    "for ticker in TICKERS:\n",
    "    if ticker not in all_data:\n",
    "        continue\n",
    "    \n",
    "    torch.manual_seed(42)\n",
    "    model, acc = train_transformer(all_data[ticker])\n",
    "    results[ticker] = {'model': model, 'accuracy': acc}\n",
    "    print(f\"{ticker}: Accuracy = {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253f65f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# GENERATE SIGNALS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nðŸ“Š TRANSFORMER TRADING SIGNALS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n{'Ticker':<10} {'Signal':>10} {'Probability':>15} {'Accuracy':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "signals = {}\n",
    "for ticker in TICKERS:\n",
    "    if ticker not in results or ticker not in all_data:\n",
    "        continue\n",
    "    \n",
    "    model = results[ticker]['model']\n",
    "    X_latest = torch.FloatTensor(all_data[ticker]['X'][-1:])\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prob = model(X_latest).item()\n",
    "    \n",
    "    signal = 'BUY' if prob > 0.55 else ('SELL' if prob < 0.45 else 'HOLD')\n",
    "    emoji = \"ðŸ“ˆ\" if signal == 'BUY' else (\"ðŸ“‰\" if signal == 'SELL' else \"âšª\")\n",
    "    \n",
    "    signals[ticker] = {'signal': signal, 'probability': prob, 'accuracy': results[ticker]['accuracy']}\n",
    "    print(f\"{ticker:<10} {emoji} {signal:>6} {prob:>14.1%} {results[ticker]['accuracy']:>11.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# VISUALIZATION\n",
    "# ============================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# Accuracy comparison\n",
    "ax1 = axes[0]\n",
    "accs = [results[t]['accuracy'] if t in results else 0 for t in TICKERS]\n",
    "colors = ['green' if a > 0.55 else ('orange' if a > 0.5 else 'red') for a in accs]\n",
    "ax1.bar(TICKERS, accs, color=colors, alpha=0.7)\n",
    "ax1.axhline(y=0.5, color='r', linestyle='--', alpha=0.5, label='Random')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Transformer Accuracy by Ticker', fontweight='bold')\n",
    "ax1.legend()\n",
    "\n",
    "# Signal probabilities\n",
    "ax2 = axes[1]\n",
    "probs = [signals[t]['probability'] if t in signals else 0.5 for t in TICKERS]\n",
    "colors = ['green' if p > 0.55 else ('red' if p < 0.45 else 'gray') for p in probs]\n",
    "ax2.bar(TICKERS, probs, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=0.5, color='k', linestyle='-', alpha=0.3)\n",
    "ax2.axhline(y=0.55, color='g', linestyle='--', alpha=0.5)\n",
    "ax2.axhline(y=0.45, color='r', linestyle='--', alpha=0.5)\n",
    "ax2.set_ylabel('P(Up)')\n",
    "ax2.set_title('Transformer Predictions', fontweight='bold')\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "# Signal summary\n",
    "ax3 = axes[2]\n",
    "buys = sum(1 for t in TICKERS if t in signals and signals[t]['signal'] == 'BUY')\n",
    "sells = sum(1 for t in TICKERS if t in signals and signals[t]['signal'] == 'SELL')\n",
    "holds = len([t for t in TICKERS if t in signals]) - buys - sells\n",
    "ax3.pie([buys, sells, holds], labels=['BUY', 'SELL', 'HOLD'], \n",
    "        autopct='%1.0f%%', colors=['green', 'red', 'gray'], startangle=90)\n",
    "ax3.set_title('Signal Distribution', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f30064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# FINAL RECOMMENDATIONS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"ðŸ“Š WEEK 15 - TRANSFORMER RECOMMENDATIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = pd.DataFrame({\n",
    "    'Accuracy': [results[t]['accuracy'] if t in results else 0 for t in TICKERS],\n",
    "    'P(Up)': [signals[t]['probability'] if t in signals else 0.5 for t in TICKERS],\n",
    "    'Signal': [signals[t]['signal'] if t in signals else 'N/A' for t in TICKERS]\n",
    "}, index=TICKERS)\n",
    "\n",
    "print(\"\\nðŸ“‹ SUMMARY:\")\n",
    "print(summary.round(3).to_string())\n",
    "\n",
    "buys = [t for t in TICKERS if t in signals and signals[t]['signal'] == 'BUY']\n",
    "sells = [t for t in TICKERS if t in signals and signals[t]['signal'] == 'SELL']\n",
    "holds = [t for t in TICKERS if t in signals and signals[t]['signal'] == 'HOLD']\n",
    "\n",
    "print(f\"\\nðŸ† RECOMMENDATIONS:\")\n",
    "print(f\"ðŸ“ˆ BUY: {buys if buys else 'None'}\")\n",
    "print(f\"ðŸ“‰ SELL: {sells if sells else 'None'}\")\n",
    "print(f\"âšª HOLD: {holds if holds else 'None'}\")\n",
    "\n",
    "avg_acc = np.mean([results[t]['accuracy'] for t in TICKERS if t in results])\n",
    "print(f\"\\nðŸ“Š Average Transformer Accuracy: {avg_acc:.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âš ï¸ DISCLAIMER: Educational purposes only. Not financial advice!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4359acc1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“š Key Concepts (Week 1-15)\n",
    "\n",
    "| Week | Concept | Application |\n",
    "|------|---------|-------------|\n",
    "| 1-12 | Foundation to Advanced ML | Feature engineering |\n",
    "| 13 | Neural Networks (MLP) | Baseline deep learning |\n",
    "| 14 | LSTM/GRU | Sequence modeling |\n",
    "| **15** | **Self-Attention** | **Focus on relevant periods** |\n",
    "| **15** | **Transformer** | **Parallel sequence processing** |\n",
    "| **15** | **Positional Encoding** | **Preserve temporal order** |\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
