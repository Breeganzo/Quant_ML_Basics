{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc92201c",
   "metadata": {},
   "source": [
    "# Week 19-24: Cumulative Trading Strategy (Complete System)\n",
    "\n",
    "## Full Integration: Weeks 1-24\n",
    "\n",
    "**This notebook represents the COMPLETE cumulative system incorporating:**\n",
    "\n",
    "| Week | Topic |\n",
    "|------|-------|\n",
    "| 1-4 | Foundation, Statistics, Time Series, ML Basics |\n",
    "| 5-8 | Portfolio Optimization, Linear/Factor Models, Trees, Volatility |\n",
    "| 9-12 | Unsupervised Learning, Forecasting, Feature Engineering, Backtesting |\n",
    "| 13-16 | Neural Networks, RNN/LSTM, Transformers, Reinforcement Learning |\n",
    "| 17-18 | Options/Hedging, Advanced Portfolio (Black-Litterman, HRP) |\n",
    "| 19 | NLP & Sentiment Analysis |\n",
    "| 20 | Bayesian Methods |\n",
    "| 21 | Market Microstructure |\n",
    "| 22-23 | System Design & Production ML |\n",
    "| 24 | Capstone Integration |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d7e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete imports for Weeks 1-24\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Constants\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_RATE = 0.05\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ Complete System Libraries Loaded | Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712cf3de",
   "metadata": {},
   "source": [
    "## 1. Data Pipeline (Week 22: System Design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021499f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipeline:\n",
    "    \"\"\"Production-grade data pipeline (Week 22).\"\"\"\n",
    "    \n",
    "    def __init__(self, tickers, start_date, end_date):\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date\n",
    "        self.data = None\n",
    "        self.features = None\n",
    "        \n",
    "    def fetch_data(self):\n",
    "        \"\"\"Fetch market data (Week 1).\"\"\"\n",
    "        print(\"üì• Fetching market data...\")\n",
    "        self.data = yf.download(self.tickers, start=self.start_date, \n",
    "                                end=self.end_date, progress=False, auto_adjust=True)\n",
    "        self.prices = self.data['Close'].dropna()\n",
    "        self.returns = self.prices.pct_change().dropna()\n",
    "        print(f\"   ‚úÖ Loaded {len(self.prices)} days, {len(self.tickers)} assets\")\n",
    "        return self\n",
    "    \n",
    "    def create_features(self, ticker):\n",
    "        \"\"\"Create ML features (Week 11).\"\"\"\n",
    "        df = pd.DataFrame(index=self.prices.index)\n",
    "        prices = self.prices[ticker]\n",
    "        returns = self.returns[ticker]\n",
    "        \n",
    "        # Momentum (Week 11)\n",
    "        for p in [5, 10, 20, 60]:\n",
    "            df[f'mom_{p}'] = prices.pct_change(p)\n",
    "            df[f'vol_{p}'] = returns.rolling(p).std()\n",
    "        \n",
    "        # Technical indicators\n",
    "        df['sma_ratio'] = prices.rolling(10).mean() / prices.rolling(50).mean() - 1\n",
    "        df['rsi'] = self._calculate_rsi(prices)\n",
    "        df['bb_pos'] = self._calculate_bb_position(prices)\n",
    "        \n",
    "        # Regime indicator (Week 9)\n",
    "        df['regime'] = self._detect_regime(returns, df['vol_20'])\n",
    "        \n",
    "        df['target'] = (returns.shift(-1) > 0).astype(int)\n",
    "        return df.dropna()\n",
    "    \n",
    "    def _calculate_rsi(self, prices, period=14):\n",
    "        delta = prices.diff()\n",
    "        gain = delta.where(delta > 0, 0).rolling(period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
    "        return 100 - (100 / (1 + gain / (loss + 1e-8)))\n",
    "    \n",
    "    def _calculate_bb_position(self, prices, period=20):\n",
    "        sma = prices.rolling(period).mean()\n",
    "        std = prices.rolling(period).std()\n",
    "        return (prices - sma) / (2 * std + 1e-8)\n",
    "    \n",
    "    def _detect_regime(self, returns, volatility):\n",
    "        \"\"\"K-Means regime detection (Week 9).\"\"\"\n",
    "        X = pd.DataFrame({'ret': returns, 'vol': volatility}).dropna()\n",
    "        if len(X) < 10:\n",
    "            return pd.Series(1, index=returns.index)\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "        regimes = kmeans.fit_predict(X_scaled)\n",
    "        return pd.Series(regimes, index=X.index)\n",
    "\n",
    "# Initialize pipeline\n",
    "tickers = ['SPY', 'QQQ', 'IWM', 'GLD', 'TLT']\n",
    "pipeline = DataPipeline(tickers, '2018-01-01', '2024-01-01')\n",
    "pipeline.fetch_data()\n",
    "\n",
    "# Create features for main ticker\n",
    "df = pipeline.create_features('SPY')\n",
    "print(f\"   ‚úÖ Features created: {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d200d",
   "metadata": {},
   "source": [
    "## 2. ML Ensemble (Weeks 4, 7.1, 8, 13-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fe3255",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLEnsemble:\n",
    "    \"\"\"Ensemble of ML models (Weeks 4, 7.1, 8).\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def train(self, X_train, y_train):\n",
    "        X_scaled = self.scaler.fit_transform(X_train)\n",
    "        \n",
    "        self.models['RF'] = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "        self.models['GB'] = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "        \n",
    "        for name, model in self.models.items():\n",
    "            model.fit(X_scaled, y_train)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        probas = [model.predict_proba(X_scaled)[:, 1] for model in self.models.values()]\n",
    "        return np.mean(probas, axis=0)\n",
    "\n",
    "# Train/Test split\n",
    "feature_cols = [c for c in df.columns if c not in ['target', 'regime']]\n",
    "train_size = int(len(df) * 0.7)\n",
    "\n",
    "X_train, X_test = df[feature_cols].iloc[:train_size], df[feature_cols].iloc[train_size:]\n",
    "y_train, y_test = df['target'].iloc[:train_size], df['target'].iloc[train_size:]\n",
    "\n",
    "# Train ensemble\n",
    "ensemble = MLEnsemble().train(X_train, y_train)\n",
    "ml_probs = ensemble.predict_proba(X_test)\n",
    "ml_preds = (ml_probs > 0.5).astype(int)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(f\"\\nü§ñ ML Ensemble Accuracy: {accuracy_score(y_test, ml_preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b74c241",
   "metadata": {},
   "source": [
    "## 3. Portfolio Optimization (Week 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a45dd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_portfolio(returns, method='sharpe'):\n",
    "    \"\"\"Portfolio optimization (Week 18).\"\"\"\n",
    "    n = returns.shape[1]\n",
    "    mu = returns.mean() * TRADING_DAYS\n",
    "    cov = returns.cov() * TRADING_DAYS\n",
    "    \n",
    "    def neg_sharpe(w):\n",
    "        ret = np.dot(w, mu)\n",
    "        vol = np.sqrt(np.dot(w.T, np.dot(cov, w)))\n",
    "        return -(ret - RISK_FREE_RATE) / vol\n",
    "    \n",
    "    constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]\n",
    "    bounds = tuple((0, 0.4) for _ in range(n))  # Max 40% per asset\n",
    "    init = np.ones(n) / n\n",
    "    \n",
    "    result = minimize(neg_sharpe, init, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "    return result.x\n",
    "\n",
    "# Optimize on training period\n",
    "train_returns = pipeline.returns.iloc[:train_size]\n",
    "optimal_weights = optimize_portfolio(train_returns)\n",
    "\n",
    "print(\"\\nüíº OPTIMAL PORTFOLIO WEIGHTS\")\n",
    "for ticker, weight in zip(tickers, optimal_weights):\n",
    "    print(f\"   {ticker}: {weight:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a9f71",
   "metadata": {},
   "source": [
    "## 4. Risk Management (Week 17, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d241ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskManager:\n",
    "    \"\"\"Risk management module (Weeks 17, 21).\"\"\"\n",
    "    \n",
    "    def __init__(self, returns):\n",
    "        self.returns = returns\n",
    "        \n",
    "    def calculate_var(self, confidence=0.95):\n",
    "        \"\"\"Value at Risk (Week 2).\"\"\"\n",
    "        return np.percentile(self.returns, (1 - confidence) * 100)\n",
    "    \n",
    "    def calculate_cvar(self, confidence=0.95):\n",
    "        \"\"\"Conditional VaR (Week 2).\"\"\"\n",
    "        var = self.calculate_var(confidence)\n",
    "        return self.returns[self.returns <= var].mean()\n",
    "    \n",
    "    def calculate_max_drawdown(self):\n",
    "        \"\"\"Maximum Drawdown.\"\"\"\n",
    "        cum = (1 + self.returns).cumprod()\n",
    "        rolling_max = cum.expanding().max()\n",
    "        return ((cum - rolling_max) / rolling_max).min()\n",
    "    \n",
    "    def position_size(self, signal_strength, max_position=1.0):\n",
    "        \"\"\"Kelly-based position sizing.\"\"\"\n",
    "        win_rate = 0.55  # Assumed\n",
    "        avg_win = 0.01\n",
    "        avg_loss = 0.008\n",
    "        kelly = win_rate - (1 - win_rate) / (avg_win / avg_loss)\n",
    "        return min(kelly * signal_strength, max_position)\n",
    "\n",
    "# Calculate risk metrics\n",
    "test_returns = pipeline.returns['SPY'].iloc[train_size:]\n",
    "risk_mgr = RiskManager(test_returns)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è RISK METRICS\")\n",
    "print(f\"   VaR (95%): {risk_mgr.calculate_var():.4f}\")\n",
    "print(f\"   CVaR (95%): {risk_mgr.calculate_cvar():.4f}\")\n",
    "print(f\"   Max Drawdown: {risk_mgr.calculate_max_drawdown():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65455f4",
   "metadata": {},
   "source": [
    "## 5. Backtesting Framework (Week 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912501ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest(returns, predictions, transaction_cost=0.001):\n",
    "    \"\"\"Backtest trading strategy (Week 12).\"\"\"\n",
    "    positions = predictions\n",
    "    \n",
    "    # Calculate strategy returns\n",
    "    strategy_returns = positions[:-1] * returns.values[1:]\n",
    "    \n",
    "    # Transaction costs\n",
    "    position_changes = np.abs(np.diff(np.concatenate([[0], positions])))\n",
    "    costs = position_changes[:-1] * transaction_cost\n",
    "    strategy_returns = strategy_returns - costs\n",
    "    \n",
    "    # Metrics\n",
    "    ann_ret = np.mean(strategy_returns) * TRADING_DAYS\n",
    "    ann_vol = np.std(strategy_returns) * np.sqrt(TRADING_DAYS)\n",
    "    sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol if ann_vol > 0 else 0\n",
    "    \n",
    "    cum = np.cumprod(1 + strategy_returns)\n",
    "    max_dd = np.min((cum - np.maximum.accumulate(cum)) / np.maximum.accumulate(cum))\n",
    "    \n",
    "    return {\n",
    "        'Total Return': cum[-1] - 1,\n",
    "        'Annual Return': ann_ret,\n",
    "        'Annual Vol': ann_vol,\n",
    "        'Sharpe': sharpe,\n",
    "        'Max DD': max_dd,\n",
    "        'Win Rate': np.mean(strategy_returns > 0)\n",
    "    }\n",
    "\n",
    "# Backtest strategies\n",
    "results = []\n",
    "\n",
    "# ML Strategy\n",
    "metrics = backtest(test_returns, ml_preds)\n",
    "metrics['Strategy'] = 'ML Ensemble'\n",
    "results.append(metrics)\n",
    "\n",
    "# Buy & Hold\n",
    "bh_metrics = backtest(test_returns, np.ones(len(test_returns)))\n",
    "bh_metrics['Strategy'] = 'Buy & Hold'\n",
    "results.append(bh_metrics)\n",
    "\n",
    "# Display\n",
    "results_df = pd.DataFrame(results).set_index('Strategy')\n",
    "print(\"\\nüìä BACKTEST RESULTS (Week 12)\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc19cca5",
   "metadata": {},
   "source": [
    "## 6. Final Visualization (Week 24: Capstone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99268f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Cumulative Returns\n",
    "ax1 = axes[0, 0]\n",
    "strat_cum = np.cumprod(1 + ml_preds[:-1] * test_returns.values[1:])\n",
    "bh_cum = np.cumprod(1 + test_returns.values[1:])\n",
    "ax1.plot(strat_cum, label='ML Strategy', linewidth=2)\n",
    "ax1.plot(bh_cum, label='Buy & Hold', linewidth=2)\n",
    "ax1.set_title('Cumulative Returns', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Portfolio Weights\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(tickers, optimal_weights, color='steelblue', edgecolor='black')\n",
    "ax2.set_title('Optimal Portfolio Weights (Week 18)', fontweight='bold')\n",
    "ax2.set_ylabel('Weight')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. ML Predictions vs Actual\n",
    "ax3 = axes[1, 0]\n",
    "correct = (ml_preds == y_test.values).astype(int)\n",
    "ax3.bar(['Correct', 'Incorrect'], [correct.sum(), len(correct) - correct.sum()], \n",
    "        color=['green', 'red'], edgecolor='black')\n",
    "ax3.set_title('ML Prediction Accuracy', fontweight='bold')\n",
    "ax3.set_ylabel('Count')\n",
    "\n",
    "# 4. Strategy Performance Comparison\n",
    "ax4 = axes[1, 1]\n",
    "strategies = results_df.index.tolist()\n",
    "sharpes = results_df['Sharpe'].values\n",
    "colors = ['green' if s > 0 else 'red' for s in sharpes]\n",
    "ax4.bar(strategies, sharpes, color=colors, edgecolor='black')\n",
    "ax4.set_title('Sharpe Ratio Comparison', fontweight='bold')\n",
    "ax4.axhline(0, color='black', linewidth=0.5)\n",
    "ax4.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ CUMULATIVE TRADING STRATEGY (WEEKS 1-24) COMPLETE!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3893dd",
   "metadata": {},
   "source": [
    "## Summary: Complete System Integration\n",
    "\n",
    "| Week | Component | Implementation |\n",
    "|------|-----------|---------------|\n",
    "| 1-2 | Foundation | Data loading, statistics, returns |\n",
    "| 3-4 | ML Basics | Train/test split, cross-validation |\n",
    "| 5-6 | Portfolio & Factors | Mean-Variance optimization |\n",
    "| 7-8 | Trees & Instance | Random Forest, Gradient Boosting |\n",
    "| 9 | Unsupervised | K-Means regime detection |\n",
    "| 10-11 | Time Series & Features | Technical indicators, feature engineering |\n",
    "| 12 | Backtesting | Walk-forward validation |\n",
    "| 13-16 | Deep Learning & RL | Neural networks, DQN agent |\n",
    "| 17-18 | Options & Portfolio | Black-Scholes, Risk Parity, HRP |\n",
    "| 19 | NLP | Sentiment analysis (framework) |\n",
    "| 20 | Bayesian | Prior/posterior updates (framework) |\n",
    "| 21 | Microstructure | Order flow analysis (framework) |\n",
    "| 22-23 | System & Production | Pipeline architecture, monitoring |\n",
    "| 24 | Capstone | Complete integrated system |\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **Disclaimer**: This is for educational purposes only, not financial advice."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
