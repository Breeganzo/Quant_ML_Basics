{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43dead2e",
   "metadata": {},
   "source": [
    "# Day 2: Bayesian Linear Regression with Uncertainty Quantification\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the Bayesian approach to linear regression\n",
    "- Implement Bayesian linear regression from scratch\n",
    "- Quantify uncertainty in predictions (epistemic vs aleatoric)\n",
    "- Compare with frequentist approaches\n",
    "- Apply to financial return prediction with confidence intervals\n",
    "\n",
    "## Why Bayesian Regression in Finance?\n",
    "- **Uncertainty Quantification**: Get probability distributions over predictions, not just point estimates\n",
    "- **Risk Management**: Understand confidence in predictions for position sizing\n",
    "- **Small Data**: Works better with limited data (common in finance)\n",
    "- **Prior Knowledge**: Incorporate domain expertise through priors\n",
    "- **Regularization**: Priors naturally regularize, preventing overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a89432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.stats import norm, multivariate_normal, invgamma\n",
    "import yfinance as yf\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26803673",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Bayesian vs Frequentist Linear Regression\n",
    "\n",
    "### Frequentist Approach (OLS)\n",
    "$$y = X\\beta + \\epsilon, \\quad \\epsilon \\sim N(0, \\sigma^2)$$\n",
    "\n",
    "Finds point estimate: $\\hat{\\beta} = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "### Bayesian Approach\n",
    "Treats $\\beta$ as a random variable with a prior distribution:\n",
    "\n",
    "**Prior**: $p(\\beta) = N(\\mu_0, \\Sigma_0)$\n",
    "\n",
    "**Likelihood**: $p(y|X, \\beta, \\sigma^2) = N(X\\beta, \\sigma^2 I)$\n",
    "\n",
    "**Posterior**: $p(\\beta|y, X, \\sigma^2) \\propto p(y|X, \\beta, \\sigma^2) \\cdot p(\\beta)$\n",
    "\n",
    "The posterior is also Gaussian (conjugate prior):\n",
    "$$p(\\beta|y, X, \\sigma^2) = N(\\mu_n, \\Sigma_n)$$\n",
    "\n",
    "Where:\n",
    "- $\\Sigma_n = (\\Sigma_0^{-1} + \\frac{1}{\\sigma^2}X^TX)^{-1}$\n",
    "- $\\mu_n = \\Sigma_n(\\Sigma_0^{-1}\\mu_0 + \\frac{1}{\\sigma^2}X^Ty)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa7a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLinearRegression:\n",
    "    \"\"\"\n",
    "    Bayesian Linear Regression with conjugate Gaussian prior.\n",
    "    \n",
    "    Assumes known noise variance sigma^2 (can be estimated from data).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prior_mean=None, prior_cov=None, noise_var=1.0):\n",
    "        \"\"\"\n",
    "        Initialize with prior parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        prior_mean : array-like, shape (n_features,)\n",
    "            Mean of prior distribution over weights\n",
    "        prior_cov : array-like, shape (n_features, n_features)\n",
    "            Covariance matrix of prior distribution\n",
    "        noise_var : float\n",
    "            Observation noise variance (sigma^2)\n",
    "        \"\"\"\n",
    "        self.prior_mean = prior_mean\n",
    "        self.prior_cov = prior_cov\n",
    "        self.noise_var = noise_var\n",
    "        self.posterior_mean = None\n",
    "        self.posterior_cov = None\n",
    "        self.n_features = None\n",
    "        \n",
    "    def _initialize_prior(self, n_features):\n",
    "        \"\"\"Initialize uninformative prior if not provided.\"\"\"\n",
    "        if self.prior_mean is None:\n",
    "            self.prior_mean = np.zeros(n_features)\n",
    "        if self.prior_cov is None:\n",
    "            # Large variance = uninformative prior\n",
    "            self.prior_cov = np.eye(n_features) * 100\n",
    "            \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Compute posterior distribution given data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "        y : array-like, shape (n_samples,)\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        y = np.atleast_1d(y)\n",
    "        \n",
    "        self.n_features = X.shape[1]\n",
    "        self._initialize_prior(self.n_features)\n",
    "        \n",
    "        # Prior precision (inverse covariance)\n",
    "        prior_precision = np.linalg.inv(self.prior_cov)\n",
    "        \n",
    "        # Posterior precision\n",
    "        posterior_precision = prior_precision + (1/self.noise_var) * X.T @ X\n",
    "        \n",
    "        # Posterior covariance\n",
    "        self.posterior_cov = np.linalg.inv(posterior_precision)\n",
    "        \n",
    "        # Posterior mean\n",
    "        self.posterior_mean = self.posterior_cov @ (\n",
    "            prior_precision @ self.prior_mean + \n",
    "            (1/self.noise_var) * X.T @ y\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X, return_std=False):\n",
    "        \"\"\"\n",
    "        Make predictions with uncertainty.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "        return_std : bool\n",
    "            If True, return standard deviation of predictions\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        y_mean : array, shape (n_samples,)\n",
    "            Predictive mean\n",
    "        y_std : array, shape (n_samples,)\n",
    "            Predictive standard deviation (if return_std=True)\n",
    "        \"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        \n",
    "        # Predictive mean\n",
    "        y_mean = X @ self.posterior_mean\n",
    "        \n",
    "        if return_std:\n",
    "            # Predictive variance = epistemic + aleatoric\n",
    "            # epistemic: X @ posterior_cov @ X.T (diagonal)\n",
    "            # aleatoric: noise_var\n",
    "            epistemic_var = np.sum(X @ self.posterior_cov * X, axis=1)\n",
    "            total_var = epistemic_var + self.noise_var\n",
    "            y_std = np.sqrt(total_var)\n",
    "            return y_mean, y_std\n",
    "        \n",
    "        return y_mean\n",
    "    \n",
    "    def sample_posterior(self, n_samples=100):\n",
    "        \"\"\"\n",
    "        Sample weight vectors from posterior distribution.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        samples : array, shape (n_samples, n_features)\n",
    "        \"\"\"\n",
    "        return np.random.multivariate_normal(\n",
    "            self.posterior_mean, \n",
    "            self.posterior_cov, \n",
    "            size=n_samples\n",
    "        )\n",
    "    \n",
    "    def credible_interval(self, X, alpha=0.05):\n",
    "        \"\"\"\n",
    "        Compute credible interval for predictions.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like\n",
    "        alpha : float\n",
    "            Significance level (default: 0.05 for 95% CI)\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        lower, upper : arrays\n",
    "            Lower and upper bounds of credible interval\n",
    "        \"\"\"\n",
    "        y_mean, y_std = self.predict(X, return_std=True)\n",
    "        z = norm.ppf(1 - alpha/2)\n",
    "        \n",
    "        lower = y_mean - z * y_std\n",
    "        upper = y_mean + z * y_std\n",
    "        \n",
    "        return lower, upper\n",
    "\n",
    "print(\"BayesianLinearRegression class defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa7d1aa",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Synthetic Data Example: Understanding Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d0fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples = 30\n",
    "true_beta = np.array([2.0, -1.5])  # True weights\n",
    "true_sigma = 0.5  # True noise std\n",
    "\n",
    "# Generate X with a gap (to show uncertainty)\n",
    "X_left = np.random.uniform(-3, -1, n_samples // 2)\n",
    "X_right = np.random.uniform(1, 3, n_samples // 2)\n",
    "X_train = np.concatenate([X_left, X_right])\n",
    "\n",
    "# Design matrix with intercept and feature\n",
    "X_design = np.column_stack([np.ones(len(X_train)), X_train])\n",
    "\n",
    "# Generate y\n",
    "y_train = X_design @ true_beta + np.random.normal(0, true_sigma, len(X_train))\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"True coefficients: intercept={true_beta[0]:.2f}, slope={true_beta[1]:.2f}\")\n",
    "print(f\"True noise std: {true_sigma}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ee605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Bayesian regression\n",
    "blr = BayesianLinearRegression(\n",
    "    prior_mean=np.zeros(2),      # Neutral prior\n",
    "    prior_cov=np.eye(2) * 10,    # Moderately uninformative\n",
    "    noise_var=true_sigma**2       # Known noise (in practice, estimate this)\n",
    ")\n",
    "blr.fit(X_design, y_train)\n",
    "\n",
    "print(\"Posterior Distribution:\")\n",
    "print(f\"Posterior mean: {blr.posterior_mean}\")\n",
    "print(f\"Posterior std: {np.sqrt(np.diag(blr.posterior_cov))}\")\n",
    "print(f\"\\nTrue values: {true_beta}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce34892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions with uncertainty\n",
    "X_test = np.linspace(-4, 4, 200)\n",
    "X_test_design = np.column_stack([np.ones(len(X_test)), X_test])\n",
    "\n",
    "y_pred, y_std = blr.predict(X_test_design, return_std=True)\n",
    "lower_95, upper_95 = blr.credible_interval(X_test_design, alpha=0.05)\n",
    "lower_50, upper_50 = blr.credible_interval(X_test_design, alpha=0.50)\n",
    "\n",
    "# Sample from posterior to show different plausible regression lines\n",
    "posterior_samples = blr.sample_posterior(n_samples=50)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Predictions with credible intervals\n",
    "ax = axes[0]\n",
    "ax.scatter(X_train, y_train, c='black', s=50, zorder=5, label='Training data')\n",
    "ax.plot(X_test, y_pred, 'b-', lw=2, label='Posterior mean')\n",
    "ax.fill_between(X_test, lower_95, upper_95, alpha=0.2, color='blue', label='95% CI')\n",
    "ax.fill_between(X_test, lower_50, upper_50, alpha=0.3, color='blue', label='50% CI')\n",
    "\n",
    "# True line\n",
    "y_true = X_test_design @ true_beta\n",
    "ax.plot(X_test, y_true, 'r--', lw=2, label='True function')\n",
    "\n",
    "ax.axvspan(-1, 1, alpha=0.1, color='red', label='No training data')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Bayesian Regression: Uncertainty Quantification')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "# Right: Posterior samples (multiple plausible lines)\n",
    "ax = axes[1]\n",
    "ax.scatter(X_train, y_train, c='black', s=50, zorder=5, label='Training data')\n",
    "\n",
    "for i, beta_sample in enumerate(posterior_samples[:30]):\n",
    "    y_sample = X_test_design @ beta_sample\n",
    "    ax.plot(X_test, y_sample, 'b-', alpha=0.1, \n",
    "            label='Posterior samples' if i == 0 else '')\n",
    "\n",
    "ax.plot(X_test, y_true, 'r--', lw=2, label='True function')\n",
    "ax.axvspan(-1, 1, alpha=0.1, color='red')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_title('Posterior Samples: Plausible Regression Lines')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Key Observation:\")\n",
    "print(\"Notice how uncertainty (credible interval width) INCREASES in the region\")\n",
    "print(\"where we have NO training data (-1 to 1). This is epistemic uncertainty!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc72f74c",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Types of Uncertainty\n",
    "\n",
    "### Epistemic Uncertainty (Model Uncertainty)\n",
    "- Comes from uncertainty in the model parameters\n",
    "- **Reducible** with more data\n",
    "- Captured by the posterior variance of $\\beta$\n",
    "\n",
    "### Aleatoric Uncertainty (Data/Observation Uncertainty)\n",
    "- Comes from inherent noise in the data\n",
    "- **Irreducible** - cannot be reduced with more data\n",
    "- Captured by $\\sigma^2$ (observation noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ab757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompose_uncertainty(model, X):\n",
    "    \"\"\"\n",
    "    Decompose predictive variance into epistemic and aleatoric components.\n",
    "    \"\"\"\n",
    "    X = np.atleast_2d(X)\n",
    "    \n",
    "    # Epistemic: uncertainty about the weights\n",
    "    epistemic_var = np.sum(X @ model.posterior_cov * X, axis=1)\n",
    "    \n",
    "    # Aleatoric: observation noise\n",
    "    aleatoric_var = np.full(X.shape[0], model.noise_var)\n",
    "    \n",
    "    # Total\n",
    "    total_var = epistemic_var + aleatoric_var\n",
    "    \n",
    "    return epistemic_var, aleatoric_var, total_var\n",
    "\n",
    "# Decompose uncertainty\n",
    "epistemic, aleatoric, total = decompose_uncertainty(blr, X_test_design)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.fill_between(X_test, 0, np.sqrt(aleatoric), alpha=0.5, \n",
    "                color='orange', label='Aleatoric (irreducible)')\n",
    "ax.fill_between(X_test, np.sqrt(aleatoric), np.sqrt(total), alpha=0.5, \n",
    "                color='blue', label='Epistemic (reducible)')\n",
    "\n",
    "ax.axvspan(-1, 1, alpha=0.1, color='red', label='No training data region')\n",
    "\n",
    "# Mark training data regions\n",
    "for x in X_train:\n",
    "    ax.axvline(x, color='gray', alpha=0.2, lw=0.5)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Predictive Std')\n",
    "ax.set_title('Uncertainty Decomposition: Epistemic vs Aleatoric')\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Interpretation:\")\n",
    "print(\"- Aleatoric uncertainty is CONSTANT (inherent noise in observations)\")\n",
    "print(\"- Epistemic uncertainty VARIES with distance from training data\")\n",
    "print(\"- In the gap region, epistemic uncertainty dominates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eeaf74",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Effect of Data Size on Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_with_n_samples(n):\n",
    "    \"\"\"Fit Bayesian regression with n samples.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    X = np.random.uniform(-3, 3, n)\n",
    "    X_design = np.column_stack([np.ones(n), X])\n",
    "    y = X_design @ true_beta + np.random.normal(0, true_sigma, n)\n",
    "    \n",
    "    model = BayesianLinearRegression(\n",
    "        prior_mean=np.zeros(2),\n",
    "        prior_cov=np.eye(2) * 10,\n",
    "        noise_var=true_sigma**2\n",
    "    )\n",
    "    model.fit(X_design, y)\n",
    "    return model\n",
    "\n",
    "# Fit with different sample sizes\n",
    "sample_sizes = [5, 20, 100, 500]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "X_plot = np.linspace(-4, 4, 200)\n",
    "X_plot_design = np.column_stack([np.ones(len(X_plot)), X_plot])\n",
    "y_true_plot = X_plot_design @ true_beta\n",
    "\n",
    "for i, n in enumerate(sample_sizes):\n",
    "    model = fit_with_n_samples(n)\n",
    "    y_pred, y_std = model.predict(X_plot_design, return_std=True)\n",
    "    \n",
    "    ax = axes[i]\n",
    "    ax.plot(X_plot, y_pred, 'b-', lw=2, label='Posterior mean')\n",
    "    ax.fill_between(X_plot, y_pred - 2*y_std, y_pred + 2*y_std, \n",
    "                    alpha=0.3, color='blue', label='95% CI')\n",
    "    ax.plot(X_plot, y_true_plot, 'r--', lw=2, label='True function')\n",
    "    \n",
    "    # Show posterior std on weights\n",
    "    weight_std = np.sqrt(np.diag(model.posterior_cov))\n",
    "    ax.set_title(f'n={n} samples\\n'\n",
    "                 f'Weight uncertainty: Î²â‚€Â±{weight_std[0]:.3f}, Î²â‚Â±{weight_std[1]:.3f}')\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_ylim(-10, 10)\n",
    "\n",
    "plt.suptitle('Effect of Sample Size on Epistemic Uncertainty', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Key Insight:\")\n",
    "print(\"As n increases, epistemic uncertainty (credible interval) SHRINKS\")\n",
    "print(\"Eventually converging to just the aleatoric uncertainty (noise).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b801d8e",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Financial Application: Factor Return Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127bbfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download market data\n",
    "print(\"Downloading financial data...\")\n",
    "\n",
    "tickers = ['SPY', 'TLT', 'GLD', 'VIX']  # Market, Bonds, Gold, Volatility\n",
    "data = yf.download(tickers, start='2018-01-01', end='2024-01-01', progress=False)['Adj Close']\n",
    "\n",
    "# Calculate returns\n",
    "returns = data.pct_change().dropna()\n",
    "\n",
    "# Target: SPY returns\n",
    "# Features: lagged returns of all assets\n",
    "df = pd.DataFrame()\n",
    "df['target'] = returns['SPY']\n",
    "\n",
    "# Lagged features (1-day lag)\n",
    "for ticker in tickers:\n",
    "    df[f'{ticker}_lag1'] = returns[ticker].shift(1)\n",
    "    df[f'{ticker}_lag2'] = returns[ticker].shift(2)\n",
    "    df[f'{ticker}_lag5'] = returns[ticker].shift(5)  # Weekly lag\n",
    "\n",
    "df = df.dropna()\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index[0].date()} to {df.index[-1].date()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aa40f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "feature_cols = [c for c in df.columns if c != 'target']\n",
    "X = df[feature_cols].values\n",
    "y = df['target'].values\n",
    "\n",
    "# Split: use last year as test\n",
    "split_idx = -252  # ~1 year of trading days\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "dates_test = df.index[split_idx:]\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Add intercept\n",
    "X_train_design = np.column_stack([np.ones(len(X_train_scaled)), X_train_scaled])\n",
    "X_test_design = np.column_stack([np.ones(len(X_test_scaled)), X_test_scaled])\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Test samples: {len(X_test)}\")\n",
    "print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eab8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate noise variance from training data residuals (using OLS first)\n",
    "ols = LinearRegression(fit_intercept=False)\n",
    "ols.fit(X_train_design, y_train)\n",
    "residuals = y_train - ols.predict(X_train_design)\n",
    "estimated_noise_var = np.var(residuals)\n",
    "\n",
    "print(f\"Estimated noise std: {np.sqrt(estimated_noise_var):.4f}\")\n",
    "print(f\"(Daily SPY volatility: {np.std(y_train):.4f})\")\n",
    "\n",
    "# Fit Bayesian regression\n",
    "n_features = X_train_design.shape[1]\n",
    "\n",
    "# Informative prior: we expect small coefficients for return prediction\n",
    "prior_mean = np.zeros(n_features)\n",
    "prior_cov = np.eye(n_features) * 0.01  # Regularizing prior (like Ridge)\n",
    "\n",
    "blr_finance = BayesianLinearRegression(\n",
    "    prior_mean=prior_mean,\n",
    "    prior_cov=prior_cov,\n",
    "    noise_var=estimated_noise_var\n",
    ")\n",
    "blr_finance.fit(X_train_design, y_train)\n",
    "\n",
    "print(\"\\nBayesian regression fitted!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b748e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze coefficient uncertainty\n",
    "feature_names = ['intercept'] + feature_cols\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Posterior Mean': blr_finance.posterior_mean,\n",
    "    'Posterior Std': np.sqrt(np.diag(blr_finance.posterior_cov)),\n",
    "    'OLS Estimate': ols.coef_\n",
    "})\n",
    "coef_df['95% CI Lower'] = coef_df['Posterior Mean'] - 1.96 * coef_df['Posterior Std']\n",
    "coef_df['95% CI Upper'] = coef_df['Posterior Mean'] + 1.96 * coef_df['Posterior Std']\n",
    "coef_df['Significant'] = (coef_df['95% CI Lower'] > 0) | (coef_df['95% CI Upper'] < 0)\n",
    "\n",
    "print(\"\\nCoefficient Posterior Distributions:\")\n",
    "print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ec0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coefficient uncertainty\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "y_pos = np.arange(len(feature_names))\n",
    "colors = ['green' if sig else 'gray' for sig in coef_df['Significant']]\n",
    "\n",
    "ax.barh(y_pos, coef_df['Posterior Mean'], xerr=1.96*coef_df['Posterior Std'],\n",
    "        color=colors, alpha=0.7, capsize=3)\n",
    "ax.axvline(0, color='black', linestyle='--', lw=1)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(feature_names)\n",
    "ax.set_xlabel('Coefficient Value')\n",
    "ax.set_title('Bayesian Regression Coefficients with 95% Credible Intervals\\n'\n",
    "             '(Green = CI excludes 0, Gray = CI includes 0)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "significant_features = coef_df[coef_df['Significant']]['Feature'].tolist()\n",
    "print(f\"\\nðŸ“Š Features with 95% credible intervals excluding 0:\")\n",
    "print(f\"   {significant_features if significant_features else 'None - high uncertainty!'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d60e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with uncertainty\n",
    "y_pred_test, y_std_test = blr_finance.predict(X_test_design, return_std=True)\n",
    "lower_95, upper_95 = blr_finance.credible_interval(X_test_design, alpha=0.05)\n",
    "\n",
    "# Create results DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': y_pred_test,\n",
    "    'Std': y_std_test,\n",
    "    'Lower_95': lower_95,\n",
    "    'Upper_95': upper_95\n",
    "}, index=dates_test)\n",
    "\n",
    "# Check calibration: % of actuals within 95% CI\n",
    "coverage = np.mean((y_test >= lower_95) & (y_test <= upper_95))\n",
    "print(f\"95% Credible Interval Coverage: {coverage:.1%}\")\n",
    "print(f\"(Should be close to 95% for well-calibrated uncertainty)\")\n",
    "\n",
    "# RMSE comparison\n",
    "ols_pred = ols.predict(X_test_design)\n",
    "rmse_bayesian = np.sqrt(np.mean((y_test - y_pred_test)**2))\n",
    "rmse_ols = np.sqrt(np.mean((y_test - ols_pred)**2))\n",
    "print(f\"\\nRMSE Bayesian: {rmse_bayesian:.6f}\")\n",
    "print(f\"RMSE OLS: {rmse_ols:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157a51ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions with uncertainty bands\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Top: Time series of predictions\n",
    "ax = axes[0]\n",
    "ax.plot(results.index, results['Actual'], 'k-', alpha=0.7, lw=0.8, label='Actual')\n",
    "ax.plot(results.index, results['Predicted'], 'b-', alpha=0.7, lw=1, label='Predicted')\n",
    "ax.fill_between(results.index, results['Lower_95'], results['Upper_95'], \n",
    "                alpha=0.3, color='blue', label='95% CI')\n",
    "ax.set_ylabel('Daily Return')\n",
    "ax.set_title('SPY Return Prediction with Bayesian Uncertainty')\n",
    "ax.legend(loc='upper right')\n",
    "ax.axhline(0, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Bottom: Prediction errors vs uncertainty\n",
    "ax = axes[1]\n",
    "errors = np.abs(results['Actual'] - results['Predicted'])\n",
    "ax.scatter(results['Std'], errors, alpha=0.5, s=20)\n",
    "\n",
    "# Add regression line\n",
    "z = np.polyfit(results['Std'], errors, 1)\n",
    "p = np.poly1d(z)\n",
    "x_line = np.linspace(results['Std'].min(), results['Std'].max(), 100)\n",
    "ax.plot(x_line, p(x_line), 'r--', lw=2, label=f'Trend: y={z[0]:.2f}x+{z[1]:.4f}')\n",
    "\n",
    "ax.set_xlabel('Predicted Uncertainty (Std)')\n",
    "ax.set_ylabel('Absolute Prediction Error')\n",
    "ax.set_title('Error vs Uncertainty: Are Uncertain Predictions Less Accurate?')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Correlation between uncertainty and error\n",
    "corr = np.corrcoef(results['Std'], errors)[0, 1]\n",
    "print(f\"\\nðŸ“Š Correlation between uncertainty and |error|: {corr:.3f}\")\n",
    "print(\"Positive correlation means higher uncertainty â†’ larger errors (well-calibrated!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036aed2c",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Using Uncertainty for Position Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53956a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_weighted_strategy(predictions, uncertainties, risk_aversion=1.0):\n",
    "    \"\"\"\n",
    "    Scale positions by prediction confidence.\n",
    "    \n",
    "    Position = prediction / (uncertainty * risk_aversion)\n",
    "    \n",
    "    High confidence (low uncertainty) â†’ larger positions\n",
    "    Low confidence (high uncertainty) â†’ smaller positions\n",
    "    \"\"\"\n",
    "    # Information ratio based sizing\n",
    "    positions = predictions / (uncertainties * risk_aversion)\n",
    "    \n",
    "    # Normalize to reasonable leverage\n",
    "    positions = np.clip(positions, -2, 2)  # Max 2x leverage\n",
    "    \n",
    "    return positions\n",
    "\n",
    "# Compare strategies\n",
    "# 1. Equal weight: always long/short based on prediction sign\n",
    "positions_equal = np.sign(y_pred_test)\n",
    "\n",
    "# 2. Uncertainty weighted\n",
    "positions_uncertainty = uncertainty_weighted_strategy(y_pred_test, y_std_test, risk_aversion=1.0)\n",
    "\n",
    "# Calculate returns\n",
    "returns_equal = positions_equal * y_test\n",
    "returns_uncertainty = positions_uncertainty * y_test\n",
    "returns_buy_hold = y_test\n",
    "\n",
    "# Calculate cumulative returns\n",
    "cum_equal = (1 + returns_equal).cumprod()\n",
    "cum_uncertainty = (1 + returns_uncertainty).cumprod()\n",
    "cum_buy_hold = (1 + returns_buy_hold).cumprod()\n",
    "\n",
    "# Statistics\n",
    "def calc_stats(returns):\n",
    "    return {\n",
    "        'Total Return': (1 + returns).prod() - 1,\n",
    "        'Ann. Volatility': returns.std() * np.sqrt(252),\n",
    "        'Sharpe': returns.mean() / returns.std() * np.sqrt(252),\n",
    "        'Max Drawdown': (pd.Series((1 + returns).cumprod()).cummax() - \n",
    "                        pd.Series((1 + returns).cumprod())).max()\n",
    "    }\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'Buy & Hold': calc_stats(returns_buy_hold),\n",
    "    'Equal Weight': calc_stats(returns_equal),\n",
    "    'Uncertainty Weighted': calc_stats(returns_uncertainty)\n",
    "}).T\n",
    "\n",
    "print(\"\\nStrategy Comparison:\")\n",
    "print(stats_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba468c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Cumulative returns\n",
    "ax = axes[0]\n",
    "ax.plot(dates_test, cum_buy_hold, label='Buy & Hold', lw=2)\n",
    "ax.plot(dates_test, cum_equal, label='Equal Weight (sign of prediction)', lw=2)\n",
    "ax.plot(dates_test, cum_uncertainty, label='Uncertainty Weighted', lw=2)\n",
    "ax.set_ylabel('Cumulative Return')\n",
    "ax.set_title('Strategy Comparison: Leveraging Uncertainty')\n",
    "ax.legend()\n",
    "ax.axhline(1, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Position sizes over time\n",
    "ax = axes[1]\n",
    "ax.fill_between(dates_test, 0, positions_uncertainty, alpha=0.5, label='Uncertainty Weighted Position')\n",
    "ax.axhline(0, color='black', linestyle='-', lw=0.5)\n",
    "ax.set_ylabel('Position Size')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_title('Position Sizing Based on Prediction Confidence')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Key Insight:\")\n",
    "print(\"Uncertainty-weighted positions scale down during high uncertainty periods,\")\n",
    "print(\"potentially reducing drawdowns and improving risk-adjusted returns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c877dc",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Scikit-learn's BayesianRidge Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ccead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn's Bayesian Ridge automatically estimates noise variance\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "\n",
    "br_sklearn = BayesianRidge(\n",
    "    alpha_1=1e-6, alpha_2=1e-6,  # Gamma prior on alpha (precision of weights)\n",
    "    lambda_1=1e-6, lambda_2=1e-6, # Gamma prior on lambda (precision of noise)\n",
    "    fit_intercept=True\n",
    ")\n",
    "br_sklearn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get predictions with uncertainty\n",
    "y_pred_sklearn, y_std_sklearn = br_sklearn.predict(X_test_scaled, return_std=True)\n",
    "\n",
    "print(\"Scikit-learn BayesianRidge:\")\n",
    "print(f\"Estimated noise precision (alpha): {br_sklearn.alpha_:.6f}\")\n",
    "print(f\"Estimated weight precision (lambda): {br_sklearn.lambda_:.6f}\")\n",
    "\n",
    "# Compare with our implementation\n",
    "rmse_sklearn = np.sqrt(np.mean((y_test - y_pred_sklearn)**2))\n",
    "print(f\"\\nRMSE sklearn: {rmse_sklearn:.6f}\")\n",
    "print(f\"RMSE our impl: {rmse_bayesian:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0937f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare coefficient estimates\n",
    "coef_comparison = pd.DataFrame({\n",
    "    'Feature': feature_cols,\n",
    "    'Our Bayesian': blr_finance.posterior_mean[1:],  # Skip intercept\n",
    "    'Sklearn Bayesian': br_sklearn.coef_,\n",
    "    'OLS': ols.coef_[1:]\n",
    "})\n",
    "\n",
    "print(\"\\nCoefficient Comparison:\")\n",
    "print(coef_comparison.round(6).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12612b9b",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Sequential Bayesian Updating (Online Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e4d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OnlineBayesianRegression:\n",
    "    \"\"\"\n",
    "    Bayesian regression with sequential updates.\n",
    "    Uses the posterior from previous observations as prior for new ones.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_features, prior_mean=None, prior_cov=None, noise_var=1.0):\n",
    "        self.n_features = n_features\n",
    "        self.noise_var = noise_var\n",
    "        \n",
    "        # Initialize prior\n",
    "        self.mean = prior_mean if prior_mean is not None else np.zeros(n_features)\n",
    "        self.cov = prior_cov if prior_cov is not None else np.eye(n_features) * 100\n",
    "        \n",
    "        self.history = {'mean': [self.mean.copy()], 'cov': [self.cov.copy()]}\n",
    "        \n",
    "    def update(self, x, y):\n",
    "        \"\"\"\n",
    "        Update posterior with single observation.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        x : array, shape (n_features,)\n",
    "        y : float\n",
    "        \"\"\"\n",
    "        x = np.atleast_1d(x).reshape(-1, 1)  # Column vector\n",
    "        \n",
    "        # Kalman-like update\n",
    "        # S = x.T @ cov @ x + noise_var  (scalar)\n",
    "        S = x.T @ self.cov @ x + self.noise_var\n",
    "        \n",
    "        # Kalman gain\n",
    "        K = self.cov @ x / S\n",
    "        \n",
    "        # Update mean\n",
    "        innovation = y - x.T @ self.mean\n",
    "        self.mean = self.mean + (K * innovation).flatten()\n",
    "        \n",
    "        # Update covariance\n",
    "        self.cov = self.cov - K @ x.T @ self.cov\n",
    "        \n",
    "        # Store history\n",
    "        self.history['mean'].append(self.mean.copy())\n",
    "        self.history['cov'].append(self.cov.copy())\n",
    "        \n",
    "    def predict(self, X, return_std=False):\n",
    "        \"\"\"Predict using current posterior.\"\"\"\n",
    "        X = np.atleast_2d(X)\n",
    "        y_mean = X @ self.mean\n",
    "        \n",
    "        if return_std:\n",
    "            var = np.sum(X @ self.cov * X, axis=1) + self.noise_var\n",
    "            return y_mean, np.sqrt(var)\n",
    "        return y_mean\n",
    "\n",
    "print(\"OnlineBayesianRegression class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14823d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate online learning: watch uncertainty decrease as data arrives\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simple 1D example with intercept\n",
    "n_online = 100\n",
    "X_online = np.random.uniform(-3, 3, n_online)\n",
    "X_online_design = np.column_stack([np.ones(n_online), X_online])\n",
    "y_online = X_online_design @ true_beta + np.random.normal(0, 0.5, n_online)\n",
    "\n",
    "# Initialize online learner\n",
    "online_blr = OnlineBayesianRegression(\n",
    "    n_features=2,\n",
    "    prior_mean=np.zeros(2),\n",
    "    prior_cov=np.eye(2) * 10,\n",
    "    noise_var=0.25\n",
    ")\n",
    "\n",
    "# Process observations one at a time\n",
    "for i in range(n_online):\n",
    "    online_blr.update(X_online_design[i], y_online[i])\n",
    "\n",
    "print(f\"After {n_online} sequential updates:\")\n",
    "print(f\"Posterior mean: {online_blr.mean}\")\n",
    "print(f\"True values: {true_beta}\")\n",
    "print(f\"Posterior std: {np.sqrt(np.diag(online_blr.cov))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9ed055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how uncertainty evolves over time\n",
    "means_history = np.array(online_blr.history['mean'])\n",
    "stds_history = np.array([np.sqrt(np.diag(c)) for c in online_blr.history['cov']])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for i, (name, true_val) in enumerate([('Intercept (Î²â‚€)', true_beta[0]), ('Slope (Î²â‚)', true_beta[1])]):\n",
    "    ax = axes[i]\n",
    "    n_obs = np.arange(len(means_history))\n",
    "    \n",
    "    ax.plot(n_obs, means_history[:, i], 'b-', lw=2, label='Posterior mean')\n",
    "    ax.fill_between(n_obs, \n",
    "                    means_history[:, i] - 2*stds_history[:, i],\n",
    "                    means_history[:, i] + 2*stds_history[:, i],\n",
    "                    alpha=0.3, color='blue', label='95% CI')\n",
    "    ax.axhline(true_val, color='red', linestyle='--', lw=2, label=f'True value: {true_val}')\n",
    "    \n",
    "    ax.set_xlabel('Number of Observations')\n",
    "    ax.set_ylabel('Parameter Value')\n",
    "    ax.set_title(f'{name} - Sequential Bayesian Learning')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“Š Key Observation:\")\n",
    "print(\"The credible interval SHRINKS as more data arrives (epistemic uncertainty decreases).\")\n",
    "print(\"The posterior mean converges to the true value!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdb9e66",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Calibration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4546fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_analysis(y_true, y_pred, y_std, n_bins=10):\n",
    "    \"\"\"\n",
    "    Check if predicted uncertainties are calibrated.\n",
    "    \n",
    "    For each confidence level, check if the actual coverage matches.\n",
    "    \"\"\"\n",
    "    confidence_levels = np.linspace(0.1, 0.99, 20)\n",
    "    actual_coverage = []\n",
    "    \n",
    "    for conf in confidence_levels:\n",
    "        z = norm.ppf((1 + conf) / 2)\n",
    "        lower = y_pred - z * y_std\n",
    "        upper = y_pred + z * y_std\n",
    "        coverage = np.mean((y_true >= lower) & (y_true <= upper))\n",
    "        actual_coverage.append(coverage)\n",
    "    \n",
    "    return confidence_levels, np.array(actual_coverage)\n",
    "\n",
    "# Check calibration for our Bayesian model\n",
    "conf_levels, actual_cov = calibration_analysis(y_test, y_pred_test, y_std_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Perfect calibration')\n",
    "ax.plot(conf_levels, actual_cov, 'bo-', lw=2, markersize=6, label='Bayesian Regression')\n",
    "\n",
    "ax.set_xlabel('Expected Coverage (Confidence Level)')\n",
    "ax.set_ylabel('Actual Coverage')\n",
    "ax.set_title('Calibration Plot: Expected vs Actual Coverage')\n",
    "ax.legend()\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate calibration error\n",
    "calibration_error = np.mean(np.abs(conf_levels - actual_cov))\n",
    "print(f\"\\nMean Calibration Error: {calibration_error:.3f}\")\n",
    "print(\"(Lower is better, 0 = perfectly calibrated)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13ad3d",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Summary & Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **Bayesian vs Frequentist**:\n",
    "   - Frequentist: Point estimates only\n",
    "   - Bayesian: Full probability distributions over predictions\n",
    "\n",
    "2. **Uncertainty Types**:\n",
    "   - **Epistemic**: Model uncertainty, reducible with more data\n",
    "   - **Aleatoric**: Observation noise, irreducible\n",
    "\n",
    "3. **Financial Applications**:\n",
    "   - Uncertainty-based position sizing\n",
    "   - Confidence intervals for risk management\n",
    "   - Online learning for adaptive models\n",
    "\n",
    "4. **Practical Benefits**:\n",
    "   - Built-in regularization through priors\n",
    "   - Works well with limited data\n",
    "   - Principled uncertainty quantification\n",
    "\n",
    "### Key Formulas:\n",
    "\n",
    "**Posterior Distribution**:\n",
    "$$\\Sigma_n = (\\Sigma_0^{-1} + \\frac{1}{\\sigma^2}X^TX)^{-1}$$\n",
    "$$\\mu_n = \\Sigma_n(\\Sigma_0^{-1}\\mu_0 + \\frac{1}{\\sigma^2}X^Ty)$$\n",
    "\n",
    "**Predictive Distribution**:\n",
    "$$p(y_*|x_*, X, y) = N(x_*^T\\mu_n, x_*^T\\Sigma_n x_* + \\sigma^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference implementation\n",
    "print(\"=\" * 60)\n",
    "print(\"QUICK REFERENCE: Bayesian Linear Regression\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "quick_ref = \"\"\"\n",
    "# 1. Basic Usage (our implementation)\n",
    "blr = BayesianLinearRegression(\n",
    "    prior_mean=np.zeros(n_features),  # Prior belief about weights\n",
    "    prior_cov=np.eye(n_features) * 10,  # Prior uncertainty\n",
    "    noise_var=estimated_noise_var  # Observation noise\n",
    ")\n",
    "blr.fit(X_train, y_train)\n",
    "y_pred, y_std = blr.predict(X_test, return_std=True)\n",
    "\n",
    "# 2. Scikit-learn\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "y_pred, y_std = br.predict(X_test, return_std=True)\n",
    "\n",
    "# 3. Credible Intervals\n",
    "z = 1.96  # For 95% CI\n",
    "lower = y_pred - z * y_std\n",
    "upper = y_pred + z * y_std\n",
    "\n",
    "# 4. Position Sizing with Uncertainty\n",
    "positions = predictions / (uncertainties * risk_aversion)\n",
    "\"\"\"\n",
    "print(quick_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d32d70",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercises\n",
    "\n",
    "1. **Prior Sensitivity**: How do different priors affect the posterior? Try informative vs uninformative priors.\n",
    "\n",
    "2. **Unknown Variance**: Implement Bayesian regression with unknown noise variance (conjugate prior: Normal-Inverse-Gamma).\n",
    "\n",
    "3. **Feature Selection**: Use the credible intervals to perform Bayesian feature selection.\n",
    "\n",
    "4. **Rolling Bayesian**: Implement a rolling window Bayesian regression for adaptive return prediction.\n",
    "\n",
    "5. **Compare with MCMC**: Use PyMC or Stan to implement Bayesian regression and compare with the analytical solution."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
