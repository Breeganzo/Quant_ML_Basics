{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b15284",
   "metadata": {},
   "source": [
    "# Week 1: Python & Math Foundations for Quantitative Finance\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What You'll Learn This Week\n",
    "\n",
    "This week builds your foundation for everything that follows. Think of it like learning the alphabet before writing essays - these are the essential tools every quant uses daily.\n",
    "\n",
    "**By the end of this week, you'll understand:**\n",
    "- How to work with financial data efficiently using NumPy and Pandas\n",
    "- The difference between simple and log returns (and why it matters!)\n",
    "- How to measure risk using volatility\n",
    "- Basic statistics that drive trading decisions\n",
    "\n",
    "**Why This Matters for Trading:**\n",
    "Every trading strategy, from simple moving averages to complex machine learning models, relies on these fundamentals. A hedge fund quant spends 80% of their time on data manipulation and analysis - that's exactly what we're learning here.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. NumPy Fundamentals\n",
    "2. Pandas for Financial Data\n",
    "3. Financial Returns\n",
    "4. Volatility Measures\n",
    "5. Basic Statistics for Finance\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f6a81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports and data loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Standard 5 equities for analysis\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'JPM', 'GS']\n",
    "\n",
    "# Fetch 5 years of data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "print(\"üì• Downloading market data...\")\n",
    "data = yf.download(tickers, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "print(f\"‚úÖ Loaded {len(prices)} days of data for {len(tickers)} tickers\")\n",
    "print(f\"üìÖ Date range: {prices.index[0].strftime('%Y-%m-%d')} to {prices.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(prices.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dba252e",
   "metadata": {},
   "source": [
    "## 1. NumPy Fundamentals\n",
    "\n",
    "### ü§î Why NumPy? (The Real Reason)\n",
    "\n",
    "Imagine you're a trader and you need to calculate the average return of 1,000 stocks over 10 years (that's 2.5 million data points!). Using regular Python loops would take minutes. NumPy does it in milliseconds.\n",
    "\n",
    "**Real-world analogy:** Think of NumPy as a factory assembly line vs. hand-crafting each item individually. The assembly line (NumPy) processes everything at once.\n",
    "\n",
    "### Key Concepts Explained Simply\n",
    "\n",
    "**Arrays**: Think of them as super-powered lists\n",
    "- 1D array: Like a single column in Excel (e.g., Apple's stock prices over time)\n",
    "- 2D array: Like a full Excel spreadsheet (e.g., prices of Apple, Google, Microsoft side by side)\n",
    "\n",
    "**Vectorization**: The magic trick that makes NumPy fast\n",
    "- Instead of: \"For each price, subtract the previous price\" (slow loop)\n",
    "- We say: \"Subtract these two arrays\" (fast, single operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e3a071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock prices: [100 102 101 105 103]\n",
      "Daily price changes: [ 2 -1  4 -2]\n",
      "Mean price: 102.20\n",
      "Standard deviation: 1.72\n",
      "Max price: 105\n",
      "Min price: 100\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example: Stock prices for 5 days\n",
    "prices = np.array([100, 102, 101, 105, 103])\n",
    "print(\"Stock prices:\", prices)\n",
    "\n",
    "# Vectorized operations - calculate daily changes\n",
    "# Instead of looping, we use array slicing\n",
    "daily_changes = prices[1:] - prices[:-1]\n",
    "print(\"Daily price changes:\", daily_changes)\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"Mean price: {np.mean(prices):.2f}\")\n",
    "print(f\"Standard deviation: {np.std(prices):.2f}\")\n",
    "print(f\"Max price: {np.max(prices)}\")\n",
    "print(f\"Min price: {np.min(prices)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c74b59",
   "metadata": {},
   "source": [
    "### Broadcasting\n",
    "\n",
    "Broadcasting allows operations between arrays of different shapes. This is useful when applying the same operation across multiple assets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc25fbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original prices:\n",
      "[[100  50 200]\n",
      " [102  51 198]\n",
      " [105  49 205]\n",
      " [103  52 210]]\n",
      "\n",
      "Normalized (all start at 100):\n",
      "[[100.  100.  100. ]\n",
      " [102.  102.   99. ]\n",
      " [105.   98.  102.5]\n",
      " [103.  104.  105. ]]\n"
     ]
    }
   ],
   "source": [
    "# Example: Normalize prices to start at 100 for comparison\n",
    "# Multiple stocks: rows = days, columns = stocks\n",
    "stock_prices = np.array([\n",
    "    [100, 50, 200],   # Day 1: Stock A, B, C\n",
    "    [102, 51, 198],   # Day 2\n",
    "    [105, 49, 205],   # Day 3\n",
    "    [103, 52, 210]    # Day 4\n",
    "])\n",
    "\n",
    "# Normalize: divide each column by its first value, multiply by 100\n",
    "# Broadcasting: first_prices is (3,), stock_prices is (4,3)\n",
    "first_prices = stock_prices[0]  # Shape: (3,)\n",
    "normalized = (stock_prices / first_prices) * 100\n",
    "\n",
    "print(\"Original prices:\")\n",
    "print(stock_prices)\n",
    "print(\"\\nNormalized (all start at 100):\")\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923115f1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Pandas for Financial Data\n",
    "\n",
    "### Why Pandas?\n",
    "- **Labeled data**: Dates as index, ticker symbols as columns\n",
    "- **Missing data handling**: Financial data often has gaps (holidays, missing quotes)\n",
    "- **Time series functions**: Rolling windows, resampling, shifting\n",
    "\n",
    "### DataFrame Structure\n",
    "```\n",
    "             AAPL    MSFT    GOOGL\n",
    "2024-01-01  185.5   375.2   140.3\n",
    "2024-01-02  186.2   376.8   141.5\n",
    "2024-01-03  184.9   374.1   139.8\n",
    "```\n",
    "- **Index**: Dates (DatetimeIndex)\n",
    "- **Columns**: Asset tickers\n",
    "- **Values**: Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc82c758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price DataFrame:\n",
      "             AAPL   MSFT\n",
      "2024-01-01  185.5  375.2\n",
      "2024-01-02  186.2  376.8\n",
      "2024-01-03  184.9  374.1\n",
      "2024-01-04  187.3  378.5\n",
      "2024-01-05  186.8  377.2\n",
      "\n",
      "AAPL prices: [185.5 186.2 184.9 187.3 186.8]\n",
      "Price on 2024-01-03: \n",
      "AAPL    184.9\n",
      "MSFT    374.1\n",
      "Name: 2024-01-03 00:00:00, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a simple price DataFrame\n",
    "dates = pd.date_range('2024-01-01', periods=5, freq='D')\n",
    "prices_df = pd.DataFrame({\n",
    "    'AAPL': [185.5, 186.2, 184.9, 187.3, 186.8],\n",
    "    'MSFT': [375.2, 376.8, 374.1, 378.5, 377.2]\n",
    "}, index=dates)\n",
    "\n",
    "print(\"Price DataFrame:\")\n",
    "print(prices_df)\n",
    "\n",
    "# Access specific data\n",
    "print(f\"\\nAAPL prices: {prices_df['AAPL'].values}\")\n",
    "print(f\"Price on 2024-01-03: \\n{prices_df.loc['2024-01-03']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62b90d3",
   "metadata": {},
   "source": [
    "### Essential Pandas Operations for Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac5700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifted data (yesterday's price):\n",
      "             AAPL  AAPL_yesterday\n",
      "2024-01-01  185.5             NaN\n",
      "2024-01-02  186.2           185.5\n",
      "2024-01-03  184.9           186.2\n",
      "2024-01-04  187.3           184.9\n",
      "2024-01-05  186.8           187.3\n",
      "\n",
      "Daily returns:\n",
      "                AAPL      MSFT\n",
      "2024-01-01       NaN       NaN\n",
      "2024-01-02  0.003774  0.004264\n",
      "2024-01-03 -0.006982 -0.007166\n",
      "2024-01-04  0.012980  0.011762\n",
      "2024-01-05 -0.002670 -0.003435\n",
      "\n",
      "3-day moving average:\n",
      "             AAPL    AAPL_MA3\n",
      "2024-01-01  185.5         NaN\n",
      "2024-01-02  186.2         NaN\n",
      "2024-01-03  184.9  185.533333\n",
      "2024-01-04  187.3  186.133333\n",
      "2024-01-05  186.8  186.333333\n"
     ]
    }
   ],
   "source": [
    "# 1. Shifting: Compare today's price to yesterday's\n",
    "prices_df['AAPL_yesterday'] = prices_df['AAPL'].shift(1)\n",
    "print(\"Shifted data (yesterday's price):\")\n",
    "print(prices_df[['AAPL', 'AAPL_yesterday']])\n",
    "\n",
    "# 2. Percentage change: Built-in return calculation\n",
    "returns = prices_df[['AAPL', 'MSFT']].pct_change()\n",
    "print(\"\\nDaily returns:\")\n",
    "print(returns)\n",
    "\n",
    "# 3. Rolling window: Moving average\n",
    "prices_df['AAPL_MA3'] = prices_df['AAPL'].rolling(window=3).mean()\n",
    "print(\"\\n3-day moving average:\")\n",
    "print(prices_df[['AAPL', 'AAPL_MA3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f642eb5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Financial Returns\n",
    "\n",
    "### Why Returns Instead of Prices?\n",
    "1. **Comparability**: A $1 change means different things for a $10 stock vs $1000 stock\n",
    "2. **Stationarity**: Prices trend over time; returns fluctuate around a mean\n",
    "3. **Aggregation**: Returns can be combined across assets and time\n",
    "\n",
    "### Simple (Arithmetic) Returns\n",
    "\n",
    "**Definition**: The percentage change in price\n",
    "\n",
    "$$R_t = \\frac{P_t - P_{t-1}}{P_{t-1}} = \\frac{P_t}{P_{t-1}} - 1$$\n",
    "\n",
    "Where:\n",
    "- $R_t$ = Return at time t\n",
    "- $P_t$ = Price at time t\n",
    "- $P_{t-1}$ = Price at time t-1\n",
    "\n",
    "**Properties**:\n",
    "- Easy to interpret: \"Stock went up 5%\"\n",
    "- Portfolio returns are weighted averages of individual returns\n",
    "- NOT additive over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833729f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prices: [100 105 103 108 106]\n",
      "Simple returns: [ 0.05       -0.01904762  0.04854369 -0.01851852]\n",
      "\n",
      "Day 1: Price went from 100 to 105\n",
      "Return = (105 - 100) / 100 = 0.0500 = 5.00%\n"
     ]
    }
   ],
   "source": [
    "# Simple Returns Example\n",
    "prices = np.array([100, 105, 103, 108, 106])\n",
    "\n",
    "# Calculate simple returns\n",
    "simple_returns = (prices[1:] - prices[:-1]) / prices[:-1]\n",
    "# Or equivalently:\n",
    "simple_returns_v2 = prices[1:] / prices[:-1] - 1\n",
    "\n",
    "print(\"Prices:\", prices)\n",
    "print(\"Simple returns:\", simple_returns)\n",
    "print(f\"\\nDay 1: Price went from {prices[0]} to {prices[1]}\")\n",
    "print(f\"Return = ({prices[1]} - {prices[0]}) / {prices[0]} = {simple_returns[0]:.4f} = {simple_returns[0]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a47c8e",
   "metadata": {},
   "source": [
    "### Log (Continuously Compounded) Returns\n",
    "\n",
    "**Definition**: The natural logarithm of the price ratio\n",
    "\n",
    "$$r_t = \\ln\\left(\\frac{P_t}{P_{t-1}}\\right) = \\ln(P_t) - \\ln(P_{t-1})$$\n",
    "\n",
    "**Properties**:\n",
    "- **Time additive**: Multi-period return = sum of single-period returns\n",
    "- **Symmetric**: +10% and -10% are equidistant from 0\n",
    "- **Approximately normal**: Better for statistical analysis\n",
    "\n",
    "**Relationship to Simple Returns**:\n",
    "$$r_t = \\ln(1 + R_t)$$\n",
    "$$R_t = e^{r_t} - 1$$\n",
    "\n",
    "For small returns (< 10%), they are approximately equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17706ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple returns: [ 0.05   -0.019   0.0485 -0.0185]\n",
      "Log returns:    [ 0.0488 -0.0192  0.0474 -0.0187]\n",
      "\n",
      "Total return over period:\n",
      "From prices: (106 - 100) / 100 = 0.0600\n",
      "Compounding simple returns: 0.0600\n",
      "Sum of log returns: 0.0583 ‚Üí exp(0.0583) - 1 = 0.0600\n"
     ]
    }
   ],
   "source": [
    "# Log Returns Example\n",
    "log_returns = np.log(prices[1:] / prices[:-1])\n",
    "\n",
    "print(\"Simple returns:\", simple_returns.round(4))\n",
    "print(\"Log returns:   \", log_returns.round(4))\n",
    "\n",
    "# Key advantage: Time additivity\n",
    "total_simple = (1 + simple_returns).prod() - 1  # Compound simple returns\n",
    "total_log = log_returns.sum()  # Just sum log returns!\n",
    "\n",
    "print(f\"\\nTotal return over period:\")\n",
    "print(f\"From prices: ({prices[-1]} - {prices[0]}) / {prices[0]} = {(prices[-1]/prices[0] - 1):.4f}\")\n",
    "print(f\"Compounding simple returns: {total_simple:.4f}\")\n",
    "print(f\"Sum of log returns: {total_log:.4f} ‚Üí exp({total_log:.4f}) - 1 = {np.exp(total_log) - 1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f299d0",
   "metadata": {},
   "source": [
    "### Multi-Period Returns\n",
    "\n",
    "**Simple Returns** (must compound):\n",
    "$$R_{t,t+n} = (1 + R_{t+1})(1 + R_{t+2})...(1 + R_{t+n}) - 1$$\n",
    "\n",
    "**Log Returns** (just add):\n",
    "$$r_{t,t+n} = r_{t+1} + r_{t+2} + ... + r_{t+n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e29a9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weekly return (simple): 0.0076 = 0.76%\n",
      "Weekly return (log): 0.0076 = 0.76%\n",
      "Converting log back to simple: 0.0076\n"
     ]
    }
   ],
   "source": [
    "# Practical example: Which is easier for multi-period analysis?\n",
    "daily_simple = np.array([0.01, -0.02, 0.015, 0.008, -0.005])  # 5 days of returns\n",
    "daily_log = np.log(1 + daily_simple)  # Convert to log returns\n",
    "\n",
    "# Weekly return from daily\n",
    "weekly_simple = np.prod(1 + daily_simple) - 1  # Must multiply\n",
    "weekly_log = np.sum(daily_log)  # Just add!\n",
    "\n",
    "print(f\"Weekly return (simple): {weekly_simple:.4f} = {weekly_simple*100:.2f}%\")\n",
    "print(f\"Weekly return (log): {weekly_log:.4f} = {weekly_log*100:.2f}%\")\n",
    "print(f\"Converting log back to simple: {np.exp(weekly_log) - 1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882ba146",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Volatility Measures\n",
    "\n",
    "### What is Volatility?\n",
    "Volatility measures the dispersion of returns - how much returns deviate from their average. It's the most common measure of **risk** in finance.\n",
    "\n",
    "### Standard Deviation\n",
    "\n",
    "**Population Standard Deviation**:\n",
    "$$\\sigma = \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}(r_i - \\bar{r})^2}$$\n",
    "\n",
    "**Sample Standard Deviation** (for estimation):\n",
    "$$s = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^{N}(r_i - \\bar{r})^2}$$\n",
    "\n",
    "Where:\n",
    "- $r_i$ = Return for period i\n",
    "- $\\bar{r}$ = Mean return\n",
    "- $N$ = Number of observations\n",
    "- $N-1$ = Bessel's correction (reduces bias when estimating from sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2162d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Mean return: 0.0050\n",
      "Step 2 - Deviations: [ 0.015 -0.015  0.025 -0.025  0.005  0.015 -0.02 ]\n",
      "Step 3 - Squared deviations: [2.25e-04 2.25e-04 6.25e-04 6.25e-04 2.50e-05 2.25e-04 4.00e-04]\n",
      "Step 4 - Variance: 0.000392\n",
      "Step 5 - Standard deviation: 0.0198\n",
      "\n",
      "Numpy std (ddof=1): 0.0198\n"
     ]
    }
   ],
   "source": [
    "# Volatility calculation step by step\n",
    "returns = np.array([0.02, -0.01, 0.03, -0.02, 0.01, 0.02, -0.015])\n",
    "\n",
    "# Step 1: Calculate mean\n",
    "mean_return = np.mean(returns)\n",
    "print(f\"Step 1 - Mean return: {mean_return:.4f}\")\n",
    "\n",
    "# Step 2: Calculate deviations from mean\n",
    "deviations = returns - mean_return\n",
    "print(f\"Step 2 - Deviations: {deviations.round(4)}\")\n",
    "\n",
    "# Step 3: Square the deviations\n",
    "squared_deviations = deviations ** 2\n",
    "print(f\"Step 3 - Squared deviations: {squared_deviations.round(6)}\")\n",
    "\n",
    "# Step 4: Calculate variance (average of squared deviations)\n",
    "variance = np.sum(squared_deviations) / (len(returns) - 1)  # Sample variance\n",
    "print(f\"Step 4 - Variance: {variance:.6f}\")\n",
    "\n",
    "# Step 5: Take square root to get standard deviation\n",
    "std_dev = np.sqrt(variance)\n",
    "print(f\"Step 5 - Standard deviation: {std_dev:.4f}\")\n",
    "\n",
    "# Verify with numpy\n",
    "print(f\"\\nNumpy std (ddof=1): {np.std(returns, ddof=1):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc41378",
   "metadata": {},
   "source": [
    "### Annualizing Volatility\n",
    "\n",
    "Volatility scales with the square root of time. To annualize:\n",
    "\n",
    "$$\\sigma_{annual} = \\sigma_{daily} \\times \\sqrt{252}$$\n",
    "\n",
    "Where 252 is the typical number of trading days per year.\n",
    "\n",
    "**Why square root?** Variance is additive over time (for independent returns), so:\n",
    "$$\\sigma^2_{annual} = 252 \\times \\sigma^2_{daily}$$\n",
    "$$\\sigma_{annual} = \\sqrt{252} \\times \\sigma_{daily}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04567de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily volatility: 1.50%\n",
      "Annual volatility: 23.81%\n",
      "\n",
      "Annualization factors:\n",
      "Daily ‚Üí Annual: ‚àö252 = 15.87\n",
      "Weekly ‚Üí Annual: ‚àö52 = 7.21\n",
      "Monthly ‚Üí Annual: ‚àö12 = 3.46\n"
     ]
    }
   ],
   "source": [
    "# Annualization example\n",
    "daily_vol = 0.015  # 1.5% daily volatility\n",
    "\n",
    "# Annualize\n",
    "annual_vol = daily_vol * np.sqrt(252)\n",
    "print(f\"Daily volatility: {daily_vol:.2%}\")\n",
    "print(f\"Annual volatility: {annual_vol:.2%}\")\n",
    "\n",
    "# Different frequencies\n",
    "print(f\"\\nAnnualization factors:\")\n",
    "print(f\"Daily ‚Üí Annual: ‚àö252 = {np.sqrt(252):.2f}\")\n",
    "print(f\"Weekly ‚Üí Annual: ‚àö52 = {np.sqrt(52):.2f}\")\n",
    "print(f\"Monthly ‚Üí Annual: ‚àö12 = {np.sqrt(12):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa87053",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Basic Statistics for Finance\n",
    "\n",
    "### Measures of Central Tendency\n",
    "\n",
    "**Mean (Expected Return)**:\n",
    "$$\\bar{r} = \\frac{1}{N}\\sum_{i=1}^{N} r_i$$\n",
    "\n",
    "**Median**: Middle value when sorted (robust to outliers)\n",
    "\n",
    "### Measures of Shape\n",
    "\n",
    "**Skewness**: Measures asymmetry of the distribution\n",
    "$$Skew = \\frac{1}{N}\\sum_{i=1}^{N}\\left(\\frac{r_i - \\bar{r}}{\\sigma}\\right)^3$$\n",
    "\n",
    "- Skew > 0: Right tail is longer (more extreme positive returns)\n",
    "- Skew < 0: Left tail is longer (more extreme negative returns - typical for stocks)\n",
    "- Skew = 0: Symmetric distribution\n",
    "\n",
    "**Kurtosis**: Measures \"tail heaviness\"\n",
    "$$Kurt = \\frac{1}{N}\\sum_{i=1}^{N}\\left(\\frac{r_i - \\bar{r}}{\\sigma}\\right)^4$$\n",
    "\n",
    "- Normal distribution has kurtosis = 3\n",
    "- **Excess Kurtosis** = Kurtosis - 3\n",
    "- Excess Kurt > 0: Fat tails (more extreme events than normal)\n",
    "- Financial returns typically have positive excess kurtosis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc07c5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution Statistics:\n",
      "Mean (daily):     0.0912%\n",
      "Median (daily):   0.0914%\n",
      "Std Dev (daily):  1.5684%\n",
      "\n",
      "Skewness:         0.1016\n",
      "Excess Kurtosis:  0.5279\n",
      "\n",
      "Interpretation:\n",
      "- Positive excess kurtosis: Fat tails (extreme events more likely than normal)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Generate sample returns (simulating real stock behavior)\n",
    "np.random.seed(42)\n",
    "# Real returns have fat tails, so we mix normal with some extreme values\n",
    "normal_returns = np.random.normal(0.0005, 0.015, 1000)  # Daily returns\n",
    "extreme_returns = np.random.choice([-0.05, -0.03, 0.03, 0.05], 20)  # Some extreme days\n",
    "stock_returns = np.concatenate([normal_returns, extreme_returns])\n",
    "np.random.shuffle(stock_returns)\n",
    "\n",
    "# Calculate statistics\n",
    "print(\"Distribution Statistics:\")\n",
    "print(f\"Mean (daily):     {np.mean(stock_returns):.4%}\")\n",
    "print(f\"Median (daily):   {np.median(stock_returns):.4%}\")\n",
    "print(f\"Std Dev (daily):  {np.std(stock_returns):.4%}\")\n",
    "print(f\"\\nSkewness:         {stats.skew(stock_returns):.4f}\")\n",
    "print(f\"Excess Kurtosis:  {stats.kurtosis(stock_returns):.4f}\")\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "if stats.skew(stock_returns) < 0:\n",
    "    print(\"- Negative skew: More extreme negative returns (typical for stocks)\")\n",
    "if stats.kurtosis(stock_returns) > 0:\n",
    "    print(\"- Positive excess kurtosis: Fat tails (extreme events more likely than normal)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8af43b",
   "metadata": {},
   "source": [
    "### Correlation\n",
    "\n",
    "Correlation measures the linear relationship between two variables.\n",
    "\n",
    "$$\\rho_{X,Y} = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y} = \\frac{\\sum_{i=1}^{N}(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum(X_i - \\bar{X})^2}\\sqrt{\\sum(Y_i - \\bar{Y})^2}}$$\n",
    "\n",
    "**Range**: -1 to +1\n",
    "- +1: Perfect positive correlation (move together)\n",
    "- 0: No linear relationship\n",
    "- -1: Perfect negative correlation (move opposite)\n",
    "\n",
    "**In Portfolio Theory**: Low correlation between assets = better diversification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8559a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations:\n",
      "Stock A vs Stock B: 0.517 (both driven by market)\n",
      "Stock A vs Gold:    -0.073 (largely independent)\n",
      "\n",
      "Diversification insight:\n",
      "Adding Stock B to A: Limited diversification (high correlation)\n",
      "Adding Gold to A: Better diversification (low correlation)\n"
     ]
    }
   ],
   "source": [
    "# Correlation example with two stocks\n",
    "np.random.seed(123)\n",
    "\n",
    "# Simulate two correlated stocks\n",
    "market = np.random.normal(0, 0.01, 100)  # Market factor\n",
    "stock_a = market + np.random.normal(0, 0.005, 100)  # High beta stock\n",
    "stock_b = 0.5 * market + np.random.normal(0, 0.008, 100)  # Lower beta\n",
    "gold = np.random.normal(0, 0.008, 100)  # Uncorrelated asset\n",
    "\n",
    "# Calculate correlations\n",
    "corr_ab = np.corrcoef(stock_a, stock_b)[0, 1]\n",
    "corr_a_gold = np.corrcoef(stock_a, gold)[0, 1]\n",
    "\n",
    "print(\"Correlations:\")\n",
    "print(f\"Stock A vs Stock B: {corr_ab:.3f} (both driven by market)\")\n",
    "print(f\"Stock A vs Gold:    {corr_a_gold:.3f} (largely independent)\")\n",
    "\n",
    "print(\"\\nDiversification insight:\")\n",
    "print(f\"Adding Stock B to A: Limited diversification (high correlation)\")\n",
    "print(f\"Adding Gold to A: Better diversification (low correlation)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dec08b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Week 1 Key Formulas\n",
    "\n",
    "| Concept | Formula |\n",
    "|---------|--------|\n",
    "| Simple Return | $R_t = \\frac{P_t - P_{t-1}}{P_{t-1}}$ |\n",
    "| Log Return | $r_t = \\ln(P_t) - \\ln(P_{t-1})$ |\n",
    "| Variance | $\\sigma^2 = \\frac{1}{N-1}\\sum(r_i - \\bar{r})^2$ |\n",
    "| Annualized Vol | $\\sigma_{annual} = \\sigma_{daily} \\times \\sqrt{252}$ |\n",
    "| Correlation | $\\rho = \\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}$ |\n",
    "\n",
    "---\n",
    "\n",
    "*Next Week: Statistics and Probability Distributions*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a2471e",
   "metadata": {},
   "source": [
    "## üî¥ PROS & CONS: THEORY\n",
    "\n",
    "### ‚úÖ PROS (Advantages)\n",
    "\n",
    "| Advantage | Description | Real-World Application |\n",
    "|-----------|-------------|----------------------|\n",
    "| **Industry Standard** | Widely adopted in quantitative finance | Used by major hedge funds and banks |\n",
    "| **Well-Documented** | Extensive research and documentation | Easy to find resources and support |\n",
    "| **Proven Track Record** | Years of practical application | Validated in real market conditions |\n",
    "| **Interpretable** | Results can be explained to stakeholders | Important for risk management and compliance |\n",
    "\n",
    "### ‚ùå CONS (Limitations)\n",
    "\n",
    "| Limitation | Description | How to Mitigate |\n",
    "|------------|-------------|-----------------|\n",
    "| **Assumptions** | May not hold in all market conditions | Validate assumptions with data |\n",
    "| **Historical Bias** | Based on past data patterns | Use rolling windows and regime detection |\n",
    "| **Overfitting Risk** | May fit noise rather than signal | Use proper cross-validation |\n",
    "| **Computational Cost** | Can be resource-intensive | Optimize code and use appropriate hardware |\n",
    "\n",
    "### üéØ Real-World Usage\n",
    "\n",
    "**WHERE THIS IS USED:**\n",
    "- ‚úÖ Quantitative hedge funds (Two Sigma, Renaissance, Citadel)\n",
    "- ‚úÖ Investment banks (Goldman Sachs, JP Morgan, Morgan Stanley)\n",
    "- ‚úÖ Asset management firms\n",
    "- ‚úÖ Risk management departments\n",
    "- ‚úÖ Algorithmic trading desks\n",
    "\n",
    "**NOT JUST THEORY - THIS IS PRODUCTION CODE:**\n",
    "The techniques in this notebook are used daily by professionals managing billions of dollars."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
