{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6c67b3b",
   "metadata": {},
   "source": [
    "# Day 5: Advanced Deep Hedging - CVaR Objectives & Risk-Aware Hedging\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand Conditional Value-at-Risk (CVaR) as a coherent risk measure\n",
    "- Implement CVaR-based objective functions for deep hedging\n",
    "- Build risk-aware neural network hedging strategies\n",
    "- Compare mean-variance vs CVaR optimization approaches\n",
    "- Explore spectral risk measures and their implementation\n",
    "\n",
    "## Topics Covered\n",
    "1. CVaR (Expected Shortfall) Theory\n",
    "2. Differentiable CVaR for Neural Networks\n",
    "3. Risk-Aware Deep Hedging Architecture\n",
    "4. Multi-Objective Optimization (P&L vs Risk)\n",
    "5. Practical Implementation with Transaction Costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b51442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Optional, Callable\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb8ef2c",
   "metadata": {},
   "source": [
    "## 1. CVaR (Conditional Value-at-Risk) Theory\n",
    "\n",
    "### Definition\n",
    "CVaR (also known as Expected Shortfall) at confidence level $\\alpha$ is defined as:\n",
    "\n",
    "$$\\text{CVaR}_\\alpha(X) = \\mathbb{E}[X | X \\leq \\text{VaR}_\\alpha(X)]$$\n",
    "\n",
    "For a loss distribution, CVaR represents the expected loss in the worst $(1-\\alpha)\\%$ of cases.\n",
    "\n",
    "### Why CVaR for Hedging?\n",
    "- **Coherent risk measure**: Satisfies subadditivity (diversification reduces risk)\n",
    "- **Tail-sensitive**: Focuses on extreme losses\n",
    "- **Differentiable formulation**: Can be optimized with gradient descent\n",
    "\n",
    "### Rockafellar-Uryasev Formulation\n",
    "CVaR can be computed as:\n",
    "\n",
    "$$\\text{CVaR}_\\alpha(X) = \\min_{\\nu} \\left\\{ \\nu + \\frac{1}{1-\\alpha} \\mathbb{E}[(X - \\nu)^+] \\right\\}$$\n",
    "\n",
    "This formulation is crucial for neural network optimization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b4201",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MarketParams:\n",
    "    \"\"\"Market parameters for simulation.\"\"\"\n",
    "    S0: float = 100.0        # Initial stock price\n",
    "    K: float = 100.0         # Strike price\n",
    "    T: float = 1/12          # Time to maturity (1 month)\n",
    "    r: float = 0.05          # Risk-free rate\n",
    "    sigma: float = 0.20      # Volatility\n",
    "    n_steps: int = 21        # Trading days\n",
    "    transaction_cost: float = 0.001  # 10 bps\n",
    "\n",
    "\n",
    "class GBMSimulator:\n",
    "    \"\"\"Geometric Brownian Motion simulator for stock prices.\"\"\"\n",
    "    \n",
    "    def __init__(self, params: MarketParams):\n",
    "        self.params = params\n",
    "        self.dt = params.T / params.n_steps\n",
    "    \n",
    "    def simulate_paths(self, n_paths: int) -> np.ndarray:\n",
    "        \"\"\"Generate stock price paths.\"\"\"\n",
    "        dt = self.dt\n",
    "        drift = (self.params.r - 0.5 * self.params.sigma**2) * dt\n",
    "        diffusion = self.params.sigma * np.sqrt(dt)\n",
    "        \n",
    "        # Generate random increments\n",
    "        Z = np.random.randn(n_paths, self.params.n_steps)\n",
    "        log_returns = drift + diffusion * Z\n",
    "        \n",
    "        # Construct paths\n",
    "        log_prices = np.zeros((n_paths, self.params.n_steps + 1))\n",
    "        log_prices[:, 0] = np.log(self.params.S0)\n",
    "        log_prices[:, 1:] = log_returns.cumsum(axis=1) + np.log(self.params.S0)\n",
    "        \n",
    "        return np.exp(log_prices)\n",
    "    \n",
    "    def get_time_to_maturity(self) -> np.ndarray:\n",
    "        \"\"\"Return time to maturity at each step.\"\"\"\n",
    "        return np.linspace(self.params.T, 0, self.params.n_steps + 1)\n",
    "\n",
    "\n",
    "# Initialize\n",
    "params = MarketParams()\n",
    "simulator = GBMSimulator(params)\n",
    "\n",
    "# Test simulation\n",
    "test_paths = simulator.simulate_paths(1000)\n",
    "print(f\"Simulated {test_paths.shape[0]} paths with {test_paths.shape[1]} time steps\")\n",
    "print(f\"Final price range: [{test_paths[:, -1].min():.2f}, {test_paths[:, -1].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbc7bbf",
   "metadata": {},
   "source": [
    "## 2. CVaR Loss Functions for Deep Learning\n",
    "\n",
    "### Differentiable CVaR Implementation\n",
    "\n",
    "We implement CVaR using the Rockafellar-Uryasev formulation which allows gradient-based optimization:\n",
    "\n",
    "$$\\mathcal{L}_{\\text{CVaR}} = \\nu + \\frac{1}{(1-\\alpha) \\cdot N} \\sum_{i=1}^{N} \\max(L_i - \\nu, 0)$$\n",
    "\n",
    "Where $\\nu$ (VaR) is jointly optimized with the hedging strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b46ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVaRLoss(nn.Module):\n",
    "    \"\"\"Differentiable CVaR (Expected Shortfall) loss function.\n",
    "    \n",
    "    Uses Rockafellar-Uryasev formulation for gradient-based optimization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.95):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Confidence level (e.g., 0.95 for 95% CVaR)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        # Learnable VaR parameter\n",
    "        self.nu = nn.Parameter(torch.tensor(0.0))\n",
    "    \n",
    "    def forward(self, losses: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute CVaR of the loss distribution.\n",
    "        \n",
    "        Args:\n",
    "            losses: Tensor of loss values (positive = loss, negative = profit)\n",
    "        \n",
    "        Returns:\n",
    "            CVaR value\n",
    "        \"\"\"\n",
    "        # Rockafellar-Uryasev formulation\n",
    "        excess_loss = torch.relu(losses - self.nu)\n",
    "        cvar = self.nu + excess_loss.mean() / (1 - self.alpha)\n",
    "        return cvar\n",
    "    \n",
    "    def get_var(self) -> float:\n",
    "        \"\"\"Return current VaR estimate.\"\"\"\n",
    "        return self.nu.item()\n",
    "\n",
    "\n",
    "class SortingCVaRLoss(nn.Module):\n",
    "    \"\"\"CVaR computed via sorting (non-parametric).\n",
    "    \n",
    "    More accurate but slightly less smooth gradients.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.95):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def forward(self, losses: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute CVaR by sorting and averaging tail losses.\"\"\"\n",
    "        sorted_losses, _ = torch.sort(losses, descending=True)\n",
    "        n_tail = max(1, int((1 - self.alpha) * len(losses)))\n",
    "        cvar = sorted_losses[:n_tail].mean()\n",
    "        return cvar\n",
    "\n",
    "\n",
    "# Test CVaR implementations\n",
    "torch.manual_seed(42)\n",
    "test_losses = torch.randn(10000) * 10 + 5  # Mean=5, std=10\n",
    "\n",
    "cvar_loss = CVaRLoss(alpha=0.95)\n",
    "sorting_cvar = SortingCVaRLoss(alpha=0.95)\n",
    "\n",
    "print(f\"Parametric CVaR (95%): {cvar_loss(test_losses).item():.4f}\")\n",
    "print(f\"Sorting CVaR (95%): {sorting_cvar(test_losses).item():.4f}\")\n",
    "print(f\"Empirical VaR (95%): {np.percentile(test_losses.numpy(), 95):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445b8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectralRiskMeasure(nn.Module):\n",
    "    \"\"\"Generalized spectral risk measure.\n",
    "    \n",
    "    Spectral risk measures are weighted averages of quantiles:\n",
    "    ρ(X) = ∫₀¹ φ(p) · VaR_p(X) dp\n",
    "    \n",
    "    Where φ is a non-negative, non-increasing weight function with ∫φ=1.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, risk_aversion: float = 2.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            risk_aversion: Higher values = more weight on tail losses\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.risk_aversion = risk_aversion\n",
    "    \n",
    "    def forward(self, losses: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute spectral risk measure.\"\"\"\n",
    "        sorted_losses, _ = torch.sort(losses, descending=True)\n",
    "        n = len(sorted_losses)\n",
    "        \n",
    "        # Exponential weighting (more weight on larger losses)\n",
    "        positions = torch.arange(1, n + 1, dtype=torch.float32, device=losses.device)\n",
    "        weights = torch.exp(-self.risk_aversion * positions / n)\n",
    "        weights = weights / weights.sum()  # Normalize\n",
    "        \n",
    "        return (weights * sorted_losses).sum()\n",
    "\n",
    "\n",
    "class MeanCVaRLoss(nn.Module):\n",
    "    \"\"\"Combined Mean + λ·CVaR objective.\n",
    "    \n",
    "    Balances expected P&L with tail risk control.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float = 0.95, lambda_cvar: float = 0.5):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: CVaR confidence level\n",
    "            lambda_cvar: Weight on CVaR (0=mean only, 1=CVaR only)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.lambda_cvar = lambda_cvar\n",
    "        self.cvar_module = CVaRLoss(alpha)\n",
    "    \n",
    "    def forward(self, losses: torch.Tensor) -> Tuple[torch.Tensor, dict]:\n",
    "        \"\"\"Compute combined objective.\"\"\"\n",
    "        mean_loss = losses.mean()\n",
    "        cvar = self.cvar_module(losses)\n",
    "        \n",
    "        total_loss = (1 - self.lambda_cvar) * mean_loss + self.lambda_cvar * cvar\n",
    "        \n",
    "        metrics = {\n",
    "            'mean': mean_loss.item(),\n",
    "            'cvar': cvar.item(),\n",
    "            'var': self.cvar_module.get_var()\n",
    "        }\n",
    "        \n",
    "        return total_loss, metrics\n",
    "\n",
    "\n",
    "# Visualize different risk measures\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: Loss distribution with risk measures\n",
    "ax1 = axes[0]\n",
    "losses_np = test_losses.numpy()\n",
    "ax1.hist(losses_np, bins=100, density=True, alpha=0.7, label='P&L Distribution')\n",
    "\n",
    "var_95 = np.percentile(losses_np, 95)\n",
    "cvar_95 = losses_np[losses_np >= var_95].mean()\n",
    "\n",
    "ax1.axvline(losses_np.mean(), color='green', linestyle='-', linewidth=2, label=f'Mean: {losses_np.mean():.2f}')\n",
    "ax1.axvline(var_95, color='orange', linestyle='--', linewidth=2, label=f'VaR 95%: {var_95:.2f}')\n",
    "ax1.axvline(cvar_95, color='red', linestyle='--', linewidth=2, label=f'CVaR 95%: {cvar_95:.2f}')\n",
    "\n",
    "ax1.fill_between(np.linspace(var_95, losses_np.max(), 100), 0, 0.02, alpha=0.3, color='red', label='Tail (5%)')\n",
    "ax1.set_xlabel('Loss')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('Risk Measures on Loss Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Spectral weights\n",
    "ax2 = axes[1]\n",
    "x = np.linspace(0, 1, 100)\n",
    "for gamma in [0.5, 1.0, 2.0, 5.0]:\n",
    "    weights = np.exp(-gamma * x)\n",
    "    weights = weights / weights.sum() * 100\n",
    "    ax2.plot(x, weights, label=f'γ = {gamma}')\n",
    "\n",
    "ax2.set_xlabel('Quantile (sorted by loss)')\n",
    "ax2.set_ylabel('Weight (%)')\n",
    "ax2.set_title('Spectral Risk Measure Weights')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b927bfaa",
   "metadata": {},
   "source": [
    "## 3. Risk-Aware Deep Hedging Neural Network\n",
    "\n",
    "### Architecture Design\n",
    "Our network learns the optimal hedging strategy that minimizes CVaR of the hedging P&L.\n",
    "\n",
    "**Inputs at each time step:**\n",
    "- Current stock price (normalized)\n",
    "- Time to maturity\n",
    "- Current hedge position\n",
    "- Implied volatility (if available)\n",
    "\n",
    "**Output:**\n",
    "- Optimal hedge ratio (delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce64ceb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiskAwareHedgingNetwork(nn.Module):\n",
    "    \"\"\"Neural network for risk-aware deep hedging.\n",
    "    \n",
    "    Architecture designed to learn CVaR-optimal hedging strategies.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 4,\n",
    "        hidden_dims: list = [64, 64, 32],\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.extend([\n",
    "                nn.Linear(prev_dim, hidden_dim),\n",
    "                nn.LayerNorm(hidden_dim),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Dropout(dropout)\n",
    "            ])\n",
    "            prev_dim = hidden_dim\n",
    "        \n",
    "        # Output layer: hedge ratio in [-1, 1] (can short)\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        layers.append(nn.Tanh())  # Constrain to [-1, 1]\n",
    "        \n",
    "        self.network = nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights\n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Xavier initialization for better gradient flow.\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute hedge ratio.\n",
    "        \n",
    "        Args:\n",
    "            x: Input features [batch, features]\n",
    "        \n",
    "        Returns:\n",
    "            Hedge ratio in [-1, 1]\n",
    "        \"\"\"\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "class RecurrentHedgingNetwork(nn.Module):\n",
    "    \"\"\"LSTM-based hedging network for capturing path dependencies.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 4,\n",
    "        hidden_dim: int = 64,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Process sequence and output hedge ratios.\n",
    "        \n",
    "        Args:\n",
    "            x: Input sequence [batch, seq_len, features]\n",
    "        \n",
    "        Returns:\n",
    "            Hedge ratios [batch, seq_len, 1]\n",
    "        \"\"\"\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        return self.output_layer(lstm_out)\n",
    "\n",
    "\n",
    "# Test networks\n",
    "ffn = RiskAwareHedgingNetwork()\n",
    "rnn = RecurrentHedgingNetwork()\n",
    "\n",
    "# FFN test\n",
    "test_input = torch.randn(32, 4)\n",
    "ffn_output = ffn(test_input)\n",
    "print(f\"FFN output shape: {ffn_output.shape}, range: [{ffn_output.min():.3f}, {ffn_output.max():.3f}]\")\n",
    "\n",
    "# RNN test\n",
    "test_seq = torch.randn(32, 21, 4)\n",
    "rnn_output = rnn(test_seq)\n",
    "print(f\"RNN output shape: {rnn_output.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d074cee",
   "metadata": {},
   "source": [
    "## 4. Deep Hedging Training Framework\n",
    "\n",
    "### P&L Calculation\n",
    "The hedging P&L consists of:\n",
    "1. **Option payoff**: What we owe at maturity\n",
    "2. **Hedging gains/losses**: From delta hedging\n",
    "3. **Transaction costs**: From rebalancing\n",
    "\n",
    "$$\\text{P\\&L} = -\\text{Payoff}(S_T) + \\sum_{t=0}^{T-1} \\delta_t (S_{t+1} - S_t) - \\sum_{t=0}^{T-1} c |\\delta_t - \\delta_{t-1}| S_t$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d97eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_delta(S: np.ndarray, K: float, T: np.ndarray, r: float, sigma: float) -> np.ndarray:\n",
    "    \"\"\"Compute Black-Scholes delta for call option.\"\"\"\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    # Handle T=0 case\n",
    "    T = np.maximum(T, 1e-10)\n",
    "    \n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
    "    return norm.cdf(d1)\n",
    "\n",
    "\n",
    "class DeepHedgingTrainer:\n",
    "    \"\"\"Training framework for risk-aware deep hedging.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        params: MarketParams,\n",
    "        risk_measure: str = 'cvar',\n",
    "        alpha: float = 0.95,\n",
    "        lambda_risk: float = 0.5\n",
    "    ):\n",
    "        self.model = model.to(device)\n",
    "        self.params = params\n",
    "        self.simulator = GBMSimulator(params)\n",
    "        \n",
    "        # Setup risk measure\n",
    "        if risk_measure == 'cvar':\n",
    "            self.risk_module = MeanCVaRLoss(alpha, lambda_risk).to(device)\n",
    "        elif risk_measure == 'spectral':\n",
    "            self.risk_module = SpectralRiskMeasure(risk_aversion=2.0).to(device)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown risk measure: {risk_measure}\")\n",
    "        \n",
    "        self.risk_measure = risk_measure\n",
    "        \n",
    "    def prepare_features(self, paths: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"Prepare input features for the model.\n",
    "        \n",
    "        Features:\n",
    "        - Normalized stock price (S/K)\n",
    "        - Time to maturity\n",
    "        - Log-moneyness\n",
    "        - Previous delta (initialized to 0)\n",
    "        \"\"\"\n",
    "        n_paths, n_steps = paths.shape\n",
    "        ttm = self.simulator.get_time_to_maturity()\n",
    "        \n",
    "        features = np.zeros((n_paths, n_steps - 1, 4))  # Exclude last step (maturity)\n",
    "        \n",
    "        for t in range(n_steps - 1):\n",
    "            features[:, t, 0] = paths[:, t] / self.params.K  # Normalized price\n",
    "            features[:, t, 1] = ttm[t]  # Time to maturity\n",
    "            features[:, t, 2] = np.log(paths[:, t] / self.params.K)  # Log-moneyness\n",
    "            # Feature 3 (previous delta) will be filled during forward pass\n",
    "        \n",
    "        return torch.tensor(features, dtype=torch.float32, device=device)\n",
    "    \n",
    "    def compute_hedging_pnl(\n",
    "        self,\n",
    "        paths: torch.Tensor,\n",
    "        features: torch.Tensor,\n",
    "        include_costs: bool = True\n",
    "    ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"Compute P&L from hedging strategy.\n",
    "        \n",
    "        Returns:\n",
    "            pnl: Hedging P&L for each path\n",
    "            deltas: Hedge ratios used\n",
    "        \"\"\"\n",
    "        n_paths, n_steps = paths.shape\n",
    "        n_hedging_steps = n_steps - 1\n",
    "        \n",
    "        # Initialize\n",
    "        deltas = torch.zeros((n_paths, n_hedging_steps), device=device)\n",
    "        hedging_pnl = torch.zeros(n_paths, device=device)\n",
    "        transaction_costs = torch.zeros(n_paths, device=device)\n",
    "        \n",
    "        prev_delta = torch.zeros(n_paths, device=device)\n",
    "        \n",
    "        # Forward pass through time\n",
    "        for t in range(n_hedging_steps):\n",
    "            # Update feature with previous delta\n",
    "            feat = features[:, t, :].clone()\n",
    "            feat[:, 3] = prev_delta\n",
    "            \n",
    "            # Get hedge ratio from model\n",
    "            delta = self.model(feat).squeeze(-1)\n",
    "            deltas[:, t] = delta\n",
    "            \n",
    "            # Hedging P&L from price change\n",
    "            price_change = paths[:, t + 1] - paths[:, t]\n",
    "            hedging_pnl += delta * price_change\n",
    "            \n",
    "            # Transaction costs from rebalancing\n",
    "            if include_costs:\n",
    "                delta_change = torch.abs(delta - prev_delta)\n",
    "                transaction_costs += self.params.transaction_cost * delta_change * paths[:, t]\n",
    "            \n",
    "            prev_delta = delta\n",
    "        \n",
    "        # Option payoff (short call)\n",
    "        final_prices = paths[:, -1]\n",
    "        payoff = torch.relu(final_prices - self.params.K)\n",
    "        \n",
    "        # Total P&L = Hedging gains - Option liability - Transaction costs\n",
    "        total_pnl = hedging_pnl - payoff - transaction_costs\n",
    "        \n",
    "        # Return LOSS (negative P&L) for minimization\n",
    "        return -total_pnl, deltas\n",
    "    \n",
    "    def train_epoch(\n",
    "        self,\n",
    "        optimizer: optim.Optimizer,\n",
    "        n_paths: int = 10000\n",
    "    ) -> dict:\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        \n",
    "        # Generate new paths\n",
    "        paths_np = self.simulator.simulate_paths(n_paths)\n",
    "        paths = torch.tensor(paths_np, dtype=torch.float32, device=device)\n",
    "        features = self.prepare_features(paths_np)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        losses, deltas = self.compute_hedging_pnl(paths, features)\n",
    "        \n",
    "        # Compute risk measure\n",
    "        if self.risk_measure == 'cvar':\n",
    "            loss, metrics = self.risk_module(losses)\n",
    "        else:\n",
    "            loss = self.risk_module(losses)\n",
    "            metrics = {'spectral_risk': loss.item()}\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Add P&L statistics\n",
    "        pnl = -losses  # Convert back to P&L\n",
    "        metrics['pnl_mean'] = pnl.mean().item()\n",
    "        metrics['pnl_std'] = pnl.std().item()\n",
    "        metrics['avg_delta'] = deltas.mean().item()\n",
    "        metrics['loss'] = loss.item()\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(\n",
    "        self,\n",
    "        n_paths: int = 50000\n",
    "    ) -> Tuple[dict, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Evaluate model on test paths.\"\"\"\n",
    "        self.model.eval()\n",
    "        \n",
    "        paths_np = self.simulator.simulate_paths(n_paths)\n",
    "        paths = torch.tensor(paths_np, dtype=torch.float32, device=device)\n",
    "        features = self.prepare_features(paths_np)\n",
    "        \n",
    "        losses, deltas = self.compute_hedging_pnl(paths, features)\n",
    "        pnl = -losses\n",
    "        \n",
    "        metrics = {\n",
    "            'pnl_mean': pnl.mean().item(),\n",
    "            'pnl_std': pnl.std().item(),\n",
    "            'pnl_var_95': torch.quantile(pnl, 0.05).item(),\n",
    "            'pnl_cvar_95': pnl[pnl <= torch.quantile(pnl, 0.05)].mean().item(),\n",
    "            'sharpe': pnl.mean().item() / (pnl.std().item() + 1e-8)\n",
    "        }\n",
    "        \n",
    "        return metrics, pnl.cpu().numpy(), deltas.cpu().numpy()\n",
    "\n",
    "\n",
    "print(\"Training framework initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6eee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_hedger(\n",
    "    risk_measure: str = 'cvar',\n",
    "    lambda_risk: float = 0.5,\n",
    "    n_epochs: int = 100,\n",
    "    lr: float = 1e-3\n",
    ") -> Tuple[nn.Module, list]:\n",
    "    \"\"\"Train a deep hedging model.\"\"\"\n",
    "    \n",
    "    # Initialize model and trainer\n",
    "    model = RiskAwareHedgingNetwork(input_dim=4, hidden_dims=[64, 64, 32])\n",
    "    trainer = DeepHedgingTrainer(\n",
    "        model=model,\n",
    "        params=params,\n",
    "        risk_measure=risk_measure,\n",
    "        alpha=0.95,\n",
    "        lambda_risk=lambda_risk\n",
    "    )\n",
    "    \n",
    "    # Optimizer with weight decay\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "    \n",
    "    history = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        metrics = trainer.train_epoch(optimizer, n_paths=5000)\n",
    "        scheduler.step()\n",
    "        history.append(metrics)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f\"Epoch {epoch+1:3d} | Loss: {metrics['loss']:.4f} | \"\n",
    "                  f\"P&L Mean: {metrics['pnl_mean']:.4f} | \"\n",
    "                  f\"P&L Std: {metrics['pnl_std']:.4f}\")\n",
    "    \n",
    "    return model, history, trainer\n",
    "\n",
    "\n",
    "# Train with different risk preferences\n",
    "print(\"Training CVaR-optimized hedger (λ=0.8, risk-averse)...\")\n",
    "model_cvar, history_cvar, trainer_cvar = train_deep_hedger(\n",
    "    risk_measure='cvar',\n",
    "    lambda_risk=0.8,\n",
    "    n_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ec28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining mean-focused hedger (λ=0.2, less risk-averse)...\")\n",
    "model_mean, history_mean, trainer_mean = train_deep_hedger(\n",
    "    risk_measure='cvar',\n",
    "    lambda_risk=0.2,\n",
    "    n_epochs=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffdf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate both models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Evaluation (50,000 test paths)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "metrics_cvar, pnl_cvar, deltas_cvar = trainer_cvar.evaluate()\n",
    "metrics_mean, pnl_mean, deltas_mean = trainer_mean.evaluate()\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'CVaR-Focused':<15} {'Mean-Focused':<15}\")\n",
    "print(\"-\" * 50)\n",
    "for key in metrics_cvar:\n",
    "    print(f\"{key:<20} {metrics_cvar[key]:<15.4f} {metrics_mean[key]:<15.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84926fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with Black-Scholes delta hedging\n",
    "def evaluate_bs_hedging(n_paths: int = 50000) -> Tuple[dict, np.ndarray]:\n",
    "    \"\"\"Evaluate Black-Scholes delta hedging baseline.\"\"\"\n",
    "    paths = simulator.simulate_paths(n_paths)\n",
    "    ttm = simulator.get_time_to_maturity()\n",
    "    \n",
    "    hedging_pnl = np.zeros(n_paths)\n",
    "    transaction_costs = np.zeros(n_paths)\n",
    "    prev_delta = np.zeros(n_paths)\n",
    "    \n",
    "    for t in range(params.n_steps):\n",
    "        # Black-Scholes delta\n",
    "        delta = black_scholes_delta(\n",
    "            paths[:, t], params.K, ttm[t], params.r, params.sigma\n",
    "        )\n",
    "        \n",
    "        # P&L from hedge\n",
    "        hedging_pnl += delta * (paths[:, t + 1] - paths[:, t])\n",
    "        \n",
    "        # Transaction costs\n",
    "        transaction_costs += params.transaction_cost * np.abs(delta - prev_delta) * paths[:, t]\n",
    "        prev_delta = delta\n",
    "    \n",
    "    # Option payoff\n",
    "    payoff = np.maximum(paths[:, -1] - params.K, 0)\n",
    "    \n",
    "    # Total P&L\n",
    "    pnl = hedging_pnl - payoff - transaction_costs\n",
    "    \n",
    "    metrics = {\n",
    "        'pnl_mean': pnl.mean(),\n",
    "        'pnl_std': pnl.std(),\n",
    "        'pnl_var_95': np.percentile(pnl, 5),\n",
    "        'pnl_cvar_95': pnl[pnl <= np.percentile(pnl, 5)].mean(),\n",
    "        'sharpe': pnl.mean() / (pnl.std() + 1e-8)\n",
    "    }\n",
    "    \n",
    "    return metrics, pnl\n",
    "\n",
    "metrics_bs, pnl_bs = evaluate_bs_hedging()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Comparison with Black-Scholes Delta Hedging\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n{'Metric':<20} {'BS Delta':<15} {'CVaR-NN':<15} {'Mean-NN':<15}\")\n",
    "print(\"-\" * 65)\n",
    "for key in metrics_bs:\n",
    "    print(f\"{key:<20} {metrics_bs[key]:<15.4f} {metrics_cvar[key]:<15.4f} {metrics_mean[key]:<15.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727f48d7",
   "metadata": {},
   "source": [
    "## 5. Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8793d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: P&L Distributions\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(pnl_bs, bins=100, alpha=0.5, density=True, label='BS Delta', color='blue')\n",
    "ax1.hist(pnl_cvar, bins=100, alpha=0.5, density=True, label='CVaR-NN', color='red')\n",
    "ax1.hist(pnl_mean, bins=100, alpha=0.5, density=True, label='Mean-NN', color='green')\n",
    "\n",
    "ax1.axvline(np.percentile(pnl_bs, 5), color='blue', linestyle='--', alpha=0.8)\n",
    "ax1.axvline(np.percentile(pnl_cvar, 5), color='red', linestyle='--', alpha=0.8)\n",
    "ax1.axvline(np.percentile(pnl_mean, 5), color='green', linestyle='--', alpha=0.8)\n",
    "\n",
    "ax1.set_xlabel('P&L')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title('P&L Distribution Comparison')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Training curves\n",
    "ax2 = axes[0, 1]\n",
    "epochs = range(1, len(history_cvar) + 1)\n",
    "ax2.plot(epochs, [h['loss'] for h in history_cvar], label='CVaR-NN Loss', color='red')\n",
    "ax2.plot(epochs, [h['loss'] for h in history_mean], label='Mean-NN Loss', color='green')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('Loss')\n",
    "ax2.set_title('Training Loss Curves')\n",
    "ax2.legend()\n",
    "\n",
    "# Plot 3: Tail comparison (worst 10%)\n",
    "ax3 = axes[1, 0]\n",
    "tail_pct = 10\n",
    "tail_bs = np.sort(pnl_bs)[:int(len(pnl_bs) * tail_pct / 100)]\n",
    "tail_cvar = np.sort(pnl_cvar)[:int(len(pnl_cvar) * tail_pct / 100)]\n",
    "tail_mean = np.sort(pnl_mean)[:int(len(pnl_mean) * tail_pct / 100)]\n",
    "\n",
    "ax3.hist(tail_bs, bins=50, alpha=0.5, density=True, label='BS Delta', color='blue')\n",
    "ax3.hist(tail_cvar, bins=50, alpha=0.5, density=True, label='CVaR-NN', color='red')\n",
    "ax3.hist(tail_mean, bins=50, alpha=0.5, density=True, label='Mean-NN', color='green')\n",
    "ax3.set_xlabel('P&L (Worst 10%)')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.set_title(f'Tail Risk Comparison (Worst {tail_pct}%)')\n",
    "ax3.legend()\n",
    "\n",
    "# Plot 4: Average delta by moneyness\n",
    "ax4 = axes[1, 1]\n",
    "\n",
    "# Compute delta surface\n",
    "moneyness = np.linspace(0.8, 1.2, 50)\n",
    "ttm_grid = np.linspace(0.01, params.T, 5)\n",
    "\n",
    "for tau in ttm_grid:\n",
    "    bs_deltas = []\n",
    "    nn_deltas = []\n",
    "    \n",
    "    for m in moneyness:\n",
    "        S = m * params.K\n",
    "        bs_delta = black_scholes_delta(S, params.K, tau, params.r, params.sigma)\n",
    "        bs_deltas.append(bs_delta)\n",
    "        \n",
    "        # Neural network delta\n",
    "        feat = torch.tensor([[m, tau, np.log(m), 0.5]], dtype=torch.float32, device=device)\n",
    "        with torch.no_grad():\n",
    "            nn_delta = model_cvar(feat).item()\n",
    "        nn_deltas.append(nn_delta)\n",
    "    \n",
    "    label = f'τ = {tau*252:.0f} days'\n",
    "    ax4.plot(moneyness, bs_deltas, '--', alpha=0.5, label=f'BS {label}' if tau == ttm_grid[0] else '')\n",
    "    ax4.plot(moneyness, nn_deltas, '-', alpha=0.8, label=f'NN {label}' if tau == ttm_grid[0] else '')\n",
    "\n",
    "ax4.set_xlabel('Moneyness (S/K)')\n",
    "ax4.set_ylabel('Delta')\n",
    "ax4.set_title('Delta vs Moneyness (CVaR-NN vs BS)')\n",
    "ax4.legend(['BS', 'NN'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c070754a",
   "metadata": {},
   "source": [
    "## 6. Risk-Return Frontier\n",
    "\n",
    "Let's explore how different λ values create a risk-return trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2351ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_train_and_eval(lambda_risk: float, n_epochs: int = 50) -> dict:\n",
    "    \"\"\"Quickly train and evaluate a model.\"\"\"\n",
    "    model = RiskAwareHedgingNetwork(input_dim=4, hidden_dims=[32, 32])\n",
    "    trainer = DeepHedgingTrainer(\n",
    "        model=model,\n",
    "        params=params,\n",
    "        risk_measure='cvar',\n",
    "        lambda_risk=lambda_risk\n",
    "    )\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    for _ in range(n_epochs):\n",
    "        trainer.train_epoch(optimizer, n_paths=3000)\n",
    "    \n",
    "    metrics, _, _ = trainer.evaluate(n_paths=20000)\n",
    "    metrics['lambda'] = lambda_risk\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Compute risk-return frontier\n",
    "print(\"Computing risk-return frontier...\")\n",
    "lambdas = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "frontier_results = []\n",
    "\n",
    "for lam in lambdas:\n",
    "    print(f\"  λ = {lam}...\", end=\" \")\n",
    "    result = quick_train_and_eval(lam)\n",
    "    frontier_results.append(result)\n",
    "    print(f\"Mean: {result['pnl_mean']:.4f}, CVaR: {result['pnl_cvar_95']:.4f}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4922b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot risk-return frontier\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "means = [r['pnl_mean'] for r in frontier_results]\n",
    "cvars = [r['pnl_cvar_95'] for r in frontier_results]\n",
    "stds = [r['pnl_std'] for r in frontier_results]\n",
    "\n",
    "# Plot 1: Mean vs CVaR frontier\n",
    "ax1 = axes[0]\n",
    "scatter = ax1.scatter([-c for c in cvars], means, c=lambdas, cmap='coolwarm', s=100, edgecolors='black')\n",
    "ax1.plot([-c for c in cvars], means, 'k--', alpha=0.5)\n",
    "\n",
    "for i, lam in enumerate(lambdas):\n",
    "    ax1.annotate(f'λ={lam}', (-cvars[i], means[i]), textcoords=\"offset points\", xytext=(5, 5))\n",
    "\n",
    "ax1.axhline(metrics_bs['pnl_mean'], color='blue', linestyle=':', label='BS Delta Mean')\n",
    "ax1.axvline(-metrics_bs['pnl_cvar_95'], color='blue', linestyle='--', label='BS Delta CVaR')\n",
    "\n",
    "ax1.set_xlabel('Tail Risk (-CVaR 95%)')\n",
    "ax1.set_ylabel('Expected P&L')\n",
    "ax1.set_title('Risk-Return Frontier (CVaR Objective)')\n",
    "ax1.legend()\n",
    "plt.colorbar(scatter, ax=ax1, label='λ (CVaR weight)')\n",
    "\n",
    "# Plot 2: Mean vs Std frontier\n",
    "ax2 = axes[1]\n",
    "scatter2 = ax2.scatter(stds, means, c=lambdas, cmap='coolwarm', s=100, edgecolors='black')\n",
    "ax2.plot(stds, means, 'k--', alpha=0.5)\n",
    "\n",
    "for i, lam in enumerate(lambdas):\n",
    "    ax2.annotate(f'λ={lam}', (stds[i], means[i]), textcoords=\"offset points\", xytext=(5, 5))\n",
    "\n",
    "ax2.scatter(metrics_bs['pnl_std'], metrics_bs['pnl_mean'], marker='*', s=200, color='blue', label='BS Delta')\n",
    "\n",
    "ax2.set_xlabel('P&L Volatility (Std)')\n",
    "ax2.set_ylabel('Expected P&L')\n",
    "ax2.set_title('Mean-Variance Frontier')\n",
    "ax2.legend()\n",
    "plt.colorbar(scatter2, ax=ax2, label='λ (CVaR weight)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ec9c2",
   "metadata": {},
   "source": [
    "## 7. Advanced: Entropic Risk Measure\n",
    "\n",
    "The entropic risk measure provides exponential penalization of losses:\n",
    "\n",
    "$$\\rho_\\gamma(X) = \\frac{1}{\\gamma} \\log\\left( \\mathbb{E}[e^{\\gamma X}] \\right)$$\n",
    "\n",
    "Where $\\gamma > 0$ is the risk aversion parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f7b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropicRiskMeasure(nn.Module):\n",
    "    \"\"\"Entropic (exponential) risk measure.\n",
    "    \n",
    "    Provides exponential penalization of large losses.\n",
    "    Relates to exponential utility maximization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gamma: float = 1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            gamma: Risk aversion parameter (higher = more risk averse)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def forward(self, losses: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute entropic risk measure.\n",
    "        \n",
    "        Uses log-sum-exp trick for numerical stability.\n",
    "        \"\"\"\n",
    "        # Log-sum-exp trick: log(mean(exp(γX))) = max(γX) + log(mean(exp(γX - max(γX))))\n",
    "        scaled = self.gamma * losses\n",
    "        max_val = scaled.max()\n",
    "        risk = (1 / self.gamma) * (max_val + torch.log(torch.exp(scaled - max_val).mean()))\n",
    "        return risk\n",
    "\n",
    "\n",
    "class DistortionRiskMeasure(nn.Module):\n",
    "    \"\"\"Wang distortion risk measure.\n",
    "    \n",
    "    Uses a distortion function g:[0,1]->[0,1] to transform the distribution.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, distortion_param: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = distortion_param  # Wang parameter\n",
    "    \n",
    "    def forward(self, losses: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute distortion risk measure.\"\"\"\n",
    "        from scipy.stats import norm\n",
    "        \n",
    "        sorted_losses, _ = torch.sort(losses)\n",
    "        n = len(sorted_losses)\n",
    "        \n",
    "        # Wang distortion: g(u) = Φ(Φ^{-1}(u) + α)\n",
    "        u = torch.linspace(1/n, 1, n)\n",
    "        weights = torch.diff(\n",
    "            torch.tensor(norm.cdf(norm.ppf(u.numpy()) + self.alpha)),\n",
    "            prepend=torch.tensor([0.0])\n",
    "        )\n",
    "        weights = weights.to(losses.device)\n",
    "        \n",
    "        return (weights * sorted_losses).sum()\n",
    "\n",
    "\n",
    "# Test different risk measures\n",
    "test_losses = torch.randn(10000) * 10 + 5\n",
    "\n",
    "entropic_1 = EntropicRiskMeasure(gamma=0.1)\n",
    "entropic_2 = EntropicRiskMeasure(gamma=1.0)\n",
    "cvar = CVaRLoss(alpha=0.95)\n",
    "\n",
    "print(\"Risk Measure Comparison:\")\n",
    "print(f\"  Mean:              {test_losses.mean().item():.4f}\")\n",
    "print(f\"  CVaR 95%:          {cvar(test_losses).item():.4f}\")\n",
    "print(f\"  Entropic (γ=0.1):  {entropic_1(test_losses).item():.4f}\")\n",
    "print(f\"  Entropic (γ=1.0):  {entropic_2(test_losses).item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02eb447",
   "metadata": {},
   "source": [
    "## 8. Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "1. **CVaR as a Hedging Objective**\n",
    "   - CVaR (Expected Shortfall) is a coherent risk measure focusing on tail losses\n",
    "   - The Rockafellar-Uryasev formulation enables gradient-based optimization\n",
    "   - CVaR-optimized strategies reduce worst-case losses vs mean-variance\n",
    "\n",
    "2. **Risk-Aware Neural Networks**\n",
    "   - Deep hedging networks can learn to optimize any differentiable risk measure\n",
    "   - The λ parameter controls the mean-CVaR trade-off\n",
    "   - Higher λ → more conservative hedging → smaller tails but lower average P&L\n",
    "\n",
    "3. **Comparison with Black-Scholes**\n",
    "   - BS delta hedging is optimal only under BS assumptions (no costs, continuous trading)\n",
    "   - Deep hedging can outperform BS when:\n",
    "     - Transaction costs are significant\n",
    "     - Volatility is stochastic\n",
    "     - Tail risk is important\n",
    "\n",
    "4. **Advanced Risk Measures**\n",
    "   - Spectral risk measures: weighted quantile averages\n",
    "   - Entropic risk: exponential utility-based\n",
    "   - Choice depends on risk preferences and regulatory requirements\n",
    "\n",
    "### Practical Considerations\n",
    "\n",
    "- **Training stability**: Use gradient clipping, layer normalization\n",
    "- **Sample size**: Need many scenarios to estimate tail risk accurately\n",
    "- **Model capacity**: Simple networks often suffice; overparameterization can hurt\n",
    "- **Transaction costs**: Critical for realistic performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bad3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY: Advanced Deep Hedging with CVaR\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nMarket Parameters:\")\n",
    "print(f\"  S0 = {params.S0}, K = {params.K}, T = {params.T*252:.0f} days\")\n",
    "print(f\"  σ = {params.sigma*100:.1f}%, r = {params.r*100:.1f}%\")\n",
    "print(f\"  Transaction costs = {params.transaction_cost*10000:.0f} bps\")\n",
    "\n",
    "print(f\"\\nModel Comparison (50k test scenarios):\")\n",
    "print(f\"\\n{'Strategy':<25} {'Mean P&L':<12} {'P&L Vol':<12} {'VaR 5%':<12} {'CVaR 5%':<12}\")\n",
    "print(\"-\" * 75)\n",
    "print(f\"{'Black-Scholes Delta':<25} {metrics_bs['pnl_mean']:<12.4f} {metrics_bs['pnl_std']:<12.4f} \"\n",
    "      f\"{metrics_bs['pnl_var_95']:<12.4f} {metrics_bs['pnl_cvar_95']:<12.4f}\")\n",
    "print(f\"{'CVaR-NN (λ=0.8)':<25} {metrics_cvar['pnl_mean']:<12.4f} {metrics_cvar['pnl_std']:<12.4f} \"\n",
    "      f\"{metrics_cvar['pnl_var_95']:<12.4f} {metrics_cvar['pnl_cvar_95']:<12.4f}\")\n",
    "print(f\"{'Mean-NN (λ=0.2)':<25} {metrics_mean['pnl_mean']:<12.4f} {metrics_mean['pnl_std']:<12.4f} \"\n",
    "      f\"{metrics_mean['pnl_var_95']:<12.4f} {metrics_mean['pnl_cvar_95']:<12.4f}\")\n",
    "\n",
    "print(\"\\n✓ CVaR-focused strategy reduces tail risk at cost of average P&L\")\n",
    "print(\"✓ Deep hedging adapts to transaction costs automatically\")\n",
    "print(\"✓ Risk-return trade-off controlled by λ parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951530f3",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. **Modify the CVaR confidence level**: Train models with α = 0.90, 0.95, 0.99. How does the hedging strategy change?\n",
    "\n",
    "2. **Add stochastic volatility**: Implement a Heston model simulator and compare deep hedging vs BS delta.\n",
    "\n",
    "3. **Multi-asset hedging**: Extend to hedging a basket option with multiple underlyings.\n",
    "\n",
    "4. **LSTM architecture**: Use the RecurrentHedgingNetwork and compare to the feedforward model.\n",
    "\n",
    "5. **Transaction cost sensitivity**: How does optimal λ change with different transaction cost levels?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
