{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de3bacca",
   "metadata": {},
   "source": [
    "# Week 14 - Day 6: Practical Trading with RNNs\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement **sequence classification** for market regime detection\n",
    "- Understand **many-to-one vs many-to-many** RNN architectures\n",
    "- Combine **LSTM with technical indicators** for enhanced predictions\n",
    "- Build a **complete trading strategy with backtesting**\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Data Preparation](#1-setup)\n",
    "2. [Sequence Classification for Regime Detection](#2-regime)\n",
    "3. [Many-to-One vs Many-to-Many Architectures](#3-architectures)\n",
    "4. [LSTM + Technical Indicators Combination](#4-lstm-indicators)\n",
    "5. [Full Trading Strategy with Backtest](#5-backtest)\n",
    "6. [Summary and Key Takeaways](#6-summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd874386",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='1-setup'></a>\n",
    "## 1. Setup and Data Preparation\n",
    "\n",
    "First, let's import all necessary libraries and download market data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be44359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Data\n",
    "import yfinance as yf\n",
    "\n",
    "# Sklearn utilities\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd38853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download market data\n",
    "tickers = ['SPY', 'QQQ', 'IWM']  # S&P 500, Nasdaq, Russell 2000\n",
    "start_date = '2015-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "# Download data\n",
    "data = {}\n",
    "for ticker in tickers:\n",
    "    df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "    data[ticker] = df['Close']\n",
    "\n",
    "# Create DataFrame\n",
    "prices = pd.DataFrame(data)\n",
    "prices.columns = prices.columns.droplevel(1) if isinstance(prices.columns, pd.MultiIndex) else prices.columns\n",
    "prices = prices.dropna()\n",
    "\n",
    "print(f\"Data shape: {prices.shape}\")\n",
    "print(f\"Date range: {prices.index[0]} to {prices.index[-1]}\")\n",
    "prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d48cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# Focus on SPY for main analysis\n",
    "spy_close = prices['SPY'].values\n",
    "spy_returns = returns['SPY'].values\n",
    "\n",
    "# Visualize price and returns\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "axes[0].plot(prices.index, prices['SPY'], label='SPY', color='blue')\n",
    "axes[0].set_title('SPY Close Price', fontsize=14)\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(returns.index, returns['SPY'], label='Returns', color='green', alpha=0.7)\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "axes[1].set_title('SPY Daily Returns', fontsize=14)\n",
    "axes[1].set_ylabel('Return')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f2441c",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='2-regime'></a>\n",
    "## 2. Sequence Classification for Regime Detection\n",
    "\n",
    "### What is Regime Detection?\n",
    "\n",
    "Market regimes represent distinct market states characterized by:\n",
    "- **Bull Market**: Sustained upward trend, low volatility\n",
    "- **Bear Market**: Sustained downward trend, high volatility\n",
    "- **Sideways/Consolidation**: Range-bound, moderate volatility\n",
    "- **High Volatility**: Large swings regardless of direction\n",
    "\n",
    "We'll use an LSTM to classify market regimes based on historical price sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e5f4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_regime_labels(prices_series, lookback=20):\n",
    "    \"\"\"\n",
    "    Create regime labels based on rolling statistics.\n",
    "    \n",
    "    Regimes:\n",
    "    0 - Bear (negative return, high vol)\n",
    "    1 - Consolidation (low abs return, low vol)\n",
    "    2 - Bull (positive return, moderate vol)\n",
    "    3 - High Volatility (high vol regardless of direction)\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(index=prices_series.index)\n",
    "    df['price'] = prices_series.values\n",
    "    df['returns'] = df['price'].pct_change()\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df['rolling_return'] = df['returns'].rolling(lookback).sum()\n",
    "    df['rolling_vol'] = df['returns'].rolling(lookback).std() * np.sqrt(252)\n",
    "    \n",
    "    # Percentile thresholds\n",
    "    vol_median = df['rolling_vol'].median()\n",
    "    vol_75 = df['rolling_vol'].quantile(0.75)\n",
    "    \n",
    "    # Classify regimes\n",
    "    def classify_regime(row):\n",
    "        if pd.isna(row['rolling_vol']):\n",
    "            return np.nan\n",
    "        \n",
    "        if row['rolling_vol'] > vol_75:\n",
    "            return 3  # High Volatility\n",
    "        elif row['rolling_return'] < -0.02 and row['rolling_vol'] > vol_median:\n",
    "            return 0  # Bear\n",
    "        elif row['rolling_return'] > 0.02:\n",
    "            return 2  # Bull\n",
    "        else:\n",
    "            return 1  # Consolidation\n",
    "    \n",
    "    df['regime'] = df.apply(classify_regime, axis=1)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Calculate regimes\n",
    "regime_df = calculate_regime_labels(prices['SPY'])\n",
    "print(\"Regime Distribution:\")\n",
    "print(regime_df['regime'].value_counts().sort_index())\n",
    "print(\"\\nRegime Labels: 0=Bear, 1=Consolidation, 2=Bull, 3=High Volatility\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ec6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize regimes\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Plot price with regime colors\n",
    "regime_colors = {0: 'red', 1: 'gray', 2: 'green', 3: 'orange'}\n",
    "regime_names = {0: 'Bear', 1: 'Consolidation', 2: 'Bull', 3: 'High Volatility'}\n",
    "\n",
    "axes[0].plot(regime_df.index, regime_df['price'], color='black', alpha=0.5, linewidth=0.5)\n",
    "for regime in [0, 1, 2, 3]:\n",
    "    mask = regime_df['regime'] == regime\n",
    "    axes[0].scatter(regime_df.index[mask], regime_df['price'][mask], \n",
    "                   c=regime_colors[regime], label=regime_names[regime], s=5, alpha=0.6)\n",
    "axes[0].set_title('SPY Price Colored by Market Regime', fontsize=14)\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].legend(loc='upper left')\n",
    "\n",
    "# Regime over time\n",
    "axes[1].plot(regime_df.index, regime_df['regime'], color='blue', alpha=0.7)\n",
    "axes[1].set_title('Market Regime Over Time', fontsize=14)\n",
    "axes[1].set_ylabel('Regime')\n",
    "axes[1].set_yticks([0, 1, 2, 3])\n",
    "axes[1].set_yticklabels(['Bear', 'Consolidation', 'Bull', 'High Vol'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bc5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegimeClassifierLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM for Sequence Classification (Many-to-One)\n",
    "    \n",
    "    Takes a sequence of features and outputs a single class prediction.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout=0.2):\n",
    "        super(RegimeClassifierLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Take the last hidden state (many-to-one)\n",
    "        out = out[:, -1, :]  # Shape: (batch, hidden_size)\n",
    "        \n",
    "        # Classification\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa85d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_regime_data(df, seq_length=30, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Prepare sequences for regime classification.\n",
    "    \"\"\"\n",
    "    # Features: returns, rolling volatility, rolling return\n",
    "    features = df[['returns', 'rolling_vol', 'rolling_return']].values\n",
    "    labels = df['regime'].values.astype(int)\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(features_scaled)):\n",
    "        X.append(features_scaled[i-seq_length:i])\n",
    "        y.append(labels[i])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Train/test split\n",
    "    split_idx = int(len(X) * train_split)\n",
    "    \n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    y_test = torch.LongTensor(y_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# Prepare data\n",
    "SEQ_LENGTH = 30\n",
    "X_train, X_test, y_train, y_test, scaler = prepare_regime_data(regime_df, SEQ_LENGTH)\n",
    "\n",
    "print(f\"Training set: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set: X={X_test.shape}, y={y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b43ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize model\n",
    "INPUT_SIZE = 3  # Number of features\n",
    "HIDDEN_SIZE = 64\n",
    "NUM_LAYERS = 2\n",
    "NUM_CLASSES = 4  # 4 regimes\n",
    "\n",
    "model_regime = RegimeClassifierLSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    num_classes=NUM_CLASSES\n",
    ").to(device)\n",
    "\n",
    "print(model_regime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(model, train_loader, test_loader, epochs=50, lr=0.001):\n",
    "    \"\"\"\n",
    "    Train the regime classifier.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, factor=0.5)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += y_batch.size(0)\n",
    "                correct += (predicted == y_batch).sum().item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        accuracy = correct / total\n",
    "        test_accuracies.append(accuracy)\n",
    "        \n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, '\n",
    "                  f'Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "    \n",
    "    return train_losses, test_losses, test_accuracies\n",
    "\n",
    "# Train the model\n",
    "train_losses, test_losses, test_accuracies = train_classifier(\n",
    "    model_regime, train_loader, test_loader, epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c774828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(train_losses, label='Train Loss')\n",
    "axes[0].plot(test_losses, label='Test Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Test Loss')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(test_accuracies, label='Test Accuracy', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_title('Test Accuracy')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model_regime.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        outputs = model_regime(X_batch)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.numpy())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, \n",
    "                           target_names=['Bear', 'Consolidation', 'Bull', 'High Vol']))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Bear', 'Consol', 'Bull', 'HiVol'],\n",
    "            yticklabels=['Bear', 'Consol', 'Bull', 'HiVol'])\n",
    "plt.title('Regime Classification Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c604f567",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='3-architectures'></a>\n",
    "## 3. Many-to-One vs Many-to-Many Architectures\n",
    "\n",
    "### Architecture Comparison\n",
    "\n",
    "| Architecture | Input | Output | Use Case |\n",
    "|-------------|-------|--------|----------|\n",
    "| **Many-to-One** | Sequence | Single value | Classification, next-day prediction |\n",
    "| **Many-to-Many** | Sequence | Sequence | Multi-step forecasting, sequence labeling |\n",
    "\n",
    "![RNN Architectures](https://miro.medium.com/max/1400/1*6xj691fPWD8ns3LtmJCNvA.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33665f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManyToOneLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Many-to-One: Predict single output from sequence.\n",
    "    Used for: next-day direction, regime classification\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2, output_size=1):\n",
    "        super(ManyToOneLSTM, self).__init__()\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "        # Take ONLY the last output\n",
    "        out = self.fc(lstm_out[:, -1, :])  # (batch, output_size)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ManyToManyLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Many-to-Many: Predict sequence from sequence.\n",
    "    Used for: multi-step forecasting, sequence tagging\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2, output_size=1, forecast_horizon=5):\n",
    "        super(ManyToManyLSTM, self).__init__()\n",
    "        \n",
    "        self.forecast_horizon = forecast_horizon\n",
    "        \n",
    "        # Encoder LSTM\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        # Decoder LSTM\n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size=output_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, target=None, teacher_forcing_ratio=0.5):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # Encode input sequence\n",
    "        _, (hidden, cell) = self.encoder(x)\n",
    "        \n",
    "        # Initialize decoder input with last value\n",
    "        decoder_input = x[:, -1, :1].unsqueeze(1)  # (batch, 1, 1)\n",
    "        \n",
    "        outputs = []\n",
    "        \n",
    "        for t in range(self.forecast_horizon):\n",
    "            decoder_out, (hidden, cell) = self.decoder(decoder_input, (hidden, cell))\n",
    "            prediction = self.fc(decoder_out[:, -1, :])  # (batch, output_size)\n",
    "            outputs.append(prediction)\n",
    "            \n",
    "            # Teacher forcing\n",
    "            if target is not None and np.random.random() < teacher_forcing_ratio:\n",
    "                decoder_input = target[:, t:t+1, :]  # Use actual value\n",
    "            else:\n",
    "                decoder_input = prediction.unsqueeze(1)  # Use prediction\n",
    "        \n",
    "        outputs = torch.stack(outputs, dim=1)  # (batch, forecast_horizon, output_size)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "print(\"Many-to-One Model:\")\n",
    "m2o = ManyToOneLSTM(input_size=3, hidden_size=64, output_size=1)\n",
    "print(m2o)\n",
    "print(f\"\\nOutput shape for input (32, 30, 3): {m2o(torch.randn(32, 30, 3)).shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nMany-to-Many Model:\")\n",
    "m2m = ManyToManyLSTM(input_size=3, hidden_size=64, output_size=1, forecast_horizon=5)\n",
    "print(m2m)\n",
    "print(f\"\\nOutput shape for input (32, 30, 3): {m2m(torch.randn(32, 30, 3)).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9013e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_multi_step_data(prices_series, seq_length=30, forecast_horizon=5, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Prepare data for many-to-many forecasting.\n",
    "    \"\"\"\n",
    "    # Calculate returns\n",
    "    returns = prices_series.pct_change().dropna().values.reshape(-1, 1)\n",
    "    \n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    returns_scaled = scaler.fit_transform(returns)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(returns_scaled) - forecast_horizon):\n",
    "        X.append(returns_scaled[i-seq_length:i])\n",
    "        y.append(returns_scaled[i:i+forecast_horizon])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Split\n",
    "    split_idx = int(len(X) * train_split)\n",
    "    \n",
    "    X_train = torch.FloatTensor(X[:split_idx])\n",
    "    X_test = torch.FloatTensor(X[split_idx:])\n",
    "    y_train = torch.FloatTensor(y[:split_idx])\n",
    "    y_test = torch.FloatTensor(y[split_idx:])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# Prepare multi-step data\n",
    "FORECAST_HORIZON = 5\n",
    "X_train_ms, X_test_ms, y_train_ms, y_test_ms, scaler_ms = prepare_multi_step_data(\n",
    "    prices['SPY'], seq_length=30, forecast_horizon=FORECAST_HORIZON\n",
    ")\n",
    "\n",
    "print(f\"Many-to-Many Data:\")\n",
    "print(f\"X_train: {X_train_ms.shape}, y_train: {y_train_ms.shape}\")\n",
    "print(f\"X_test: {X_test_ms.shape}, y_test: {y_test_ms.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16eb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Many-to-Many model for multi-step forecasting\n",
    "model_m2m = ManyToManyLSTM(\n",
    "    input_size=1, \n",
    "    hidden_size=64, \n",
    "    output_size=1, \n",
    "    forecast_horizon=FORECAST_HORIZON\n",
    ").to(device)\n",
    "\n",
    "criterion_m2m = nn.MSELoss()\n",
    "optimizer_m2m = optim.Adam(model_m2m.parameters(), lr=0.001)\n",
    "\n",
    "train_dataset_ms = TensorDataset(X_train_ms, y_train_ms)\n",
    "train_loader_ms = DataLoader(train_dataset_ms, batch_size=64, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "epochs = 30\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model_m2m.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader_ms:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer_m2m.zero_grad()\n",
    "        \n",
    "        # Teacher forcing ratio decays over epochs\n",
    "        tf_ratio = max(0.1, 1 - epoch / epochs)\n",
    "        outputs = model_m2m(X_batch, y_batch, teacher_forcing_ratio=tf_ratio)\n",
    "        \n",
    "        loss = criterion_m2m(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_m2m.parameters(), max_norm=1.0)\n",
    "        optimizer_m2m.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    losses.append(epoch_loss / len(train_loader_ms))\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {losses[-1]:.6f}')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Many-to-Many Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa19c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize multi-step predictions\n",
    "model_m2m.eval()\n",
    "\n",
    "# Get predictions for a sample\n",
    "sample_idx = 100\n",
    "X_sample = X_test_ms[sample_idx:sample_idx+1].to(device)\n",
    "y_actual = y_test_ms[sample_idx].numpy().flatten()\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model_m2m(X_sample).cpu().numpy().flatten()\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "# Historical data\n",
    "hist = X_sample.cpu().numpy().flatten()\n",
    "ax.plot(range(len(hist)), hist, 'b-', label='Historical', linewidth=2)\n",
    "\n",
    "# Forecasts\n",
    "forecast_x = range(len(hist), len(hist) + FORECAST_HORIZON)\n",
    "ax.plot(forecast_x, y_actual, 'g-o', label='Actual', linewidth=2, markersize=8)\n",
    "ax.plot(forecast_x, y_pred, 'r--o', label='Predicted', linewidth=2, markersize=8)\n",
    "\n",
    "ax.axvline(x=len(hist)-1, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_title('Many-to-Many: 5-Day Return Forecast', fontsize=14)\n",
    "ax.set_xlabel('Time Step')\n",
    "ax.set_ylabel('Scaled Return')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494a430",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='4-lstm-indicators'></a>\n",
    "## 4. LSTM + Technical Indicators Combination\n",
    "\n",
    "Combining LSTM with technical indicators can improve predictions by:\n",
    "1. **Adding domain knowledge** - Technical indicators capture known patterns\n",
    "2. **Feature engineering** - Pre-computed signals reduce what LSTM must learn\n",
    "3. **Multi-scale information** - Indicators at different timeframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38618baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_technical_indicators(prices_df, ticker='SPY'):\n",
    "    \"\"\"\n",
    "    Calculate technical indicators for LSTM input.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(index=prices_df.index)\n",
    "    close = prices_df[ticker]\n",
    "    \n",
    "    # Returns\n",
    "    df['returns'] = close.pct_change()\n",
    "    df['log_returns'] = np.log(close / close.shift(1))\n",
    "    \n",
    "    # Moving averages\n",
    "    df['sma_10'] = close.rolling(10).mean() / close - 1\n",
    "    df['sma_20'] = close.rolling(20).mean() / close - 1\n",
    "    df['sma_50'] = close.rolling(50).mean() / close - 1\n",
    "    \n",
    "    # EMA\n",
    "    df['ema_12'] = close.ewm(span=12).mean() / close - 1\n",
    "    df['ema_26'] = close.ewm(span=26).mean() / close - 1\n",
    "    \n",
    "    # MACD\n",
    "    ema12 = close.ewm(span=12).mean()\n",
    "    ema26 = close.ewm(span=26).mean()\n",
    "    df['macd'] = (ema12 - ema26) / close\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    \n",
    "    # RSI\n",
    "    delta = close.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    df['rsi'] = (100 - (100 / (1 + rs))) / 100 - 0.5  # Normalize around 0\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    sma20 = close.rolling(20).mean()\n",
    "    std20 = close.rolling(20).std()\n",
    "    df['bb_upper'] = (sma20 + 2 * std20) / close - 1\n",
    "    df['bb_lower'] = (sma20 - 2 * std20) / close - 1\n",
    "    df['bb_width'] = (df['bb_upper'] - df['bb_lower'])\n",
    "    df['bb_position'] = (close - (sma20 - 2*std20)) / (4 * std20) - 0.5\n",
    "    \n",
    "    # Volatility\n",
    "    df['volatility_10'] = df['returns'].rolling(10).std() * np.sqrt(252)\n",
    "    df['volatility_20'] = df['returns'].rolling(20).std() * np.sqrt(252)\n",
    "    \n",
    "    # Momentum\n",
    "    df['momentum_5'] = close.pct_change(5)\n",
    "    df['momentum_10'] = close.pct_change(10)\n",
    "    df['momentum_20'] = close.pct_change(20)\n",
    "    \n",
    "    # Target: next day return direction (1 for up, 0 for down)\n",
    "    df['target'] = (df['returns'].shift(-1) > 0).astype(int)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Calculate indicators\n",
    "indicators_df = calculate_technical_indicators(prices)\n",
    "print(f\"Features: {indicators_df.columns.tolist()}\")\n",
    "print(f\"\\nShape: {indicators_df.shape}\")\n",
    "indicators_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c88f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize some indicators\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 12))\n",
    "\n",
    "# Price with SMAs\n",
    "ax0 = axes[0]\n",
    "ax0.plot(prices.index[-500:], prices['SPY'].values[-500:], label='SPY', alpha=0.8)\n",
    "ax0.set_title('SPY Price (Last 500 Days)')\n",
    "ax0.legend()\n",
    "\n",
    "# MACD\n",
    "ax1 = axes[1]\n",
    "ax1.plot(indicators_df.index[-500:], indicators_df['macd'].values[-500:], label='MACD', color='blue')\n",
    "ax1.plot(indicators_df.index[-500:], indicators_df['macd_signal'].values[-500:], label='Signal', color='orange')\n",
    "ax1.bar(indicators_df.index[-500:], indicators_df['macd_hist'].values[-500:], alpha=0.3, label='Histogram')\n",
    "ax1.axhline(y=0, color='gray', linestyle='--')\n",
    "ax1.set_title('MACD')\n",
    "ax1.legend()\n",
    "\n",
    "# RSI\n",
    "ax2 = axes[2]\n",
    "rsi_plot = (indicators_df['rsi'] + 0.5) * 100  # Convert back to 0-100 scale\n",
    "ax2.plot(indicators_df.index[-500:], rsi_plot.values[-500:], color='purple')\n",
    "ax2.axhline(y=70, color='red', linestyle='--', alpha=0.5)\n",
    "ax2.axhline(y=30, color='green', linestyle='--', alpha=0.5)\n",
    "ax2.fill_between(indicators_df.index[-500:], 30, 70, alpha=0.1)\n",
    "ax2.set_title('RSI')\n",
    "ax2.set_ylim(0, 100)\n",
    "\n",
    "# Volatility\n",
    "ax3 = axes[3]\n",
    "ax3.plot(indicators_df.index[-500:], indicators_df['volatility_20'].values[-500:], color='red')\n",
    "ax3.set_title('20-Day Rolling Volatility (Annualized)')\n",
    "ax3.set_ylabel('Volatility')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a700900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_TechnicalIndicators(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM with Technical Indicators for Trading Signal Generation.\n",
    "    \n",
    "    Architecture:\n",
    "    - Bidirectional LSTM for pattern recognition\n",
    "    - Attention mechanism for important timesteps\n",
    "    - Dense layers for classification\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2, dropout=0.3):\n",
    "        super(LSTM_TechnicalIndicators, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_size, 1)\n",
    "        )\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 2, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, input_size)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x)  # (batch, seq_len, hidden*2)\n",
    "        \n",
    "        # Attention\n",
    "        attention_weights = self.attention(lstm_out)  # (batch, seq_len, 1)\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)\n",
    "        \n",
    "        # Weighted sum\n",
    "        context = torch.sum(attention_weights * lstm_out, dim=1)  # (batch, hidden*2)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(context)\n",
    "        \n",
    "        return output.squeeze(-1), attention_weights.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_indicator_data(df, seq_length=20, train_split=0.8):\n",
    "    \"\"\"\n",
    "    Prepare technical indicator data for LSTM.\n",
    "    \"\"\"\n",
    "    # Feature columns (exclude target)\n",
    "    feature_cols = [col for col in df.columns if col != 'target']\n",
    "    \n",
    "    features = df[feature_cols].values\n",
    "    targets = df['target'].values\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(features_scaled)):\n",
    "        X.append(features_scaled[i-seq_length:i])\n",
    "        y.append(targets[i])\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    # Split\n",
    "    split_idx = int(len(X) * train_split)\n",
    "    \n",
    "    X_train = torch.FloatTensor(X[:split_idx])\n",
    "    X_test = torch.FloatTensor(X[split_idx:])\n",
    "    y_train = torch.FloatTensor(y[:split_idx])\n",
    "    y_test = torch.FloatTensor(y[split_idx:])\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, scaler, feature_cols\n",
    "\n",
    "# Prepare data\n",
    "X_train_ind, X_test_ind, y_train_ind, y_test_ind, scaler_ind, feature_cols = prepare_indicator_data(\n",
    "    indicators_df, seq_length=20\n",
    ")\n",
    "\n",
    "print(f\"Training set: X={X_train_ind.shape}, y={y_train_ind.shape}\")\n",
    "print(f\"Test set: X={X_test_ind.shape}, y={y_test_ind.shape}\")\n",
    "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and train\n",
    "model_indicators = LSTM_TechnicalIndicators(\n",
    "    input_size=len(feature_cols),\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "criterion_ind = nn.BCELoss()\n",
    "optimizer_ind = optim.Adam(model_indicators.parameters(), lr=0.001)\n",
    "scheduler_ind = optim.lr_scheduler.ReduceLROnPlateau(optimizer_ind, patience=5, factor=0.5)\n",
    "\n",
    "# Data loaders\n",
    "train_dataset_ind = TensorDataset(X_train_ind, y_train_ind)\n",
    "test_dataset_ind = TensorDataset(X_test_ind, y_test_ind)\n",
    "train_loader_ind = DataLoader(train_dataset_ind, batch_size=64, shuffle=True)\n",
    "test_loader_ind = DataLoader(test_dataset_ind, batch_size=64, shuffle=False)\n",
    "\n",
    "# Training\n",
    "epochs = 50\n",
    "train_losses_ind = []\n",
    "test_accuracies_ind = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training\n",
    "    model_indicators.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader_ind:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer_ind.zero_grad()\n",
    "        outputs, _ = model_indicators(X_batch)\n",
    "        loss = criterion_ind(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model_indicators.parameters(), max_norm=1.0)\n",
    "        optimizer_ind.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader_ind)\n",
    "    train_losses_ind.append(train_loss)\n",
    "    \n",
    "    # Evaluation\n",
    "    model_indicators.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_loader_ind:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs, _ = model_indicators(X_batch)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += y_batch.size(0)\n",
    "            correct += (predicted == y_batch).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    test_accuracies_ind.append(accuracy)\n",
    "    scheduler_ind.step(train_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {train_loss:.4f}, Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2316a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize attention weights\n",
    "model_indicators.eval()\n",
    "\n",
    "# Get attention for a sample\n",
    "sample_idx = 50\n",
    "X_sample = X_test_ind[sample_idx:sample_idx+1].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred, attention = model_indicators(X_sample)\n",
    "\n",
    "attention = attention.cpu().numpy().flatten()\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# Attention weights\n",
    "axes[0].bar(range(len(attention)), attention, color='blue', alpha=0.7)\n",
    "axes[0].set_xlabel('Time Step')\n",
    "axes[0].set_ylabel('Attention Weight')\n",
    "axes[0].set_title('Attention Weights Across Sequence')\n",
    "\n",
    "# Feature values with attention overlay\n",
    "sample_data = X_sample.cpu().numpy()[0]\n",
    "im = axes[1].imshow(sample_data.T, aspect='auto', cmap='RdYlGn')\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_ylabel('Feature')\n",
    "axes[1].set_yticks(range(len(feature_cols)))\n",
    "axes[1].set_yticklabels(feature_cols, fontsize=8)\n",
    "axes[1].set_title('Feature Values Over Sequence (with Attention)')\n",
    "\n",
    "# Overlay attention\n",
    "ax2 = axes[1].twinx()\n",
    "ax2.plot(range(len(attention)), attention * len(feature_cols), 'k-', linewidth=2, label='Attention')\n",
    "ax2.set_ylabel('Attention')\n",
    "\n",
    "plt.colorbar(im, ax=axes[1], label='Feature Value')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff39034",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='5-backtest'></a>\n",
    "## 5. Full Trading Strategy with Backtest\n",
    "\n",
    "Now let's build a complete trading system that:\n",
    "1. Uses the LSTM + Technical Indicators model for signal generation\n",
    "2. Implements position sizing based on prediction confidence\n",
    "3. Includes transaction costs\n",
    "4. Calculates comprehensive performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30b67b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingBacktester:\n",
    "    \"\"\"\n",
    "    Backtesting framework for LSTM trading strategies.\n",
    "    \"\"\"\n",
    "    def __init__(self, initial_capital=100000, transaction_cost=0.001):\n",
    "        self.initial_capital = initial_capital\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "    def generate_signals(self, model, X_data, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Generate trading signals from model predictions.\n",
    "        \n",
    "        Returns:\n",
    "            signals: 1 (long), 0 (no position), -1 (short)\n",
    "            probabilities: raw model outputs\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            X_tensor = X_data.to(device)\n",
    "            probs, _ = model(X_tensor)\n",
    "            probs = probs.cpu().numpy()\n",
    "        \n",
    "        # Generate signals based on probability threshold\n",
    "        signals = np.zeros(len(probs))\n",
    "        signals[probs > 0.5 + threshold/2] = 1   # Strong buy\n",
    "        signals[probs < 0.5 - threshold/2] = -1  # Strong sell\n",
    "        \n",
    "        return signals, probs\n",
    "    \n",
    "    def run_backtest(self, signals, returns, probabilities=None):\n",
    "        \"\"\"\n",
    "        Run backtest with given signals.\n",
    "        \n",
    "        Args:\n",
    "            signals: trading signals (1, 0, -1)\n",
    "            returns: actual returns for the period\n",
    "            probabilities: model confidence for position sizing\n",
    "        \"\"\"\n",
    "        n = len(signals)\n",
    "        \n",
    "        # Position sizing based on confidence\n",
    "        if probabilities is not None:\n",
    "            confidence = np.abs(probabilities - 0.5) * 2  # Scale to 0-1\n",
    "            positions = signals * confidence\n",
    "        else:\n",
    "            positions = signals\n",
    "        \n",
    "        # Calculate strategy returns\n",
    "        strategy_returns = positions[:-1] * returns[1:]\n",
    "        \n",
    "        # Transaction costs (when position changes)\n",
    "        position_changes = np.abs(np.diff(positions))\n",
    "        costs = position_changes * self.transaction_cost\n",
    "        strategy_returns = strategy_returns - costs\n",
    "        \n",
    "        # Calculate equity curve\n",
    "        equity = self.initial_capital * np.cumprod(1 + strategy_returns)\n",
    "        equity = np.insert(equity, 0, self.initial_capital)\n",
    "        \n",
    "        # Buy and hold benchmark\n",
    "        benchmark_equity = self.initial_capital * np.cumprod(1 + returns)\n",
    "        benchmark_equity = np.insert(benchmark_equity, 0, self.initial_capital)\n",
    "        \n",
    "        results = {\n",
    "            'signals': signals,\n",
    "            'positions': positions,\n",
    "            'strategy_returns': strategy_returns,\n",
    "            'equity': equity,\n",
    "            'benchmark_equity': benchmark_equity[:len(equity)],\n",
    "            'returns': returns\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def calculate_metrics(self, results):\n",
    "        \"\"\"\n",
    "        Calculate comprehensive performance metrics.\n",
    "        \"\"\"\n",
    "        strategy_returns = results['strategy_returns']\n",
    "        equity = results['equity']\n",
    "        benchmark_equity = results['benchmark_equity']\n",
    "        \n",
    "        # Total returns\n",
    "        total_return = (equity[-1] / equity[0]) - 1\n",
    "        benchmark_return = (benchmark_equity[-1] / benchmark_equity[0]) - 1\n",
    "        \n",
    "        # Annualized returns (assuming 252 trading days)\n",
    "        n_days = len(strategy_returns)\n",
    "        annual_return = (1 + total_return) ** (252 / n_days) - 1\n",
    "        benchmark_annual = (1 + benchmark_return) ** (252 / n_days) - 1\n",
    "        \n",
    "        # Volatility\n",
    "        volatility = np.std(strategy_returns) * np.sqrt(252)\n",
    "        benchmark_vol = np.std(results['returns'][1:]) * np.sqrt(252)\n",
    "        \n",
    "        # Sharpe ratio (assuming 0 risk-free rate)\n",
    "        sharpe = annual_return / volatility if volatility > 0 else 0\n",
    "        benchmark_sharpe = benchmark_annual / benchmark_vol if benchmark_vol > 0 else 0\n",
    "        \n",
    "        # Maximum drawdown\n",
    "        rolling_max = np.maximum.accumulate(equity)\n",
    "        drawdown = (equity - rolling_max) / rolling_max\n",
    "        max_drawdown = np.min(drawdown)\n",
    "        \n",
    "        # Calmar ratio\n",
    "        calmar = annual_return / abs(max_drawdown) if max_drawdown != 0 else 0\n",
    "        \n",
    "        # Win rate\n",
    "        winning_trades = np.sum(strategy_returns > 0)\n",
    "        total_trades = np.sum(strategy_returns != 0)\n",
    "        win_rate = winning_trades / total_trades if total_trades > 0 else 0\n",
    "        \n",
    "        # Profit factor\n",
    "        gross_profit = np.sum(strategy_returns[strategy_returns > 0])\n",
    "        gross_loss = abs(np.sum(strategy_returns[strategy_returns < 0]))\n",
    "        profit_factor = gross_profit / gross_loss if gross_loss > 0 else np.inf\n",
    "        \n",
    "        metrics = {\n",
    "            'Total Return': f\"{total_return:.2%}\",\n",
    "            'Benchmark Return': f\"{benchmark_return:.2%}\",\n",
    "            'Annual Return': f\"{annual_return:.2%}\",\n",
    "            'Benchmark Annual': f\"{benchmark_annual:.2%}\",\n",
    "            'Volatility': f\"{volatility:.2%}\",\n",
    "            'Sharpe Ratio': f\"{sharpe:.2f}\",\n",
    "            'Benchmark Sharpe': f\"{benchmark_sharpe:.2f}\",\n",
    "            'Max Drawdown': f\"{max_drawdown:.2%}\",\n",
    "            'Calmar Ratio': f\"{calmar:.2f}\",\n",
    "            'Win Rate': f\"{win_rate:.2%}\",\n",
    "            'Profit Factor': f\"{profit_factor:.2f}\",\n",
    "            'Total Trades': total_trades\n",
    "        }\n",
    "        \n",
    "        return metrics, drawdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run backtest on test data\n",
    "backtester = TradingBacktester(initial_capital=100000, transaction_cost=0.001)\n",
    "\n",
    "# Generate signals\n",
    "signals, probabilities = backtester.generate_signals(\n",
    "    model_indicators, \n",
    "    X_test_ind, \n",
    "    threshold=0.1  # Only trade when confidence > 55% or < 45%\n",
    ")\n",
    "\n",
    "# Get actual returns for test period\n",
    "test_start_idx = int(len(indicators_df) * 0.8) + 20  # Account for sequence length\n",
    "test_returns = indicators_df['returns'].values[test_start_idx:test_start_idx + len(signals)]\n",
    "\n",
    "# Run backtest\n",
    "results = backtester.run_backtest(signals, test_returns, probabilities)\n",
    "\n",
    "# Calculate metrics\n",
    "metrics, drawdown = backtester.calculate_metrics(results)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"BACKTEST RESULTS\")\n",
    "print(\"=\"*50)\n",
    "for key, value in metrics.items():\n",
    "    print(f\"{key:20}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed14314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize backtest results\n",
    "fig, axes = plt.subplots(4, 1, figsize=(14, 16))\n",
    "\n",
    "# 1. Equity curves\n",
    "ax1 = axes[0]\n",
    "ax1.plot(results['equity'], label='Strategy', linewidth=2, color='blue')\n",
    "ax1.plot(results['benchmark_equity'], label='Buy & Hold', linewidth=2, color='gray', alpha=0.7)\n",
    "ax1.set_title('Equity Curves', fontsize=14)\n",
    "ax1.set_ylabel('Portfolio Value ($)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Drawdown\n",
    "ax2 = axes[1]\n",
    "ax2.fill_between(range(len(drawdown)), drawdown, 0, color='red', alpha=0.3)\n",
    "ax2.plot(drawdown, color='red', linewidth=1)\n",
    "ax2.set_title('Drawdown', fontsize=14)\n",
    "ax2.set_ylabel('Drawdown')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Signals and positions\n",
    "ax3 = axes[2]\n",
    "ax3.plot(results['positions'], label='Position', color='green', alpha=0.7)\n",
    "ax3.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "ax3.set_title('Trading Positions', fontsize=14)\n",
    "ax3.set_ylabel('Position Size')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Prediction probabilities\n",
    "ax4 = axes[3]\n",
    "ax4.plot(probabilities, label='Prediction Probability', color='purple', alpha=0.7)\n",
    "ax4.axhline(y=0.5, color='black', linestyle='--', alpha=0.3)\n",
    "ax4.axhline(y=0.55, color='green', linestyle='--', alpha=0.3, label='Long Threshold')\n",
    "ax4.axhline(y=0.45, color='red', linestyle='--', alpha=0.3, label='Short Threshold')\n",
    "ax4.set_title('Model Predictions', fontsize=14)\n",
    "ax4.set_ylabel('Probability')\n",
    "ax4.set_xlabel('Trading Day')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17340fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly returns heatmap\n",
    "def create_monthly_returns(strategy_returns, start_date):\n",
    "    \"\"\"\n",
    "    Create monthly returns DataFrame for heatmap.\n",
    "    \"\"\"\n",
    "    # Create date index\n",
    "    dates = pd.date_range(start=start_date, periods=len(strategy_returns), freq='B')\n",
    "    returns_series = pd.Series(strategy_returns, index=dates)\n",
    "    \n",
    "    # Resample to monthly\n",
    "    monthly_returns = returns_series.resample('M').apply(lambda x: (1 + x).prod() - 1)\n",
    "    \n",
    "    # Create pivot table\n",
    "    monthly_df = pd.DataFrame({\n",
    "        'Year': monthly_returns.index.year,\n",
    "        'Month': monthly_returns.index.month,\n",
    "        'Return': monthly_returns.values\n",
    "    })\n",
    "    \n",
    "    pivot = monthly_df.pivot(index='Year', columns='Month', values='Return')\n",
    "    pivot.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "                     'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'][:len(pivot.columns)]\n",
    "    \n",
    "    return pivot\n",
    "\n",
    "# Get start date for test period\n",
    "test_start_date = indicators_df.index[test_start_idx]\n",
    "monthly_returns_pivot = create_monthly_returns(results['strategy_returns'], test_start_date)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 6))\n",
    "sns.heatmap(monthly_returns_pivot, annot=True, fmt='.1%', cmap='RdYlGn', center=0,\n",
    "            linewidths=0.5, cbar_kws={'label': 'Return'})\n",
    "plt.title('Monthly Returns Heatmap', fontsize=14)\n",
    "plt.ylabel('Year')\n",
    "plt.xlabel('Month')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b56d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return distribution analysis\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Strategy returns distribution\n",
    "ax1 = axes[0]\n",
    "ax1.hist(results['strategy_returns'], bins=50, alpha=0.7, color='blue', label='Strategy', density=True)\n",
    "ax1.hist(results['returns'][1:], bins=50, alpha=0.5, color='gray', label='Buy & Hold', density=True)\n",
    "ax1.axvline(x=0, color='black', linestyle='--')\n",
    "ax1.set_title('Return Distribution', fontsize=14)\n",
    "ax1.set_xlabel('Daily Return')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.legend()\n",
    "\n",
    "# Rolling Sharpe ratio\n",
    "ax2 = axes[1]\n",
    "rolling_sharpe = pd.Series(results['strategy_returns']).rolling(63).apply(\n",
    "    lambda x: np.mean(x) / np.std(x) * np.sqrt(252) if np.std(x) > 0 else 0\n",
    ")\n",
    "ax2.plot(rolling_sharpe, color='green', label='Rolling Sharpe (63-day)')\n",
    "ax2.axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "ax2.axhline(y=1, color='green', linestyle='--', alpha=0.3, label='Sharpe = 1')\n",
    "ax2.set_title('Rolling Sharpe Ratio', fontsize=14)\n",
    "ax2.set_xlabel('Trading Day')\n",
    "ax2.set_ylabel('Sharpe Ratio')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eace84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trade analysis\n",
    "def analyze_trades(signals, returns, probabilities):\n",
    "    \"\"\"\n",
    "    Analyze individual trades.\n",
    "    \"\"\"\n",
    "    trades = []\n",
    "    \n",
    "    in_trade = False\n",
    "    trade_start = 0\n",
    "    trade_signal = 0\n",
    "    \n",
    "    for i in range(len(signals)):\n",
    "        if not in_trade and signals[i] != 0:\n",
    "            # Enter trade\n",
    "            in_trade = True\n",
    "            trade_start = i\n",
    "            trade_signal = signals[i]\n",
    "        elif in_trade and (signals[i] == 0 or signals[i] != trade_signal or i == len(signals)-1):\n",
    "            # Exit trade\n",
    "            trade_return = np.sum(trade_signal * returns[trade_start+1:i+1])\n",
    "            trades.append({\n",
    "                'start': trade_start,\n",
    "                'end': i,\n",
    "                'duration': i - trade_start,\n",
    "                'direction': 'Long' if trade_signal > 0 else 'Short',\n",
    "                'return': trade_return,\n",
    "                'confidence': np.mean(probabilities[trade_start:i])\n",
    "            })\n",
    "            in_trade = False\n",
    "            \n",
    "            # Check if new trade starts\n",
    "            if signals[i] != 0:\n",
    "                in_trade = True\n",
    "                trade_start = i\n",
    "                trade_signal = signals[i]\n",
    "    \n",
    "    return pd.DataFrame(trades)\n",
    "\n",
    "trades_df = analyze_trades(signals, test_returns, probabilities)\n",
    "\n",
    "if len(trades_df) > 0:\n",
    "    print(f\"Total Trades: {len(trades_df)}\")\n",
    "    print(f\"\\nTrade Statistics:\")\n",
    "    print(trades_df[['duration', 'return']].describe())\n",
    "    \n",
    "    print(f\"\\nBy Direction:\")\n",
    "    print(trades_df.groupby('direction')['return'].agg(['count', 'mean', 'sum']))\n",
    "else:\n",
    "    print(\"No trades generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34738abf",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='6-summary'></a>\n",
    "## 6. Summary and Key Takeaways\n",
    "\n",
    "### What We Learned\n",
    "\n",
    "#### 1. Sequence Classification for Regime Detection\n",
    "- LSTMs can classify market states (Bull, Bear, Consolidation, High Volatility)\n",
    "- Rolling statistics help define regime labels\n",
    "- Multi-class classification using CrossEntropyLoss\n",
    "\n",
    "#### 2. Many-to-One vs Many-to-Many Architectures\n",
    "- **Many-to-One**: Sequence  Single output (classification, next-day prediction)\n",
    "- **Many-to-Many**: Sequence  Sequence (multi-step forecasting)\n",
    "- Encoder-decoder architecture for sequence-to-sequence tasks\n",
    "- Teacher forcing for training sequence generators\n",
    "\n",
    "#### 3. LSTM + Technical Indicators\n",
    "- Combining domain knowledge (indicators) with deep learning\n",
    "- Attention mechanism highlights important time steps\n",
    "- Bidirectional LSTM captures patterns in both directions\n",
    "\n",
    "#### 4. Trading Strategy Backtest\n",
    "- Position sizing based on model confidence\n",
    "- Transaction costs significantly impact returns\n",
    "- Multiple metrics needed: Sharpe, Calmar, Win Rate, Profit Factor\n",
    "- Visualizations help understand strategy behavior\n",
    "\n",
    "### Important Caveats\n",
    "\n",
    " **This is for educational purposes only!**\n",
    "\n",
    "1. **Overfitting Risk**: Neural networks easily overfit to historical patterns\n",
    "2. **Look-ahead Bias**: Ensure features don't use future information\n",
    "3. **Regime Changes**: Models trained on past regimes may fail in new ones\n",
    "4. **Transaction Costs**: Real costs may be higher than simulated\n",
    "5. **Slippage**: Not modeled here but significant for high-frequency strategies\n",
    "6. **Market Impact**: Large positions can move prices\n",
    "\n",
    "### Next Steps\n",
    "- Implement walk-forward optimization\n",
    "- Add more sophisticated risk management\n",
    "- Test on multiple assets\n",
    "- Combine with fundamental data\n",
    "- Explore transformer architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c96b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary statistics\n",
    "print(\"=\"*60)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. REGIME CLASSIFIER\")\n",
    "print(f\"   - Test Accuracy: {test_accuracies[-1]:.2%}\")\n",
    "print(f\"   - Number of Regimes: 4\")\n",
    "\n",
    "print(\"\\n2. MANY-TO-MANY FORECASTER\")\n",
    "print(f\"   - Forecast Horizon: {FORECAST_HORIZON} days\")\n",
    "print(f\"   - Final Training Loss: {losses[-1]:.6f}\")\n",
    "\n",
    "print(\"\\n3. LSTM + INDICATORS TRADING MODEL\")\n",
    "print(f\"   - Features: {len(feature_cols)}\")\n",
    "print(f\"   - Test Accuracy: {test_accuracies_ind[-1]:.2%}\")\n",
    "\n",
    "print(\"\\n4. BACKTEST RESULTS\")\n",
    "for key in ['Total Return', 'Sharpe Ratio', 'Max Drawdown', 'Win Rate']:\n",
    "    print(f\"   - {key}: {metrics[key]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Notebook completed successfully!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
