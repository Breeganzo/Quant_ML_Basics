{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e58c0dbc",
   "metadata": {},
   "source": [
    "# Week 14 - Day 5: Bidirectional and Stacked RNNs\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand bidirectional RNNs and their applications in pattern recognition\n",
    "- Implement stacked/deep LSTM architectures\n",
    "- Apply dropout regularization for sequential models\n",
    "- Build a deep LSTM trading model for price prediction\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction to Advanced RNN Architectures](#1-introduction)\n",
    "2. [Bidirectional RNNs](#2-bidirectional)\n",
    "3. [Stacked/Deep LSTMs](#3-stacked)\n",
    "4. [Dropout for Sequences](#4-dropout)\n",
    "5. [Deep LSTM Trading Model](#5-trading-model)\n",
    "6. [Key Takeaways](#6-takeaways)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef29e075",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Introduction to Advanced RNN Architectures <a id='1-introduction'></a>\n",
    "\n",
    "### Why Go Beyond Simple RNNs?\n",
    "\n",
    "While basic LSTMs and GRUs can capture sequential patterns, more sophisticated architectures can:\n",
    "\n",
    "1. **Bidirectional RNNs**: Process sequences in both forward and backward directions\n",
    "   - Capture context from both past and future\n",
    "   - Useful for pattern recognition where full sequence is available\n",
    "\n",
    "2. **Stacked/Deep LSTMs**: Multiple layers of LSTM cells\n",
    "   - Learn hierarchical representations\n",
    "   - Lower layers capture simple patterns, higher layers capture complex abstractions\n",
    "\n",
    "3. **Regularization**: Dropout prevents overfitting\n",
    "   - Essential for deep networks with limited financial data\n",
    "\n",
    "### Architecture Overview\n",
    "\n",
    "```\n",
    "Bidirectional:          Stacked:\n",
    "→ LSTM →                LSTM Layer 3\n",
    "    ↓    concat              ↑\n",
    "← LSTM ←                LSTM Layer 2\n",
    "                             ↑\n",
    "                        LSTM Layer 1\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c92d71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download financial data\n",
    "ticker = 'SPY'\n",
    "start_date = '2018-01-01'\n",
    "end_date = '2024-01-01'\n",
    "\n",
    "data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "prices = data['Close'].values.reshape(-1, 1)\n",
    "\n",
    "print(f\"Data shape: {prices.shape}\")\n",
    "print(f\"Date range: {data.index[0].date()} to {data.index[-1].date()}\")\n",
    "print(f\"Price range: ${prices.min():.2f} - ${prices.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62c1d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_prices = scaler.fit_transform(prices)\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    \"\"\"Create sequences for time series prediction.\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Parameters\n",
    "SEQ_LENGTH = 60\n",
    "TRAIN_SPLIT = 0.8\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(scaled_prices, SEQ_LENGTH)\n",
    "print(f\"Sequences shape: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# Train/test split\n",
    "train_size = int(len(X) * TRAIN_SPLIT)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d75aaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).to(device)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b986a8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Bidirectional RNNs <a id='2-bidirectional'></a>\n",
    "\n",
    "### Concept\n",
    "\n",
    "Bidirectional RNNs process sequences in **two directions**:\n",
    "- **Forward**: From $t_1$ to $t_n$ (past → future)\n",
    "- **Backward**: From $t_n$ to $t_1$ (future → past)\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "For each timestep $t$:\n",
    "\n",
    "$$\\overrightarrow{h_t} = \\text{LSTM}_{forward}(x_t, \\overrightarrow{h_{t-1}})$$\n",
    "\n",
    "$$\\overleftarrow{h_t} = \\text{LSTM}_{backward}(x_t, \\overleftarrow{h_{t+1}})$$\n",
    "\n",
    "$$h_t = [\\overrightarrow{h_t}; \\overleftarrow{h_t}]$$\n",
    "\n",
    "### When to Use Bidirectional RNNs\n",
    "\n",
    "| Use Case | Suitable? | Reason |\n",
    "|----------|-----------|--------|\n",
    "| Pattern recognition (post-hoc) | ✅ Yes | Full sequence available |\n",
    "| Real-time prediction | ❌ No | Future data unavailable |\n",
    "| Backtesting analysis | ✅ Yes | Historical patterns |\n",
    "| Regime classification | ✅ Yes | Identify patterns after the fact |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9bc4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionalLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM for sequence pattern recognition.\n",
    "    \n",
    "    The output dimension is doubled (hidden_size * 2) due to\n",
    "    concatenation of forward and backward hidden states.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.0):\n",
    "        super(BidirectionalLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,  # Key parameter!\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        \n",
    "        # Output layer (hidden_size * 2 for bidirectional)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        \n",
    "        # LSTM output shape: (batch, seq_len, hidden_size * 2)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Use the last output (contains info from both directions)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        # Predict\n",
    "        out = self.fc(last_output)\n",
    "        return out\n",
    "\n",
    "# Instantiate model\n",
    "bi_lstm = BidirectionalLSTM(\n",
    "    input_size=1,\n",
    "    hidden_size=64,\n",
    "    num_layers=1\n",
    ").to(device)\n",
    "\n",
    "print(bi_lstm)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in bi_lstm.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc30fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize bidirectional processing\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Left: Unidirectional concept\n",
    "ax1 = axes[0]\n",
    "timesteps = np.arange(10)\n",
    "ax1.plot(timesteps, np.sin(timesteps * 0.5), 'b-o', linewidth=2, markersize=8)\n",
    "for i in range(len(timesteps)-1):\n",
    "    ax1.annotate('', xy=(timesteps[i+1], np.sin((i+1)*0.5)), \n",
    "                 xytext=(timesteps[i], np.sin(i*0.5)),\n",
    "                 arrowprops=dict(arrowstyle='->', color='blue', lw=2))\n",
    "ax1.set_title('Unidirectional LSTM\\n(Forward Only)', fontsize=12)\n",
    "ax1.set_xlabel('Time Step')\n",
    "ax1.set_ylabel('Hidden State Flow')\n",
    "\n",
    "# Right: Bidirectional concept\n",
    "ax2 = axes[1]\n",
    "ax2.plot(timesteps, np.sin(timesteps * 0.5), 'b-o', linewidth=2, markersize=8, label='Forward')\n",
    "ax2.plot(timesteps, np.sin(timesteps * 0.5) - 0.3, 'r-s', linewidth=2, markersize=8, label='Backward')\n",
    "for i in range(len(timesteps)-1):\n",
    "    # Forward arrows\n",
    "    ax2.annotate('', xy=(timesteps[i+1], np.sin((i+1)*0.5)), \n",
    "                 xytext=(timesteps[i], np.sin(i*0.5)),\n",
    "                 arrowprops=dict(arrowstyle='->', color='blue', lw=1.5))\n",
    "    # Backward arrows\n",
    "    ax2.annotate('', xy=(timesteps[i], np.sin(i*0.5) - 0.3), \n",
    "                 xytext=(timesteps[i+1], np.sin((i+1)*0.5) - 0.3),\n",
    "                 arrowprops=dict(arrowstyle='->', color='red', lw=1.5))\n",
    "ax2.set_title('Bidirectional LSTM\\n(Forward + Backward)', fontsize=12)\n",
    "ax2.set_xlabel('Time Step')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1486f02b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Stacked/Deep LSTMs <a id='3-stacked'></a>\n",
    "\n",
    "### Why Stack LSTM Layers?\n",
    "\n",
    "Stacking multiple LSTM layers creates a **hierarchical representation**:\n",
    "\n",
    "1. **Layer 1**: Captures low-level patterns (trends, simple oscillations)\n",
    "2. **Layer 2**: Combines low-level patterns into mid-level features\n",
    "3. **Layer 3+**: Learns complex, abstract representations\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Input Sequence: [x₁, x₂, ..., xₜ]\n",
    "        ↓\n",
    "    LSTM Layer 1  →  h₁⁽¹⁾, h₂⁽¹⁾, ..., hₜ⁽¹⁾  (simple patterns)\n",
    "        ↓\n",
    "    LSTM Layer 2  →  h₁⁽²⁾, h₂⁽²⁾, ..., hₜ⁽²⁾  (complex patterns)\n",
    "        ↓\n",
    "    LSTM Layer 3  →  h₁⁽³⁾, h₂⁽³⁾, ..., hₜ⁽³⁾  (abstract features)\n",
    "        ↓\n",
    "    Dense Layer   →  Output\n",
    "```\n",
    "\n",
    "### Guidelines for Depth\n",
    "\n",
    "| Dataset Size | Recommended Layers |\n",
    "|--------------|--------------------|\n",
    "| < 1,000 samples | 1 layer |\n",
    "| 1,000 - 10,000 | 1-2 layers |\n",
    "| 10,000 - 100,000 | 2-3 layers |\n",
    "| > 100,000 | 3-4+ layers |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d637d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StackedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Stacked (Deep) LSTM with configurable number of layers.\n",
    "    \n",
    "    Each layer passes its output sequence to the next layer,\n",
    "    enabling hierarchical feature learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.0):\n",
    "        super(StackedLSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Stacked LSTM (PyTorch handles stacking automatically)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        \n",
    "        # Get last timestep output\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Compare different depths\n",
    "depths = [1, 2, 3, 4]\n",
    "for depth in depths:\n",
    "    model = StackedLSTM(input_size=1, hidden_size=64, num_layers=depth)\n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Layers: {depth} | Parameters: {params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96a0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ManualStackedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Manually stacked LSTM layers for fine-grained control.\n",
    "    \n",
    "    Useful when you want different hidden sizes per layer\n",
    "    or custom connections between layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_sizes, dropout=0.2):\n",
    "        super(ManualStackedLSTM, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        \n",
    "        # First layer\n",
    "        self.layers.append(\n",
    "            nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
    "        )\n",
    "        self.dropouts.append(nn.Dropout(dropout))\n",
    "        \n",
    "        # Subsequent layers\n",
    "        for i in range(1, len(hidden_sizes)):\n",
    "            self.layers.append(\n",
    "                nn.LSTM(hidden_sizes[i-1], hidden_sizes[i], batch_first=True)\n",
    "            )\n",
    "            self.dropouts.append(nn.Dropout(dropout))\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_sizes[-1], 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Process through each layer\n",
    "        for lstm, dropout in zip(self.layers, self.dropouts):\n",
    "            x, _ = lstm(x)\n",
    "            x = dropout(x)\n",
    "        \n",
    "        # Get last timestep\n",
    "        out = self.fc(x[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# Example: Pyramid architecture (decreasing hidden sizes)\n",
    "pyramid_lstm = ManualStackedLSTM(\n",
    "    input_size=1,\n",
    "    hidden_sizes=[128, 64, 32],  # Decreasing sizes\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "print(\"Pyramid LSTM Architecture:\")\n",
    "print(pyramid_lstm)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in pyramid_lstm.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0728790b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Dropout for Sequences <a id='4-dropout'></a>\n",
    "\n",
    "### Types of Dropout in RNNs\n",
    "\n",
    "1. **Standard Dropout**: Applied between LSTM layers\n",
    "   - Different mask for each timestep\n",
    "   - Can disrupt temporal information flow\n",
    "\n",
    "2. **Variational Dropout**: Same mask across all timesteps\n",
    "   - Preserves temporal consistency\n",
    "   - Better for sequence modeling\n",
    "\n",
    "3. **Recurrent Dropout**: Applied to recurrent connections\n",
    "   - Drops hidden-to-hidden connections\n",
    "\n",
    "### Dropout Placement\n",
    "\n",
    "```\n",
    "Input → LSTM₁ → Dropout → LSTM₂ → Dropout → LSTM₃ → Output\n",
    "                  ↑                 ↑\n",
    "           Between layers    Between layers\n",
    "```\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "- **Rate**: 0.2-0.5 typically works well\n",
    "- **Position**: After LSTM output, not on input\n",
    "- **Training only**: Disabled during inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6586685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    Variational Dropout for sequences.\n",
    "    \n",
    "    Uses the same dropout mask across all timesteps,\n",
    "    preserving temporal correlations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dropout_rate=0.2):\n",
    "        super(VariationalDropout, self).__init__()\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not self.training or self.dropout_rate == 0:\n",
    "            return x\n",
    "        \n",
    "        # x shape: (batch, seq_len, features)\n",
    "        # Create mask for (batch, 1, features) - same mask for all timesteps\n",
    "        mask = torch.bernoulli(\n",
    "            torch.ones(x.size(0), 1, x.size(2)) * (1 - self.dropout_rate)\n",
    "        ).to(x.device)\n",
    "        \n",
    "        # Expand mask across timesteps and apply\n",
    "        mask = mask.expand_as(x)\n",
    "        return x * mask / (1 - self.dropout_rate)\n",
    "\n",
    "# Demonstrate difference\n",
    "sample_seq = torch.randn(2, 5, 4)  # (batch=2, seq_len=5, features=4)\n",
    "\n",
    "# Standard dropout - different mask each time\n",
    "std_dropout = nn.Dropout(0.5)\n",
    "std_dropout.train()\n",
    "\n",
    "# Variational dropout - same mask across timesteps\n",
    "var_dropout = VariationalDropout(0.5)\n",
    "var_dropout.train()\n",
    "\n",
    "print(\"Standard Dropout (different mask per timestep):\")\n",
    "out_std = std_dropout(sample_seq)\n",
    "print(f\"Non-zero pattern varies: {(out_std[0] != 0).int()}\")\n",
    "\n",
    "print(\"\\nVariational Dropout (same mask across timesteps):\")\n",
    "out_var = var_dropout(sample_seq)\n",
    "print(f\"Consistent pattern: {(out_var[0] != 0).int()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f5680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMWithVariationalDropout(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM with Variational Dropout between layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super(LSTMWithVariationalDropout, self).__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropouts = nn.ModuleList()\n",
    "        \n",
    "        # Build layers\n",
    "        for i in range(num_layers):\n",
    "            input_dim = input_size if i == 0 else hidden_size\n",
    "            self.layers.append(\n",
    "                nn.LSTM(input_dim, hidden_size, batch_first=True)\n",
    "            )\n",
    "            if i < num_layers - 1:  # No dropout after last layer\n",
    "                self.dropouts.append(VariationalDropout(dropout))\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, lstm in enumerate(self.layers):\n",
    "            x, _ = lstm(x)\n",
    "            if i < len(self.dropouts):\n",
    "                x = self.dropouts[i](x)\n",
    "        \n",
    "        return self.fc(x[:, -1, :])\n",
    "\n",
    "# Create model\n",
    "var_lstm = LSTMWithVariationalDropout(\n",
    "    input_size=1,\n",
    "    hidden_size=64,\n",
    "    num_layers=3,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(var_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78880a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Deep LSTM Trading Model <a id='5-trading-model'></a>\n",
    "\n",
    "Now we'll combine all concepts into a comprehensive trading model:\n",
    "\n",
    "1. **Bidirectional + Stacked**: For pattern recognition\n",
    "2. **Dropout**: For regularization\n",
    "3. **Multiple features**: Technical indicators\n",
    "4. **Attention mechanism**: Focus on important timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e88213",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepLSTMTradingModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Production-grade Deep LSTM for Trading.\n",
    "    \n",
    "    Features:\n",
    "    - Bidirectional first layer for pattern recognition\n",
    "    - Stacked unidirectional layers for prediction\n",
    "    - Variational dropout for regularization\n",
    "    - Skip connections for gradient flow\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size=128, num_layers=3, dropout=0.3):\n",
    "        super(DeepLSTMTradingModel, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Layer 1: Bidirectional for pattern recognition\n",
    "        self.bi_lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Projection from bidirectional output to hidden_size\n",
    "        self.projection = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        \n",
    "        # Layer 2+: Stacked unidirectional LSTMs\n",
    "        self.stacked_lstm = nn.LSTM(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers - 1,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 2 else 0.0\n",
    "        )\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Output layers\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, 1)\n",
    "        \n",
    "        # Activation\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Bidirectional layer\n",
    "        bi_out, _ = self.bi_lstm(x)\n",
    "        \n",
    "        # Project to hidden_size\n",
    "        projected = self.relu(self.projection(bi_out))\n",
    "        projected = self.dropout(projected)\n",
    "        \n",
    "        # Stacked layers\n",
    "        stacked_out, _ = self.stacked_lstm(projected)\n",
    "        \n",
    "        # Get last output\n",
    "        last_output = stacked_out[:, -1, :]\n",
    "        last_output = self.dropout(last_output)\n",
    "        \n",
    "        # Dense layers\n",
    "        out = self.relu(self.fc1(last_output))\n",
    "        out = self.fc2(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Create model\n",
    "model = DeepLSTMTradingModel(\n",
    "    input_size=1,\n",
    "    hidden_size=128,\n",
    "    num_layers=3,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbaaf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, epochs=50, lr=0.001):\n",
    "    \"\"\"\n",
    "    Training loop with early stopping and learning rate scheduling.\n",
    "    \"\"\"\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    best_test_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 10\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        \n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        test_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in test_loader:\n",
    "                outputs = model(X_batch)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                test_loss += loss.item()\n",
    "        \n",
    "        test_loss /= len(test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(test_loss)\n",
    "        \n",
    "        # Early stopping check\n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "                  f\"Train Loss: {train_loss:.6f} | \"\n",
    "                  f\"Test Loss: {test_loss:.6f}\")\n",
    "        \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            model.load_state_dict(best_model_state)\n",
    "            break\n",
    "    \n",
    "    return train_losses, test_losses\n",
    "\n",
    "# Train the model\n",
    "print(\"Training Deep LSTM Trading Model...\\n\")\n",
    "train_losses, test_losses = train_model(\n",
    "    model, train_loader, test_loader, epochs=100, lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c0ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "ax1.plot(train_losses, label='Train Loss', linewidth=2)\n",
    "ax1.plot(test_losses, label='Test Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('MSE Loss')\n",
    "ax1.set_title('Training Progress')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Log scale\n",
    "ax2 = axes[1]\n",
    "ax2.semilogy(train_losses, label='Train Loss', linewidth=2)\n",
    "ax2.semilogy(test_losses, label='Test Loss', linewidth=2)\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_ylabel('MSE Loss (log scale)')\n",
    "ax2.set_title('Training Progress (Log Scale)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dfcdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_predictions = model(X_train_tensor).cpu().numpy()\n",
    "    test_predictions = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "# Inverse transform\n",
    "train_predictions = scaler.inverse_transform(train_predictions)\n",
    "test_predictions = scaler.inverse_transform(test_predictions)\n",
    "y_train_actual = scaler.inverse_transform(y_train)\n",
    "y_test_actual = scaler.inverse_transform(y_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_actual, train_predictions))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_actual, test_predictions))\n",
    "train_mae = mean_absolute_error(y_train_actual, train_predictions)\n",
    "test_mae = mean_absolute_error(y_test_actual, test_predictions)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"{'Metric':<15} {'Train':<15} {'Test':<15}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'RMSE':<15} ${train_rmse:<14.2f} ${test_rmse:<14.2f}\")\n",
    "print(f\"{'MAE':<15} ${train_mae:<14.2f} ${test_mae:<14.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cb135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Full timeline\n",
    "ax1 = axes[0]\n",
    "dates = data.index[SEQ_LENGTH:]\n",
    "train_dates = dates[:train_size]\n",
    "test_dates = dates[train_size:]\n",
    "\n",
    "ax1.plot(train_dates, y_train_actual, 'b-', label='Train Actual', alpha=0.7)\n",
    "ax1.plot(train_dates, train_predictions, 'g-', label='Train Predicted', alpha=0.7)\n",
    "ax1.plot(test_dates, y_test_actual, 'b-', alpha=0.7)\n",
    "ax1.plot(test_dates, test_predictions, 'r-', label='Test Predicted', alpha=0.7)\n",
    "ax1.axvline(x=test_dates[0], color='black', linestyle='--', label='Train/Test Split')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Price ($)')\n",
    "ax1.set_title(f'{ticker} Price Prediction - Deep LSTM Model')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Test set zoom\n",
    "ax2 = axes[1]\n",
    "ax2.plot(test_dates, y_test_actual, 'b-', label='Actual', linewidth=2)\n",
    "ax2.plot(test_dates, test_predictions, 'r--', label='Predicted', linewidth=2)\n",
    "ax2.fill_between(test_dates.to_numpy(), \n",
    "                  y_test_actual.flatten(), \n",
    "                  test_predictions.flatten(),\n",
    "                  alpha=0.3, color='gray', label='Prediction Error')\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('Price ($)')\n",
    "ax2.set_title('Test Set Predictions (Zoomed)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f3af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different architectures\n",
    "def evaluate_architecture(model_class, model_params, name):\n",
    "    \"\"\"Train and evaluate a model architecture.\"\"\"\n",
    "    model = model_class(**model_params).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Quick training (reduced epochs for comparison)\n",
    "    for epoch in range(30):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_pred = model(X_test_tensor).cpu().numpy()\n",
    "    \n",
    "    test_pred = scaler.inverse_transform(test_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_actual, test_pred))\n",
    "    \n",
    "    params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    return {'name': name, 'rmse': rmse, 'params': params}\n",
    "\n",
    "# Define architectures to compare\n",
    "architectures = [\n",
    "    (StackedLSTM, {'input_size': 1, 'hidden_size': 64, 'num_layers': 1}, 'Simple LSTM (1 layer)'),\n",
    "    (StackedLSTM, {'input_size': 1, 'hidden_size': 64, 'num_layers': 2, 'dropout': 0.2}, 'Stacked LSTM (2 layers)'),\n",
    "    (StackedLSTM, {'input_size': 1, 'hidden_size': 64, 'num_layers': 3, 'dropout': 0.2}, 'Stacked LSTM (3 layers)'),\n",
    "    (BidirectionalLSTM, {'input_size': 1, 'hidden_size': 64, 'num_layers': 1}, 'Bidirectional LSTM'),\n",
    "    (DeepLSTMTradingModel, {'input_size': 1, 'hidden_size': 64, 'num_layers': 3, 'dropout': 0.2}, 'Deep Trading Model'),\n",
    "]\n",
    "\n",
    "print(\"Comparing architectures (30 epochs each)...\\n\")\n",
    "results = []\n",
    "\n",
    "for model_class, params, name in architectures:\n",
    "    result = evaluate_architecture(model_class, params, name)\n",
    "    results.append(result)\n",
    "    print(f\"{name}: RMSE=${result['rmse']:.2f}, Params={result['params']:,}\")\n",
    "\n",
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('rmse')\n",
    "print(\"\\nRanking by RMSE:\")\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b574f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize architecture comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "ax1 = axes[0]\n",
    "colors = plt.cm.viridis(np.linspace(0, 0.8, len(results_df)))\n",
    "bars = ax1.barh(results_df['name'], results_df['rmse'], color=colors)\n",
    "ax1.set_xlabel('RMSE ($)')\n",
    "ax1.set_title('Model Comparison: Test RMSE')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Add value labels\n",
    "for bar, rmse in zip(bars, results_df['rmse']):\n",
    "    ax1.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2,\n",
    "             f'${rmse:.2f}', va='center', fontsize=10)\n",
    "\n",
    "# Parameters vs RMSE\n",
    "ax2 = axes[1]\n",
    "ax2.scatter(results_df['params'], results_df['rmse'], s=200, c=colors, edgecolors='black')\n",
    "for _, row in results_df.iterrows():\n",
    "    ax2.annotate(row['name'].split('(')[0].strip(), \n",
    "                 (row['params'], row['rmse']),\n",
    "                 textcoords=\"offset points\", xytext=(5,5), fontsize=9)\n",
    "ax2.set_xlabel('Number of Parameters')\n",
    "ax2.set_ylabel('RMSE ($)')\n",
    "ax2.set_title('Parameters vs Performance')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b209e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Key Takeaways <a id='6-takeaways'></a>\n",
    "\n",
    "### Bidirectional RNNs\n",
    "\n",
    "| Aspect | Details |\n",
    "|--------|--------|\n",
    "| **When to Use** | Post-hoc analysis, pattern recognition, regime identification |\n",
    "| **When NOT to Use** | Real-time prediction (future unavailable) |\n",
    "| **Output Size** | Doubles hidden size (forward + backward concatenated) |\n",
    "| **Trade-off** | Better context understanding vs. 2x parameters |\n",
    "\n",
    "### Stacked LSTMs\n",
    "\n",
    "| Aspect | Details |\n",
    "|--------|--------|\n",
    "| **Purpose** | Hierarchical feature learning |\n",
    "| **Depth Guidelines** | Match to data size (1-4 layers typically) |\n",
    "| **Architecture** | Can use decreasing sizes (pyramid) |\n",
    "| **Regularization** | Essential as depth increases |\n",
    "\n",
    "### Dropout for Sequences\n",
    "\n",
    "| Type | Application | Best For |\n",
    "|------|-------------|----------|\n",
    "| Standard | Between layers | General regularization |\n",
    "| Variational | Same mask across time | Temporal consistency |\n",
    "| Recurrent | Hidden-to-hidden | Preventing co-adaptation |\n",
    "\n",
    "### Practical Recommendations\n",
    "\n",
    "1. **Start Simple**: Begin with 1-2 layer LSTM, add complexity if needed\n",
    "2. **Use Dropout**: 0.2-0.3 between LSTM layers\n",
    "3. **Bidirectional**: Only when full sequence is available at inference\n",
    "4. **Monitor Overfitting**: Deep models need more regularization\n",
    "5. **Gradient Clipping**: Essential for deep networks (max_norm=1.0)\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "- **Day 6**: Sequence-to-Sequence Models\n",
    "- **Day 7**: Advanced Training Techniques"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
