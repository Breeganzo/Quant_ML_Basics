{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98742d71",
   "metadata": {},
   "source": [
    "# Day 7: Interview Review & Practice Problems\n",
    "\n",
    "## Week 12 - Backtesting & Validation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Review all Week 12 concepts\n",
    "- Practice interview-style questions\n",
    "- Solve timed coding challenges\n",
    "- Build confidence for quant interviews\n",
    "\n",
    "### ‚è±Ô∏è Time Allocation\n",
    "- Concept review: 30 min\n",
    "- Coding challenges: 90 min\n",
    "- Interview Q&A: 60 min\n",
    "- Mock interview: 30 min\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: ML Quant Finance Mastery  \n",
    "**Difficulty**: Interview Level  \n",
    "**Prerequisites**: Week 12 Day 1-6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf651c",
   "metadata": {},
   "source": [
    "## 1. Week 12 Concept Summary\n",
    "\n",
    "| Day | Topic | Key Concepts |\n",
    "|-----|-------|--------------|\n",
    "| 1 | Performance Metrics | Sharpe, Sortino, Max Drawdown, Calmar |\n",
    "| 2 | Transaction Costs | Commission, spread, slippage, market impact |\n",
    "| 3 | Walk-Forward | Time series CV, expanding vs rolling, embargo |\n",
    "| 4 | Best Practices | Point-in-time, survivorship bias, sanity checks |\n",
    "| 5 | Common Pitfalls | Lookahead, overfitting, multiple testing |\n",
    "| 6 | Full Pipeline | End-to-end backtest framework |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c845f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data for exercises\n",
    "n = 1000\n",
    "returns_data = np.random.randn(n) * 0.01 + 0.0002\n",
    "prices_data = 100 * np.cumprod(1 + returns_data)\n",
    "\n",
    "print(\"üìä Practice data loaded\")\n",
    "print(f\"   {n} days of returns\")\n",
    "print(f\"   Mean daily return: {np.mean(returns_data):.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a2b50a",
   "metadata": {},
   "source": [
    "## 2. Interview Questions - Theory\n",
    "\n",
    "### Q1: Explain the Sharpe Ratio and its limitations.\n",
    "\n",
    "**Answer Framework:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d834dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sharpe Ratio demonstration and limitations\n",
    "\n",
    "def sharpe_ratio(returns, rf=0):\n",
    "    \"\"\"Calculate annualized Sharpe Ratio\"\"\"\n",
    "    excess = returns - rf\n",
    "    return np.mean(excess) / np.std(returns) * np.sqrt(252)\n",
    "\n",
    "# Standard calculation\n",
    "sharpe = sharpe_ratio(returns_data)\n",
    "print(f\"Sharpe Ratio: {sharpe:.2f}\")\n",
    "\n",
    "# Limitations:\n",
    "print(\"\\nüìä SHARPE RATIO LIMITATIONS:\")\n",
    "print(\"1. Assumes normal distribution (returns have fat tails)\")\n",
    "print(\"2. Penalizes upside and downside volatility equally\")\n",
    "print(\"3. Sensitive to measurement period\")\n",
    "print(\"4. Can be manipulated (sell OTM puts)\")\n",
    "\n",
    "# Demonstrate sensitivity\n",
    "periods = [63, 126, 252, 500]\n",
    "print(\"\\nPeriod Sensitivity:\")\n",
    "for p in periods:\n",
    "    s = sharpe_ratio(returns_data[-p:])\n",
    "    print(f\"   Last {p} days: Sharpe = {s:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85166929",
   "metadata": {},
   "source": [
    "### Q2: Why does K-Fold CV fail for time series?\n",
    "\n",
    "**Answer Framework:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdc3382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate lookahead bias in K-Fold\n",
    "\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit\n",
    "\n",
    "# Create features and target\n",
    "X = np.column_stack([\n",
    "    np.roll(returns_data, 1),  # lag 1\n",
    "    np.roll(returns_data, 5),  # lag 5\n",
    "])[10:]\n",
    "y = returns_data[10:]\n",
    "\n",
    "# K-Fold (WRONG)\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "kfold_scores = []\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    score = model.score(X[test_idx], y[test_idx])\n",
    "    kfold_scores.append(score)\n",
    "\n",
    "# Time Series (CORRECT)\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "ts_scores = []\n",
    "for train_idx, test_idx in tscv.split(X):\n",
    "    model = Ridge(alpha=1.0)\n",
    "    model.fit(X[train_idx], y[train_idx])\n",
    "    score = model.score(X[test_idx], y[test_idx])\n",
    "    ts_scores.append(score)\n",
    "\n",
    "print(\"üìä CV COMPARISON:\")\n",
    "print(f\"K-Fold (WRONG): R¬≤ = {np.mean(kfold_scores):.4f}\")\n",
    "print(f\"TimeSeriesSplit (CORRECT): R¬≤ = {np.mean(ts_scores):.4f}\")\n",
    "print(\"\\n‚ö†Ô∏è K-Fold uses future data to predict past = LOOKAHEAD BIAS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e74ff4",
   "metadata": {},
   "source": [
    "### Q3: How do you account for transaction costs in backtests?\n",
    "\n",
    "**Answer Framework:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40057f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_with_costs(signals, returns, cost_bps=10):\n",
    "    \"\"\"\n",
    "    Backtest with transaction costs\n",
    "    \n",
    "    Cost model: cost_bps per round-trip trade\n",
    "    \"\"\"\n",
    "    cost = cost_bps / 10000\n",
    "    \n",
    "    # Position changes = turnover\n",
    "    turnover = np.abs(np.diff(signals, prepend=0))\n",
    "    \n",
    "    # Gross returns\n",
    "    gross_returns = signals * returns\n",
    "    \n",
    "    # Net returns\n",
    "    transaction_costs = turnover * cost\n",
    "    net_returns = gross_returns - transaction_costs\n",
    "    \n",
    "    return {\n",
    "        'gross': gross_returns,\n",
    "        'net': net_returns,\n",
    "        'costs': transaction_costs.sum(),\n",
    "        'turnover': turnover.sum()\n",
    "    }\n",
    "\n",
    "# Create momentum signal\n",
    "momentum = pd.Series(returns_data).rolling(20).mean().values\n",
    "signal = np.sign(momentum)\n",
    "signal = np.nan_to_num(signal)\n",
    "\n",
    "# Compare with different costs\n",
    "print(\"üìä TRANSACTION COST IMPACT:\")\n",
    "for cost in [0, 5, 10, 20, 50]:\n",
    "    result = backtest_with_costs(signal, returns_data, cost)\n",
    "    sharpe_net = np.mean(result['net']) / np.std(result['net']) * np.sqrt(252)\n",
    "    print(f\"   {cost:2d} bps: Net Sharpe = {sharpe_net:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3480fcd",
   "metadata": {},
   "source": [
    "## 3. Coding Challenges\n",
    "\n",
    "### Challenge 1: Implement Maximum Drawdown (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01648db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHALLENGE: Implement maximum drawdown calculation\n",
    "\n",
    "def calculate_max_drawdown(returns):\n",
    "    \"\"\"\n",
    "    Calculate maximum drawdown from returns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : array-like\n",
    "        Asset returns\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float : Maximum drawdown (negative percentage)\n",
    "    \n",
    "    YOUR CODE HERE:\n",
    "    \"\"\"\n",
    "    # Step 1: Calculate cumulative returns (growth of $1)\n",
    "    # cumulative = ...\n",
    "    \n",
    "    # Step 2: Track running peak\n",
    "    # peak = ...\n",
    "    \n",
    "    # Step 3: Calculate drawdown at each point\n",
    "    # drawdown = ...\n",
    "    \n",
    "    # Step 4: Return minimum (maximum drawdown)\n",
    "    # return ...\n",
    "    pass\n",
    "\n",
    "# TEST YOUR IMPLEMENTATION:\n",
    "# Expected: max_dd should be negative\n",
    "# max_dd = calculate_max_drawdown(returns_data)\n",
    "# print(f\"Max Drawdown: {max_dd:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "def calculate_max_drawdown_solution(returns):\n",
    "    cumulative = np.cumprod(1 + returns)\n",
    "    peak = np.maximum.accumulate(cumulative)\n",
    "    drawdown = (cumulative - peak) / peak\n",
    "    return np.min(drawdown)\n",
    "\n",
    "max_dd = calculate_max_drawdown_solution(returns_data)\n",
    "print(f\"Max Drawdown: {max_dd:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6df9cb",
   "metadata": {},
   "source": [
    "### Challenge 2: Walk-Forward Cross-Validation (15 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5107b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHALLENGE: Implement walk-forward CV\n",
    "\n",
    "def walk_forward_cv(X, y, model, train_size, test_size, gap=0):\n",
    "    \"\"\"\n",
    "    Walk-forward cross-validation\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X : array (n_samples, n_features)\n",
    "    y : array (n_samples,)\n",
    "    model : sklearn model\n",
    "    train_size : int\n",
    "    test_size : int\n",
    "    gap : int (embargo period)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict with predictions, actuals, and metrics\n",
    "    \n",
    "    YOUR CODE HERE:\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    # Start from after first training window\n",
    "    # ...\n",
    "    \n",
    "    # Loop until we run out of data\n",
    "    # while ...:\n",
    "    #     ...\n",
    "    \n",
    "    return {\n",
    "        'predictions': np.array(predictions),\n",
    "        'actuals': np.array(actuals)\n",
    "    }\n",
    "\n",
    "# TEST:\n",
    "# X_test = np.column_stack([np.roll(returns_data, i) for i in [1,5,10]])[20:]\n",
    "# y_test = returns_data[20:]\n",
    "# results = walk_forward_cv(X_test, y_test, Ridge(alpha=1.0), 252, 21, gap=1)\n",
    "# print(f\"Predictions: {len(results['predictions'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07afeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "def walk_forward_cv_solution(X, y, model, train_size, test_size, gap=0):\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    n = len(X)\n",
    "    start = train_size\n",
    "    \n",
    "    while start + gap + test_size <= n:\n",
    "        # Split\n",
    "        train_end = start\n",
    "        test_start = start + gap\n",
    "        test_end = test_start + test_size\n",
    "        \n",
    "        X_train, y_train = X[:train_end], y[:train_end]\n",
    "        X_test, y_test = X[test_start:test_end], y[test_start:test_end]\n",
    "        \n",
    "        # Train and predict\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        \n",
    "        predictions.extend(preds)\n",
    "        actuals.extend(y_test)\n",
    "        \n",
    "        start += test_size\n",
    "    \n",
    "    return {\n",
    "        'predictions': np.array(predictions),\n",
    "        'actuals': np.array(actuals)\n",
    "    }\n",
    "\n",
    "# Test\n",
    "X_test = np.column_stack([np.roll(returns_data, i) for i in [1,5,10]])[20:]\n",
    "y_test = returns_data[20:]\n",
    "results = walk_forward_cv_solution(X_test, y_test, Ridge(alpha=1.0), 252, 21, gap=1)\n",
    "print(f\"‚úÖ Walk-forward predictions: {len(results['predictions'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30f5c8",
   "metadata": {},
   "source": [
    "### Challenge 3: Break-Even Cost Analysis (10 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e7aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHALLENGE: Find break-even transaction cost\n",
    "\n",
    "def find_breakeven_cost(signals, returns, target_sharpe=0.0):\n",
    "    \"\"\"\n",
    "    Find the cost level where strategy Sharpe equals target\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals : array\n",
    "    returns : array\n",
    "    target_sharpe : float\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    int : Break-even cost in basis points\n",
    "    \n",
    "    YOUR CODE HERE:\n",
    "    \"\"\"\n",
    "    # Binary search or linear scan for break-even point\n",
    "    # ...\n",
    "    pass\n",
    "\n",
    "# TEST:\n",
    "# breakeven = find_breakeven_cost(signal, returns_data, target_sharpe=0.5)\n",
    "# print(f\"Break-even at {breakeven} bps for Sharpe = 0.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7780042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION:\n",
    "def find_breakeven_cost_solution(signals, returns, target_sharpe=0.0):\n",
    "    for cost in range(0, 200):\n",
    "        result = backtest_with_costs(signals, returns, cost)\n",
    "        sharpe = np.mean(result['net']) / np.std(result['net']) * np.sqrt(252)\n",
    "        if sharpe < target_sharpe:\n",
    "            return cost - 1\n",
    "    return 200\n",
    "\n",
    "breakeven_0 = find_breakeven_cost_solution(signal, returns_data, target_sharpe=0.0)\n",
    "breakeven_05 = find_breakeven_cost_solution(signal, returns_data, target_sharpe=0.5)\n",
    "print(f\"‚úÖ Break-even (Sharpe=0): {breakeven_0} bps\")\n",
    "print(f\"‚úÖ Break-even (Sharpe=0.5): {breakeven_05} bps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73659da5",
   "metadata": {},
   "source": [
    "## 4. Behavioral Interview Questions\n",
    "\n",
    "### Q1: \"Walk me through how you would backtest a trading strategy.\"\n",
    "\n",
    "**Sample Answer:**\n",
    "1. **Data preparation**: Load point-in-time data, handle survivorship bias\n",
    "2. **Feature engineering**: Create predictive features (momentum, volatility, etc.)\n",
    "3. **Model training**: Use walk-forward validation with embargo\n",
    "4. **Signal generation**: Convert predictions to trading signals\n",
    "5. **Execution simulation**: Include transaction costs (commission + spread + slippage)\n",
    "6. **Performance analysis**: Calculate Sharpe, max drawdown, sanity checks\n",
    "7. **Validation**: Check for overfitting, run sensitivity analysis\n",
    "\n",
    "### Q2: \"Tell me about a time you discovered a bug in a backtest.\"\n",
    "\n",
    "**Framework:**\n",
    "- Situation: Describe the backtest and the suspiciously good results\n",
    "- Task: What made you suspicious (Sharpe too high, etc.)\n",
    "- Action: How you debugged (checked for lookahead, costs, etc.)\n",
    "- Result: What you found and fixed\n",
    "\n",
    "### Q3: \"How would you explain overfitting to a non-technical stakeholder?\"\n",
    "\n",
    "**Sample Answer:**\n",
    "\"Imagine memorizing answers to a practice test instead of learning the material. You'd ace that specific test but fail a new one. Overfitting is similar - the model memorizes historical patterns but can't generalize to new data.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45de7fd2",
   "metadata": {},
   "source": [
    "## 5. Quick Formula Reference\n",
    "\n",
    "| Metric | Formula |\n",
    "|--------|---------|\n",
    "| Sharpe | $(R - R_f) / \\sigma √ó \\sqrt{252}$ |\n",
    "| Sortino | $(R - R_f) / \\sigma_{down} √ó \\sqrt{252}$ |\n",
    "| Max DD | $\\max_t (Peak_t - Value_t) / Peak_t$ |\n",
    "| Calmar | $R_{annual} / |MDD|$ |\n",
    "| IR | $(R - R_{bench}) / \\sigma_{active} √ó \\sqrt{252}$ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df40ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reference implementations\n",
    "def quick_metrics(returns):\n",
    "    \"\"\"Calculate all key metrics at once\"\"\"\n",
    "    ret = pd.Series(returns)\n",
    "    \n",
    "    metrics = {\n",
    "        'Sharpe': ret.mean() / ret.std() * np.sqrt(252),\n",
    "        'Sortino': ret.mean() / ret[ret < 0].std() * np.sqrt(252),\n",
    "        'Annual Return': ret.mean() * 252,\n",
    "        'Annual Vol': ret.std() * np.sqrt(252),\n",
    "    }\n",
    "    \n",
    "    # Max DD\n",
    "    cum = (1 + ret).cumprod()\n",
    "    peak = cum.expanding().max()\n",
    "    dd = (cum - peak) / peak\n",
    "    metrics['Max DD'] = dd.min()\n",
    "    \n",
    "    # Calmar\n",
    "    metrics['Calmar'] = metrics['Annual Return'] / abs(metrics['Max DD'])\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Print reference\n",
    "metrics = quick_metrics(returns_data)\n",
    "print(\"üìä QUICK METRICS REFERENCE:\")\n",
    "for k, v in metrics.items():\n",
    "    if 'Ratio' in k or k in ['Sharpe', 'Sortino', 'Calmar']:\n",
    "        print(f\"   {k}: {v:.2f}\")\n",
    "    else:\n",
    "        print(f\"   {k}: {v:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31ea25",
   "metadata": {},
   "source": [
    "## 6. Week 12 Checklist\n",
    "\n",
    "Before moving to Week 13, ensure you can:\n",
    "\n",
    "- [ ] Calculate Sharpe, Sortino, Max Drawdown from scratch\n",
    "- [ ] Explain why K-Fold CV fails for time series\n",
    "- [ ] Implement walk-forward validation\n",
    "- [ ] Model transaction costs in backtests\n",
    "- [ ] Identify lookahead bias and survivorship bias\n",
    "- [ ] Explain overfitting in financial ML\n",
    "- [ ] Apply multiple testing corrections\n",
    "- [ ] Build a production-ready backtest pipeline\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Key Takeaways\n",
    "\n",
    "1. **Metrics**: Know Sharpe, Sortino, Max DD and their limitations\n",
    "2. **Costs**: Include realistic transaction costs (5-20 bps typical)\n",
    "3. **Validation**: Always use walk-forward, never K-Fold\n",
    "4. **Bias**: Watch for lookahead, survivorship, overfitting\n",
    "5. **Production**: Point-in-time data, sanity checks, monitoring\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations! You've completed Week 12!**\n",
    "\n",
    "*Next: Week 13 - Neural Networks & Deep Learning*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
