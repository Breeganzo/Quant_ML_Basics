{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa9b3d66",
   "metadata": {},
   "source": [
    "# Day 6: Full Backtest Pipeline\n",
    "\n",
    "## Week 12 - Backtesting & Validation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Build a complete end-to-end backtesting pipeline\n",
    "- Integrate all best practices from the week\n",
    "- Create reusable backtesting framework\n",
    "- Generate comprehensive performance reports\n",
    "\n",
    "### ‚è±Ô∏è Time Allocation\n",
    "- Theory review: 15 min\n",
    "- Implementation: 120 min\n",
    "- Testing: 45 min\n",
    "- Documentation: 30 min\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: ML Quant Finance Mastery  \n",
    "**Difficulty**: Advanced  \n",
    "**Prerequisites**: Day 1-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9867cd",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45298c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Callable, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "@dataclass\n",
    "class BacktestConfig:\n",
    "    \"\"\"Configuration for backtesting\"\"\"\n",
    "    initial_capital: float = 1_000_000\n",
    "    commission_bps: float = 5\n",
    "    slippage_bps: float = 3\n",
    "    max_position_pct: float = 0.1\n",
    "    train_window: int = 252\n",
    "    test_window: int = 21\n",
    "    embargo_days: int = 1\n",
    "    \n",
    "config = BacktestConfig()\n",
    "print(\"üìä BACKTEST CONFIGURATION\")\n",
    "print(f\"   Initial Capital: ${config.initial_capital:,.0f}\")\n",
    "print(f\"   Commission: {config.commission_bps} bps\")\n",
    "print(f\"   Slippage: {config.slippage_bps} bps\")\n",
    "print(f\"   Train Window: {config.train_window} days\")\n",
    "print(f\"   Test Window: {config.test_window} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71602a8d",
   "metadata": {},
   "source": [
    "## 2. Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ade5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule:\n",
    "    \"\"\"\n",
    "    Handles data loading, cleaning, and feature engineering\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tickers: List[str], start_date: str, end_date: str = None):\n",
    "        self.tickers = tickers\n",
    "        self.start_date = start_date\n",
    "        self.end_date = end_date or datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Load price data from yfinance\"\"\"\n",
    "        print(f\"üì• Loading data for {self.tickers}...\")\n",
    "        data = yf.download(\n",
    "            self.tickers, \n",
    "            start=self.start_date, \n",
    "            end=self.end_date, \n",
    "            progress=False,\n",
    "            auto_adjust=True\n",
    "        )\n",
    "        \n",
    "        self.prices = data['Close'].dropna()\n",
    "        self.returns = self.prices.pct_change().dropna()\n",
    "        \n",
    "        print(f\"   ‚úÖ Loaded {len(self.prices)} days of data\")\n",
    "        return self.prices\n",
    "    \n",
    "    def engineer_features(self, lookbacks: List[int] = [5, 10, 20, 60]) -> pd.DataFrame:\n",
    "        \"\"\"Create standard features for each asset\"\"\"\n",
    "        features_list = []\n",
    "        \n",
    "        for ticker in self.tickers:\n",
    "            ret = self.returns[ticker]\n",
    "            \n",
    "            features = pd.DataFrame(index=ret.index)\n",
    "            \n",
    "            # Momentum features\n",
    "            for lb in lookbacks:\n",
    "                features[f'{ticker}_mom_{lb}'] = ret.rolling(lb).mean()\n",
    "                features[f'{ticker}_vol_{lb}'] = ret.rolling(lb).std()\n",
    "            \n",
    "            # RSI-like feature\n",
    "            up = ret.clip(lower=0).rolling(14).mean()\n",
    "            down = (-ret.clip(upper=0)).rolling(14).mean()\n",
    "            features[f'{ticker}_rsi'] = up / (up + down + 1e-10)\n",
    "            \n",
    "            # Mean reversion\n",
    "            features[f'{ticker}_zscore'] = (ret - ret.rolling(20).mean()) / (ret.rolling(20).std() + 1e-10)\n",
    "            \n",
    "            features_list.append(features)\n",
    "        \n",
    "        self.features = pd.concat(features_list, axis=1).dropna()\n",
    "        print(f\"   ‚úÖ Created {len(self.features.columns)} features\")\n",
    "        \n",
    "        return self.features\n",
    "    \n",
    "    def create_targets(self, horizon: int = 1) -> pd.Series:\n",
    "        \"\"\"Create target variable (forward returns)\"\"\"\n",
    "        # Use simple average of all assets as target\n",
    "        self.target = self.returns.mean(axis=1).shift(-horizon)\n",
    "        self.target = self.target.loc[self.features.index].dropna()\n",
    "        \n",
    "        # Align features\n",
    "        self.features = self.features.loc[self.target.index]\n",
    "        \n",
    "        return self.target\n",
    "\n",
    "# Initialize data module\n",
    "data_module = DataModule(\n",
    "    tickers=['SPY', 'QQQ', 'IWM'],\n",
    "    start_date='2018-01-01'\n",
    ")\n",
    "data_module.load_data()\n",
    "data_module.engineer_features()\n",
    "data_module.create_targets(horizon=1)\n",
    "\n",
    "print(f\"\\nüìä DATA SUMMARY:\")\n",
    "print(f\"   Features: {data_module.features.shape}\")\n",
    "print(f\"   Target: {len(data_module.target)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc33b7a",
   "metadata": {},
   "source": [
    "## 3. Model Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f1b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelModule:\n",
    "    \"\"\"\n",
    "    Handles model training and prediction with walk-forward validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_class, model_params: Dict = None):\n",
    "        self.model_class = model_class\n",
    "        self.model_params = model_params or {}\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def walk_forward_predict(self, X: np.ndarray, y: np.ndarray, \n",
    "                             train_size: int, test_size: int, \n",
    "                             embargo: int = 0) -> Dict:\n",
    "        \"\"\"\n",
    "        Walk-forward cross-validation with predictions\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        dates = []\n",
    "        fold_metrics = []\n",
    "        \n",
    "        n = len(X)\n",
    "        start = train_size\n",
    "        fold = 0\n",
    "        \n",
    "        while start + embargo + test_size <= n:\n",
    "            fold += 1\n",
    "            \n",
    "            # Split indices\n",
    "            train_end = start\n",
    "            test_start = start + embargo\n",
    "            test_end = test_start + test_size\n",
    "            \n",
    "            # Get data\n",
    "            X_train = X[:train_end]\n",
    "            y_train = y[:train_end]\n",
    "            X_test = X[test_start:test_end]\n",
    "            y_test = y[test_start:test_end]\n",
    "            \n",
    "            # Scale\n",
    "            X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "            X_test_scaled = self.scaler.transform(X_test)\n",
    "            \n",
    "            # Train and predict\n",
    "            model = self.model_class(**self.model_params)\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            preds = model.predict(X_test_scaled)\n",
    "            \n",
    "            # Store\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(y_test)\n",
    "            dates.extend(range(test_start, test_end))\n",
    "            \n",
    "            # Metrics\n",
    "            corr = np.corrcoef(preds, y_test)[0, 1] if len(preds) > 1 else 0\n",
    "            fold_metrics.append({\n",
    "                'fold': fold,\n",
    "                'train_size': len(X_train),\n",
    "                'correlation': corr\n",
    "            })\n",
    "            \n",
    "            start += test_size\n",
    "        \n",
    "        self.results = {\n",
    "            'predictions': np.array(predictions),\n",
    "            'actuals': np.array(actuals),\n",
    "            'dates': np.array(dates),\n",
    "            'fold_metrics': pd.DataFrame(fold_metrics)\n",
    "        }\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "# Initialize model\n",
    "model_module = ModelModule(\n",
    "    model_class=Ridge,\n",
    "    model_params={'alpha': 1.0}\n",
    ")\n",
    "\n",
    "# Run walk-forward\n",
    "X = data_module.features.values\n",
    "y = data_module.target.values\n",
    "\n",
    "results = model_module.walk_forward_predict(\n",
    "    X, y,\n",
    "    train_size=config.train_window,\n",
    "    test_size=config.test_window,\n",
    "    embargo=config.embargo_days\n",
    ")\n",
    "\n",
    "print(f\"üìä MODEL RESULTS:\")\n",
    "print(f\"   Folds: {len(results['fold_metrics'])}\")\n",
    "print(f\"   Mean correlation: {results['fold_metrics']['correlation'].mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bcf31e",
   "metadata": {},
   "source": [
    "## 4. Strategy Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0353bb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrategyModule:\n",
    "    \"\"\"\n",
    "    Converts predictions to trading signals and calculates positions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, predictions: np.ndarray, config: BacktestConfig):\n",
    "        self.predictions = predictions\n",
    "        self.config = config\n",
    "        \n",
    "    def generate_signals(self, method: str = 'sign') -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate trading signals from predictions\n",
    "        \n",
    "        Methods:\n",
    "        - 'sign': Long if positive, short if negative\n",
    "        - 'quantile': Position based on prediction quantile\n",
    "        - 'threshold': Only trade if prediction exceeds threshold\n",
    "        \"\"\"\n",
    "        if method == 'sign':\n",
    "            self.signals = np.sign(self.predictions)\n",
    "        elif method == 'quantile':\n",
    "            # Scale to [-1, 1] based on rolling quantile\n",
    "            from scipy.stats import rankdata\n",
    "            ranks = rankdata(self.predictions) / len(self.predictions)\n",
    "            self.signals = (ranks - 0.5) * 2\n",
    "        elif method == 'threshold':\n",
    "            threshold = np.std(self.predictions)\n",
    "            self.signals = np.where(self.predictions > threshold, 1,\n",
    "                                   np.where(self.predictions < -threshold, -1, 0))\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown method: {method}\")\n",
    "            \n",
    "        return self.signals\n",
    "    \n",
    "    def calculate_positions(self) -> np.ndarray:\n",
    "        \"\"\"Convert signals to position sizes\"\"\"\n",
    "        # Simple: signal * max_position\n",
    "        self.positions = self.signals * self.config.max_position_pct\n",
    "        return self.positions\n",
    "    \n",
    "    def calculate_turnover(self) -> float:\n",
    "        \"\"\"Calculate strategy turnover\"\"\"\n",
    "        position_changes = np.abs(np.diff(self.positions, prepend=0))\n",
    "        self.turnover = position_changes.sum()\n",
    "        self.daily_turnover = position_changes\n",
    "        return self.turnover\n",
    "\n",
    "# Initialize strategy\n",
    "strategy_module = StrategyModule(results['predictions'], config)\n",
    "strategy_module.generate_signals(method='sign')\n",
    "strategy_module.calculate_positions()\n",
    "strategy_module.calculate_turnover()\n",
    "\n",
    "print(f\"üìä STRATEGY SUMMARY:\")\n",
    "print(f\"   Signal range: [{strategy_module.signals.min():.2f}, {strategy_module.signals.max():.2f}]\")\n",
    "print(f\"   Total turnover: {strategy_module.turnover:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67844d2c",
   "metadata": {},
   "source": [
    "## 5. Execution Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb579044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecutionModule:\n",
    "    \"\"\"\n",
    "    Simulates trade execution with costs\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: BacktestConfig):\n",
    "        self.config = config\n",
    "        self.total_cost_bps = config.commission_bps + config.slippage_bps\n",
    "        \n",
    "    def calculate_costs(self, turnover: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Calculate transaction costs\"\"\"\n",
    "        cost_rate = self.total_cost_bps / 10000\n",
    "        self.costs = turnover * cost_rate\n",
    "        return self.costs\n",
    "    \n",
    "    def calculate_returns(self, positions: np.ndarray, \n",
    "                         asset_returns: np.ndarray) -> Dict:\n",
    "        \"\"\"Calculate strategy returns\"\"\"\n",
    "        # Gross returns\n",
    "        gross_returns = positions * asset_returns\n",
    "        \n",
    "        # Costs\n",
    "        turnover = np.abs(np.diff(positions, prepend=0))\n",
    "        costs = self.calculate_costs(turnover)\n",
    "        \n",
    "        # Net returns\n",
    "        net_returns = gross_returns - costs\n",
    "        \n",
    "        self.results = {\n",
    "            'gross_returns': gross_returns,\n",
    "            'net_returns': net_returns,\n",
    "            'costs': costs,\n",
    "            'total_cost': costs.sum()\n",
    "        }\n",
    "        \n",
    "        return self.results\n",
    "\n",
    "# Initialize execution\n",
    "execution_module = ExecutionModule(config)\n",
    "\n",
    "# Get actual returns for the test period\n",
    "test_returns = results['actuals']\n",
    "\n",
    "# Calculate returns\n",
    "execution_results = execution_module.calculate_returns(\n",
    "    strategy_module.positions,\n",
    "    test_returns\n",
    ")\n",
    "\n",
    "print(f\"üìä EXECUTION RESULTS:\")\n",
    "print(f\"   Total cost: {execution_results['total_cost']:.4%}\")\n",
    "print(f\"   Gross return: {execution_results['gross_returns'].sum():.4%}\")\n",
    "print(f\"   Net return: {execution_results['net_returns'].sum():.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585b2d52",
   "metadata": {},
   "source": [
    "## 6. Analytics Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e8887f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyticsModule:\n",
    "    \"\"\"\n",
    "    Calculates and reports performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns: np.ndarray, benchmark_returns: np.ndarray = None):\n",
    "        self.returns = pd.Series(returns)\n",
    "        self.benchmark = pd.Series(benchmark_returns) if benchmark_returns is not None else None\n",
    "        \n",
    "    def calculate_metrics(self) -> Dict:\n",
    "        \"\"\"Calculate comprehensive performance metrics\"\"\"\n",
    "        ret = self.returns\n",
    "        \n",
    "        # Basic stats\n",
    "        total_return = (1 + ret).prod() - 1\n",
    "        n_years = len(ret) / 252\n",
    "        annual_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0\n",
    "        annual_vol = ret.std() * np.sqrt(252)\n",
    "        \n",
    "        # Risk-adjusted\n",
    "        sharpe = ret.mean() / ret.std() * np.sqrt(252) if ret.std() > 0 else 0\n",
    "        \n",
    "        downside = ret[ret < 0].std()\n",
    "        sortino = ret.mean() / downside * np.sqrt(252) if downside > 0 else 0\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative = (1 + ret).cumprod()\n",
    "        peak = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - peak) / peak\n",
    "        max_dd = drawdown.min()\n",
    "        \n",
    "        calmar = annual_return / abs(max_dd) if max_dd != 0 else 0\n",
    "        \n",
    "        # Trading stats\n",
    "        win_rate = (ret > 0).mean()\n",
    "        \n",
    "        # Information ratio (if benchmark provided)\n",
    "        if self.benchmark is not None:\n",
    "            active_ret = ret - self.benchmark\n",
    "            ir = active_ret.mean() / active_ret.std() * np.sqrt(252)\n",
    "        else:\n",
    "            ir = None\n",
    "        \n",
    "        self.metrics = {\n",
    "            'Total Return': total_return,\n",
    "            'Annual Return': annual_return,\n",
    "            'Annual Volatility': annual_vol,\n",
    "            'Sharpe Ratio': sharpe,\n",
    "            'Sortino Ratio': sortino,\n",
    "            'Max Drawdown': max_dd,\n",
    "            'Calmar Ratio': calmar,\n",
    "            'Win Rate': win_rate,\n",
    "            'Information Ratio': ir\n",
    "        }\n",
    "        \n",
    "        return self.metrics\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"Generate text report\"\"\"\n",
    "        if not hasattr(self, 'metrics'):\n",
    "            self.calculate_metrics()\n",
    "            \n",
    "        report = []\n",
    "        report.append(\"=\" * 60)\n",
    "        report.append(\"           PERFORMANCE REPORT\")\n",
    "        report.append(\"=\" * 60)\n",
    "        \n",
    "        for metric, value in self.metrics.items():\n",
    "            if value is not None:\n",
    "                if 'Ratio' in metric:\n",
    "                    report.append(f\"{metric:<25}: {value:>10.2f}\")\n",
    "                else:\n",
    "                    report.append(f\"{metric:<25}: {value:>10.2%}\")\n",
    "        \n",
    "        report.append(\"=\" * 60)\n",
    "        return \"\\n\".join(report)\n",
    "    \n",
    "    def plot_performance(self):\n",
    "        \"\"\"Generate performance visualization\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        \n",
    "        # Cumulative returns\n",
    "        cumulative = (1 + self.returns).cumprod()\n",
    "        axes[0, 0].plot(cumulative.values, label='Strategy', linewidth=2)\n",
    "        if self.benchmark is not None:\n",
    "            cum_bench = (1 + self.benchmark).cumprod()\n",
    "            axes[0, 0].plot(cum_bench.values, label='Benchmark', alpha=0.7)\n",
    "        axes[0, 0].set_title('Cumulative Returns')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Drawdown\n",
    "        peak = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - peak) / peak\n",
    "        axes[0, 1].fill_between(range(len(drawdown)), drawdown.values, 0, \n",
    "                                 color='red', alpha=0.3)\n",
    "        axes[0, 1].set_title(f'Drawdown (Max: {drawdown.min():.1%})')\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Rolling Sharpe\n",
    "        rolling_sharpe = self.returns.rolling(63).apply(\n",
    "            lambda x: x.mean() / x.std() * np.sqrt(252) if x.std() > 0 else 0\n",
    "        )\n",
    "        axes[1, 0].plot(rolling_sharpe.values)\n",
    "        axes[1, 0].axhline(y=0, color='r', linestyle='--')\n",
    "        axes[1, 0].axhline(y=1, color='g', linestyle='--', alpha=0.5)\n",
    "        axes[1, 0].set_title('Rolling Sharpe (63 days)')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Return distribution\n",
    "        axes[1, 1].hist(self.returns.values, bins=50, edgecolor='black', alpha=0.7)\n",
    "        axes[1, 1].axvline(x=0, color='r', linestyle='--')\n",
    "        axes[1, 1].set_title('Return Distribution')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Initialize analytics\n",
    "analytics_module = AnalyticsModule(\n",
    "    execution_results['net_returns'],\n",
    "    test_returns\n",
    ")\n",
    "\n",
    "# Generate report\n",
    "print(analytics_module.generate_report())\n",
    "analytics_module.plot_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4b2970",
   "metadata": {},
   "source": [
    "## 7. Complete Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestPipeline:\n",
    "    \"\"\"\n",
    "    Complete end-to-end backtesting pipeline\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: BacktestConfig):\n",
    "        self.config = config\n",
    "        \n",
    "    def run(self, tickers: List[str], start_date: str,\n",
    "            model_class, model_params: Dict = None,\n",
    "            signal_method: str = 'sign') -> Dict:\n",
    "        \"\"\"\n",
    "        Run complete backtest pipeline\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"              BACKTEST PIPELINE\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # 1. Load and prepare data\n",
    "        print(\"\\nüìä STEP 1: DATA LOADING\")\n",
    "        data = DataModule(tickers, start_date)\n",
    "        data.load_data()\n",
    "        data.engineer_features()\n",
    "        data.create_targets(horizon=1)\n",
    "        \n",
    "        # 2. Train model with walk-forward\n",
    "        print(\"\\nü§ñ STEP 2: MODEL TRAINING\")\n",
    "        model = ModelModule(model_class, model_params or {})\n",
    "        results = model.walk_forward_predict(\n",
    "            data.features.values,\n",
    "            data.target.values,\n",
    "            self.config.train_window,\n",
    "            self.config.test_window,\n",
    "            self.config.embargo_days\n",
    "        )\n",
    "        \n",
    "        # 3. Generate signals\n",
    "        print(\"\\nüìà STEP 3: SIGNAL GENERATION\")\n",
    "        strategy = StrategyModule(results['predictions'], self.config)\n",
    "        strategy.generate_signals(method=signal_method)\n",
    "        strategy.calculate_positions()\n",
    "        strategy.calculate_turnover()\n",
    "        \n",
    "        # 4. Simulate execution\n",
    "        print(\"\\nüí∞ STEP 4: EXECUTION SIMULATION\")\n",
    "        execution = ExecutionModule(self.config)\n",
    "        exec_results = execution.calculate_returns(\n",
    "            strategy.positions,\n",
    "            results['actuals']\n",
    "        )\n",
    "        \n",
    "        # 5. Analyze performance\n",
    "        print(\"\\nüìä STEP 5: PERFORMANCE ANALYSIS\")\n",
    "        analytics = AnalyticsModule(\n",
    "            exec_results['net_returns'],\n",
    "            results['actuals']\n",
    "        )\n",
    "        \n",
    "        print(analytics.generate_report())\n",
    "        analytics.plot_performance()\n",
    "        \n",
    "        return {\n",
    "            'data': data,\n",
    "            'model': model,\n",
    "            'strategy': strategy,\n",
    "            'execution': execution,\n",
    "            'analytics': analytics\n",
    "        }\n",
    "\n",
    "# Run complete pipeline\n",
    "pipeline = BacktestPipeline(config)\n",
    "results = pipeline.run(\n",
    "    tickers=['SPY', 'QQQ', 'IWM', 'TLT', 'GLD'],\n",
    "    start_date='2018-01-01',\n",
    "    model_class=Ridge,\n",
    "    model_params={'alpha': 1.0},\n",
    "    signal_method='sign'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607434bb",
   "metadata": {},
   "source": [
    "## 8. ‚è±Ô∏è TIMED CODING CHALLENGE (30 minutes)\n",
    "\n",
    "**Challenge:** Extend the pipeline to support:\n",
    "1. Multiple models comparison\n",
    "2. Parameter optimization\n",
    "3. Monte Carlo simulation for confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4627e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aa09ec",
   "metadata": {},
   "source": [
    "## 9. Key Takeaways\n",
    "\n",
    "| Component | Purpose |\n",
    "|-----------|---------|\n",
    "| DataModule | Load, clean, feature engineering |\n",
    "| ModelModule | Walk-forward training & prediction |\n",
    "| StrategyModule | Signal generation & position sizing |\n",
    "| ExecutionModule | Cost modeling & returns calculation |\n",
    "| AnalyticsModule | Performance metrics & reporting |\n",
    "\n",
    "---\n",
    "\n",
    "**Tomorrow:** Interview Review & Practice"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
