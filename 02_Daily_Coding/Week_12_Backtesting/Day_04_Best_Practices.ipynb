{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e714ed",
   "metadata": {},
   "source": [
    "# Day 4: Backtesting Best Practices\n",
    "\n",
    "## Week 12 - Backtesting & Validation\n",
    "\n",
    "### üéØ Learning Objectives\n",
    "- Implement point-in-time data handling\n",
    "- Avoid survivorship bias\n",
    "- Build sanity checks into backtests\n",
    "- Create production-ready backtesting framework\n",
    "\n",
    "### ‚è±Ô∏è Time Allocation\n",
    "- Theory review: 30 min\n",
    "- Guided exercises: 90 min\n",
    "- Practice problems: 60 min\n",
    "- Interview prep: 30 min\n",
    "\n",
    "---\n",
    "\n",
    "**Author**: ML Quant Finance Mastery  \n",
    "**Difficulty**: Intermediate  \n",
    "**Prerequisites**: Day 1-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3512724",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526faee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Download market data\n",
    "print(\"üì• Downloading market data...\")\n",
    "tickers = ['SPY', 'AAPL', 'MSFT', 'GOOGL', 'JPM']\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "data = yf.download(tickers, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(prices)} days of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe6cbd",
   "metadata": {},
   "source": [
    "## 2. Point-in-Time Data Handling\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Many data sources provide **revised** data, not what was known at the time.\n",
    "\n",
    "**Examples:**\n",
    "- GDP revised months after initial release\n",
    "- Earnings restated for accounting changes\n",
    "- Stock prices adjusted for future splits\n",
    "\n",
    "### The Solution\n",
    "\n",
    "Use data as it existed at decision time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc203291",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PointInTimeData:\n",
    "    \"\"\"\n",
    "    Ensures data integrity for backtesting\n",
    "    \n",
    "    Prevents lookahead bias by tracking when data was available\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, date_col='date', value_col='value', \n",
    "                 available_col='available_date'):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : DataFrame with columns for date, value, and when it became available\n",
    "        \"\"\"\n",
    "        self.df = df.copy()\n",
    "        self.date_col = date_col\n",
    "        self.value_col = value_col\n",
    "        self.available_col = available_col\n",
    "    \n",
    "    def get_as_of(self, as_of_date):\n",
    "        \"\"\"\n",
    "        Get data as it was known on a specific date\n",
    "        \n",
    "        Only returns data that was available by as_of_date\n",
    "        \"\"\"\n",
    "        mask = self.df[self.available_col] <= as_of_date\n",
    "        available_data = self.df[mask].copy()\n",
    "        \n",
    "        # Get most recent value for each underlying date\n",
    "        available_data = available_data.sort_values(self.available_col)\n",
    "        available_data = available_data.drop_duplicates(\n",
    "            subset=[self.date_col], \n",
    "            keep='last'\n",
    "        )\n",
    "        \n",
    "        return available_data.set_index(self.date_col)[self.value_col]\n",
    "\n",
    "# Simulate point-in-time data (GDP example)\n",
    "dates = pd.date_range('2020-01-01', periods=12, freq='Q')\n",
    "pit_data = []\n",
    "\n",
    "for i, date in enumerate(dates):\n",
    "    # Initial release: available 1 month after quarter end\n",
    "    initial_value = 100 + i * 2 + np.random.randn() * 0.5\n",
    "    pit_data.append({\n",
    "        'date': date,\n",
    "        'value': initial_value,\n",
    "        'available_date': date + pd.Timedelta(days=30),\n",
    "        'revision': 'initial'\n",
    "    })\n",
    "    \n",
    "    # First revision: 2 months after\n",
    "    revised_value = initial_value + np.random.randn() * 0.3\n",
    "    pit_data.append({\n",
    "        'date': date,\n",
    "        'value': revised_value,\n",
    "        'available_date': date + pd.Timedelta(days=60),\n",
    "        'revision': 'first'\n",
    "    })\n",
    "    \n",
    "    # Final revision: 3 months after\n",
    "    final_value = revised_value + np.random.randn() * 0.1\n",
    "    pit_data.append({\n",
    "        'date': date,\n",
    "        'value': final_value,\n",
    "        'available_date': date + pd.Timedelta(days=90),\n",
    "        'revision': 'final'\n",
    "    })\n",
    "\n",
    "pit_df = pd.DataFrame(pit_data)\n",
    "pit_handler = PointInTimeData(pit_df)\n",
    "\n",
    "# Demonstrate difference\n",
    "query_date = pd.Timestamp('2020-07-01')\n",
    "print(\"üìä POINT-IN-TIME DATA DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Query date: {query_date}\")\n",
    "print(\"\\nData as known on query date:\")\n",
    "print(pit_handler.get_as_of(query_date))\n",
    "print(\"\\n‚ö†Ô∏è Using final revisions in backtest = LOOKAHEAD BIAS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1afa92d",
   "metadata": {},
   "source": [
    "## 3. Avoiding Survivorship Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_survivorship_bias():\n",
    "    \"\"\"\n",
    "    Demonstrate survivorship bias in stock selection\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    n_stocks = 100\n",
    "    n_days = 252 * 5  # 5 years\n",
    "    \n",
    "    # Generate returns for all stocks\n",
    "    all_returns = np.random.randn(n_stocks, n_days) * 0.02\n",
    "    \n",
    "    # Some stocks will go bankrupt (cumulative return < -90%)\n",
    "    cumulative = np.cumprod(1 + all_returns, axis=1)\n",
    "    \n",
    "    # Mark stocks that survive (never dropped below 10% of initial value)\n",
    "    survivors = np.all(cumulative > 0.1, axis=1)\n",
    "    \n",
    "    # Calculate average return WITH vs WITHOUT survivorship bias\n",
    "    # Biased: only survivors\n",
    "    survivor_returns = all_returns[survivors, :]\n",
    "    avg_survivor = np.mean(survivor_returns) * 252\n",
    "    \n",
    "    # Unbiased: all stocks (but use return=0 after bankruptcy)\n",
    "    all_returns_adjusted = all_returns.copy()\n",
    "    for i in range(n_stocks):\n",
    "        if not survivors[i]:\n",
    "            # Find bankruptcy day\n",
    "            bankrupt_day = np.where(cumulative[i, :] < 0.1)[0]\n",
    "            if len(bankrupt_day) > 0:\n",
    "                all_returns_adjusted[i, bankrupt_day[0]:] = -1  # Total loss\n",
    "    \n",
    "    avg_all = np.mean(all_returns_adjusted) * 252\n",
    "    \n",
    "    return {\n",
    "        'n_total': n_stocks,\n",
    "        'n_survivors': survivors.sum(),\n",
    "        'survival_rate': survivors.mean(),\n",
    "        'avg_return_biased': avg_survivor,\n",
    "        'avg_return_unbiased': avg_all,\n",
    "        'bias': avg_survivor - avg_all\n",
    "    }\n",
    "\n",
    "results = simulate_survivorship_bias()\n",
    "\n",
    "print(\"üìä SURVIVORSHIP BIAS DEMONSTRATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total stocks: {results['n_total']}\")\n",
    "print(f\"Survivors: {results['n_survivors']} ({results['survival_rate']:.0%})\")\n",
    "print(f\"\\nBIASED return (survivors only): {results['avg_return_biased']:.1%}\")\n",
    "print(f\"UNBIASED return (all stocks): {results['avg_return_unbiased']:.1%}\")\n",
    "print(f\"BIAS: {results['bias']:.1%}\")\n",
    "print(\"\\n‚ö†Ô∏è Ignoring failed companies inflates historical returns!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc058706",
   "metadata": {},
   "source": [
    "## 4. Sanity Checks for Backtests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b545240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BacktestSanityChecker:\n",
    "    \"\"\"\n",
    "    Validate backtest results for common issues\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, returns, signals, transaction_costs=0.0010):\n",
    "        self.returns = np.array(returns)\n",
    "        self.signals = np.array(signals)\n",
    "        self.costs = transaction_costs\n",
    "        \n",
    "        # Calculate strategy returns\n",
    "        self.strategy_returns = self.signals * self.returns\n",
    "        turnover = np.abs(np.diff(self.signals, prepend=0))\n",
    "        self.net_returns = self.strategy_returns - turnover * self.costs\n",
    "    \n",
    "    def check_sharpe_ratio(self):\n",
    "        \"\"\"Check if Sharpe is suspiciously high\"\"\"\n",
    "        sharpe = np.mean(self.net_returns) / np.std(self.net_returns) * np.sqrt(252)\n",
    "        \n",
    "        status = \"‚úÖ OK\" if sharpe < 3 else \"‚ö†Ô∏è SUSPICIOUS\"\n",
    "        return {\n",
    "            'check': 'Sharpe Ratio',\n",
    "            'value': f'{sharpe:.2f}',\n",
    "            'threshold': '< 3.0',\n",
    "            'status': status,\n",
    "            'note': 'Sharpe > 3 is rare and may indicate overfitting'\n",
    "        }\n",
    "    \n",
    "    def check_turnover(self):\n",
    "        \"\"\"Check if turnover is realistic\"\"\"\n",
    "        daily_turnover = np.abs(np.diff(self.signals, prepend=0)).mean()\n",
    "        annual_turnover = daily_turnover * 252\n",
    "        \n",
    "        status = \"‚úÖ OK\" if annual_turnover < 50 else \"‚ö†Ô∏è HIGH\"\n",
    "        return {\n",
    "            'check': 'Annual Turnover',\n",
    "            'value': f'{annual_turnover:.0%}',\n",
    "            'threshold': '< 5000%',\n",
    "            'status': status,\n",
    "            'note': 'Very high turnover often destroys profits after costs'\n",
    "        }\n",
    "    \n",
    "    def check_drawdown(self):\n",
    "        \"\"\"Check if drawdown is acceptable\"\"\"\n",
    "        cumulative = (1 + pd.Series(self.net_returns)).cumprod()\n",
    "        running_peak = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_peak) / running_peak\n",
    "        max_dd = drawdown.min()\n",
    "        \n",
    "        annual_return = np.mean(self.net_returns) * 252\n",
    "        calmar = annual_return / abs(max_dd) if max_dd != 0 else 0\n",
    "        \n",
    "        status = \"‚úÖ OK\" if calmar > 0.5 else \"‚ö†Ô∏è POOR\"\n",
    "        return {\n",
    "            'check': 'Risk/Return (Calmar)',\n",
    "            'value': f'{calmar:.2f}',\n",
    "            'threshold': '> 0.5',\n",
    "            'status': status,\n",
    "            'note': 'Low Calmar suggests poor risk-adjusted returns'\n",
    "        }\n",
    "    \n",
    "    def check_consistency(self):\n",
    "        \"\"\"Check if performance is consistent over time\"\"\"\n",
    "        # Split into halves\n",
    "        mid = len(self.net_returns) // 2\n",
    "        sharpe_1 = np.mean(self.net_returns[:mid]) / np.std(self.net_returns[:mid]) * np.sqrt(252)\n",
    "        sharpe_2 = np.mean(self.net_returns[mid:]) / np.std(self.net_returns[mid:]) * np.sqrt(252)\n",
    "        \n",
    "        ratio = sharpe_2 / sharpe_1 if sharpe_1 != 0 else 0\n",
    "        \n",
    "        status = \"‚úÖ OK\" if 0.5 < ratio < 2.0 else \"‚ö†Ô∏è INCONSISTENT\"\n",
    "        return {\n",
    "            'check': 'Time Consistency',\n",
    "            'value': f'{ratio:.2f}',\n",
    "            'threshold': '0.5 - 2.0',\n",
    "            'status': status,\n",
    "            'note': 'Large variation suggests overfitting to specific period'\n",
    "        }\n",
    "    \n",
    "    def run_all_checks(self):\n",
    "        \"\"\"Run all sanity checks\"\"\"\n",
    "        checks = [\n",
    "            self.check_sharpe_ratio(),\n",
    "            self.check_turnover(),\n",
    "            self.check_drawdown(),\n",
    "            self.check_consistency()\n",
    "        ]\n",
    "        return checks\n",
    "\n",
    "# Create a test strategy\n",
    "spy_returns = returns['SPY'].values\n",
    "momentum = pd.Series(spy_returns).rolling(20).mean()\n",
    "signal = np.sign(momentum.values)\n",
    "signal = np.nan_to_num(signal)\n",
    "\n",
    "# Run sanity checks\n",
    "checker = BacktestSanityChecker(spy_returns, signal, transaction_costs=0.0010)\n",
    "results = checker.run_all_checks()\n",
    "\n",
    "print(\"üìä BACKTEST SANITY CHECK REPORT\")\n",
    "print(\"=\" * 70)\n",
    "for check in results:\n",
    "    print(f\"\\n{check['check']}\")\n",
    "    print(f\"   Value: {check['value']} (threshold: {check['threshold']})\")\n",
    "    print(f\"   Status: {check['status']}\")\n",
    "    print(f\"   Note: {check['note']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ab11c9",
   "metadata": {},
   "source": [
    "## 5. Production-Ready Backtest Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a761d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionBacktester:\n",
    "    \"\"\"\n",
    "    Production-ready backtesting framework\n",
    "    \n",
    "    Features:\n",
    "    - Point-in-time data handling\n",
    "    - Transaction costs\n",
    "    - Walk-forward validation\n",
    "    - Comprehensive metrics\n",
    "    - Sanity checks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prices, cost_bps=10, slippage_bps=2):\n",
    "        self.prices = prices\n",
    "        self.returns = prices.pct_change().dropna()\n",
    "        self.cost = (cost_bps + slippage_bps) / 10000\n",
    "        \n",
    "    def generate_signals(self, signal_func, **kwargs):\n",
    "        \"\"\"Generate trading signals using provided function\"\"\"\n",
    "        self.signals = signal_func(self.returns, **kwargs)\n",
    "        return self.signals\n",
    "    \n",
    "    def calculate_returns(self):\n",
    "        \"\"\"Calculate strategy returns with costs\"\"\"\n",
    "        # Gross returns\n",
    "        self.gross_returns = self.signals * self.returns.values\n",
    "        \n",
    "        # Turnover and costs\n",
    "        self.turnover = np.abs(np.diff(self.signals, prepend=0))\n",
    "        self.costs = self.turnover * self.cost\n",
    "        \n",
    "        # Net returns\n",
    "        self.net_returns = self.gross_returns - self.costs\n",
    "        \n",
    "        return self.net_returns\n",
    "    \n",
    "    def calculate_metrics(self):\n",
    "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
    "        net = pd.Series(self.net_returns)\n",
    "        \n",
    "        # Returns\n",
    "        total_return = (1 + net).prod() - 1\n",
    "        n_years = len(net) / 252\n",
    "        annual_return = (1 + total_return) ** (1/n_years) - 1\n",
    "        annual_vol = net.std() * np.sqrt(252)\n",
    "        \n",
    "        # Risk metrics\n",
    "        sharpe = net.mean() / net.std() * np.sqrt(252) if net.std() > 0 else 0\n",
    "        \n",
    "        downside = net[net < 0].std()\n",
    "        sortino = net.mean() / downside * np.sqrt(252) if downside > 0 else 0\n",
    "        \n",
    "        # Drawdown\n",
    "        cumulative = (1 + net).cumprod()\n",
    "        running_peak = cumulative.expanding().max()\n",
    "        drawdown = (cumulative - running_peak) / running_peak\n",
    "        max_dd = drawdown.min()\n",
    "        \n",
    "        calmar = annual_return / abs(max_dd) if max_dd != 0 else 0\n",
    "        \n",
    "        # Trading metrics\n",
    "        win_rate = (net > 0).mean()\n",
    "        avg_turnover = self.turnover.sum() / (len(net) / 252)\n",
    "        total_costs = self.costs.sum()\n",
    "        \n",
    "        self.metrics = {\n",
    "            'Total Return': f'{total_return:.2%}',\n",
    "            'Annual Return': f'{annual_return:.2%}',\n",
    "            'Annual Vol': f'{annual_vol:.2%}',\n",
    "            'Sharpe': f'{sharpe:.2f}',\n",
    "            'Sortino': f'{sortino:.2f}',\n",
    "            'Max Drawdown': f'{max_dd:.2%}',\n",
    "            'Calmar': f'{calmar:.2f}',\n",
    "            'Win Rate': f'{win_rate:.2%}',\n",
    "            'Annual Turnover': f'{avg_turnover:.0%}',\n",
    "            'Total Cost Drag': f'{total_costs:.2%}'\n",
    "        }\n",
    "        \n",
    "        return self.metrics\n",
    "    \n",
    "    def run_sanity_checks(self):\n",
    "        \"\"\"Run all sanity checks\"\"\"\n",
    "        checker = BacktestSanityChecker(self.returns.values, self.signals, self.cost)\n",
    "        return checker.run_all_checks()\n",
    "    \n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive backtest report\"\"\"\n",
    "        print(\"=\" * 70)\n",
    "        print(\"                    BACKTEST REPORT\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        print(\"\\nüìä PERFORMANCE METRICS\")\n",
    "        print(\"-\" * 50)\n",
    "        for metric, value in self.metrics.items():\n",
    "            print(f\"   {metric:<20}: {value}\")\n",
    "        \n",
    "        print(\"\\nüîç SANITY CHECKS\")\n",
    "        print(\"-\" * 50)\n",
    "        checks = self.run_sanity_checks()\n",
    "        for check in checks:\n",
    "            print(f\"   {check['check']:<20}: {check['status']}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# Example usage\n",
    "def momentum_signal(returns, lookback=20):\n",
    "    \"\"\"Simple momentum signal\"\"\"\n",
    "    momentum = pd.Series(returns).rolling(lookback).mean()\n",
    "    signal = np.sign(momentum.values)\n",
    "    return np.nan_to_num(signal)\n",
    "\n",
    "# Run backtest\n",
    "backtester = ProductionBacktester(prices['SPY'], cost_bps=10, slippage_bps=2)\n",
    "backtester.generate_signals(momentum_signal, lookback=20)\n",
    "backtester.calculate_returns()\n",
    "backtester.calculate_metrics()\n",
    "backtester.generate_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43da857",
   "metadata": {},
   "source": [
    "## 6. ‚è±Ô∏è TIMED CODING CHALLENGE (30 minutes)\n",
    "\n",
    "**Challenge:** Extend the `ProductionBacktester` to include:\n",
    "1. Walk-forward validation\n",
    "2. Multiple asset support\n",
    "3. Portfolio-level metrics\n",
    "4. Visualization dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b78090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Extend ProductionBacktester class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd60769",
   "metadata": {},
   "source": [
    "## 7. Interview Question of the Day\n",
    "\n",
    "**Q: What are the key differences between backtesting for research vs production deployment?**\n",
    "\n",
    "Think about:\n",
    "1. Data handling requirements\n",
    "2. Execution assumptions\n",
    "3. Risk monitoring\n",
    "4. Code quality standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3828e7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä RESEARCH vs PRODUCTION BACKTESTING\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "comparison = {\n",
    "    'Aspect': ['Data', 'Execution', 'Costs', 'Validation', 'Code'],\n",
    "    'Research': [\n",
    "        'May use final revisions',\n",
    "        'Assume fill at close',\n",
    "        'Often ignored',\n",
    "        'In-sample OK for exploration',\n",
    "        'Notebooks, quick iteration'\n",
    "    ],\n",
    "    'Production': [\n",
    "        'Point-in-time only',\n",
    "        'VWAP/TWAP, partial fills',\n",
    "        'Conservative estimates',\n",
    "        'Strict walk-forward',\n",
    "        'Tested, version controlled'\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(pd.DataFrame(comparison).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac01a2",
   "metadata": {},
   "source": [
    "## 8. Key Takeaways\n",
    "\n",
    "| Practice | Description |\n",
    "|----------|-------------|\n",
    "| Point-in-Time | Use data as known at decision time |\n",
    "| No Survivorship | Include delisted/failed stocks |\n",
    "| Sanity Checks | Sharpe < 3, consistent over time |\n",
    "| Realistic Costs | Commission + spread + slippage + impact |\n",
    "| Walk-Forward | Never shuffle time series |\n",
    "\n",
    "---\n",
    "\n",
    "**Tomorrow:** Common Pitfalls & Overfitting"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
