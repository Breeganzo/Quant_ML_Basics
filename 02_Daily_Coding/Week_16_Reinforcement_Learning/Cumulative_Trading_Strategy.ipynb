{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63de60a",
   "metadata": {},
   "source": [
    "# Week 16: Cumulative Trading Strategy (Weeks 1-16)\n",
    "\n",
    "## Complete Integration of All Concepts from Foundation to Reinforcement Learning\n",
    "\n",
    "**This notebook demonstrates a production-grade trading system integrating:**\n",
    "\n",
    "| Week | Topic | Implementation |\n",
    "|------|-------|---------------|\n",
    "| 1-2 | Foundation & Statistics | Data loading, statistical analysis, returns calculation |\n",
    "| 3 | Time Series | ARIMA forecasting, stationarity tests |\n",
    "| 4 | ML Basics | Train/test split, cross-validation |\n",
    "| 5 | Portfolio Optimization | Mean-Variance, Sharpe maximization |\n",
    "| 5.1-6 | Linear & Factor Models | OLS, Ridge, Factor scores |\n",
    "| 7 | Volatility Models | GARCH, risk estimation |\n",
    "| 7.1-8 | Trees & Instance-Based | Random Forest, XGBoost, KNN |\n",
    "| 9 | Unsupervised Learning | Regime detection with clustering |\n",
    "| 10 | Time Series Forecasting | ARIMA, Prophet integration |\n",
    "| 11 | Feature Engineering | Advanced features, selection |\n",
    "| 12 | Backtesting | Walk-forward validation |\n",
    "| 13-14 | Neural Networks & RNN | MLP, LSTM for prediction |\n",
    "| 15 | Attention/Transformers | Self-attention for sequences |\n",
    "| 16 | Reinforcement Learning | DQN agent for trading |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b367fa7",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daa50ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Libraries (Week 1-2: Foundation)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data & Statistics (Week 2)\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Machine Learning (Week 4, 5.1, 7.1, 8)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# XGBoost (Week 7.1)\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    HAS_XGB = True\n",
    "except:\n",
    "    HAS_XGB = False\n",
    "    print(\"XGBoost not installed - using GradientBoosting instead\")\n",
    "\n",
    "# Deep Learning (Week 13-15)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "import random\n",
    "\n",
    "# Set seeds\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Constants\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_RATE = 0.05\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"‚úÖ All libraries loaded | Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e10998",
   "metadata": {},
   "source": [
    "## 2. Data Loading (Week 1: Foundation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0429611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Asset Universe\n",
    "tickers = ['SPY', 'QQQ', 'IWM', 'GLD', 'TLT', 'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META']\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "print(\"üì• Downloading market data...\")\n",
    "data = yf.download(tickers, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# Main asset for trading\n",
    "main_ticker = 'SPY'\n",
    "spy_prices = prices[main_ticker]\n",
    "spy_returns = returns[main_ticker]\n",
    "\n",
    "print(f\"‚úÖ Data loaded: {prices.shape[0]} days, {prices.shape[1]} assets\")\n",
    "print(f\"   Date range: {prices.index[0].date()} to {prices.index[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8985c8",
   "metadata": {},
   "source": [
    "## 3. Statistical Analysis (Week 2: Statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e0b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(returns, name='Asset'):\n",
    "    \"\"\"Calculate comprehensive statistics (Week 2).\"\"\"\n",
    "    ann_ret = returns.mean() * TRADING_DAYS\n",
    "    ann_vol = returns.std() * np.sqrt(TRADING_DAYS)\n",
    "    sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol\n",
    "    skew = returns.skew()\n",
    "    kurt = returns.kurtosis()\n",
    "    \n",
    "    # VaR and CVaR\n",
    "    var_95 = np.percentile(returns, 5)\n",
    "    cvar_95 = returns[returns <= var_95].mean()\n",
    "    \n",
    "    # Max Drawdown\n",
    "    cum_ret = (1 + returns).cumprod()\n",
    "    rolling_max = cum_ret.expanding().max()\n",
    "    drawdown = (cum_ret - rolling_max) / rolling_max\n",
    "    max_dd = drawdown.min()\n",
    "    \n",
    "    return {\n",
    "        'Asset': name,\n",
    "        'Ann. Return': ann_ret,\n",
    "        'Ann. Volatility': ann_vol,\n",
    "        'Sharpe Ratio': sharpe,\n",
    "        'Skewness': skew,\n",
    "        'Kurtosis': kurt,\n",
    "        'VaR (95%)': var_95,\n",
    "        'CVaR (95%)': cvar_95,\n",
    "        'Max Drawdown': max_dd\n",
    "    }\n",
    "\n",
    "# Calculate stats for all assets\n",
    "stats_list = [calculate_statistics(returns[t], t) for t in tickers]\n",
    "stats_df = pd.DataFrame(stats_list).set_index('Asset')\n",
    "\n",
    "print(\"\\nüìä ASSET STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "print(stats_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7bab2",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering (Week 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(prices, returns):\n",
    "    \"\"\"Create comprehensive feature set (Week 11: Feature Engineering).\"\"\"\n",
    "    df = pd.DataFrame(index=prices.index)\n",
    "    df['price'] = prices\n",
    "    df['returns'] = returns\n",
    "    \n",
    "    # Momentum Features (Week 3, 11)\n",
    "    for period in [5, 10, 20, 60]:\n",
    "        df[f'momentum_{period}d'] = prices.pct_change(period)\n",
    "        df[f'volatility_{period}d'] = returns.rolling(period).std()\n",
    "    \n",
    "    # Moving Average Ratios\n",
    "    df['sma_5_20'] = prices.rolling(5).mean() / prices.rolling(20).mean() - 1\n",
    "    df['sma_20_50'] = prices.rolling(20).mean() / prices.rolling(50).mean() - 1\n",
    "    \n",
    "    # RSI (Week 11)\n",
    "    delta = prices.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    df['rsi'] = 100 - (100 / (1 + gain / (loss + 1e-8)))\n",
    "    df['rsi_norm'] = (df['rsi'] - 50) / 50\n",
    "    \n",
    "    # MACD\n",
    "    exp12 = prices.ewm(span=12).mean()\n",
    "    exp26 = prices.ewm(span=26).mean()\n",
    "    df['macd'] = exp12 - exp26\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    sma20 = prices.rolling(20).mean()\n",
    "    std20 = prices.rolling(20).std()\n",
    "    df['bb_upper'] = sma20 + 2 * std20\n",
    "    df['bb_lower'] = sma20 - 2 * std20\n",
    "    df['bb_position'] = (prices - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'] + 1e-8)\n",
    "    \n",
    "    # Price Position (Week 11)\n",
    "    df['high_20d'] = prices.rolling(20).max()\n",
    "    df['low_20d'] = prices.rolling(20).min()\n",
    "    df['price_position'] = (prices - df['low_20d']) / (df['high_20d'] - df['low_20d'] + 1e-8)\n",
    "    \n",
    "    # Target: Next day direction\n",
    "    df['target'] = (returns.shift(-1) > 0).astype(int)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Create features\n",
    "df = create_features(spy_prices, spy_returns)\n",
    "print(f\"‚úÖ Features created: {df.shape[1]} columns, {df.shape[0]} samples\")\n",
    "\n",
    "# Feature columns for ML\n",
    "feature_cols = [c for c in df.columns if c not in ['price', 'returns', 'target', 'high_20d', 'low_20d', \n",
    "                                                     'bb_upper', 'bb_lower', 'rsi']]\n",
    "print(f\"   ML Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ddc1a",
   "metadata": {},
   "source": [
    "## 5. Regime Detection (Week 9: Unsupervised Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e7a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_regimes(returns, volatility, n_regimes=3):\n",
    "    \"\"\"Detect market regimes using K-Means (Week 9).\"\"\"\n",
    "    # Prepare features for clustering\n",
    "    X_regime = pd.DataFrame({\n",
    "        'returns': returns,\n",
    "        'volatility': volatility\n",
    "    }).dropna()\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_regime)\n",
    "    \n",
    "    # K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=n_regimes, random_state=SEED, n_init=10)\n",
    "    regimes = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Map to intuitive labels\n",
    "    regime_stats = pd.DataFrame({\n",
    "        'regime': regimes,\n",
    "        'returns': X_regime['returns'].values\n",
    "    })\n",
    "    regime_means = regime_stats.groupby('regime')['returns'].mean()\n",
    "    \n",
    "    # Sort by return: 0=bear, 1=neutral, 2=bull\n",
    "    sorted_regimes = regime_means.sort_values().index.tolist()\n",
    "    regime_map = {old: new for new, old in enumerate(sorted_regimes)}\n",
    "    regimes_mapped = pd.Series([regime_map[r] for r in regimes], index=X_regime.index)\n",
    "    \n",
    "    return regimes_mapped\n",
    "\n",
    "# Detect regimes\n",
    "df['regime'] = detect_regimes(df['returns'], df['volatility_20d'])\n",
    "\n",
    "# Regime statistics\n",
    "print(\"\\nüéØ MARKET REGIMES (Week 9: Unsupervised Learning)\")\n",
    "print(\"=\"*60)\n",
    "regime_labels = {0: 'Bear', 1: 'Neutral', 2: 'Bull'}\n",
    "for r in sorted(df['regime'].unique()):\n",
    "    mask = df['regime'] == r\n",
    "    ret = df.loc[mask, 'returns'].mean() * TRADING_DAYS\n",
    "    vol = df.loc[mask, 'returns'].std() * np.sqrt(TRADING_DAYS)\n",
    "    count = mask.sum()\n",
    "    print(f\"   {regime_labels[r]:<8}: {count:>4} days | Return: {ret:>+7.2%} | Vol: {vol:>6.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2671091c",
   "metadata": {},
   "source": [
    "## 6. ML Models - Ensemble (Week 4, 5.1, 7.1, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79e5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ml_ensemble(X_train, y_train, X_test):\n",
    "    \"\"\"Train ensemble of ML models (Week 4, 5.1, 7.1, 8).\"\"\"\n",
    "    predictions = {}\n",
    "    probabilities = {}\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Model 1: Random Forest (Week 7.1)\n",
    "    rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=SEED)\n",
    "    rf.fit(X_train_scaled, y_train)\n",
    "    predictions['RandomForest'] = rf.predict(X_test_scaled)\n",
    "    probabilities['RandomForest'] = rf.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Model 2: Gradient Boosting or XGBoost (Week 7.1)\n",
    "    if HAS_XGB:\n",
    "        xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, \n",
    "                                       random_state=SEED, verbosity=0)\n",
    "        xgb_model.fit(X_train_scaled, y_train)\n",
    "        predictions['XGBoost'] = xgb_model.predict(X_test_scaled)\n",
    "        probabilities['XGBoost'] = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    else:\n",
    "        gb = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=SEED)\n",
    "        gb.fit(X_train_scaled, y_train)\n",
    "        predictions['GradientBoosting'] = gb.predict(X_test_scaled)\n",
    "        probabilities['GradientBoosting'] = gb.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Model 3: KNN (Week 8)\n",
    "    knn = KNeighborsClassifier(n_neighbors=10)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    predictions['KNN'] = knn.predict(X_test_scaled)\n",
    "    probabilities['KNN'] = knn.predict_proba(X_test_scaled)[:, 1]\n",
    "    \n",
    "    # Ensemble: Average probability\n",
    "    avg_prob = np.mean(list(probabilities.values()), axis=0)\n",
    "    predictions['Ensemble'] = (avg_prob > 0.5).astype(int)\n",
    "    probabilities['Ensemble'] = avg_prob\n",
    "    \n",
    "    return predictions, probabilities, scaler\n",
    "\n",
    "# Walk-forward split (Week 12: Backtesting)\n",
    "train_size = int(len(df) * 0.7)\n",
    "train_df = df.iloc[:train_size]\n",
    "test_df = df.iloc[train_size:]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['target']\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['target']\n",
    "\n",
    "# Train ensemble\n",
    "predictions, probabilities, scaler = train_ml_ensemble(X_train, y_train, X_test)\n",
    "\n",
    "print(\"\\nü§ñ ML ENSEMBLE RESULTS (Week 4, 7.1, 8)\")\n",
    "print(\"=\"*60)\n",
    "for name, preds in predictions.items():\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    print(f\"   {name:<18}: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c120a",
   "metadata": {},
   "source": [
    "## 7. LSTM Model (Week 14: RNN/LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11445f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"LSTM for sequence classification (Week 14).\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dim=64, num_layers=2, dropout=0.2):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, \n",
    "                           batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_out = lstm_out[:, -1, :]  # Take last timestep\n",
    "        out = self.sigmoid(self.fc(last_out))\n",
    "        return out\n",
    "\n",
    "def create_sequences(X, y, seq_length=20):\n",
    "    \"\"\"Create sequences for LSTM.\"\"\"\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(seq_length, len(X)):\n",
    "        X_seq.append(X[i-seq_length:i])\n",
    "        y_seq.append(y[i])\n",
    "    return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "def train_lstm(X_train, y_train, X_test, y_test, epochs=50, seq_length=20):\n",
    "    \"\"\"Train LSTM model.\"\"\"\n",
    "    # Create sequences\n",
    "    X_train_seq, y_train_seq = create_sequences(X_train, y_train, seq_length)\n",
    "    X_test_seq, y_test_seq = create_sequences(X_test, y_test, seq_length)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train_t = torch.FloatTensor(X_train_seq).to(device)\n",
    "    y_train_t = torch.FloatTensor(y_train_seq).unsqueeze(1).to(device)\n",
    "    X_test_t = torch.FloatTensor(X_test_seq).to(device)\n",
    "    \n",
    "    # Model\n",
    "    input_dim = X_train_seq.shape[2]\n",
    "    model = LSTMClassifier(input_dim).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_t)\n",
    "        loss = criterion(outputs, y_train_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        probs = model(X_test_t).cpu().numpy().flatten()\n",
    "    \n",
    "    return probs, y_test_seq\n",
    "\n",
    "# Scale and train LSTM\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lstm_probs, lstm_y_test = train_lstm(X_train_scaled, y_train.values, \n",
    "                                      X_test_scaled, y_test.values, epochs=30)\n",
    "lstm_preds = (lstm_probs > 0.5).astype(int)\n",
    "lstm_acc = accuracy_score(lstm_y_test, lstm_preds)\n",
    "\n",
    "print(f\"\\nüß† LSTM Results (Week 14): Accuracy = {lstm_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c334d70b",
   "metadata": {},
   "source": [
    "## 8. DQN Reinforcement Learning Agent (Week 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0548df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Deep Q-Network (Week 16).\"\"\"\n",
    "    def __init__(self, state_dim, action_dim, hidden_dim=128):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, action_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "class TradingEnvironment:\n",
    "    \"\"\"RL Trading Environment.\"\"\"\n",
    "    def __init__(self, df, feature_cols, initial_balance=100000, transaction_cost=0.001):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.feature_cols = feature_cols\n",
    "        self.initial_balance = initial_balance\n",
    "        self.transaction_cost = transaction_cost\n",
    "        \n",
    "        # Normalize\n",
    "        self.feature_mean = self.df[feature_cols].mean()\n",
    "        self.feature_std = self.df[feature_cols].std() + 1e-8\n",
    "        \n",
    "        self.state_dim = len(feature_cols) + 1  # features + position\n",
    "        self.action_dim = 3  # Hold, Buy, Sell\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.step_idx = 0\n",
    "        self.position = 0  # -1, 0, 1\n",
    "        self.balance = self.initial_balance\n",
    "        self.portfolio_values = [self.initial_balance]\n",
    "        return self._get_state()\n",
    "    \n",
    "    def _get_state(self):\n",
    "        features = self.df[self.feature_cols].iloc[self.step_idx]\n",
    "        normalized = (features - self.feature_mean) / self.feature_std\n",
    "        return np.append(normalized.values, self.position).astype(np.float32)\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Actions: 0=Hold, 1=Buy, 2=Sell\n",
    "        daily_return = self.df['returns'].iloc[self.step_idx]\n",
    "        prev_position = self.position\n",
    "        \n",
    "        # Update position\n",
    "        if action == 1:  # Buy\n",
    "            self.position = 1\n",
    "        elif action == 2:  # Sell\n",
    "            self.position = -1\n",
    "        # else: Hold\n",
    "        \n",
    "        # Calculate reward\n",
    "        position_return = self.position * daily_return\n",
    "        transaction_cost = self.transaction_cost if prev_position != self.position else 0\n",
    "        reward = position_return - transaction_cost\n",
    "        \n",
    "        # Update portfolio\n",
    "        self.balance *= (1 + reward)\n",
    "        self.portfolio_values.append(self.balance)\n",
    "        \n",
    "        # Next step\n",
    "        self.step_idx += 1\n",
    "        done = self.step_idx >= len(self.df) - 1\n",
    "        next_state = self._get_state() if not done else None\n",
    "        \n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "class DQNAgent:\n",
    "    \"\"\"DQN Agent with experience replay.\"\"\"\n",
    "    def __init__(self, state_dim, action_dim, lr=0.001, gamma=0.99, \n",
    "                 epsilon=1.0, epsilon_min=0.01, epsilon_decay=0.995):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_min = epsilon_min\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        \n",
    "        self.model = DQN(state_dim, action_dim).to(device)\n",
    "        self.target_model = DQN(state_dim, action_dim).to(device)\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.memory = deque(maxlen=10000)\n",
    "        \n",
    "    def act(self, state):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            return np.random.randint(self.action_dim)\n",
    "        state_t = torch.FloatTensor(state).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.model(state_t)\n",
    "        return q_values.argmax().item()\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "    def replay(self, batch_size=32):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        \n",
    "        batch = random.sample(self.memory, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        \n",
    "        states = torch.FloatTensor(states).to(device)\n",
    "        actions = torch.LongTensor(actions).to(device)\n",
    "        rewards = torch.FloatTensor(rewards).to(device)\n",
    "        next_states = torch.FloatTensor([s if s is not None else np.zeros(self.state_dim) \n",
    "                                          for s in next_states]).to(device)\n",
    "        dones = torch.FloatTensor(dones).to(device)\n",
    "        \n",
    "        # Q-learning update\n",
    "        current_q = self.model(states).gather(1, actions.unsqueeze(1))\n",
    "        next_q = self.target_model(next_states).max(1)[0].detach()\n",
    "        target_q = rewards + (1 - dones) * self.gamma * next_q\n",
    "        \n",
    "        loss = nn.MSELoss()(current_q.squeeze(), target_q)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        # Decay epsilon\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon * self.epsilon_decay)\n",
    "        \n",
    "    def update_target(self):\n",
    "        self.target_model.load_state_dict(self.model.state_dict())\n",
    "\n",
    "print(\"‚úÖ DQN Agent classes defined (Week 16)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DQN Agent\n",
    "env = TradingEnvironment(train_df, feature_cols)\n",
    "agent = DQNAgent(env.state_dim, env.action_dim)\n",
    "\n",
    "n_episodes = 50\n",
    "episode_rewards = []\n",
    "\n",
    "print(\"üéÆ Training DQN Agent...\")\n",
    "for episode in range(n_episodes):\n",
    "    state = env.reset()\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        agent.replay()\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "    \n",
    "    episode_rewards.append(total_reward)\n",
    "    \n",
    "    if (episode + 1) % 10 == 0:\n",
    "        agent.update_target()\n",
    "        avg_reward = np.mean(episode_rewards[-10:])\n",
    "        print(f\"   Episode {episode+1}/{n_episodes} | Avg Reward: {avg_reward:.4f} | Epsilon: {agent.epsilon:.3f}\")\n",
    "\n",
    "print(\"\\n‚úÖ DQN Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd5c1d8",
   "metadata": {},
   "source": [
    "## 9. Combined Strategy & Backtesting (Week 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05aa92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtest_strategy(df, predictions, name='Strategy'):\n",
    "    \"\"\"Backtest a trading strategy (Week 12).\"\"\"\n",
    "    results = df.copy()\n",
    "    results['signal'] = predictions\n",
    "    \n",
    "    # Convert prediction to position: 1=long, 0=out\n",
    "    results['position'] = results['signal']\n",
    "    \n",
    "    # Strategy returns\n",
    "    results['strategy_return'] = results['position'].shift(1) * results['returns']\n",
    "    results['strategy_cum'] = (1 + results['strategy_return'].fillna(0)).cumprod()\n",
    "    results['buyhold_cum'] = (1 + results['returns']).cumprod()\n",
    "    \n",
    "    # Metrics\n",
    "    strat_returns = results['strategy_return'].dropna()\n",
    "    ann_ret = strat_returns.mean() * TRADING_DAYS\n",
    "    ann_vol = strat_returns.std() * np.sqrt(TRADING_DAYS)\n",
    "    sharpe = (ann_ret - RISK_FREE_RATE) / ann_vol if ann_vol > 0 else 0\n",
    "    \n",
    "    # Max drawdown\n",
    "    cum = results['strategy_cum']\n",
    "    rolling_max = cum.expanding().max()\n",
    "    drawdown = (cum - rolling_max) / rolling_max\n",
    "    max_dd = drawdown.min()\n",
    "    \n",
    "    return {\n",
    "        'Strategy': name,\n",
    "        'Total Return': results['strategy_cum'].iloc[-1] - 1,\n",
    "        'Annual Return': ann_ret,\n",
    "        'Annual Vol': ann_vol,\n",
    "        'Sharpe': sharpe,\n",
    "        'Max DD': max_dd,\n",
    "        'Win Rate': (strat_returns > 0).mean()\n",
    "    }, results\n",
    "\n",
    "# Backtest all strategies\n",
    "backtest_results = []\n",
    "\n",
    "# 1. ML Ensemble\n",
    "metrics, _ = backtest_strategy(test_df, predictions['Ensemble'], 'ML Ensemble')\n",
    "backtest_results.append(metrics)\n",
    "\n",
    "# 2. LSTM (aligned to test set)\n",
    "lstm_aligned = np.zeros(len(test_df))\n",
    "lstm_aligned[20:20+len(lstm_preds)] = lstm_preds\n",
    "metrics, _ = backtest_strategy(test_df, lstm_aligned, 'LSTM')\n",
    "backtest_results.append(metrics)\n",
    "\n",
    "# 3. DQN (run on test set)\n",
    "test_env = TradingEnvironment(test_df, feature_cols)\n",
    "state = test_env.reset()\n",
    "dqn_positions = []\n",
    "agent.epsilon = 0  # No exploration during testing\n",
    "\n",
    "while True:\n",
    "    action = agent.act(state)\n",
    "    dqn_positions.append(1 if action == 1 else (0 if action == 0 else -1))\n",
    "    state, _, done, _ = test_env.step(action)\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "dqn_preds = np.array(dqn_positions + [0])[:len(test_df)]  # Pad to match length\n",
    "dqn_preds = (dqn_preds > 0).astype(int)  # Convert to binary for comparison\n",
    "metrics, _ = backtest_strategy(test_df, dqn_preds, 'DQN Agent')\n",
    "backtest_results.append(metrics)\n",
    "\n",
    "# 4. Buy & Hold\n",
    "bh_preds = np.ones(len(test_df))\n",
    "metrics, bh_results = backtest_strategy(test_df, bh_preds, 'Buy & Hold')\n",
    "backtest_results.append(metrics)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(backtest_results).set_index('Strategy')\n",
    "print(\"\\nüìä BACKTEST RESULTS (Week 12)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.round(4).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430a5bb5",
   "metadata": {},
   "source": [
    "## 10. Portfolio Optimization (Week 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ea2a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_portfolio(returns, method='sharpe'):\n",
    "    \"\"\"Portfolio optimization (Week 5).\"\"\"\n",
    "    n_assets = returns.shape[1]\n",
    "    mean_returns = returns.mean() * TRADING_DAYS\n",
    "    cov_matrix = returns.cov() * TRADING_DAYS\n",
    "    \n",
    "    def portfolio_stats(weights):\n",
    "        port_return = np.dot(weights, mean_returns)\n",
    "        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        return port_return, port_vol\n",
    "    \n",
    "    def neg_sharpe(weights):\n",
    "        ret, vol = portfolio_stats(weights)\n",
    "        return -(ret - RISK_FREE_RATE) / vol\n",
    "    \n",
    "    def portfolio_vol(weights):\n",
    "        return portfolio_stats(weights)[1]\n",
    "    \n",
    "    # Constraints\n",
    "    constraints = [{'type': 'eq', 'fun': lambda x: np.sum(x) - 1}]\n",
    "    bounds = tuple((0, 1) for _ in range(n_assets))\n",
    "    init_weights = np.ones(n_assets) / n_assets\n",
    "    \n",
    "    if method == 'sharpe':\n",
    "        result = minimize(neg_sharpe, init_weights, method='SLSQP', \n",
    "                         bounds=bounds, constraints=constraints)\n",
    "    else:  # min variance\n",
    "        result = minimize(portfolio_vol, init_weights, method='SLSQP', \n",
    "                         bounds=bounds, constraints=constraints)\n",
    "    \n",
    "    return result.x\n",
    "\n",
    "# Optimize portfolio\n",
    "train_returns = returns.loc[:train_df.index[-1]]\n",
    "optimal_weights = optimize_portfolio(train_returns, method='sharpe')\n",
    "\n",
    "print(\"\\nüíº PORTFOLIO OPTIMIZATION (Week 5)\")\n",
    "print(\"=\"*60)\n",
    "print(\"Optimal Weights (Max Sharpe):\")\n",
    "for ticker, weight in zip(tickers, optimal_weights):\n",
    "    if weight > 0.01:\n",
    "        print(f\"   {ticker}: {weight:.1%}\")\n",
    "\n",
    "# Portfolio performance on test set\n",
    "test_returns = returns.loc[test_df.index]\n",
    "port_returns = (test_returns * optimal_weights).sum(axis=1)\n",
    "port_cum = (1 + port_returns).cumprod()\n",
    "\n",
    "port_ann_ret = port_returns.mean() * TRADING_DAYS\n",
    "port_ann_vol = port_returns.std() * np.sqrt(TRADING_DAYS)\n",
    "port_sharpe = (port_ann_ret - RISK_FREE_RATE) / port_ann_vol\n",
    "\n",
    "print(f\"\\nTest Period Performance:\")\n",
    "print(f\"   Return: {port_ann_ret:.2%} | Vol: {port_ann_vol:.2%} | Sharpe: {port_sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e43b2f",
   "metadata": {},
   "source": [
    "## 11. Final Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eb76c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Cumulative Returns\n",
    "ax1 = axes[0, 0]\n",
    "test_df_plot = test_df.copy()\n",
    "test_df_plot['buyhold'] = (1 + test_df_plot['returns']).cumprod()\n",
    "test_df_plot['ensemble'] = (1 + test_df_plot['returns'] * predictions['Ensemble']).cumprod()\n",
    "\n",
    "ax1.plot(test_df_plot.index, test_df_plot['buyhold'], label='Buy & Hold', linewidth=2)\n",
    "ax1.plot(test_df_plot.index, test_df_plot['ensemble'], label='ML Ensemble', linewidth=2)\n",
    "ax1.set_title('Cumulative Returns: ML vs Buy & Hold', fontweight='bold')\n",
    "ax1.set_ylabel('Cumulative Return')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Market Regimes\n",
    "ax2 = axes[0, 1]\n",
    "regime_colors = {0: 'red', 1: 'gray', 2: 'green'}\n",
    "for regime in sorted(df['regime'].unique()):\n",
    "    mask = df['regime'] == regime\n",
    "    ax2.scatter(df.index[mask], df['returns'][mask], \n",
    "               c=regime_colors[regime], alpha=0.5, s=10, label=regime_labels[regime])\n",
    "ax2.axhline(0, color='black', linewidth=0.5)\n",
    "ax2.set_title('Returns by Market Regime (Week 9)', fontweight='bold')\n",
    "ax2.set_ylabel('Daily Return')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Strategy Comparison\n",
    "ax3 = axes[1, 0]\n",
    "strategies = results_df.index.tolist()\n",
    "sharpes = results_df['Sharpe'].values\n",
    "colors = ['green' if s > 0 else 'red' for s in sharpes]\n",
    "bars = ax3.bar(strategies, sharpes, color=colors, edgecolor='black')\n",
    "ax3.axhline(0, color='black', linewidth=0.5)\n",
    "ax3.set_title('Sharpe Ratio by Strategy', fontweight='bold')\n",
    "ax3.set_ylabel('Sharpe Ratio')\n",
    "plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45)\n",
    "ax3.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Feature Importance (from RF)\n",
    "ax4 = axes[1, 1]\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=SEED)\n",
    "rf.fit(scaler.transform(X_train), y_train)\n",
    "importances = pd.Series(rf.feature_importances_, index=feature_cols).sort_values(ascending=True)\n",
    "importances.tail(10).plot(kind='barh', ax=ax4, color='steelblue', edgecolor='black')\n",
    "ax4.set_title('Top 10 Feature Importances (Week 11)', fontweight='bold')\n",
    "ax4.set_xlabel('Importance')\n",
    "ax4.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Cumulative Trading Strategy (Weeks 1-16) Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71feee",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated a **cumulative trading system** integrating:\n",
    "\n",
    "| Component | Week | Implementation |\n",
    "|-----------|------|---------------|\n",
    "| Data Loading | 1 | Multi-asset universe from Yahoo Finance |\n",
    "| Statistics | 2 | Return, risk, VaR, CVaR, drawdown metrics |\n",
    "| Features | 11 | Momentum, volatility, RSI, MACD, BBands |\n",
    "| Regime Detection | 9 | K-Means clustering on returns/volatility |\n",
    "| ML Ensemble | 4, 7.1, 8 | Random Forest, XGBoost, KNN |\n",
    "| Deep Learning | 14 | LSTM for sequence classification |\n",
    "| Reinforcement Learning | 16 | DQN agent for trading decisions |\n",
    "| Portfolio Optimization | 5 | Mean-Variance, Max Sharpe |\n",
    "| Backtesting | 12 | Walk-forward evaluation |\n",
    "\n",
    "---\n",
    "\n",
    "**Key Insights:**\n",
    "- Each technique adds value in different market conditions\n",
    "- Ensemble methods typically outperform individual models\n",
    "- Regime detection helps adapt strategies to market conditions\n",
    "- RL agents can learn complex trading patterns\n",
    "- Portfolio optimization reduces overall risk\n",
    "\n",
    "‚ö†Ô∏è **Disclaimer**: This is for educational purposes only, not financial advice."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
