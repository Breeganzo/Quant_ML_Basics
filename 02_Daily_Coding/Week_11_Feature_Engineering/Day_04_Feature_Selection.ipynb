{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "178999bf",
   "metadata": {},
   "source": [
    "# Day 4: Feature Selection Methods\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "- Filter, wrapper, embedded methods\n",
    "- Recursive Feature Elimination\n",
    "- Importance-based selection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eb0d456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Downloading data...\n",
      "âœ… Data: 1254 days\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_selection import RFE, SelectKBest, f_classif, mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "ticker = 'SPY'\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "print(\"ðŸ“¥ Downloading data...\")\n",
    "data = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "\n",
    "# Handle multi-level columns from yfinance\n",
    "if isinstance(data.columns, pd.MultiIndex):\n",
    "    data.columns = data.columns.get_level_values(0)\n",
    "\n",
    "print(f\"âœ… Data: {len(data)} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2733b2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Total features: 22\n"
     ]
    }
   ],
   "source": [
    "# Create many features (potential overfitting)\n",
    "df = data.copy()\n",
    "close = df['Close']\n",
    "\n",
    "# Returns at various lags\n",
    "for lag in [1, 2, 3, 5, 10, 20, 40, 60]:\n",
    "    df[f'ret_{lag}'] = close.pct_change(lag)\n",
    "\n",
    "# Moving averages\n",
    "for w in [5, 10, 20, 50, 100, 200]:\n",
    "    df[f'sma_{w}'] = close.rolling(w).mean()\n",
    "    df[f'sma_{w}_dist'] = (close - df[f'sma_{w}']) / df[f'sma_{w}']\n",
    "\n",
    "# Volatility\n",
    "for w in [5, 10, 20, 60]:\n",
    "    df[f'vol_{w}'] = df['ret_1'].rolling(w).std()\n",
    "\n",
    "# Volume\n",
    "df['vol_ratio'] = df['Volume'] / df['Volume'].rolling(20).mean()\n",
    "\n",
    "# RSI variations\n",
    "for w in [7, 14, 21]:\n",
    "    delta = close.diff()\n",
    "    gain = delta.where(delta > 0, 0).rolling(w).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(w).mean()\n",
    "    df[f'rsi_{w}'] = 100 - 100 / (1 + gain / loss)\n",
    "\n",
    "# Target\n",
    "df['target'] = np.sign(close.shift(-1) - close)\n",
    "df['target'] = df['target'].map({1: 1, -1: 0, 0: 1})\n",
    "\n",
    "df = df.dropna()\n",
    "feature_cols = [c for c in df.columns if c not in ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'target'] + [f'sma_{w}' for w in [5,10,20,50,100,200]]]\n",
    "\n",
    "print(f\"\\nðŸ“Š Total features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08148ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_size = int(len(df) * 0.8)\n",
    "train = df.iloc[:train_size]\n",
    "test = df.iloc[train_size:]\n",
    "\n",
    "X_train = train[feature_cols]\n",
    "y_train = train['target']\n",
    "X_test = test[feature_cols]\n",
    "y_test = test['target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bb9f064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "METHOD 1: F-SCORE (Filter)\n",
      "============================================================\n",
      "         feature   f_score\n",
      "17        vol_60  6.237606\n",
      "16        vol_20  4.818270\n",
      "14         vol_5  4.468947\n",
      "13  sma_200_dist  3.861844\n",
      "15        vol_10  3.746219\n",
      "21        rsi_21  1.725685\n",
      "2          ret_3  1.000293\n",
      "12  sma_100_dist  0.828660\n",
      "0          ret_1  0.759033\n",
      "7         ret_60  0.564060\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Filter - SelectKBest with F-score\n",
    "selector_f = SelectKBest(f_classif, k=10)\n",
    "selector_f.fit(X_train_scaled, y_train)\n",
    "\n",
    "f_scores = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'f_score': selector_f.scores_\n",
    "}).sort_values('f_score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METHOD 1: F-SCORE (Filter)\")\n",
    "print(\"=\"*60)\n",
    "print(f_scores.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0a4f5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "METHOD 2: MUTUAL INFORMATION (Filter)\n",
      "============================================================\n",
      "         feature  mi_score\n",
      "15        vol_10  0.038710\n",
      "1          ret_2  0.030402\n",
      "5         ret_20  0.028798\n",
      "6         ret_40  0.022774\n",
      "18     vol_ratio  0.017205\n",
      "19         rsi_7  0.014355\n",
      "11   sma_50_dist  0.012155\n",
      "12  sma_100_dist  0.011718\n",
      "17        vol_60  0.010504\n",
      "20        rsi_14  0.009474\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Mutual Information\n",
    "mi_scores = mutual_info_classif(X_train_scaled, y_train, random_state=42)\n",
    "mi_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'mi_score': mi_scores\n",
    "}).sort_values('mi_score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METHOD 2: MUTUAL INFORMATION (Filter)\")\n",
    "print(\"=\"*60)\n",
    "print(mi_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b84584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "METHOD 3: RFE (Wrapper)\n",
      "============================================================\n",
      "Selected features: ['ret_1', 'ret_2', 'ret_3', 'ret_20', 'sma_20_dist', 'sma_50_dist', 'vol_5', 'vol_60', 'rsi_14', 'rsi_21']\n"
     ]
    }
   ],
   "source": [
    "# Method 3: RFE (Wrapper)\n",
    "base_model = RandomForestClassifier(n_estimators=50, max_depth=3, random_state=42)\n",
    "rfe = RFE(base_model, n_features_to_select=10, step=5)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "\n",
    "rfe_selected = [f for f, s in zip(feature_cols, rfe.support_) if s]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METHOD 3: RFE (Wrapper)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Selected features: {rfe_selected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74b27224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "METHOD 4: RF IMPORTANCE (Embedded)\n",
      "============================================================\n",
      "         feature  importance\n",
      "5         ret_20    0.062828\n",
      "21        rsi_21    0.058400\n",
      "11   sma_50_dist    0.055252\n",
      "14         vol_5    0.052836\n",
      "4         ret_10    0.052026\n",
      "2          ret_3    0.049790\n",
      "10   sma_20_dist    0.048202\n",
      "8     sma_5_dist    0.046454\n",
      "12  sma_100_dist    0.045545\n",
      "9    sma_10_dist    0.045344\n"
     ]
    }
   ],
   "source": [
    "# Method 4: Feature Importance (Embedded)\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"METHOD 4: RF IMPORTANCE (Embedded)\")\n",
    "print(\"=\"*60)\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffc4055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL COMPARISON\n",
      "============================================================\n",
      "\n",
      "All 22 features: 50.7%\n",
      "Top 10 features: 51.2%\n"
     ]
    }
   ],
   "source": [
    "# Compare all vs selected features\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# All features\n",
    "rf_all = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_all.fit(X_train_scaled, y_train)\n",
    "acc_all = accuracy_score(y_test, rf_all.predict(X_test_scaled))\n",
    "\n",
    "# Top 10 by importance\n",
    "top_features = importance_df['feature'].head(10).tolist()\n",
    "X_train_top = train[top_features]\n",
    "X_test_top = test[top_features]\n",
    "\n",
    "scaler_top = StandardScaler()\n",
    "X_train_top_scaled = scaler_top.fit_transform(X_train_top)\n",
    "X_test_top_scaled = scaler_top.transform(X_test_top)\n",
    "\n",
    "rf_top = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf_top.fit(X_train_top_scaled, y_train)\n",
    "acc_top = accuracy_score(y_test, rf_top.predict(X_test_top_scaled))\n",
    "\n",
    "print(f\"\\nAll {len(feature_cols)} features: {acc_all:.1%}\")\n",
    "print(f\"Top 10 features: {acc_top:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3ecca8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ðŸ“Š SIGNAL WITH SELECTED FEATURES\n",
      "============================================================\n",
      "\n",
      "Date: 2026-01-20\n",
      "\n",
      "Top 10 Features Used:\n",
      "  ret_20: 0.0046\n",
      "  rsi_21: 55.9463\n",
      "  sma_50_dist: -0.0034\n",
      "  vol_5: 0.0090\n",
      "  ret_10: -0.0147\n",
      "  ret_3: -0.0185\n",
      "  sma_20_dist: -0.0157\n",
      "  sma_5_dist: -0.0167\n",
      "  sma_100_dist: 0.0101\n",
      "  sma_10_dist: -0.0188\n",
      "\n",
      "ðŸŽ¯ Signal: ðŸ“ˆ BULLISH\n",
      "   Confidence: 51.7%\n"
     ]
    }
   ],
   "source": [
    "# Today's prediction with selected features\n",
    "latest = df[top_features].iloc[[-1]]\n",
    "latest_scaled = scaler_top.transform(latest)\n",
    "pred = rf_top.predict(latest_scaled)[0]\n",
    "prob = rf_top.predict_proba(latest_scaled)[0]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(f\"ðŸ“Š SIGNAL WITH SELECTED FEATURES\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nDate: {df.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"\\nTop 10 Features Used:\")\n",
    "for f in top_features:\n",
    "    print(f\"  {f}: {df[f].iloc[-1]:.4f}\")\n",
    "print(f\"\\nðŸŽ¯ Signal: {'ðŸ“ˆ BULLISH' if pred == 1 else 'ðŸ“‰ BEARISH'}\")\n",
    "print(f\"   Confidence: {max(prob):.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea5a62f",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸ“… Tomorrow: Feature Transformations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
