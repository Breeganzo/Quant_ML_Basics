{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e6df8d",
   "metadata": {},
   "source": [
    "# Week 9: Unsupervised Learning - PCA, Clustering, Anomaly Detection\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ What You'll Learn This Week\n",
    "\n",
    "Unsupervised learning discovers hidden patterns without labeled data. In finance, it's crucial for regime detection, factor discovery, and anomaly identification.\n",
    "\n",
    "**Key Concepts:**\n",
    "- PCA for dimensionality reduction and factor discovery\n",
    "- K-Means clustering for market regime identification\n",
    "- Hierarchical clustering for asset grouping\n",
    "- Anomaly detection for unusual market conditions\n",
    "\n",
    "**Why This Matters:**\n",
    "Markets don't come with \"regime\" labels. Unsupervised methods help us discover structure in data and identify unusual conditions for risk management.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. Principal Component Analysis (PCA)\n",
    "2. K-Means Clustering\n",
    "3. Hierarchical Clustering\n",
    "4. Anomaly Detection\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c031d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports and data loading\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Standard 5 equities + additional for clustering\n",
    "TICKERS = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META', 'JPM', 'GS', 'BAC', 'XOM', 'CVX', 'SPY']\n",
    "\n",
    "# Fetch 5 years of data\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=5*365)\n",
    "\n",
    "print(\"ðŸ“¥ Downloading market data...\")\n",
    "data = yf.download(TICKERS, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "print(f\"âœ… Loaded {len(prices)} days of data for {len(TICKERS)} tickers\")\n",
    "print(f\"ðŸ“… Date range: {prices.index[0].strftime('%Y-%m-%d')} to {prices.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(returns.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6010a41",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Principal Component Analysis (PCA)\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "PCA finds the main \"directions\" of variation in your data. Instead of looking at 50 correlated stock returns, you can look at 3-5 uncorrelated \"principal components\" that explain most of the variance.\n",
    "\n",
    "**The Algorithm:**\n",
    "1. Center data: $\\tilde{X} = X - \\bar{X}$\n",
    "2. Compute covariance matrix\n",
    "3. Find eigenvectors (directions) and eigenvalues (importance)\n",
    "4. Project data onto top k eigenvectors\n",
    "\n",
    "### Finance Application: Statistical Factors\n",
    "- PC1 usually â‰ˆ Market factor (all stocks move together)\n",
    "- PC2-3 often â‰ˆ Sector or style factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bf4aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to stock returns\n",
    "scaler = StandardScaler()\n",
    "returns_scaled = scaler.fit_transform(returns)\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(returns_scaled)\n",
    "\n",
    "# Explained variance\n",
    "exp_var = pca.explained_variance_ratio_\n",
    "cum_var = np.cumsum(exp_var)\n",
    "\n",
    "print(\"PCA Results - Stock Return Factors\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nVariance explained by top components:\")\n",
    "for i in range(min(5, len(exp_var))):\n",
    "    print(f\"  PC{i+1}: {exp_var[i]:.1%} (cumulative: {cum_var[i]:.1%})\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Scree plot\n",
    "axes[0].bar(range(1, len(exp_var)+1), exp_var, alpha=0.8)\n",
    "axes[0].set_xlabel('Principal Component')\n",
    "axes[0].set_ylabel('Variance Explained')\n",
    "axes[0].set_title('Scree Plot')\n",
    "\n",
    "# Cumulative variance\n",
    "axes[1].plot(range(1, len(cum_var)+1), cum_var, 'bo-')\n",
    "axes[1].axhline(y=0.9, color='r', linestyle='--', label='90% threshold')\n",
    "axes[1].axhline(y=0.95, color='orange', linestyle='--', label='95% threshold')\n",
    "axes[1].set_xlabel('Number of Components')\n",
    "axes[1].set_ylabel('Cumulative Variance')\n",
    "axes[1].set_title('Cumulative Explained Variance')\n",
    "axes[1].legend()\n",
    "\n",
    "# PC1 loadings (factor exposures)\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_[:3].T,\n",
    "    index=returns.columns,\n",
    "    columns=['PC1', 'PC2', 'PC3']\n",
    ")\n",
    "loadings['PC1'].plot(kind='bar', ax=axes[2], color='steelblue')\n",
    "axes[2].set_xlabel('Stock')\n",
    "axes[2].set_ylabel('Loading')\n",
    "axes[2].set_title('PC1 Loadings (Market Factor)')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nðŸ“Š Number of components for 90% variance: {np.argmax(cum_var >= 0.90) + 1}\")\n",
    "print(f\"ðŸ“Š Number of components for 95% variance: {np.argmax(cum_var >= 0.95) + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38bd1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze PC loadings for interpretation\n",
    "print(\"Factor Interpretation - Top 3 PCs\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "loadings = pd.DataFrame(\n",
    "    pca.components_[:3].T,\n",
    "    index=returns.columns,\n",
    "    columns=['PC1_Market', 'PC2', 'PC3']\n",
    ")\n",
    "\n",
    "print(\"\\nPC1 (Market Factor) - All positive = market beta:\")\n",
    "print(loadings['PC1_Market'].sort_values(ascending=False).round(3))\n",
    "\n",
    "print(\"\\nPC2 - Positive vs Negative = Long/Short factor:\")\n",
    "print(loadings['PC2'].sort_values(ascending=False).round(3))\n",
    "\n",
    "# Visualize loadings as a heatmap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "im = ax.imshow(loadings.T, cmap='RdBu_r', aspect='auto', vmin=-0.5, vmax=0.5)\n",
    "ax.set_xticks(range(len(loadings.index)))\n",
    "ax.set_xticklabels(loadings.index, rotation=45, ha='right')\n",
    "ax.set_yticks(range(3))\n",
    "ax.set_yticklabels(['PC1 (Market)', 'PC2', 'PC3'])\n",
    "ax.set_title('PCA Loadings Heatmap')\n",
    "plt.colorbar(im, ax=ax, label='Loading')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10413e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. K-Means Clustering\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "K-Means groups similar data points into k clusters by:\n",
    "1. Initialize k cluster centers\n",
    "2. Assign points to nearest center\n",
    "3. Update centers as mean of cluster\n",
    "4. Repeat until convergence\n",
    "\n",
    "**Objective:**\n",
    "$$\\min_{C} \\sum_{i=1}^{k} \\sum_{x \\in C_i} ||x - \\mu_i||^2$$\n",
    "\n",
    "### Finance Application: Market Regime Detection\n",
    "- Cluster days by volatility, momentum, correlation\n",
    "- Identify bull/bear/sideways regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create market regime features\n",
    "regime_data = pd.DataFrame(index=returns.index)\n",
    "\n",
    "# Volatility (using SPY as market proxy)\n",
    "regime_data['volatility'] = returns['SPY'].rolling(20).std() * np.sqrt(252)\n",
    "\n",
    "# Momentum\n",
    "regime_data['momentum'] = prices['SPY'].pct_change(20)\n",
    "\n",
    "# Average correlation (market stress indicator)\n",
    "corr_matrix = returns.rolling(20).corr()\n",
    "# Get average pairwise correlation\n",
    "avg_corr = []\n",
    "for date in returns.index:\n",
    "    if date in corr_matrix.index.get_level_values(0):\n",
    "        try:\n",
    "            daily_corr = corr_matrix.loc[date]\n",
    "            # Get upper triangle (excluding diagonal)\n",
    "            mask = np.triu(np.ones_like(daily_corr, dtype=bool), k=1)\n",
    "            avg_corr.append(daily_corr.values[mask].mean())\n",
    "        except:\n",
    "            avg_corr.append(np.nan)\n",
    "    else:\n",
    "        avg_corr.append(np.nan)\n",
    "\n",
    "regime_data['avg_correlation'] = avg_corr\n",
    "regime_data = regime_data.dropna()\n",
    "\n",
    "print(f\"Regime features: {len(regime_data)} days\")\n",
    "print(regime_data.describe().round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec8e481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features\n",
    "scaler_regime = StandardScaler()\n",
    "X_regime = scaler_regime.fit_transform(regime_data)\n",
    "\n",
    "# Elbow method to find optimal k\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_regime)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "axes[0].plot(K_range, inertias, 'bo-')\n",
    "axes[0].set_xlabel('Number of Clusters (k)')\n",
    "axes[0].set_ylabel('Inertia (Within-Cluster SS)')\n",
    "axes[0].set_title('Elbow Method for Optimal k')\n",
    "axes[0].axvline(x=4, color='r', linestyle='--', alpha=0.7, label='Suggested k=4')\n",
    "axes[0].legend()\n",
    "\n",
    "# Apply K-Means with k=4\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(X_regime)\n",
    "regime_data['cluster'] = clusters\n",
    "\n",
    "# Visualize clusters\n",
    "scatter = axes[1].scatter(regime_data['volatility'], regime_data['momentum'], \n",
    "                          c=clusters, cmap='viridis', alpha=0.5)\n",
    "axes[1].set_xlabel('Volatility (Annualized)')\n",
    "axes[1].set_ylabel('20-Day Momentum')\n",
    "axes[1].set_title('Market Regime Clusters')\n",
    "plt.colorbar(scatter, ax=axes[1], label='Cluster')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42925b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze clusters (regimes)\n",
    "print(\"Market Regime Analysis\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Name the regimes based on characteristics\n",
    "regime_names = {}\n",
    "cluster_stats = regime_data.groupby('cluster').agg({\n",
    "    'volatility': 'mean',\n",
    "    'momentum': 'mean',\n",
    "    'avg_correlation': 'mean'\n",
    "})\n",
    "\n",
    "# Assign names based on characteristics\n",
    "for cluster in range(4):\n",
    "    vol = cluster_stats.loc[cluster, 'volatility']\n",
    "    mom = cluster_stats.loc[cluster, 'momentum']\n",
    "    \n",
    "    if vol > cluster_stats['volatility'].median():\n",
    "        if mom < 0:\n",
    "            name = \"ðŸ”´ Crisis/High Vol\"\n",
    "        else:\n",
    "            name = \"ðŸŸ  Volatile Rally\"\n",
    "    else:\n",
    "        if mom > 0:\n",
    "            name = \"ðŸŸ¢ Bull Market\"\n",
    "        else:\n",
    "            name = \"ðŸŸ¡ Sideways/Low Vol\"\n",
    "    \n",
    "    regime_names[cluster] = name\n",
    "\n",
    "for cluster in range(4):\n",
    "    mask = regime_data['cluster'] == cluster\n",
    "    print(f\"\\n{regime_names[cluster]} (Cluster {cluster}): {mask.sum()} days ({mask.sum()/len(regime_data)*100:.1f}%)\")\n",
    "    print(f\"  Avg Volatility: {regime_data.loc[mask, 'volatility'].mean():.1%}\")\n",
    "    print(f\"  Avg Momentum: {regime_data.loc[mask, 'momentum'].mean():.2%}\")\n",
    "    print(f\"  Avg Correlation: {regime_data.loc[mask, 'avg_correlation'].mean():.2f}\")\n",
    "\n",
    "# Plot regime timeline\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6), sharex=True)\n",
    "\n",
    "# Regime over time\n",
    "colors = ['green', 'red', 'orange', 'gray']\n",
    "regime_data['regime_color'] = regime_data['cluster'].map({i: colors[i] for i in range(4)})\n",
    "\n",
    "axes[0].scatter(regime_data.index, regime_data['volatility'], \n",
    "               c=regime_data['cluster'], cmap='viridis', alpha=0.5, s=10)\n",
    "axes[0].set_ylabel('Volatility')\n",
    "axes[0].set_title('Market Regimes Over Time')\n",
    "\n",
    "# SPY price with regime coloring\n",
    "spy_aligned = prices['SPY'].loc[regime_data.index]\n",
    "axes[1].plot(spy_aligned.index, spy_aligned.values, 'k-', alpha=0.7)\n",
    "axes[1].set_ylabel('SPY Price')\n",
    "axes[1].set_xlabel('Date')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3b7fa",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Hierarchical Clustering\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "Hierarchical clustering builds a tree of clusters:\n",
    "- **Agglomerative**: Start with each point as cluster, merge upward\n",
    "- **Dendrogram**: Visualizes the hierarchy\n",
    "\n",
    "### Finance Application: Asset Grouping\n",
    "- Find which stocks naturally group together\n",
    "- Build sector-neutral portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579fbaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering on stock returns\n",
    "# Use correlation as distance metric\n",
    "returns_for_clustering = returns.dropna()\n",
    "\n",
    "# Compute correlation matrix and convert to distance\n",
    "corr_matrix = returns_for_clustering.corr()\n",
    "distance_matrix = 1 - corr_matrix  # Convert correlation to distance\n",
    "\n",
    "# Linkage\n",
    "Z = linkage(distance_matrix, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "dendrogram(Z, labels=returns.columns.tolist(), leaf_rotation=45)\n",
    "ax.set_title('Hierarchical Clustering of Stocks (Correlation-Based)')\n",
    "ax.set_ylabel('Distance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Cut dendrogram at k=3 clusters\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "stock_clusters = fcluster(Z, t=3, criterion='maxclust')\n",
    "\n",
    "print(\"\\nStock Clusters:\")\n",
    "print(\"=\"*40)\n",
    "for i, (stock, cluster) in enumerate(zip(returns.columns, stock_clusters)):\n",
    "    print(f\"{stock}: Cluster {cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07364b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze stock clusters\n",
    "cluster_df = pd.DataFrame({\n",
    "    'Stock': returns.columns,\n",
    "    'Cluster': stock_clusters\n",
    "})\n",
    "\n",
    "print(\"\\nCluster Composition:\")\n",
    "print(\"=\"*60)\n",
    "for cluster in sorted(cluster_df['Cluster'].unique()):\n",
    "    stocks_in_cluster = cluster_df[cluster_df['Cluster'] == cluster]['Stock'].tolist()\n",
    "    print(f\"\\nCluster {cluster}: {stocks_in_cluster}\")\n",
    "    \n",
    "    # Calculate average correlation within cluster\n",
    "    if len(stocks_in_cluster) > 1:\n",
    "        cluster_returns = returns[stocks_in_cluster]\n",
    "        cluster_corr = cluster_returns.corr()\n",
    "        mask = np.triu(np.ones_like(cluster_corr, dtype=bool), k=1)\n",
    "        avg_intra_corr = cluster_corr.values[mask].mean()\n",
    "        print(f\"  Average intra-cluster correlation: {avg_intra_corr:.3f}\")\n",
    "\n",
    "# Visualize correlation matrix with cluster ordering\n",
    "cluster_order = cluster_df.sort_values('Cluster')['Stock'].tolist()\n",
    "sorted_corr = corr_matrix.loc[cluster_order, cluster_order]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "im = ax.imshow(sorted_corr, cmap='RdYlGn', vmin=-1, vmax=1)\n",
    "ax.set_xticks(range(len(cluster_order)))\n",
    "ax.set_yticks(range(len(cluster_order)))\n",
    "ax.set_xticklabels(cluster_order, rotation=45, ha='right')\n",
    "ax.set_yticklabels(cluster_order)\n",
    "ax.set_title('Correlation Matrix (Ordered by Cluster)')\n",
    "plt.colorbar(im, ax=ax, label='Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f757f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Anomaly Detection\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "Anomaly detection identifies unusual data points. In finance:\n",
    "- Unusual trading days\n",
    "- Market stress detection\n",
    "- Risk management triggers\n",
    "\n",
    "### Methods:\n",
    "- **Isolation Forest**: Isolates anomalies using random trees\n",
    "- **Z-Score**: Statistical threshold\n",
    "- **DBSCAN**: Points not belonging to any cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c15f9e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“Š Summary & Key Takeaways\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **PCA**: Reduces dimensions, finds statistical factors\n",
    "2. **K-Means**: Groups similar market conditions into regimes\n",
    "3. **Hierarchical Clustering**: Builds tree of asset similarities\n",
    "4. **Anomaly Detection**: Identifies unusual market conditions\n",
    "\n",
    "### Trading Applications:\n",
    "\n",
    "| Method | Use Case |\n",
    "|--------|----------|\n",
    "| PCA | Factor models, risk decomposition |\n",
    "| K-Means | Regime-based trading rules |\n",
    "| Hierarchical | Portfolio construction, sector analysis |\n",
    "| Isolation Forest | Risk management triggers |\n",
    "\n",
    "### Key Insight:\n",
    "- **90% of variance in stock returns explained by ~3-5 factors**\n",
    "- First factor is almost always \"market\" (all stocks move together)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”‘ Interview Questions\n",
    "\n",
    "1. **How many principal components should you keep?**\n",
    "2. **How do you choose k for K-Means?**\n",
    "3. **What makes Isolation Forest good for finance?**\n",
    "4. **How would you use clustering for portfolio construction?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a41cec2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Anomaly Detection\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "Anomaly detection identifies unusual data points. In finance:\n",
    "- Unusual trading days\n",
    "- Market stress detection\n",
    "- Risk management triggers\n",
    "\n",
    "### Methods:\n",
    "- **Isolation Forest**: Isolates anomalies using random trees\n",
    "- **Z-Score**: Statistical threshold\n",
    "- **DBSCAN**: Points not belonging to any cluster"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
