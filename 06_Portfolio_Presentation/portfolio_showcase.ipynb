{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30ee5ac2",
   "metadata": {},
   "source": [
    "# Portfolio Showcase: Quant ML Trading Skills\n",
    "\n",
    "## ðŸ“Š Professional Portfolio Demonstration\n",
    "\n",
    "This notebook demonstrates the core quantitative machine learning skills \n",
    "acquired through the 24-week learning program. Run this to generate \n",
    "portfolio-ready outputs for interviews and presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615030d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio Showcase - Complete Demo\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"QUANTITATIVE ML TRADING PORTFOLIO SHOWCASE\")\n",
    "print(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d35e20",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Data Engineering & Feature Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill 1: Data Engineering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL 1: DATA ENGINEERING & QUALITY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "TICKERS = ['AAPL', 'GOOGL', 'MSFT', 'GS', 'JPM']\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=3*365)\n",
    "\n",
    "# Download data\n",
    "data = yf.download(TICKERS, start=start_date, end=end_date, progress=False, auto_adjust=True)\n",
    "prices = data['Close'].dropna()\n",
    "volumes = data['Volume'].dropna()\n",
    "\n",
    "# Data quality metrics\n",
    "print(f\"\\nðŸ“Š Data Quality Report:\")\n",
    "print(f\"   Date range: {prices.index[0].date()} to {prices.index[-1].date()}\")\n",
    "print(f\"   Trading days: {len(prices)}\")\n",
    "print(f\"   Assets: {list(prices.columns)}\")\n",
    "print(f\"   Missing values: {prices.isna().sum().sum()}\")\n",
    "print(f\"   âœ… Data validation passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e3e4b7",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Statistical Analysis Skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b37541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill 2: Statistical Analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL 2: STATISTICAL ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "returns = prices.pct_change().dropna()\n",
    "\n",
    "# Calculate statistics\n",
    "statistics = pd.DataFrame(index=TICKERS)\n",
    "statistics['Ann. Return'] = returns.mean() * 252\n",
    "statistics['Ann. Volatility'] = returns.std() * np.sqrt(252)\n",
    "statistics['Sharpe Ratio'] = statistics['Ann. Return'] / statistics['Ann. Volatility']\n",
    "statistics['Skewness'] = returns.skew()\n",
    "statistics['Kurtosis'] = returns.kurtosis()\n",
    "\n",
    "# VaR calculation\n",
    "var_95 = returns.quantile(0.05)\n",
    "statistics['VaR (95%)'] = var_95\n",
    "\n",
    "print(\"\\nðŸ“Š Asset Statistics:\")\n",
    "print(statistics.round(3).to_string())\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\nðŸ“Š Correlation Matrix:\")\n",
    "print(returns.corr().round(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa3b847",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f14b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill 3: Feature Engineering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL 3: FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def engineer_features(prices, returns, stock):\n",
    "    \"\"\"Create comprehensive feature set.\"\"\"\n",
    "    df = pd.DataFrame(index=returns.index)\n",
    "    \n",
    "    # Momentum features\n",
    "    df['momentum_5'] = returns[stock].rolling(5).mean().shift(1)\n",
    "    df['momentum_21'] = returns[stock].rolling(21).mean().shift(1)\n",
    "    \n",
    "    # Mean reversion\n",
    "    df['mean_rev'] = (prices[stock] / prices[stock].rolling(20).mean() - 1).shift(1)\n",
    "    \n",
    "    # Volatility\n",
    "    df['volatility'] = returns[stock].rolling(20).std().shift(1)\n",
    "    \n",
    "    # RSI\n",
    "    delta = prices[stock].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    df['rsi'] = (100 - (100 / (1 + rs))).shift(1)\n",
    "    \n",
    "    # Bollinger Band position\n",
    "    bb_middle = prices[stock].rolling(20).mean()\n",
    "    bb_std = prices[stock].rolling(20).std()\n",
    "    df['bb_position'] = ((prices[stock] - bb_middle) / (2 * bb_std)).shift(1)\n",
    "    \n",
    "    # Lagged returns\n",
    "    for lag in [1, 2, 3, 5]:\n",
    "        df[f'ret_lag_{lag}'] = returns[stock].shift(lag)\n",
    "    \n",
    "    # Target\n",
    "    df['target'] = (returns[stock].shift(-1) > 0).astype(int)\n",
    "    \n",
    "    return df.dropna()\n",
    "\n",
    "# Create features for each stock\n",
    "all_features = {}\n",
    "for stock in TICKERS:\n",
    "    all_features[stock] = engineer_features(prices, returns, stock)\n",
    "\n",
    "print(f\"\\nðŸ“Š Features Created:\")\n",
    "sample_df = all_features['AAPL']\n",
    "print(f\"   Total features: {len(sample_df.columns) - 1}\")\n",
    "print(f\"   Feature list: {[c for c in sample_df.columns if c != 'target']}\")\n",
    "print(f\"   Samples per asset: {len(sample_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449f306a",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d286ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill 4: ML Model Training\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL 4: MACHINE LEARNING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def train_models(df, stock):\n",
    "    \"\"\"Train ensemble of ML models.\"\"\"\n",
    "    feature_cols = [c for c in df.columns if c != 'target']\n",
    "    X = df[feature_cols]\n",
    "    y = df['target']\n",
    "    \n",
    "    # Time series split\n",
    "    train_size = int(len(X) * 0.8)\n",
    "    X_train, X_test = X[:train_size], X[train_size:]\n",
    "    y_train, y_test = y[:train_size], y[train_size:]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train models\n",
    "    models = {\n",
    "        'Logistic': LogisticRegression(max_iter=1000),\n",
    "        'RandomForest': RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42),\n",
    "        'GradientBoosting': GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        results[name] = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Ensemble\n",
    "    ensemble_probs = np.mean([m.predict_proba(X_test_scaled)[:, 1] for m in models.values()], axis=0)\n",
    "    ensemble_pred = (ensemble_probs > 0.5).astype(int)\n",
    "    results['Ensemble'] = accuracy_score(y_test, ensemble_pred)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Train for all stocks\n",
    "all_results = {}\n",
    "for stock in TICKERS:\n",
    "    all_results[stock] = train_models(all_features[stock], stock)\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(all_results).T\n",
    "print(\"\\nðŸ“Š Model Accuracy by Stock:\")\n",
    "print(results_df.round(3).to_string())\n",
    "print(f\"\\nðŸ“Š Average Ensemble Accuracy: {results_df['Ensemble'].mean():.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875698c3",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Trading Signal Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee188e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill 5: Signal Generation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL 5: TRADING SIGNAL GENERATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def generate_signal(df, stock, threshold=0.55):\n",
    "    \"\"\"Generate trading signal for next day.\"\"\"\n",
    "    feature_cols = [c for c in df.columns if c != 'target']\n",
    "    X = df[feature_cols]\n",
    "    y = df['target']\n",
    "    \n",
    "    # Train on all available data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "    model.fit(X_scaled[:-1], y[:-1])\n",
    "    \n",
    "    # Predict on latest\n",
    "    prob = model.predict_proba(X_scaled[-1:])[0, 1]\n",
    "    \n",
    "    if prob > threshold:\n",
    "        signal = 'BUY'\n",
    "    elif prob < (1 - threshold):\n",
    "        signal = 'SELL'\n",
    "    else:\n",
    "        signal = 'HOLD'\n",
    "    \n",
    "    return signal, prob\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"NEXT-DAY TRADING SIGNALS - {datetime.now().strftime('%Y-%m-%d')}\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "signals = []\n",
    "for stock in TICKERS:\n",
    "    signal, prob = generate_signal(all_features[stock], stock)\n",
    "    latest_price = prices[stock].iloc[-1]\n",
    "    signals.append({\n",
    "        'Stock': stock,\n",
    "        'Price': f'${latest_price:.2f}',\n",
    "        'Signal': signal,\n",
    "        'Confidence': f'{abs(prob - 0.5) * 200:.1f}%'\n",
    "    })\n",
    "\n",
    "signals_df = pd.DataFrame(signals)\n",
    "print(signals_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30c3480",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Portfolio Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill 6: Portfolio Optimization\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL 6: PORTFOLIO OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def optimize_portfolio(returns, n_portfolios=10000):\n",
    "    \"\"\"Find optimal portfolio weights using Monte Carlo.\"\"\"\n",
    "    n_assets = returns.shape[1]\n",
    "    \n",
    "    # Annualized metrics\n",
    "    mean_returns = returns.mean() * 252\n",
    "    cov_matrix = returns.cov() * 252\n",
    "    \n",
    "    # Monte Carlo simulation\n",
    "    results = np.zeros((n_portfolios, 3))\n",
    "    weights_record = []\n",
    "    \n",
    "    for i in range(n_portfolios):\n",
    "        weights = np.random.random(n_assets)\n",
    "        weights /= np.sum(weights)\n",
    "        \n",
    "        portfolio_return = np.dot(weights, mean_returns)\n",
    "        portfolio_std = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "        \n",
    "        results[i, 0] = portfolio_return\n",
    "        results[i, 1] = portfolio_std\n",
    "        results[i, 2] = portfolio_return / portfolio_std  # Sharpe\n",
    "        weights_record.append(weights)\n",
    "    \n",
    "    # Best Sharpe portfolio\n",
    "    best_idx = np.argmax(results[:, 2])\n",
    "    best_weights = weights_record[best_idx]\n",
    "    \n",
    "    return {\n",
    "        'weights': dict(zip(returns.columns, best_weights)),\n",
    "        'return': results[best_idx, 0],\n",
    "        'volatility': results[best_idx, 1],\n",
    "        'sharpe': results[best_idx, 2]\n",
    "    }\n",
    "\n",
    "optimal = optimize_portfolio(returns)\n",
    "\n",
    "print(f\"\\nðŸ“Š Optimal Portfolio (Maximum Sharpe):\")\n",
    "print(f\"   Expected Return: {optimal['return']:.2%}\")\n",
    "print(f\"   Volatility: {optimal['volatility']:.2%}\")\n",
    "print(f\"   Sharpe Ratio: {optimal['sharpe']:.2f}\")\n",
    "print(f\"\\n   Optimal Weights:\")\n",
    "for stock, weight in optimal['weights'].items():\n",
    "    print(f\"   {stock}: {weight:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1153ac79",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Risk Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26fc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skill 7: Risk Management\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SKILL 7: RISK MANAGEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calculate portfolio returns with optimal weights\n",
    "weights_array = np.array([optimal['weights'][stock] for stock in TICKERS])\n",
    "portfolio_returns = returns @ weights_array\n",
    "\n",
    "# Risk metrics\n",
    "print(f\"\\nðŸ“Š Risk Metrics (Optimal Portfolio):\")\n",
    "\n",
    "# VaR (Value at Risk)\n",
    "var_95 = np.percentile(portfolio_returns, 5)\n",
    "var_99 = np.percentile(portfolio_returns, 1)\n",
    "print(f\"   VaR (95%): {var_95:.2%}\")\n",
    "print(f\"   VaR (99%): {var_99:.2%}\")\n",
    "\n",
    "# CVaR (Conditional VaR)\n",
    "cvar_95 = portfolio_returns[portfolio_returns <= var_95].mean()\n",
    "print(f\"   CVaR (95%): {cvar_95:.2%}\")\n",
    "\n",
    "# Maximum Drawdown\n",
    "cum_returns = (1 + portfolio_returns).cumprod()\n",
    "rolling_max = cum_returns.cummax()\n",
    "drawdown = (cum_returns - rolling_max) / rolling_max\n",
    "max_dd = drawdown.min()\n",
    "print(f\"   Max Drawdown: {max_dd:.2%}\")\n",
    "\n",
    "# Sortino Ratio\n",
    "downside_returns = portfolio_returns[portfolio_returns < 0]\n",
    "downside_std = downside_returns.std() * np.sqrt(252)\n",
    "sortino = (portfolio_returns.mean() * 252) / downside_std\n",
    "print(f\"   Sortino Ratio: {sortino:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fe05bb",
   "metadata": {},
   "source": [
    "## ðŸ“Š Portfolio Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dce397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Cumulative Returns\n",
    "ax1 = axes[0, 0]\n",
    "normalized = prices / prices.iloc[0] * 100\n",
    "for stock in TICKERS:\n",
    "    ax1.plot(normalized.index, normalized[stock], label=stock, linewidth=1.5)\n",
    "ax1.set_title('Cumulative Returns (Base 100)', fontweight='bold')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_ylabel('Value')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Correlation Heatmap\n",
    "ax2 = axes[0, 1]\n",
    "corr = returns.corr()\n",
    "im = ax2.imshow(corr, cmap='RdYlBu_r', vmin=-1, vmax=1)\n",
    "ax2.set_xticks(range(len(TICKERS)))\n",
    "ax2.set_yticks(range(len(TICKERS)))\n",
    "ax2.set_xticklabels(TICKERS)\n",
    "ax2.set_yticklabels(TICKERS)\n",
    "ax2.set_title('Correlation Matrix', fontweight='bold')\n",
    "for i in range(len(TICKERS)):\n",
    "    for j in range(len(TICKERS)):\n",
    "        ax2.text(j, i, f'{corr.iloc[i, j]:.2f}', ha='center', va='center')\n",
    "plt.colorbar(im, ax=ax2)\n",
    "\n",
    "# 3. Model Accuracy\n",
    "ax3 = axes[1, 0]\n",
    "ensemble_acc = [all_results[stock]['Ensemble'] for stock in TICKERS]\n",
    "bars = ax3.bar(TICKERS, ensemble_acc, color='steelblue', edgecolor='black')\n",
    "ax3.axhline(0.5, color='red', linestyle='--', label='Random (50%)')\n",
    "ax3.set_title('Ensemble Model Accuracy by Stock', fontweight='bold')\n",
    "ax3.set_ylabel('Accuracy')\n",
    "ax3.set_ylim(0.45, 0.60)\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Portfolio Weights\n",
    "ax4 = axes[1, 1]\n",
    "weights = [optimal['weights'][stock] * 100 for stock in TICKERS]\n",
    "ax4.pie(weights, labels=TICKERS, autopct='%1.1f%%', startangle=90, colors=plt.cm.Paired.colors)\n",
    "ax4.set_title('Optimal Portfolio Weights', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('portfolio_showcase.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… Portfolio visualization saved as 'portfolio_showcase.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7fc44e",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Skills Summary\n",
    "\n",
    "| Skill Area | Demonstrated |\n",
    "|------------|-------------|\n",
    "| Data Engineering | âœ… API data download, quality checks |\n",
    "| Statistical Analysis | âœ… Returns, volatility, VaR, correlations |\n",
    "| Feature Engineering | âœ… Technical indicators, momentum, mean reversion |\n",
    "| Machine Learning | âœ… Ensemble models, time series CV |\n",
    "| Signal Generation | âœ… Next-day predictions with confidence |\n",
    "| Portfolio Optimization | âœ… Mean-variance, Sharpe maximization |\n",
    "| Risk Management | âœ… VaR, CVaR, drawdown analysis |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
