{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17a2657c",
   "metadata": {},
   "source": [
    "# Week 6: Classification - Logistic Regression, SVM, Meta-Labeling\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this week, you will understand:\n",
    "- **Logistic Regression**: Probability-based classification\n",
    "- **Support Vector Machines (SVM)**: Maximum margin classifiers\n",
    "- **Meta-Labeling**: Marcos Lopez de Prado's approach to bet sizing\n",
    "- **Evaluation Metrics**: Precision, Recall, ROC-AUC\n",
    "\n",
    "---\n",
    "\n",
    "## Why Classification in Finance?\n",
    "\n",
    "Many trading problems are classification tasks:\n",
    "- **Direction prediction**: Will the price go up or down?\n",
    "- **Event detection**: Will there be a volatility spike?\n",
    "- **Trade filtering**: Should we take this signal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76e9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"âœ… Libraries loaded!\")\n",
    "print(\"ðŸ“š Week 6: Classification Theory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de29f4f6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Logistic Regression\n",
    "\n",
    "### The Problem\n",
    "\n",
    "Predict probability that $y = 1$ given features $X$.\n",
    "\n",
    "### The Sigmoid Function\n",
    "\n",
    "$$P(y=1|X) = \\sigma(X\\beta) = \\frac{1}{1 + e^{-X\\beta}}$$\n",
    "\n",
    "### Loss Function (Cross-Entropy)\n",
    "\n",
    "$$L = -\\sum_{i} [y_i \\log(p_i) + (1-y_i) \\log(1-p_i)]$$\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "Logistic regression is like linear regression, but squashed through a sigmoid function to output probabilities (0 to 1). It answers: \"What's the probability of success given these features?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a93320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the sigmoid function\n",
    "x = np.linspace(-6, 6, 100)\n",
    "sigmoid = 1 / (1 + np.exp(-x))\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, sigmoid, 'b-', linewidth=2)\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.5)\n",
    "plt.axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Linear combination (XÎ²)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Create classification data\n",
    "n = 500\n",
    "momentum = np.random.randn(n) * 2\n",
    "volatility = np.random.randn(n) * 2\n",
    "\n",
    "# True probability of positive return\n",
    "linear_comb = 0.5 * momentum - 0.3 * volatility\n",
    "prob = 1 / (1 + np.exp(-linear_comb))\n",
    "y = (np.random.random(n) < prob).astype(int)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "colors = ['red' if label == 0 else 'green' for label in y]\n",
    "plt.scatter(momentum, volatility, c=colors, alpha=0.5, s=20)\n",
    "plt.xlabel('Momentum Signal')\n",
    "plt.ylabel('Volatility')\n",
    "plt.title('Classification: Up (green) vs Down (red)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3887fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit logistic regression\n",
    "X = np.column_stack([momentum, volatility])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
    "\n",
    "logit = LogisticRegression()\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = logit.predict(X_test)\n",
    "y_prob = logit.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Logistic Regression Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Coefficients: Momentum={logit.coef_[0][0]:.3f}, Volatility={logit.coef_[0][1]:.3f}\")\n",
    "print(f\"Intercept: {logit.intercept_[0]:.3f}\")\n",
    "print(f\"\\nROC-AUC Score: {roc_auc_score(y_test, y_prob):.3f}\")\n",
    "print(f\"\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b9e2d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Support Vector Machines (SVM)\n",
    "\n",
    "### The Idea: Maximum Margin\n",
    "\n",
    "Find the hyperplane that maximizes the margin between classes.\n",
    "\n",
    "$$\\max_{w,b} \\frac{2}{||w||} \\text{ subject to } y_i(w^Tx_i + b) \\geq 1$$\n",
    "\n",
    "### Kernel Trick\n",
    "\n",
    "Map data to higher dimensions where it becomes linearly separable:\n",
    "\n",
    "- **Linear**: $K(x_i, x_j) = x_i^T x_j$\n",
    "- **RBF**: $K(x_i, x_j) = \\exp(-\\gamma ||x_i - x_j||^2)$\n",
    "- **Polynomial**: $K(x_i, x_j) = (x_i^T x_j + c)^d$\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "SVM finds the best \"dividing line\" between classes. It's like drawing a line between red and blue points, but making sure the line is as far as possible from both colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0ffed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SVM kernels\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "results = {}\n",
    "\n",
    "print(\"SVM Kernel Comparison\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for kernel in kernels:\n",
    "    svm = SVC(kernel=kernel, probability=True, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_prob = svm.predict_proba(X_test)[:, 1]\n",
    "    auc = roc_auc_score(y_test, y_prob)\n",
    "    results[kernel] = auc\n",
    "    print(f\"{kernel.upper():8} kernel: AUC = {auc:.3f}\")\n",
    "\n",
    "print(f\"\\nâœ… Best kernel: {max(results, key=results.get).upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0406e52",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Meta-Labeling\n",
    "\n",
    "### The Concept (Marcos Lopez de Prado)\n",
    "\n",
    "Instead of predicting direction, predict **whether to take a trade** given a primary signal.\n",
    "\n",
    "### Two-Stage Process\n",
    "\n",
    "1. **Primary Model**: Predicts direction (up/down)\n",
    "2. **Meta Model**: Predicts if primary model's trade will be profitable\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "Think of it as a filter:\n",
    "- Your main model says \"BUY\"\n",
    "- The meta-model asks \"Should we actually buy? Is this a good opportunity?\"\n",
    "\n",
    "### Why Meta-Labeling?\n",
    "\n",
    "- Decouples direction from sizing\n",
    "- Allows confident model to reject uncertain trades\n",
    "- Controls false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bbe4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-Labeling Example\n",
    "np.random.seed(42)\n",
    "\n",
    "n_trades = 1000\n",
    "\n",
    "# Primary signal (e.g., momentum crossover)\n",
    "primary_signal = np.random.choice([1, -1], n_trades)  # Long or Short\n",
    "\n",
    "# Features for meta-model\n",
    "volatility = np.random.exponential(0.02, n_trades)\n",
    "volume = np.random.exponential(1, n_trades)\n",
    "trend_strength = np.random.random(n_trades)\n",
    "\n",
    "# True profitability depends on conditions\n",
    "# Trade is profitable if: low vol + high trend + decent volume\n",
    "profit_prob = 0.3 + 0.3 * (1 - volatility/volatility.max()) + 0.2 * trend_strength + 0.1 * (volume > 0.5)\n",
    "profit_prob = np.clip(profit_prob, 0, 1)\n",
    "is_profitable = (np.random.random(n_trades) < profit_prob).astype(int)\n",
    "\n",
    "# Actual PnL (for visualization)\n",
    "returns = np.where(is_profitable, np.abs(np.random.randn(n_trades) * 0.02),\n",
    "                   -np.abs(np.random.randn(n_trades) * 0.02))\n",
    "\n",
    "# Create meta-model\n",
    "X_meta = np.column_stack([volatility, volume, trend_strength])\n",
    "X_train_m, X_test_m, y_train_m, y_test_m, ret_train, ret_test = train_test_split(\n",
    "    X_meta, is_profitable, returns, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "meta_model.fit(X_train_m, y_train_m)\n",
    "\n",
    "# Predictions\n",
    "meta_prob = meta_model.predict_proba(X_test_m)[:, 1]\n",
    "\n",
    "print(\"Meta-Labeling Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Meta-Model AUC: {roc_auc_score(y_test_m, meta_prob):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19f6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare strategies: Take All Trades vs Meta-Filtered\n",
    "threshold = 0.5\n",
    "take_trade = meta_prob >= threshold\n",
    "\n",
    "pnl_all = ret_test.sum()\n",
    "pnl_filtered = ret_test[take_trade].sum()\n",
    "\n",
    "n_all = len(ret_test)\n",
    "n_filtered = take_trade.sum()\n",
    "\n",
    "print(\"\\nStrategy Comparison\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Take All Trades:\")\n",
    "print(f\"  Trades: {n_all}, Total PnL: {pnl_all:.2%}, Avg PnL: {pnl_all/n_all:.4%}\")\n",
    "print(f\"\\nMeta-Filtered (threshold={threshold}):\")\n",
    "print(f\"  Trades: {n_filtered}, Total PnL: {pnl_filtered:.2%}, Avg PnL: {pnl_filtered/n_filtered:.4%}\")\n",
    "print(f\"\\nâœ… Meta-labeling filtered out {n_all-n_filtered} low-quality trades!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c65485",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Classification Metrics for Finance\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "| Metric | Formula | Finance Meaning |\n",
    "|--------|---------|----------------|\n",
    "| **Precision** | TP/(TP+FP) | % of predicted wins that are actual wins |\n",
    "| **Recall** | TP/(TP+FN) | % of actual wins we captured |\n",
    "| **F1** | 2Ã—(PÃ—R)/(P+R) | Balance of precision and recall |\n",
    "| **ROC-AUC** | Area under ROC | Overall ranking ability |\n",
    "\n",
    "### Finance Consideration\n",
    "\n",
    "**Precision vs Recall Trade-off:**\n",
    "- High precision = Fewer but higher quality trades\n",
    "- High recall = Don't miss opportunities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5d3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision-Recall trade-off\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "print(\"Threshold Analysis\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Threshold':<12} {'Trades':<10} {'Precision':<12} {'Recall':<10} {'PnL/Trade'}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for thresh in thresholds:\n",
    "    take = meta_prob >= thresh\n",
    "    if take.sum() == 0:\n",
    "        continue\n",
    "    precision = y_test_m[take].mean()\n",
    "    recall = y_test_m[take].sum() / y_test_m.sum()\n",
    "    pnl_per_trade = ret_test[take].mean()\n",
    "    print(f\"{thresh:<12.1f} {take.sum():<10} {precision:<12.3f} {recall:<10.3f} {pnl_per_trade:.4%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fb48a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Questions\n",
    "\n",
    "### Conceptual\n",
    "1. When would you use logistic regression over SVM?\n",
    "2. What is the kernel trick and why is it useful?\n",
    "3. Explain meta-labeling and its advantages.\n",
    "\n",
    "### Technical\n",
    "1. Derive the gradient of logistic regression's loss function.\n",
    "2. How do you handle class imbalance in trading (many non-events)?\n",
    "3. What's the difference between hard and soft margin SVM?\n",
    "\n",
    "### Finance-Specific\n",
    "1. Should you optimize for precision or recall in a trading system?\n",
    "2. How would you use classification probabilities for position sizing?\n",
    "3. What features would you include in a meta-labeling model?\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Model | Output | Best For |\n",
    "|-------|--------|----------|\n",
    "| Logistic | Probabilities | Interpretable, bet sizing |\n",
    "| SVM | Decision boundary | Non-linear patterns |\n",
    "| Meta-Label | Trade filter | Quality over quantity |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
