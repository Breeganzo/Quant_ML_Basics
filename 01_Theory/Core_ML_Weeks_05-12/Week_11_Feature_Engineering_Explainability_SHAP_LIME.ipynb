{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6442b701",
   "metadata": {},
   "source": [
    "# Week 11: Feature Engineering & Model Explainability\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this week, you will understand:\n",
    "- **Feature Engineering**: Creating predictive signals\n",
    "- **Feature Selection**: Choosing what matters\n",
    "- **SHAP**: Game-theoretic feature importance\n",
    "- **LIME**: Local interpretable explanations\n",
    "\n",
    "---\n",
    "\n",
    "## Why Feature Engineering?\n",
    "\n",
    "Raw data is rarely predictive. Feature engineering transforms data into signals:\n",
    "- Technical indicators from prices\n",
    "- Rolling statistics\n",
    "- Cross-sectional features\n",
    "- Interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ed24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"‚úÖ Libraries loaded!\")\n",
    "print(\"üìö Week 11: Feature Engineering & Explainability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacd5b0e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Financial Feature Engineering\n",
    "\n",
    "### Common Feature Categories\n",
    "\n",
    "1. **Price-based**: Returns, log returns, momentum\n",
    "2. **Volume-based**: Volume ratios, OBV\n",
    "3. **Volatility**: Rolling std, ATR, Bollinger bands\n",
    "4. **Technical**: RSI, MACD, moving averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9f8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic OHLCV data\n",
    "n = 1000\n",
    "np.random.seed(42)\n",
    "\n",
    "returns = np.random.randn(n) * 0.02\n",
    "close = 100 * np.cumprod(1 + returns)\n",
    "high = close * (1 + np.abs(np.random.randn(n) * 0.01))\n",
    "low = close * (1 - np.abs(np.random.randn(n) * 0.01))\n",
    "open_price = close * (1 + np.random.randn(n) * 0.005)\n",
    "volume = np.random.exponential(1e6, n)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'open': open_price,\n",
    "    'high': high,\n",
    "    'low': low,\n",
    "    'close': close,\n",
    "    'volume': volume\n",
    "})\n",
    "\n",
    "# Create features\n",
    "def create_features(df):\n",
    "    features = pd.DataFrame(index=df.index)\n",
    "    \n",
    "    # Returns\n",
    "    features['return_1d'] = df['close'].pct_change()\n",
    "    features['return_5d'] = df['close'].pct_change(5)\n",
    "    features['return_20d'] = df['close'].pct_change(20)\n",
    "    \n",
    "    # Volatility\n",
    "    features['volatility_20d'] = df['close'].pct_change().rolling(20).std()\n",
    "    features['volatility_5d'] = df['close'].pct_change().rolling(5).std()\n",
    "    \n",
    "    # Volume\n",
    "    features['volume_ratio'] = df['volume'] / df['volume'].rolling(20).mean()\n",
    "    \n",
    "    # Moving Averages\n",
    "    features['ma_ratio_5_20'] = df['close'].rolling(5).mean() / df['close'].rolling(20).mean()\n",
    "    features['ma_ratio_20_50'] = df['close'].rolling(20).mean() / df['close'].rolling(50).mean()\n",
    "    \n",
    "    # RSI\n",
    "    delta = df['close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "    rs = gain / loss\n",
    "    features['rsi'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # Bollinger Band position\n",
    "    ma20 = df['close'].rolling(20).mean()\n",
    "    std20 = df['close'].rolling(20).std()\n",
    "    features['bb_position'] = (df['close'] - ma20) / (2 * std20)\n",
    "    \n",
    "    return features\n",
    "\n",
    "features = create_features(df)\n",
    "print(\"Feature Statistics\")\n",
    "print(\"=\"*60)\n",
    "print(features.describe().round(4).T[['mean', 'std', 'min', 'max']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7d5a9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Feature Selection\n",
    "\n",
    "### Methods\n",
    "\n",
    "1. **Correlation filtering**: Remove highly correlated features\n",
    "2. **Variance threshold**: Remove low-variance features\n",
    "3. **Importance-based**: Use model feature importance\n",
    "4. **Recursive elimination**: Iteratively remove least important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "features['target'] = df['close'].pct_change(5).shift(-5)  # 5-day forward return\n",
    "features_clean = features.dropna()\n",
    "\n",
    "X = features_clean.drop('target', axis=1)\n",
    "y = features_clean['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Correlation matrix\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# Feature importance with Random Forest\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Random Forest)\")\n",
    "print(\"=\"*50)\n",
    "print(importance.to_string(index=False))\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "importance.plot.barh(x='feature', y='importance', ax=axes[0], legend=False)\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].set_title('Feature Importance')\n",
    "\n",
    "im = axes[1].imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "axes[1].set_xticks(range(len(X.columns)))\n",
    "axes[1].set_yticks(range(len(X.columns)))\n",
    "axes[1].set_xticklabels(X.columns, rotation=45, ha='right')\n",
    "axes[1].set_yticklabels(X.columns)\n",
    "axes[1].set_title('Feature Correlation')\n",
    "plt.colorbar(im, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606fb78",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: SHAP - SHapley Additive exPlanations\n",
    "\n",
    "### The Idea\n",
    "\n",
    "SHAP values come from game theory. They measure each feature's contribution to the prediction.\n",
    "\n",
    "### Properties\n",
    "\n",
    "- **Local accuracy**: SHAP values sum to prediction - expected value\n",
    "- **Consistency**: If a feature becomes more important, its SHAP increases\n",
    "- **Missingness**: Missing features contribute zero\n",
    "\n",
    "### ü§î Simple Explanation\n",
    "\n",
    "SHAP asks: \"How much did each feature contribute to moving the prediction away from the average?\" It's like splitting the credit among team members fairly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "    \n",
    "    # Use TreeExplainer for speed\n",
    "    explainer = shap.TreeExplainer(rf)\n",
    "    \n",
    "    # Calculate SHAP values for test set (subset for speed)\n",
    "    X_explain = X_test[:100]\n",
    "    shap_values = explainer.shap_values(X_explain)\n",
    "    \n",
    "    print(\"SHAP Analysis\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Global importance\n",
    "    shap_importance = np.abs(shap_values).mean(axis=0)\n",
    "    for feat, imp in sorted(zip(X.columns, shap_importance), key=lambda x: -x[1]):\n",
    "        print(f\"  {feat}: {imp:.6f}\")\n",
    "    \n",
    "    # Summary plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    shap.summary_plot(shap_values, X_explain, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è SHAP not installed. Install with: pip install shap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e79670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual prediction explanation\n",
    "try:\n",
    "    sample_idx = 50\n",
    "    sample = X_explain.iloc[sample_idx:sample_idx+1]\n",
    "    pred = rf.predict(sample)[0]\n",
    "    \n",
    "    print(f\"\\nSingle Prediction Explanation\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Predicted return: {pred:.4%}\")\n",
    "    print(f\"Actual return: {y_test.iloc[sample_idx]:.4%}\")\n",
    "    print(f\"\\nFeature contributions:\")\n",
    "    \n",
    "    for feat, val, sv in sorted(zip(X.columns, sample.values[0], shap_values[sample_idx]), \n",
    "                                 key=lambda x: -abs(x[2]))[:5]:\n",
    "        direction = \"‚Üë\" if sv > 0 else \"‚Üì\"\n",
    "        print(f\"  {feat}: {val:.4f} ‚Üí {direction} {sv:.6f}\")\n",
    "        \n",
    "except:\n",
    "    print(\"SHAP analysis skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e181b4c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: LIME - Local Interpretable Model-agnostic Explanations\n",
    "\n",
    "### The Idea\n",
    "\n",
    "Fit a simple, interpretable model locally around a prediction.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Generate perturbed samples around the instance\n",
    "2. Get predictions from the complex model\n",
    "3. Weight samples by proximity\n",
    "4. Fit a linear model to explain locally\n",
    "\n",
    "### ü§î Simple Explanation\n",
    "\n",
    "LIME asks: \"Even if the model is complex, can we explain THIS prediction with a simple linear model?\" It zooms in on one prediction and finds a simple explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47e6f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "    \n",
    "    # Create LIME explainer\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train.values,\n",
    "        feature_names=X_train.columns.tolist(),\n",
    "        mode='regression'\n",
    "    )\n",
    "    \n",
    "    # Explain a single prediction\n",
    "    sample_idx = 50\n",
    "    exp = lime_explainer.explain_instance(\n",
    "        X_test.iloc[sample_idx].values,\n",
    "        rf.predict,\n",
    "        num_features=10\n",
    "    )\n",
    "    \n",
    "    print(\"LIME Explanation\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Prediction: {rf.predict(X_test.iloc[sample_idx:sample_idx+1])[0]:.4%}\")\n",
    "    print(f\"\\nLocal Linear Model Coefficients:\")\n",
    "    for feat, coef in exp.as_list()[:5]:\n",
    "        print(f\"  {feat}: {coef:.6f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è LIME not installed. Install with: pip install lime\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50870e5a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Questions\n",
    "\n",
    "### Feature Engineering\n",
    "1. What features would you create for a momentum strategy?\n",
    "2. How do you handle lookahead bias in feature creation?\n",
    "3. When would you use cross-sectional vs. time-series features?\n",
    "\n",
    "### Explainability\n",
    "1. What's the difference between SHAP and LIME?\n",
    "2. Why is model explainability important in finance?\n",
    "3. Can you trust feature importance from Random Forest?\n",
    "\n",
    "### Technical\n",
    "1. How do you handle multicollinearity in feature selection?\n",
    "2. What are the computational costs of SHAP vs. LIME?\n",
    "3. How would you explain model decisions to regulators?\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Topic | Key Point |\n",
    "|-------|----------|\n",
    "| Feature Engineering | Transform raw data into predictive signals |\n",
    "| Feature Selection | Remove redundant, keep important features |\n",
    "| SHAP | Global & local importance, theoretically grounded |\n",
    "| LIME | Model-agnostic, local linear approximation |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
