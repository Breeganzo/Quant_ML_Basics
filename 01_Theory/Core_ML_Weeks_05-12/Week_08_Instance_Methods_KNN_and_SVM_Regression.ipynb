{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a9bb43",
   "metadata": {},
   "source": [
    "# Week 8: Instance-Based Methods - KNN & SVM Regression\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this week, you will understand:\n",
    "- **K-Nearest Neighbors (KNN)**: Non-parametric predictions\n",
    "- **Distance Metrics**: Euclidean, Manhattan, Mahalanobis\n",
    "- **SVM Regression (SVR)**: Epsilon-insensitive loss\n",
    "- **Finance Applications**: Similar historical patterns, regime matching\n",
    "\n",
    "---\n",
    "\n",
    "## Why Instance-Based Methods?\n",
    "\n",
    "Instead of learning explicit parameters, these methods:\n",
    "- Store training data\n",
    "- Make predictions based on similar examples\n",
    "- Capture local structure in data\n",
    "- \"Show me similar market conditions in the past\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159a6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"âœ… Libraries loaded!\")\n",
    "print(\"ðŸ“š Week 8: Instance-Based Methods\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f883b63a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: K-Nearest Neighbors\n",
    "\n",
    "### The Algorithm\n",
    "\n",
    "1. Store all training data\n",
    "2. For new point $x$, find $k$ nearest neighbors\n",
    "3. Prediction = average (regression) or majority vote (classification)\n",
    "\n",
    "$$\\hat{y} = \\frac{1}{k}\\sum_{i \\in N_k(x)} y_i$$\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "KNN is like asking: \"What happened the last 5 times the market looked like this?\" Then average those outcomes for your prediction.\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "- **k**: Number of neighbors (bias-variance tradeoff)\n",
    "- **metric**: Distance function\n",
    "- **weights**: Uniform or distance-weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2e155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate market regime data\n",
    "n = 1000\n",
    "vix = np.random.exponential(20, n)  # VIX-like\n",
    "momentum = np.random.randn(n) * 10  # Momentum score\n",
    "\n",
    "# Returns depend on regime\n",
    "returns = np.where(\n",
    "    vix < 15,\n",
    "    0.001 + 0.0002 * momentum,  # Low vol: momentum works\n",
    "    np.where(\n",
    "        vix > 30,\n",
    "        -0.002 - 0.0001 * vix,  # High vol: negative\n",
    "        0.0001 * momentum  # Medium vol: slight momentum\n",
    "    )\n",
    ") + np.random.randn(n) * 0.01\n",
    "\n",
    "X = np.column_stack([vix, momentum])\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, returns, test_size=0.3, random_state=42)\n",
    "\n",
    "# KNN with different k\n",
    "print(\"KNN: Effect of k\")\n",
    "print(\"=\"*50)\n",
    "for k in [1, 5, 10, 20, 50]:\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=5)\n",
    "    print(f\"k={k:2d}: CV RÂ² = {scores.mean():.4f} Â± {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c08fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize KNN predictions\n",
    "knn = KNeighborsRegressor(n_neighbors=10)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Create grid for visualization\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X_scaled[:, 0].min(), X_scaled[:, 0].max(), 50),\n",
    "    np.linspace(X_scaled[:, 1].min(), X_scaled[:, 1].max(), 50)\n",
    ")\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "predictions = knn.predict(grid).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.contourf(xx, yy, predictions, levels=20, cmap='RdYlGn', alpha=0.8)\n",
    "plt.colorbar(label='Predicted Return')\n",
    "plt.scatter(X_train[:100, 0], X_train[:100, 1], c=y_train[:100], cmap='RdYlGn', edgecolors='k', s=30)\n",
    "plt.xlabel('VIX (scaled)')\n",
    "plt.ylabel('Momentum (scaled)')\n",
    "plt.title('KNN Prediction Surface')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, knn.predict(X_test), alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Return')\n",
    "plt.ylabel('Predicted Return')\n",
    "plt.title(f'KNN Predictions (RÂ² = {knn.score(X_test, y_test):.3f})')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08de569d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Distance Metrics\n",
    "\n",
    "### Common Metrics\n",
    "\n",
    "**Euclidean** (L2): $d(x, y) = \\sqrt{\\sum_i (x_i - y_i)^2}$\n",
    "\n",
    "**Manhattan** (L1): $d(x, y) = \\sum_i |x_i - y_i|$\n",
    "\n",
    "**Mahalanobis**: $d(x, y) = \\sqrt{(x-y)^T \\Sigma^{-1} (x-y)}$\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "- **Euclidean**: Straight-line distance (bird flies)\n",
    "- **Manhattan**: City-block distance (taxi drives)\n",
    "- **Mahalanobis**: Accounts for feature correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e22b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distance metrics\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
    "\n",
    "print(\"Distance Metric Comparison (k=10)\")\n",
    "print(\"=\"*50)\n",
    "for metric in metrics:\n",
    "    knn = KNeighborsRegressor(n_neighbors=10, metric=metric)\n",
    "    knn.fit(X_train, y_train)\n",
    "    score = knn.score(X_test, y_test)\n",
    "    print(f\"{metric:12}: Test RÂ² = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa778d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Support Vector Regression (SVR)\n",
    "\n",
    "### The Idea: Îµ-Insensitive Loss\n",
    "\n",
    "SVR finds a function that:\n",
    "- Deviates at most Îµ from actual targets\n",
    "- Is as flat as possible\n",
    "\n",
    "**Loss Function:**\n",
    "$$L_\\epsilon(y, f(x)) = \\max(0, |y - f(x)| - \\epsilon)$$\n",
    "\n",
    "### ðŸ¤” Simple Explanation\n",
    "\n",
    "SVR creates a \"tube\" around the predictions. Points inside the tube have zero error. Only points outside the tube contribute to the loss.\n",
    "\n",
    "### Key Hyperparameters\n",
    "\n",
    "- **C**: Penalty for points outside tube\n",
    "- **epsilon**: Width of the tube\n",
    "- **kernel**: RBF, linear, polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad7df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVR comparison\n",
    "kernels = ['linear', 'rbf', 'poly']\n",
    "\n",
    "print(\"SVR Kernel Comparison\")\n",
    "print(\"=\"*50)\n",
    "for kernel in kernels:\n",
    "    svr = SVR(kernel=kernel, C=1.0, epsilon=0.001)\n",
    "    svr.fit(X_train, y_train)\n",
    "    score = svr.score(X_test, y_test)\n",
    "    print(f\"{kernel:8} kernel: Test RÂ² = {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1310570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize SVR epsilon tube\n",
    "# 1D example for clarity\n",
    "X_1d = np.sort(np.random.randn(100))[:, np.newaxis]\n",
    "y_1d = np.sin(X_1d.ravel()) + np.random.randn(100) * 0.2\n",
    "\n",
    "svr = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "svr.fit(X_1d, y_1d)\n",
    "\n",
    "X_plot = np.linspace(X_1d.min(), X_1d.max(), 200)[:, np.newaxis]\n",
    "y_pred = svr.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.scatter(X_1d, y_1d, alpha=0.5, label='Data')\n",
    "plt.plot(X_plot, y_pred, 'r-', linewidth=2, label='SVR')\n",
    "plt.fill_between(X_plot.ravel(), y_pred - 0.1, y_pred + 0.1, alpha=0.3, color='red', label='Îµ-tube')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Target')\n",
    "plt.title('SVR with Îµ-Insensitive Tube')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53217bfd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Finance Application - Regime Matching\n",
    "\n",
    "Use KNN to find similar historical market conditions and predict outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5ba55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate historical market data\n",
    "np.random.seed(42)\n",
    "n_days = 2520  # 10 years\n",
    "\n",
    "# Features: VIX, momentum, volume\n",
    "vix_history = 20 + 15 * np.abs(np.random.randn(n_days)) * np.sin(np.linspace(0, 10*np.pi, n_days))\n",
    "vix_history = np.clip(vix_history, 10, 80)\n",
    "momentum_history = pd.Series(np.random.randn(n_days) * 10).rolling(20).mean().fillna(0).values\n",
    "returns_history = np.random.randn(n_days) * 0.01 + 0.0002 - 0.0001 * vix_history / 20\n",
    "\n",
    "# Forward returns (what we want to predict)\n",
    "fwd_returns = pd.Series(returns_history).shift(-5).rolling(5).sum().fillna(0).values\n",
    "\n",
    "X_hist = np.column_stack([vix_history, momentum_history])\n",
    "scaler = StandardScaler()\n",
    "X_hist_scaled = scaler.fit_transform(X_hist)\n",
    "\n",
    "# Train on first 8 years, test on last 2\n",
    "train_size = 2016\n",
    "X_train_h = X_hist_scaled[:train_size]\n",
    "y_train_h = fwd_returns[:train_size]\n",
    "X_test_h = X_hist_scaled[train_size:]\n",
    "y_test_h = fwd_returns[train_size:]\n",
    "\n",
    "# KNN regime matching\n",
    "knn_regime = KNeighborsRegressor(n_neighbors=20, weights='distance')\n",
    "knn_regime.fit(X_train_h, y_train_h)\n",
    "\n",
    "print(\"Regime Matching Results\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Train RÂ²: {knn_regime.score(X_train_h, y_train_h):.3f}\")\n",
    "print(f\"Test RÂ²:  {knn_regime.score(X_test_h, y_test_h):.3f}\")\n",
    "\n",
    "# Example: Current market conditions\n",
    "current_vix = 25\n",
    "current_momentum = 5\n",
    "current = scaler.transform([[current_vix, current_momentum]])\n",
    "\n",
    "# Find similar historical periods\n",
    "distances, indices = knn_regime.kneighbors(current, n_neighbors=5)\n",
    "similar_returns = fwd_returns[indices[0]]\n",
    "\n",
    "print(f\"\\nCurrent conditions: VIX={current_vix}, Momentum={current_momentum}\")\n",
    "print(f\"5-day predicted return: {knn_regime.predict(current)[0]:.4f}\")\n",
    "print(f\"Similar historical 5-day returns: {np.round(similar_returns, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df36328",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Questions\n",
    "\n",
    "### Conceptual\n",
    "1. What are the advantages of KNN over parametric models?\n",
    "2. When would you prefer SVR over linear regression?\n",
    "3. How does the choice of distance metric affect KNN?\n",
    "\n",
    "### Technical\n",
    "1. What is the time complexity of KNN prediction?\n",
    "2. How would you scale KNN to millions of data points?\n",
    "3. Explain the role of epsilon in SVR.\n",
    "\n",
    "### Finance-Specific\n",
    "1. How would you use KNN to identify market regimes?\n",
    "2. What features would you use to find \"similar\" market conditions?\n",
    "3. What are the risks of regime-matching strategies?\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Model | Type | Strengths | Weaknesses |\n",
    "|-------|------|-----------|------------|\n",
    "| KNN | Instance | Simple, local patterns | Slow prediction, curse of dimensionality |\n",
    "| SVR | Kernel | Robust to outliers | Slow training, hyperparameter sensitive |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
