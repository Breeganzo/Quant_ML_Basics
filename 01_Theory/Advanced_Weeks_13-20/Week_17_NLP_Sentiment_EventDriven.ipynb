{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1e5e62",
   "metadata": {},
   "source": [
    "# Week 17: Advanced NLP - Sentiment & Event-Driven Trading\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "\n",
    "By the end of this week, you will understand:\n",
    "- **Text Preprocessing**: Cleaning financial text\n",
    "- **Sentiment Analysis**: VADER, TextBlob, FinBERT\n",
    "- **Event Detection**: News impact analysis\n",
    "- **Trading Signals**: From text to alpha\n",
    "\n",
    "---\n",
    "\n",
    "## Why NLP in Finance?\n",
    "\n",
    "Markets react to information:\n",
    "- Earnings calls\n",
    "- News headlines\n",
    "- Social media\n",
    "- SEC filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a23fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"âœ… Libraries loaded!\")\n",
    "print(\"ðŸ“š Week 17: NLP for Finance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb05fbd4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Text Preprocessing\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. **Cleaning**: Remove HTML, special chars\n",
    "2. **Tokenization**: Split into words\n",
    "3. **Normalization**: Lowercase, stemming\n",
    "4. **Stop words**: Remove common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a2aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Basic text preprocessing\"\"\"\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "# Example headlines\n",
    "headlines = [\n",
    "    \"Apple Reports Record Q4 Earnings, Stock Surges 5%\",\n",
    "    \"Tesla Misses Delivery Targets, Shares Tumble\",\n",
    "    \"Fed Signals Rate Hikes Amid Inflation Concerns\",\n",
    "    \"Microsoft Cloud Revenue Beats Expectations\",\n",
    "    \"Oil Prices Crash on Global Demand Worries\"\n",
    "]\n",
    "\n",
    "print(\"Text Preprocessing Example\")\n",
    "print(\"=\"*50)\n",
    "for h in headlines[:2]:\n",
    "    print(f\"Original: {h}\")\n",
    "    print(f\"Cleaned:  {preprocess_text(h)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a013e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Sentiment Analysis\n",
    "\n",
    "### Rule-Based: VADER\n",
    "\n",
    "- Valence Aware Dictionary and sEntiment Reasoner\n",
    "- Good for short social media text\n",
    "- Returns positive, negative, neutral, compound scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3596850c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "    \n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    print(\"VADER Sentiment Analysis\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for headline in headlines:\n",
    "        scores = analyzer.polarity_scores(headline)\n",
    "        print(f\"\\n{headline}\")\n",
    "        print(f\"  Compound: {scores['compound']:.3f}\")\n",
    "        sentiment = 'Positive' if scores['compound'] > 0.05 else ('Negative' if scores['compound'] < -0.05 else 'Neutral')\n",
    "        print(f\"  Label: {sentiment}\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ VADER not installed. pip install vaderSentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a719f81",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Financial-Specific Sentiment\n",
    "\n",
    "### Loughran-McDonald Dictionary\n",
    "\n",
    "Standard sentiment dictionaries misinterpret financial language:\n",
    "- \"Liability\" = negative in general, neutral in finance\n",
    "- \"Tax\" = neutral in general, negative in finance\n",
    "\n",
    "### FinBERT\n",
    "\n",
    "BERT fine-tuned on financial text:\n",
    "- Understands financial context\n",
    "- State-of-the-art accuracy\n",
    "- Handles complex sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea7b274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loughran-McDonald word lists (simplified)\n",
    "lm_positive = ['profit', 'growth', 'success', 'gain', 'exceed', 'beat', 'strong', 'improve']\n",
    "lm_negative = ['loss', 'decline', 'miss', 'fail', 'weak', 'concern', 'risk', 'crash']\n",
    "\n",
    "def lm_sentiment(text):\n",
    "    \"\"\"Simple L-M sentiment score\"\"\"\n",
    "    words = preprocess_text(text).split()\n",
    "    pos = sum(1 for w in words if w in lm_positive)\n",
    "    neg = sum(1 for w in words if w in lm_negative)\n",
    "    total = pos + neg\n",
    "    if total == 0:\n",
    "        return 0\n",
    "    return (pos - neg) / total\n",
    "\n",
    "print(\"Loughran-McDonald Sentiment\")\n",
    "print(\"=\"*60)\n",
    "for headline in headlines:\n",
    "    score = lm_sentiment(headline)\n",
    "    print(f\"{headline[:50]:50} Score: {score:+.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a713575",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Sentiment Trading Signal\n",
    "\n",
    "### Strategy\n",
    "\n",
    "1. Aggregate daily news sentiment\n",
    "2. Create rolling sentiment score\n",
    "3. Generate trading signal\n",
    "4. Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceed3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate sentiment time series\n",
    "n_days = 500\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sentiment scores (would come from news/social media)\n",
    "sentiment = np.random.randn(n_days) * 0.3 + np.sin(np.linspace(0, 10, n_days)) * 0.2\n",
    "\n",
    "# Simulate stock returns with sentiment correlation\n",
    "noise = np.random.randn(n_days) * 0.02\n",
    "returns = 0.001 * sentiment + noise + 0.0001  # Small positive drift\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'sentiment': sentiment,\n",
    "    'returns': returns\n",
    "})\n",
    "\n",
    "# Rolling sentiment signal\n",
    "df['sentiment_ma'] = df['sentiment'].rolling(5).mean()\n",
    "df['signal'] = np.sign(df['sentiment_ma'])\n",
    "df['strategy_returns'] = df['signal'].shift(1) * df['returns']\n",
    "\n",
    "# Calculate performance\n",
    "df = df.dropna()\n",
    "cum_strat = (1 + df['strategy_returns']).cumprod()\n",
    "cum_bh = (1 + df['returns']).cumprod()\n",
    "\n",
    "print(\"Sentiment Strategy Performance\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Strategy Total Return: {(cum_strat.iloc[-1] - 1):.2%}\")\n",
    "print(f\"Buy & Hold Return: {(cum_bh.iloc[-1] - 1):.2%}\")\n",
    "print(f\"Strategy Sharpe: {df['strategy_returns'].mean() / df['strategy_returns'].std() * np.sqrt(252):.2f}\")\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "axes[0].plot(df['sentiment'], alpha=0.5, label='Daily')\n",
    "axes[0].plot(df['sentiment_ma'], label='5-day MA')\n",
    "axes[0].set_ylabel('Sentiment')\n",
    "axes[0].legend()\n",
    "axes[0].set_title('News Sentiment')\n",
    "\n",
    "axes[1].plot(df['signal'])\n",
    "axes[1].set_ylabel('Position')\n",
    "axes[1].set_title('Trading Signal')\n",
    "\n",
    "axes[2].plot(cum_strat, label='Sentiment Strategy')\n",
    "axes[2].plot(cum_bh, label='Buy & Hold', alpha=0.7)\n",
    "axes[2].set_ylabel('Cumulative Return')\n",
    "axes[2].legend()\n",
    "axes[2].set_title('Strategy Performance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c84e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Interview Questions\n",
    "\n",
    "### Conceptual\n",
    "1. Why do general sentiment dictionaries fail for finance?\n",
    "2. How would you validate a sentiment model?\n",
    "3. What are the latency considerations for news-based trading?\n",
    "\n",
    "### Technical\n",
    "1. How does FinBERT differ from regular BERT?\n",
    "2. How would you handle multiple news sources?\n",
    "3. What features would you extract from earnings calls?\n",
    "\n",
    "### Finance-Specific\n",
    "1. How do you avoid overfitting to historical news?\n",
    "2. What's the typical decay rate of news sentiment alpha?\n",
    "3. How would you combine sentiment with other signals?\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Method | Speed | Accuracy | Use Case |\n",
    "|--------|-------|----------|----------|\n",
    "| VADER | Fast | Moderate | Social media |\n",
    "| L-M | Fast | Financial | SEC filings |\n",
    "| FinBERT | Slow | High | Complex analysis |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
